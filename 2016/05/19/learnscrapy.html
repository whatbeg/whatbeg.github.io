
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>快速入门Scrapy(一)--简书打赏 | Whatbeg&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="whatbeg">
    

    
    <meta name="description" content="Scrapy是什么？Scrapy是一款网络爬虫框架，官方文档的描述如下：

Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬">
<meta property="og:type" content="article">
<meta property="og:title" content="快速入门Scrapy(一)--简书打赏">
<meta property="og:url" content="http://whatbeg.com/2016/05/19/learnscrapy.html">
<meta property="og:site_name" content="Whatbeg's blog">
<meta property="og:description" content="Scrapy是什么？Scrapy是一款网络爬虫框架，官方文档的描述如下：

Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬">
<meta property="og:image" content="http://7xsl28.com1.z0.glb.clouddn.com/scrapy5.png">
<meta property="og:image" content="http://7xsl28.com1.z0.glb.clouddn.com/scrapy1.png">
<meta property="og:image" content="http://7xsl28.com1.z0.glb.clouddn.com/scrapy3.png">
<meta property="og:image" content="http://7xsl28.com1.z0.glb.clouddn.com/scrapy4.png">
<meta property="og:updated_time" content="2016-05-21T07:20:14.476Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="快速入门Scrapy(一)--简书打赏">
<meta name="twitter:description" content="Scrapy是什么？Scrapy是一款网络爬虫框架，官方文档的描述如下：

Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬">
<meta name="twitter:image" content="http://7xsl28.com1.z0.glb.clouddn.com/scrapy5.png">

    
    <link rel="alternative" href="/atom.xml" title="Whatbeg&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/w.ico">
    
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Whatbeg&#39;s blog">Whatbeg&#39;s blog</a></h1>
				<h2 class="blog-motto">当你的才华撑不起你的野心时，就应该静下心来好好学习。</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页(Home)</a></li>
					
						<li><a href="/archives">归档(Archives)</a></li>
					
						<li><a href="/tags">标签(Tags)</a></li>
					
						<li><a href="/categories">分类(Categories)</a></li>
					
						<li><a href="/about">关于(About)</a></li>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/05/19/learnscrapy.html" title="快速入门Scrapy(一)--简书打赏" itemprop="url">快速入门Scrapy(一)--简书打赏</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="whatbeg" target="_blank" itemprop="author">whatbeg</a>
		
  <p class="article-time">
    <time datetime="2016-05-19T08:39:52.000Z" itemprop="datePublished"> 发表于 2016-05-19</time>
    <span id="busuanzi_container_page_pv">
    总阅读<span id="busuanzi_value_page_pv"></span>次
    </span>
  </p>

</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy是什么？"><span class="toc-number">1.</span> <span class="toc-text">Scrapy是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#平台"><span class="toc-number">2.</span> <span class="toc-text">平台</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy安装"><span class="toc-number">3.</span> <span class="toc-text">Scrapy安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-3-5下Scrapy安装"><span class="toc-number">3.1.</span> <span class="toc-text">Python 3.5下Scrapy安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-2-7下Scrapy的安装"><span class="toc-number">3.2.</span> <span class="toc-text">Python 2.7下Scrapy的安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#开始项目"><span class="toc-number">4.</span> <span class="toc-text">开始项目</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#创建Scrapy项目"><span class="toc-number">4.1.</span> <span class="toc-text">创建Scrapy项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#定义items-py"><span class="toc-number">4.2.</span> <span class="toc-text">定义items.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写主爬程序"><span class="toc-number">4.3.</span> <span class="toc-text">编写主爬程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用Item"><span class="toc-number">4.4.</span> <span class="toc-text">使用Item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取打赏描述"><span class="toc-number">4.5.</span> <span class="toc-text">获取打赏描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬取多页"><span class="toc-number">4.6.</span> <span class="toc-text">爬取多页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用Pipeline"><span class="toc-number">4.7.</span> <span class="toc-text">使用Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#合并打赏描述，根据打赏数排序"><span class="toc-number">4.8.</span> <span class="toc-text">合并打赏描述，根据打赏数排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结语"><span class="toc-number">5.</span> <span class="toc-text">结语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-number">6.</span> <span class="toc-text">参考资料</span></a></li></ol>
		
		</div>
		
		<h2 id="Scrapy是什么？"><a href="#Scrapy是什么？" class="headerlink" title="Scrapy是什么？"></a>Scrapy是什么？</h2><p>Scrapy是一款网络爬虫框架，官方文档的描述如下：</p>
<blockquote>
<p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。</p>
</blockquote>
<p>以前写小型爬虫的话还可以自己写，用urllib,BeautifulSoup,Requests什么的就能解决了，后来我发现遇到一个新问题又得重新来一遍这些代码，又得去看前面是怎么写的，而且自己写容易怎么高兴怎么来，代码写的太乱，不好维护，过段时间再来看又要花时间才能看懂。</p>
<p>用框架的好处就是代码结构清晰，代码重用，不用对新的问题又重新来一遍代码，而且功能更强大，能快速解决自己手写代码所不能短时间解决的问题。</p>
<h2 id="平台"><a href="#平台" class="headerlink" title="平台"></a>平台</h2><ul>
<li>Windows 8.1</li>
<li>Python 2.7.10</li>
<li>简书</li>
</ul>
<h2 id="Scrapy安装"><a href="#Scrapy安装" class="headerlink" title="Scrapy安装"></a>Scrapy安装</h2><p>Scrapy完美支持Python 2.x，虽然现在已经慢慢在支持Python 3.x了，但是可能还会遇到不少情况。我刚开始学习Scrapy想用Python 3.5的，都安装好了，但是运行的时候还是有引包错误：<br><figure class="highlight qml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ImportError</span>: cannot <span class="keyword">import</span><span class="string"> module '_win32stdio'</span></span><br></pre></td></tr></table></figure></p>
<p>搜了一些，也没有解决，而且后面可能还会有很多问题，就暂时等一等它们的更新吧，先用回2.7，解决问题再说。<br>（By the way,看到了下面这个）<br><img src="http://7xsl28.com1.z0.glb.clouddn.com/scrapy5.png" alt=""></p>
<p>在Windows,Python 3.x下不能简单的<code>pip install scrapy</code>来一条龙安装scrapy，因为中间会出一些错误。<br>我参考了 <a href="http://www.cnblogs.com/silverbullet11/p/4966608.html" target="_blank" rel="external">【1】</a> 以及 <a href="https://www.webucator.com/blog/2015/03/how-to-install-lxml-for-python-3-on-64-bit-windows/" target="_blank" rel="external">【2】</a>，采用安装wheel文件的方式极其有效。</p>
<h3 id="Python-3-5下Scrapy安装"><a href="#Python-3-5下Scrapy安装" class="headerlink" title="Python 3.5下Scrapy安装"></a>Python 3.5下Scrapy安装</h3><p>1.安装Python，这个不说了<br>2.去<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml" target="_blank" rel="external">http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</a>下载合适你的Python版本的lxml的wheel文件，我下载的是<code>lxml-3.4.4-cp35-none-win32.whl</code>，下载3.6.0版本好像不得行，在我的平台上报错：<br><code>lxml-3.6.0-cp35-cp35m-win32.whl is not a supported wheel on this platform</code>，不支持我的平台。</p>
<p>下载完后，将whl文件拷贝到Python安装目录下，然后cmd进入到你的Python安装目录，运行<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">pip3</span> <span class="selector-tag">install</span> <span class="selector-tag">lxml-3</span><span class="selector-class">.4</span><span class="selector-class">.4-cp35-none-win32</span><span class="selector-class">.whl</span></span><br></pre></td></tr></table></figure></p>
<p>然后运行：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 <span class="keyword">install</span> scrapy</span><br></pre></td></tr></table></figure></p>
<p>在cmd中输入scrapy，如果输出版本信息并没有报错，那么恭喜你，搞定了，是不是很爽！</p>
<h3 id="Python-2-7下Scrapy的安装"><a href="#Python-2-7下Scrapy的安装" class="headerlink" title="Python 2.7下Scrapy的安装"></a>Python 2.7下Scrapy的安装</h3><p>Python2.7下直接<code>pip install scrapy</code>，如果报错，看报错的内容是什么，找出问题出在哪个依赖包上，在网上搜索该包的whl文件（符合版本），直接pip install whl文件 来安装就好了。我是问题处在twisted包上，所以去网上下载了老版本的twisted安装的。</p>
<h2 id="开始项目"><a href="#开始项目" class="headerlink" title="开始项目"></a>开始项目</h2><p>我们将所学的马上利用到实际问题中来。[5]</p>
<blockquote>
<p><strong>爬取简书首页文章的打赏描述和打赏数，以企获得打赏描述对打赏数的影响</strong></p>
</blockquote>
<p>其实打赏数这个东西和文章的质量是最相关的，但是通过大量数据的挖掘统计，是否能将这种相关性弱化一下，从而显露出打赏描述和打赏数的关系呢？这就有趣了，值得研究。而且还可以同时学习框架和做有趣的事，岂不是人生一大乐趣。</p>
<h3 id="创建Scrapy项目"><a href="#创建Scrapy项目" class="headerlink" title="创建Scrapy项目"></a>创建Scrapy项目</h3><p>通过如下语句创建Scrapy项目：<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jia<span class="symbol">nshu2</span></span><br></pre></td></tr></table></figure></p>
<p>然后会生成一个目录jianshu，目录结构如下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jianshu/</span><br><span class="line">    scrapy<span class="selector-class">.cfg</span></span><br><span class="line">    jianshu/</span><br><span class="line">        __init__<span class="selector-class">.py</span></span><br><span class="line">        items<span class="selector-class">.py</span></span><br><span class="line">        pipelines<span class="selector-class">.py</span></span><br><span class="line">        settings<span class="selector-class">.py</span></span><br><span class="line">        spiders/</span><br><span class="line">            __init__.py</span><br></pre></td></tr></table></figure></p>
<ul>
<li>spiders目录存放主爬取代码，是整个项目的核心。需要在spider下自己新建自己的爬取程序。</li>
<li>scrapy.cfg是项目的配置文件。</li>
<li>settings.py是项目的设置文件。</li>
<li>items.py定义我们要爬取的字段信息。</li>
<li>pipelines.py是项目的管道文件。</li>
</ul>
<h3 id="定义items-py"><a href="#定义items-py" class="headerlink" title="定义items.py"></a>定义items.py</h3><p>首先定义我们需要爬取的字段：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Jianshu2Item</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    likeNum = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<h3 id="编写主爬程序"><a href="#编写主爬程序" class="headerlink" title="编写主爬程序"></a>编写主爬程序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">postSpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span></span><br><span class="line">    </span><br><span class="line">    name = <span class="string">'post'</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.jianshu.com'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        articles = response.xpath(<span class="string">'//ul[@class="article-list thumbnails"]/li'</span>)</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> articles:</span><br><span class="line">            url = article.xpath(<span class="string">'div/h4/a/@href'</span>).extract()</span><br><span class="line">            likeNum = article.xpath(<span class="string">'div/div/span[2]/text()'</span>).extract()</span><br><span class="line">            print(url,likeNum)</span><br></pre></td></tr></table></figure>
<p>然后试着运行：<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="built_in">post</span></span><br></pre></td></tr></table></figure></p>
<p>来运行我们的爬虫，中间又报了一次”No module named win32api”错误，直接pip install pypiwin32即可。<br>然后可以看到正确运行了，爬取了20篇文章后，爬虫自动停止，cmd中打印正常。<br>中间用到了XPath来解析HTML，找到元素具体的位置，我们找到首页的HTML的第一篇文章：<br><img src="http://7xsl28.com1.z0.glb.clouddn.com/scrapy1.png" alt="First Post"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">articles = response.xpath(<span class="string">'//ul[@class="article-list thumbnails"]/li'</span>)</span><br></pre></td></tr></table></figure></p>
<p>这句找到所有文章的HTML段，response是我们爬取时服务器返回的HTML。<br>我们看到所有文章都包含在<code>&lt;ul class=&quot;article-list thumbnails&quot;&gt;</code>中，并且以<code>&lt;li class=have-img&gt;</code>开头，所以就不难理解XPath中为什么这么写了。<br>有BeautifulSoup基础的同学应该很好理解XPath了。</p>
<h3 id="使用Item"><a href="#使用Item" class="headerlink" title="使用Item"></a>使用Item</h3><p>我们爬取数据肯定不是为了打印出来看一下就算了，而是想要保存数据，一般来说，Spider爬取到数据之后通过items返回，还记得我们之前定义的items么，这时候就可以派上用场了。<br>写出完整代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> jianshu2.items <span class="keyword">import</span> Jianshu2Item</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">postSpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span></span><br><span class="line">    </span><br><span class="line">    name = <span class="string">'post'</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.jianshu.com'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        articles = response.xpath(<span class="string">'//ul[@class="article-list thumbnails"]/li'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> articles:</span><br><span class="line">            url = article.xpath(<span class="string">'div/h4/a/@href'</span>).extract()</span><br><span class="line">            likeNum = article.xpath(<span class="string">'div/div/span[2]/text()'</span>).extract()</span><br><span class="line">            item = Jianshu2Item()</span><br><span class="line">            item[<span class="string">'url'</span>] = <span class="string">'http://www.jianshu.com/'</span>+url[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> likeNum == []:</span><br><span class="line">                <span class="comment">#print(url,likeNum)</span></span><br><span class="line">                item[<span class="string">'likeNum'</span>] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment">#print(url,int(likeNum[0].split(' ')[-1]))</span></span><br><span class="line">                item[<span class="string">'likeNum'</span>] = int(likeNum[<span class="number">0</span>].split(<span class="string">' '</span>)[<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></p>
<p>执行<code>scrapy crawl post -o items.json</code>就把数据保存到json中了。<br>yield 语句提交item。<br>注意打赏有可能没有，所以span也没有，这里判断一下。</p>
<p>数据如下：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">[</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/6d7bf7d611aa"</span>, <span class="attr">"likeNum"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/e47d86ce78d4"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/e69606806d6c"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/d7159874c59c"</span>, <span class="attr">"likeNum"</span>: <span class="number">2</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/d38e8074ae94"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/6c8a0d0447cd"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/beff4ff80b25"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/d7e626cf02d7"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/524b13db9ce3"</span>, <span class="attr">"likeNum"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/39449bcf9c28"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/970412b3c34d"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/2f98170f6eda"</span>, <span class="attr">"likeNum"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/e91ab8e7a517"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/59a6caf3d965"</span>, <span class="attr">"likeNum"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/ee5432e57dd3"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/00b7662bd335"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/1815b4071362"</span>, <span class="attr">"likeNum"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/b00f7a2f0295"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/7f5fc5a01b75"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">&#123;<span class="attr">"url"</span>: <span class="string">"http://www.jianshu.com//p/84c10f2cf100"</span>, <span class="attr">"likeNum"</span>: <span class="number">0</span>&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>我们想将数据直接存在CSV这样的文件中怎么办呢？方法就是使用<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/feed-exports.html" target="_blank" rel="external">Feed exports</a>，在settings.py文件中添加：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FEED_URI=<span class="string">u'D:\Python27\jianshu2\jianshu2\spiders\data.csv'</span></span><br><span class="line">FEED_FORMAT=<span class="string">'CSV'</span></span><br></pre></td></tr></table></figure></p>
<p>第一次运行<code>scrapy crawl post -o data.csv</code>，然后后面不用加-o data.csv，即可输出到data.csv中。</p>
<h3 id="获取打赏描述"><a href="#获取打赏描述" class="headerlink" title="获取打赏描述"></a>获取打赏描述</h3><p>我们已经获得了url和打赏数，这已经是一个巨大的进步了。<br>然而我们还需要根据这个url再进一步爬到文章里面去，并且我们希望在一个爬虫里面就解决了，不想搞很多爬虫。<br>这时候问题转化为： 如何爬取需要的属性在不同页面的items？<br>这时候我们加一个属性’quote’，这个属性在打开url的页面中。<br>这时候，看到<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#passing-additional-data-to-callback-functions" target="_blank" rel="external">这里</a>，仿照它的写法，通过meta传递item参数，即相当于</p>
<blockquote>
<p>主函数先确定一些参数(‘url’,’likeNum’)，剩下的交给另一个函数去做，然后另一个函数算出’quote’参数后把item还给主函数，主函数整合一下item，然后yield生成就好了。</p>
</blockquote>
<p>部分代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">request = Request(posturl,callback=self.parse_donate)</span><br><span class="line">request.meta[<span class="string">'item'</span>] = item</span><br><span class="line"><span class="keyword">yield</span> request</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_donate</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        donate = response.xpath(<span class="string">'//div[@class="support-author"]/p/text()'</span>).extract()</span><br><span class="line">        item = response.meta[<span class="string">'item'</span>]</span><br><span class="line">        <span class="keyword">if</span> len(str(donate)) == <span class="number">0</span>:</span><br><span class="line">            item[<span class="string">'quote'</span>] = <span class="string">""</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            item[<span class="string">'quote'</span>] = str(donate[<span class="number">0</span>].encode(<span class="string">'utf-8'</span>))</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<h3 id="爬取多页"><a href="#爬取多页" class="headerlink" title="爬取多页"></a>爬取多页</h3><p>这时候我们发现爬的太少了，只有20篇。又看到首页下面有一个【点击查看更多】按钮，我们试着在代码中‘按下’这个按钮，然后获取下面内容的url，递归调用parse即可添加更多的文章。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">next_link = selector.xpath(<span class="string">'//*[@id="list-container"]/div[@class="load-more"]/button/@data-url'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> next_link:</span><br><span class="line">            next_link = self.url + str(next_link)</span><br><span class="line">            <span class="keyword">yield</span> Request(next_link,callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<h3 id="使用Pipeline"><a href="#使用Pipeline" class="headerlink" title="使用Pipeline"></a>使用Pipeline</h3><p>有了item之后，item会被传递给Item Pipeline，我们可以在pipelines.py中对item做一些操作，比如写到json文件中。</p>
<p>Item Pipeline的典型应用如下，更多见中文文档。</p>
<ul>
<li>清洗HTML数据</li>
<li>验证item中的数据</li>
<li>查重或者丢弃</li>
<li>保存结果到文件(json,数据库,csv等）</li>
</ul>
<p>于是我们编写pipelines.py如下，将item数据写入到json文件中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Jianshu2Pipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">	self.file = codecs.open(<span class="string">'items.json'</span>,<span class="string">'wb'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        </span><br><span class="line">        line = json.dumps(dict(item)) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line.decode(<span class="string">"unicode_escape"</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p>不得不用codecs来解决编码问题。Python在Windows下的编码真让人头疼。<br>这时候我们写道json中，其实url都可以去掉了，我们并不关心。<br>效果如下：<br><img src="http://7xsl28.com1.z0.glb.clouddn.com/scrapy3.png" alt="Result"></p>
<h3 id="合并打赏描述，根据打赏数排序"><a href="#合并打赏描述，根据打赏数排序" class="headerlink" title="合并打赏描述，根据打赏数排序"></a>合并打赏描述，根据打赏数排序</h3><p>修改pipelines.py文件，用一个全局的字典dict记录每种语句的打赏数之和，然后根据打赏数排序，写到新的csv文件中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Jianshu2Pipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">	    self.file = codecs.open(<span class="string">'items.json'</span>,<span class="string">'wb'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">	    self.quote = &#123;&#125;</span><br><span class="line">	    self.filecsv = codecs.open(<span class="string">'items.csv'</span>,<span class="string">'w'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        </span><br><span class="line">        line = json.dumps(dict(item)) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line.decode(<span class="string">"unicode_escape"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">'quote'</span>] <span class="keyword">in</span> self.quote.keys():</span><br><span class="line">            self.quote[item[<span class="string">'quote'</span>]] += item[<span class="string">'likeNum'</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.quote[item[<span class="string">'quote'</span>]] = item[<span class="string">'likeNum'</span>]</span><br><span class="line"></span><br><span class="line">        self.filecsv.seek(<span class="number">0</span>)</span><br><span class="line">        lis = sorted(self.quote.items(),key=itemgetter(<span class="number">1</span>),reverse=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(lis)):</span><br><span class="line">            line2 = lis[i][<span class="number">0</span>] + <span class="string">'\t'</span> + str(lis[i][<span class="number">1</span>]) + <span class="string">'\r\n'</span></span><br><span class="line">            self.filecsv.write(line2.decode(<span class="string">"utf-8"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p><img src="http://7xsl28.com1.z0.glb.clouddn.com/scrapy4.png" alt="排序后结果"></p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>由结果可以看出，第一条打赏数最多，不难理解，因为这句是默认的打赏描述，所以使用的基数很大，所以不能说明什么。由于数据量太少，只能爬6页，所以还不是很能说明问题。但是学习scrapy，了解scrapy的目的已经初步达到了，虽然还只是初步学习。但是找出统计上相对能够吸引人打赏的描述的目的还没有达到，需要加大数据量。</p>
<p>由结果还可以看出，其实打赏描述的个性化挺强的，很多都是个人信息。所以呢，还是要大数据。</p>
<p>查看源码点击进入我的Github: <a href="https://github.com/whatbeg/jianshudonate" target="_blank" rel="external">本文源码</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="http://www.cnblogs.com/silverbullet11/p/4966608.html" target="_blank" rel="external">Windows上Python3.5安装Scrapy(lxml)</a><br>[2] <a href="https://www.webucator.com/blog/2015/03/how-to-install-lxml-for-python-3-on-64-bit-windows/" target="_blank" rel="external">How to install LXML for Python 3 on 64-bit Windows</a><br>[3] <a href="http://www.jianshu.com/p/61911e00abd0" target="_blank" rel="external">Python爬虫框架Scrapy快速入门</a><br>[4] <a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="external">Scrapy中文文档</a><br>[5] <a href="http://whatbeg.com/2016/05/18/hexo-donate.html">本文应用目标</a></p>
  
	</div>


    
	<!-- css -->
	<style type="text/css">
	    .center {
	        text-align: center;
	    }
	    .hidden {
	        display: none;
	    }
		.donate_bar a.btn_donate{
			display: inline-block;
			width: 82px;
			height: 82px;
			background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;
			_background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;

			<!-- http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif
			     因为本 hexo 生成的博客所用的 theme 的 a:hover 带动画效果，
				 为了在让打赏按钮显示效果正常 而 添加了以下几行 css，
				 嵌入其它博客时不一定要它们。 -->
			-webkit-transition: background 0s;
			-moz-transition: background 0s;
			-o-transition: background 0s;
			-ms-transition: background 0s;
			transition: background 0s;
			<!-- /让打赏按钮的效果显示正常 而 添加的几行 css 到此结束 -->
		}

		.donate_bar a.btn_donate:hover{ background-position: 0px -82px;}
		.donate_bar .donate_txt {
			display: block;
			color: #9d9d9d;
			font: 14px/2 "Microsoft Yahei";
		}
		.bold{ font-weight: bold; }
	</style>
	<!-- /css -->

    <!-- Donate Module -->
    <div id="donate_module">

	<!-- btn_donate & tips -->
	<div id="donate_board" class="donate_bar center">
	    <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
		<a id="btn_donate" class="btn_donate" target="_self" href="javascript:;" title="Donate 打赏"></a>
		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>
			
		
	</div>
	<!-- /btn_donate & tips -->

	<!-- donate guide -->
    
	<div id="donate_guide" class="donate_bar center hidden">
        <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
	    
	    <div width="100%" align="center"><div name="dashmain" id="dash-main-id-87895f" class="dash-main-3 87895f-0.99"></div></div>
		<script type="text/javascript" charset="utf-8" src="http://www.dashangcloud.com/static/ds.js"></script>
		

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="用微信扫一扫哦~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="微信打赏 Donate" height="190px" width="auto"/>
		</a>
        
        &nbsp;&nbsp;

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="用支付宝扫一扫即可~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="支付宝打赏 Donate" height="190px" width="auto"/>
		</a>

		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>

	</div>
	<!-- /donate guide -->

	<!-- donate script -->
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function() {
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}

		function donate_on_web(){
			$('#donate').submit();
        }

		var original_window_onload = window.onload;
        window.onload = function () {
            if (original_window_onload) {
                original_window_onload();
            }
            document.getElementById('donate_board_wdg').className = 'hidden';
		}
	</script>
	<!-- /donate script -->
</div>
<!-- /Donate Module -->
   

		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  
  <span></span> <a href="/categories/数据科学-Data-Science/">数据科学 | Data Science</a>
  </div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Python/">Python</a><a href="/tags/数据分析/">数据分析</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"husuche## e.g. 2176287895 Your weibo id,It will be used in share button."},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=2094149
2094149" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2016/05/23/talkwrite.html" title="当我谈写作时我谈些什么">
  <strong>上一篇：</strong><br/>
  <span>
  当我谈写作时我谈些什么</span>
</a>
</div>


<div class="next">
<a href="/2016/05/18/hexo-donate.html"  title="Hexo博客Jacman主题优化(二)--打赏功能">
 <strong>下一篇：</strong><br/> 
 <span>Hexo博客Jacman主题优化(二)--打赏功能
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <aside class="clearfix">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy是什么？"><span class="toc-number">1.</span> <span class="toc-text">Scrapy是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#平台"><span class="toc-number">2.</span> <span class="toc-text">平台</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy安装"><span class="toc-number">3.</span> <span class="toc-text">Scrapy安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-3-5下Scrapy安装"><span class="toc-number">3.1.</span> <span class="toc-text">Python 3.5下Scrapy安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-2-7下Scrapy的安装"><span class="toc-number">3.2.</span> <span class="toc-text">Python 2.7下Scrapy的安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#开始项目"><span class="toc-number">4.</span> <span class="toc-text">开始项目</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#创建Scrapy项目"><span class="toc-number">4.1.</span> <span class="toc-text">创建Scrapy项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#定义items-py"><span class="toc-number">4.2.</span> <span class="toc-text">定义items.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写主爬程序"><span class="toc-number">4.3.</span> <span class="toc-text">编写主爬程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用Item"><span class="toc-number">4.4.</span> <span class="toc-text">使用Item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取打赏描述"><span class="toc-number">4.5.</span> <span class="toc-text">获取打赏描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬取多页"><span class="toc-number">4.6.</span> <span class="toc-text">爬取多页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用Pipeline"><span class="toc-number">4.7.</span> <span class="toc-text">使用Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#合并打赏描述，根据打赏数排序"><span class="toc-number">4.8.</span> <span class="toc-text">合并打赏描述，根据打赏数排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结语"><span class="toc-number">5.</span> <span class="toc-text">结语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-number">6.</span> <span class="toc-text">参考资料</span></a></li></ol>
 
 </aside>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="about">
    <p class="asidetitle">Short bio</p>
    <div class="clearfix">
        <!-- <img src="http://7xsl28.com1.z0.glb.clouddn.com/niuzai.jpg" height="74px" width="74px" id="about-image" alt> -->
        <span style="font-size: medium; font-family: Calibri Light, Open Sans, Microsoft YaHei Light">
        whatbeg.com is written by Qiu Hu. He is living in Nanjing, P.R. China.
        <br>
        You can contact Qiu Hu with email.
        <br>
        Just enjoy your reading here!
        <br>
        Comments are always welcome:)
        <br>
        Some interesting non-technical articles can be seen in his WeChat official account: 
        </span>
        <br>
        <img src="https://gitee.com/whyseek/blogimages/raw/master/qrcode.jpg" height="124px" width="124px" id="qrcode" alt>
    </div>
</div>


  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/大数据-Big-Data/" title="大数据 | Big Data">大数据 | Big Data<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/大数据系统与技术-Big-Data/" title="大数据系统与技术 | Big Data">大数据系统与技术 | Big Data<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/成长之路-Biography/" title="成长之路 | Biography">成长之路 | Biography<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/数据科学-Data-Science/" title="数据科学 | Data Science">数据科学 | Data Science<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/机器学习-Mac-Learning/" title="机器学习 | Mac.Learning">机器学习 | Mac.Learning<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/机器学习系统-ML-Sys/" title="机器学习系统 | ML Sys.">机器学习系统 | ML Sys.<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/深度学习-Deep-Learning/" title="深度学习 | Deep Learning">深度学习 | Deep Learning<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/源码阅读-Source/" title="源码阅读 | Source">源码阅读 | Source<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法-Algorithm/" title="算法 | Algorithm">算法 | Algorithm<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/编程语言-Program-Lang/" title="编程语言 | Program Lang.">编程语言 | Program Lang.<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/计算机相关-CS-Related/" title="计算机相关 | CS.Related">计算机相关 | CS.Related<sup>12</sup></a></li>
		  
		
		  
			<li><a href="/categories/译文-Translation/" title="译文 | Translation">译文 | Translation<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书-Reading/" title="读书 | Reading">读书 | Reading<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/错误解决与优化-Err-Opt/" title="错误解决与优化 | Err&amp;Opt">错误解决与优化 | Err&amp;Opt<sup>14</sup></a></li>
		  
		
		  
			<li><a href="/categories/随笔-Essays/" title="随笔 | Essays">随笔 | Essays<sup>7</sup></a></li>
		  
		
		</ul>
</div>


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">23</span></li></ul>
  </div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">标签云</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/C/" style="font-size: 11px;">C++</a> <a href="/tags/CS/" style="font-size: 17px;">CS</a> <a href="/tags/Deep-Learning/" style="font-size: 17px;">Deep Learning</a> <a href="/tags/GPU/" style="font-size: 11px;">GPU</a> <a href="/tags/Git/" style="font-size: 11px;">Git</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Latex/" style="font-size: 11px;">Latex</a> <a href="/tags/Linux/" style="font-size: 14px;">Linux</a> <a href="/tags/Python/" style="font-size: 19px;">Python</a> <a href="/tags/Scala/" style="font-size: 10px;">Scala</a> <a href="/tags/Spark/" style="font-size: 12px;">Spark</a> <a href="/tags/Summary/" style="font-size: 16px;">Summary</a> <a href="/tags/TensorFlow/" style="font-size: 12px;">TensorFlow</a> <a href="/tags/Web/" style="font-size: 12px;">Web</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/人文社科/" style="font-size: 10px;">人文社科</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/历史/" style="font-size: 11px;">历史</a> <a href="/tags/吃喝玩乐/" style="font-size: 10px;">吃喝玩乐</a> <a href="/tags/大数据/" style="font-size: 17px;">大数据</a> <a href="/tags/工具使用/" style="font-size: 10px;">工具使用</a> <a href="/tags/影视/" style="font-size: 11px;">影视</a> <a href="/tags/操作系统/" style="font-size: 10px;">操作系统</a> <a href="/tags/数据分析/" style="font-size: 16px;">数据分析</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 18px;">深度学习</a> <a href="/tags/源码阅读/" style="font-size: 12px;">源码阅读</a> <a href="/tags/算法/" style="font-size: 13px;">算法</a> <a href="/tags/系统/" style="font-size: 10px;">系统</a> <a href="/tags/计算机网络/" style="font-size: 10px;">计算机网络</a> <a href="/tags/论文阅读/" style="font-size: 12px;">论文阅读</a> <a href="/tags/译文/" style="font-size: 12px;">译文</a> <a href="/tags/读书/" style="font-size: 19px;">读书</a> <a href="/tags/错误解决/" style="font-size: 13px;">错误解决</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a>
    </div>
  </div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://www.cnblogs.com/whatbeg/" target="_blank" title="Old Blog">Old Blog</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/whatbeg" target="_blank" title="My Github">My Github</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.matrix67.com/blog/" target="_blank" title="Matrix67">Matrix67</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.liaoxuefeng.com/" target="_blank" title="廖雪峰">廖雪峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.ruanyifeng.com/blog/" target="_blank" title="阮一峰">阮一峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://mindhacks.cn/" target="_blank" title="刘未鹏">刘未鹏</a>
            
          </li>
        
          <li>
            
            	<a href="http://machinelearningmastery.com/blog/" target="_blank" title="ML MYSTERY">ML MYSTERY</a>
            
          </li>
        
          <li>
            
            	<a href="http://freemind.pluskid.org/" target="_blank" title="Free Mind">Free Mind</a>
            
          </li>
        
          <li>
            
            	<a href="http://blog.csdn.net/zouxy09/" target="_blank" title="zouxy机器学习">zouxy机器学习</a>
            
          </li>
        
          <li>
            
            	<a href="http://coolshell.cn" target="_blank" title="酷壳">酷壳</a>
            
          </li>
        
    </ul>
</div>

  <table height=30 cellSpacing=0 cellPadding=0 width=180 border=0>
<form action="http://www.sogou.com/web" target="_blank">
<tr style='font-size:12px;color:#000000'>
<td align="center" width=100><input type="text" name="query" size=14 style='BORDER-RIGHT: #999 1px solid; BORDER-TOP: #999 1px solid; BORDER-LEFT: #999	1px	solid; BORDER-BOTTOM: #999 1px solid; HEIGHT: 19px; BACKGROUND-COLOR: #fff'>
<input type="hidden" name="insite" value="whatbeg.com">
<input type="hidden" name="insite2" value="whatbeg.com"></td>
<td align="left" width=45><input type="submit" name="sogou_submit" value="搜索">
</td></tr></form>
</table>



  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="rsspart">
	<a href="http://eepurl.com/cHO5An" target="_blank" title="email">Email 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
        

	    
		
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/by-nc-nd/4.0" class="cc-opacity" target="_blank">
            <img src="/img/cc-by-nc-nd.svg" alt="Creative Commons" />
          </a>
        </div>
    

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016-2019 
		
		<a href="/about" target="_blank" title="whatbeg">whatbeg</a>
		
		<br>
		<span class="post-count">Total words: <span style="color:orange">409.4k</span></span>
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">
        &nbsp;&nbsp;Total visits:&nbsp;<span style="color:orange" id="busuanzi_value_site_pv"></span>
        </span>
        <span id="busuanzi_container_site_uv">
        &nbsp;&nbsp;You are Visitor No.<span style="color:orange" id="busuanzi_value_site_uv"></span>
        </span>
        </br>
		</p>
		
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    $('#toc.toc-aside').css('display', 'block').addClass('fadeIn');  //侧边栏显示文章目录
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');   //侧边栏显示widget
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>





<script type="text/javascript">

var disqus_shortname = 'whatbeg';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1258390595'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1258390595%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->
<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
  </body>
</html>


