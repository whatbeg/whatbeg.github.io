
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>神经网络一阶优化算法手记 | Whatbeg&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="whatbeg">
    

    
    <meta name="description" content="关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。
Notations$\theta$ : parameters
$J$ : objective function
$\nabla J(\theta) = J’$ w.r.t parameter
$\eta$ :">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络一阶优化算法手记">
<meta property="og:url" content="http://whatbeg.com/2018/03/11/optimizationAlgos.html">
<meta property="og:site_name" content="Whatbeg's blog">
<meta property="og:description" content="关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。
Notations$\theta$ : parameters
$J$ : objective function
$\nabla J(\theta) = J’$ w.r.t parameter
$\eta$ :">
<meta property="og:image" content="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/optimization.jpg">
<meta property="og:updated_time" content="2018-03-18T06:21:21.212Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神经网络一阶优化算法手记">
<meta name="twitter:description" content="关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。
Notations$\theta$ : parameters
$J$ : objective function
$\nabla J(\theta) = J’$ w.r.t parameter
$\eta$ :">
<meta name="twitter:image" content="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/optimization.jpg">

    
    <link rel="alternative" href="/atom.xml" title="Whatbeg&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/w.ico">
    
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Whatbeg&#39;s blog">Whatbeg&#39;s blog</a></h1>
				<h2 class="blog-motto">当你的才华撑不起你的野心时，就应该静下心来好好学习。</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页(Home)</a></li>
					
						<li><a href="/archives">归档(Archives)</a></li>
					
						<li><a href="/tags">标签(Tags)</a></li>
					
						<li><a href="/categories">分类(Categories)</a></li>
					
						<li><a href="/about">关于(About)</a></li>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/11/optimizationAlgos.html" title="神经网络一阶优化算法手记" itemprop="url">神经网络一阶优化算法手记</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="whatbeg" target="_blank" itemprop="author">whatbeg</a>
		
  <p class="article-time">
    <time datetime="2018-03-11T09:03:38.000Z" itemprop="datePublished"> 发表于 2018-03-11</time>
    <span id="busuanzi_container_page_pv">
    总阅读<span id="busuanzi_value_page_pv"></span>次
    </span>
  </p>

</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Notations"><span class="toc-number">1.</span> <span class="toc-text">Notations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#从SGD说起"><span class="toc-number">2.</span> <span class="toc-text">从SGD说起</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Momentum"><span class="toc-number">3.</span> <span class="toc-text">Momentum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Nesterov-Accelerated-Gradient-NAG"><span class="toc-number">4.</span> <span class="toc-text">Nesterov Accelerated Gradient(NAG)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adagrad"><span class="toc-number">5.</span> <span class="toc-text">Adagrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RMSprop"><span class="toc-number">6.</span> <span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adadelta"><span class="toc-number">7.</span> <span class="toc-text">Adadelta</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam"><span class="toc-number">8.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization-Algorithms-Relationship"><span class="toc-number">9.</span> <span class="toc-text">Optimization Algorithms Relationship</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">10.</span> <span class="toc-text">References</span></a></li></ol>
		
		</div>
		
		<p>关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。</p>
<h2 id="Notations"><a href="#Notations" class="headerlink" title="Notations"></a>Notations</h2><p>$\theta$ : parameters</p>
<p>$J$ : objective function</p>
<p>$\nabla J(\theta) = J’$ w.r.t parameter</p>
<p>$\eta$ : learning rate</p>
<h2 id="从SGD说起"><a href="#从SGD说起" class="headerlink" title="从SGD说起"></a>从SGD说起</h2><p>SGD(Stochastic Gradient Descent)是目前最流行的机器学习，深度学习优化算法之一，现在通常所说的SGD指的是Mini-batch gradient descent，更新规则如下，</p>
<p>$$\theta_{t+1} = \theta_{t} - \eta \nabla J(\theta_{t}; x_{i:i+m}; y_{i:i+m})$$</p>
<p>每次采用一小批数据计算梯度来更新paramter，既能够缓解每次单个样本的SGD带来的剧烈波动问题，又能够加快训练速度，所以受到了machine learning和neural network训练的喜爱。</p>
<p>但是SGD有如下几个不足[1]：<br>1）learning rate很难选取<br>2）schedule策略需要预先选定，无法自适应<br>3）参数的每一维使用相同的学习率<br>4）SGD在鞍点或者pleatu区域容易陷入困境，难以逃离</p>
<p>根据这些不足，人们设计了许多SGD的改进算法。</p>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p>为了加速SGD的训练，以及改善面对“峡谷”型目标函数的鲁棒性，人们将物理学中的Momentum概念加入优化中。实验证明，Momentum SGD[2]能够有效地抑制函数值震荡的现象。<br>Momentum的更新公式如下：</p>
<p>$v_t = \rho v_{t-1} + \eta \nabla J(\theta)$</p>
<p>$\theta = \theta - v_t$</p>
<p>where $\rho$ 控制着前面诸参数更新的衰减率。<br>有了Momentum，SGD能够收敛的更快，并且震荡会减弱。</p>
<h2 id="Nesterov-Accelerated-Gradient-NAG"><a href="#Nesterov-Accelerated-Gradient-NAG" class="headerlink" title="Nesterov Accelerated Gradient(NAG)"></a>Nesterov Accelerated Gradient(NAG)</h2><p>接着，Nesterov提出了一种无约束凸优化方法，称为Nesterov accelerated gradient(NAG)[3]，这种方法预先估计下一个位置，然后看看该位置的梯度，根据对该“未来”梯度的判断，来调整自己的预期步长，使得更加智能的往局部最优点走去。NAG的更新式与Momentum只有一丝细微的差别：</p>
<p>$v_t = \rho v_{t-1} + \eta \nabla J(\theta-\rho v_{t-1})$</p>
<p>$\theta = \theta - v_t$</p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>虽然我们对SGD进行了加速，并且非常智能地调整好了方向，我们的参数向量各个维度更新幅度仍然是一样的，（在有些时候，尤其是稀疏场景中，对于出现极少次数的特征维，我们不会想只更新一个很小的幅度，这样会使得这个维度学习很差。）</p>
<p>另一种思路是使得参数向量$\theta$的各个维以不同步调来差异化地调整。<br>Adagrad就是其中一种，由Duchi et. al[4]在2011年提出。Ada means Adaptive，代表着它能够自适应地为参数调整学习率，非常适合稀疏数据，这种方法将梯度平方的累积值加入梯度更新中，更新方式如下：</p>
<p>$g_{t,i} = \nabla J(\theta_i)$</p>
<p>$\theta_{t+1, i} = \theta_{t, i} - \frac {\eta} {\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}$</p>
<p>$G_t \in {\mathbb R}^{d \times d}$ is a diagonal matrix that each diagonal element is sum of the squares of the gradient w.r.t $w_i$ up to time step t [4].<br>$\epsilon$ is just a smoothing term avoiding division by zero, usually 1e-8.<br>我们也可以写成向量形式：<br>$$\theta_{t+1} = \theta_{t} - \frac {\eta} {\sqrt{G_{t} + \epsilon}} \odot g_{t}$$<br>$\odot$ means element-wise matrix-vector multiplication.</p>
<h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><p>随着梯度平方的累积，Adagrad会自适应地降低频繁更新的参数的学习率，使得你无需去手动指定learning rate schedule策略来调试学习率，但是Adagrad的一大缺点就是它的学习率会随着训练中不断增长的累计梯度平方和而单调下降到任意小，甚至导致学习的停滞。</p>
<p>RMSprop[5]和Adadelta[6]是提出来解决上述Adagrad学习率降到任意小问题的，RMSprop的基本思想是，instead of 除以所有梯度平方的累积，RMSprop将学习率除以梯度平方的指数衰减平均$E[g^2]$，梯度平方的指数衰减平均$E[g^2]$可以表示前w个平方梯度的累积，又避免了直接存储前w个平方梯度的存储开销，这样能够有效防止无限小的，单调下降的，diminishing的learning rate问题，RMSprop更新规则如下：<br>$g_t$代表time step t时刻的梯度向量。</p>
<p>$E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho)g_t^2 $</p>
<p>$\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_{t,i} = \theta_t - \frac {\eta} {RMS[g]_t} \cdot g_{t,i}$</p>
<h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><p>Adadelta[6]为与RMSprop几乎同一时间提出来的，可以看做在RMSprop的基础上做了进一步的改进的版本。其与RMSprop的关键区别就在于Adadelta统一了$\Delta \theta$与$\theta$的单位(unit)。<br>作者指出，在原来的$$\Delta \theta = - \frac {\eta} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_{t,i}$$中，$\Delta \theta$的单位与$\theta$是不匹配的，在SGD，Momentum或者Adagrad中也是如此，所以Adadelta通过引入$\Delta \theta^2$的指数衰减平均，来使得单位统一。故Adadelta的更新式为：<br>$E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho)g_t^2$</p>
<p>$\theta_{t+1} = \theta_t - \frac {\sqrt {E[\Delta \theta^2]_{t-1} + \epsilon}} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_t$</p>
<p>$E[\Delta \theta^2]_t = \rho E[\Delta \theta^2]_{t-1} + (1-\rho)\Delta \theta_t^2$</p>
<p>where $\rho$ 是类似于Momentum中的衰减率常数。<br>Adadelta有两个重要的优点，1) 解决了学习率随着训练持续减小的问题 2) 无需预先设置学习率超参<br>[6]指出，在MNIST数据集上，Adadelta的参数敏感性好于SGD,Momentum和Adagrad等算法。</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>另一个现在用的较多的自适应学习率方法是Adam(Adaptive Moment Estimation)[7]，Adam结合了RMSprop和Momentum的思想，不过Adam不仅维护过去一阶梯度的指数衰减平均$m_t$(exponentially decaying average of past gradients)，而且还维护二阶梯度的指数衰减平均$v_t$，并且加入了bias-correction步骤，以纠正$m_t, v_t$初始化为0带来的偏差(bias)，由是可得到Adam的更新规则如下：</p>
<p>$m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t $</p>
<p>$v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2 $</p>
<p>$\hat{m}_t = \frac {m_t} {1-\beta_1^t} $</p>
<p>$\hat{v}_t = \frac {v_t} {1-\beta_2^t}$</p>
<p>$\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v}_t} + \epsilon} \cdot \hat{m}_t $</p>
<p>where $\beta_1, \beta_2$ is exponential decay rates of moment estimates.<br>[7]中推荐参数设置为$\eta = 0.001, \beta_1 = 0.9, \beta_2 = 0.999 \<br> and \ \epsilon = 1e-8$</p>
<blockquote>
<p>Actually, Adam algorithm works well in practice, not only in acedemia but industry. Empirical results show that Adam consistantly outperforms other methods for a variety of models and datasets, and it’s a versatile algorithm that scales to large-scale high-dimensional machine learning problems.</p>
</blockquote>
<h2 id="Optimization-Algorithms-Relationship"><a href="#Optimization-Algorithms-Relationship" class="headerlink" title="Optimization Algorithms Relationship"></a>Optimization Algorithms Relationship</h2><p><img src="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/optimization.jpg" alt=""></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://arxiv.org/pdf/1609.04747.pdf" target="_blank" rel="external">Sebastian Ruder. An overview of gradient descent optimization algorithms</a><br>[2] <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.5612&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Ning Qian. On the Momentum Term in Gradient Descent Learning Algorithms</a><br>[3] <a href="https://scholar.google.com/citations?user=DJ8Ep8YAAAAJ" target="_blank" rel="external">Y. Nestrov. A method of solving a convex programming problem with convergence rate O (1/k2)</a><br>[4] <a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" target="_blank" rel="external">John Duchi et.al. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a><br>[5] <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="external">Geoffrey Hinton et.al Lecture 6. RMSprop</a><br>[6] <a href="http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf" target="_blank" rel="external">Matthew D. Zeiler. ADADELTA: AN ADAPTIVE LEARNING RATE METHOD</a><br>[7] <a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="external">Diederik P. Kingma et.al. ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION</a></p>
  
	</div>


    
	<!-- css -->
	<style type="text/css">
	    .center {
	        text-align: center;
	    }
	    .hidden {
	        display: none;
	    }
		.donate_bar a.btn_donate{
			display: inline-block;
			width: 82px;
			height: 82px;
			background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;
			_background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;

			<!-- http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif
			     因为本 hexo 生成的博客所用的 theme 的 a:hover 带动画效果，
				 为了在让打赏按钮显示效果正常 而 添加了以下几行 css，
				 嵌入其它博客时不一定要它们。 -->
			-webkit-transition: background 0s;
			-moz-transition: background 0s;
			-o-transition: background 0s;
			-ms-transition: background 0s;
			transition: background 0s;
			<!-- /让打赏按钮的效果显示正常 而 添加的几行 css 到此结束 -->
		}

		.donate_bar a.btn_donate:hover{ background-position: 0px -82px;}
		.donate_bar .donate_txt {
			display: block;
			color: #9d9d9d;
			font: 14px/2 "Microsoft Yahei";
		}
		.bold{ font-weight: bold; }
	</style>
	<!-- /css -->

    <!-- Donate Module -->
    <div id="donate_module">

	<!-- btn_donate & tips -->
	<div id="donate_board" class="donate_bar center">
	    <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
		<a id="btn_donate" class="btn_donate" target="_self" href="javascript:;" title="Donate 打赏"></a>
		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>
			
		
	</div>
	<!-- /btn_donate & tips -->

	<!-- donate guide -->
    
	<div id="donate_guide" class="donate_bar center hidden">
        <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
	    
	    <div width="100%" align="center"><div name="dashmain" id="dash-main-id-87895f" class="dash-main-3 87895f-0.99"></div></div>
		<script type="text/javascript" charset="utf-8" src="http://www.dashangcloud.com/static/ds.js"></script>
		

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="用微信扫一扫哦~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="微信打赏 Donate" height="190px" width="auto"/>
		</a>
        
        &nbsp;&nbsp;

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="用支付宝扫一扫即可~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="支付宝打赏 Donate" height="190px" width="auto"/>
		</a>

		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>

	</div>
	<!-- /donate guide -->

	<!-- donate script -->
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function() {
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}

		function donate_on_web(){
			$('#donate').submit();
        }

		var original_window_onload = window.onload;
        window.onload = function () {
            if (original_window_onload) {
                original_window_onload();
            }
            document.getElementById('donate_board_wdg').className = 'hidden';
		}
	</script>
	<!-- /donate script -->
</div>
<!-- /Donate Module -->
   

		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  
  <span></span> <a href="/categories/机器学习-Mac-Learning/">机器学习 | Mac.Learning</a>
  </div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/优化/">优化</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"husuche## e.g. 2176287895 Your weibo id,It will be used in share button."},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=2094149
2094149" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/03/15/ray-paper.html" title="Ray 论文解读">
  <strong>上一篇：</strong><br/>
  <span>
  Ray 论文解读</span>
</a>
</div>


<div class="next">
<a href="/2018/03/07/deeplearningbook-06.html"  title="Deep Learning读书笔记（6）--【卷积神经网络】">
 <strong>下一篇：</strong><br/> 
 <span>Deep Learning读书笔记（6）--【卷积神经网络】
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <aside class="clearfix">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Notations"><span class="toc-number">1.</span> <span class="toc-text">Notations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#从SGD说起"><span class="toc-number">2.</span> <span class="toc-text">从SGD说起</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Momentum"><span class="toc-number">3.</span> <span class="toc-text">Momentum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Nesterov-Accelerated-Gradient-NAG"><span class="toc-number">4.</span> <span class="toc-text">Nesterov Accelerated Gradient(NAG)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adagrad"><span class="toc-number">5.</span> <span class="toc-text">Adagrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RMSprop"><span class="toc-number">6.</span> <span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adadelta"><span class="toc-number">7.</span> <span class="toc-text">Adadelta</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam"><span class="toc-number">8.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization-Algorithms-Relationship"><span class="toc-number">9.</span> <span class="toc-text">Optimization Algorithms Relationship</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">10.</span> <span class="toc-text">References</span></a></li></ol>
 
 </aside>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="about">
    <p class="asidetitle">Short bio</p>
    <div class="clearfix">
        <!-- <img src="http://7xsl28.com1.z0.glb.clouddn.com/niuzai.jpg" height="74px" width="74px" id="about-image" alt> -->
        <span style="font-size: medium; font-family: Calibri Light, Open Sans, Microsoft YaHei Light">
        whatbeg.com is written by Qiu Hu. He is living in Nanjing, P.R. China.
        <br>
        You can contact Qiu Hu with email.
        <br>
        Just enjoy your reading here!
        <br>
        Comments are always welcome:)
        <br>
        Some interesting non-technical articles can be seen in his WeChat official account: 
        </span>
        <br>
        <img src="https://gitee.com/whyseek/blogimages/raw/master/qrcode.jpg" height="124px" width="124px" id="qrcode" alt>
    </div>
</div>


  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/大数据系统与技术-Big-Data/" title="大数据系统与技术 | Big Data">大数据系统与技术 | Big Data<sup>11</sup></a></li>
		  
		
		  
			<li><a href="/categories/成长之路-Biography/" title="成长之路 | Biography">成长之路 | Biography<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/数据科学-Data-Science/" title="数据科学 | Data Science">数据科学 | Data Science<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/机器学习-Mac-Learning/" title="机器学习 | Mac.Learning">机器学习 | Mac.Learning<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/深度学习-Deep-Learning/" title="深度学习 | Deep Learning">深度学习 | Deep Learning<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法-Algorithm/" title="算法 | Algorithm">算法 | Algorithm<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/编程语言-Program-Lang/" title="编程语言 | Program Lang.">编程语言 | Program Lang.<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/计算机相关-CS-Related/" title="计算机相关 | CS.Related">计算机相关 | CS.Related<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/译文-Translation/" title="译文 | Translation">译文 | Translation<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书-Reading/" title="读书 | Reading">读书 | Reading<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/错误解决与优化-Err-Opt/" title="错误解决与优化 | Err&amp;Opt">错误解决与优化 | Err&amp;Opt<sup>13</sup></a></li>
		  
		
		  
			<li><a href="/categories/随笔-Essays/" title="随笔 | Essays">随笔 | Essays<sup>7</sup></a></li>
		  
		
		</ul>
</div>


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">23</span></li></ul>
  </div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">标签云</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/CS/" style="font-size: 17px;">CS</a> <a href="/tags/Deep-Learning/" style="font-size: 17px;">Deep Learning</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Git/" style="font-size: 11px;">Git</a> <a href="/tags/Hadoop/" style="font-size: 14px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Latex/" style="font-size: 11px;">Latex</a> <a href="/tags/Linux/" style="font-size: 13px;">Linux</a> <a href="/tags/Python/" style="font-size: 19px;">Python</a> <a href="/tags/Scala/" style="font-size: 10px;">Scala</a> <a href="/tags/Spark/" style="font-size: 12px;">Spark</a> <a href="/tags/Summary/" style="font-size: 16px;">Summary</a> <a href="/tags/TensorFlow/" style="font-size: 12px;">TensorFlow</a> <a href="/tags/Web/" style="font-size: 12px;">Web</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/三国/" style="font-size: 10px;">三国</a> <a href="/tags/人文社科/" style="font-size: 10px;">人文社科</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/吃喝玩乐/" style="font-size: 10px;">吃喝玩乐</a> <a href="/tags/大数据/" style="font-size: 16px;">大数据</a> <a href="/tags/工具使用/" style="font-size: 10px;">工具使用</a> <a href="/tags/影视/" style="font-size: 11px;">影视</a> <a href="/tags/数据分析/" style="font-size: 16px;">数据分析</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 18px;">深度学习</a> <a href="/tags/算法/" style="font-size: 13px;">算法</a> <a href="/tags/系统/" style="font-size: 10px;">系统</a> <a href="/tags/论文阅读/" style="font-size: 12px;">论文阅读</a> <a href="/tags/译文/" style="font-size: 12px;">译文</a> <a href="/tags/读书/" style="font-size: 19px;">读书</a> <a href="/tags/错误解决/" style="font-size: 12px;">错误解决</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a>
    </div>
  </div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://www.cnblogs.com/whatbeg/" target="_blank" title="Old Blog">Old Blog</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/whatbeg" target="_blank" title="My Github">My Github</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.matrix67.com/blog/" target="_blank" title="Matrix67">Matrix67</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.liaoxuefeng.com/" target="_blank" title="廖雪峰">廖雪峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.ruanyifeng.com/blog/" target="_blank" title="阮一峰">阮一峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://mindhacks.cn/" target="_blank" title="刘未鹏">刘未鹏</a>
            
          </li>
        
          <li>
            
            	<a href="http://machinelearningmastery.com/blog/" target="_blank" title="ML MYSTERY">ML MYSTERY</a>
            
          </li>
        
          <li>
            
            	<a href="http://freemind.pluskid.org/" target="_blank" title="Free Mind">Free Mind</a>
            
          </li>
        
          <li>
            
            	<a href="http://blog.csdn.net/zouxy09/" target="_blank" title="zouxy机器学习">zouxy机器学习</a>
            
          </li>
        
          <li>
            
            	<a href="http://coolshell.cn" target="_blank" title="酷壳">酷壳</a>
            
          </li>
        
    </ul>
</div>

  <table height=30 cellSpacing=0 cellPadding=0 width=180 border=0>
<form action="http://www.sogou.com/web" target="_blank">
<tr style='font-size:12px;color:#000000'>
<td align="center" width=100><input type="text" name="query" size=14 style='BORDER-RIGHT: #999 1px solid; BORDER-TOP: #999 1px solid; BORDER-LEFT: #999	1px	solid; BORDER-BOTTOM: #999 1px solid; HEIGHT: 19px; BACKGROUND-COLOR: #fff'>
<input type="hidden" name="insite" value="whatbeg.com">
<input type="hidden" name="insite2" value="whatbeg.com"></td>
<td align="left" width=45><input type="submit" name="sogou_submit" value="搜索">
</td></tr></form>
</table>



  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="rsspart">
	<a href="http://eepurl.com/cHO5An" target="_blank" title="email">Email 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
        

	    
		
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/by-nc-nd/4.0" class="cc-opacity" target="_blank">
            <img src="/img/cc-by-nc-nd.svg" alt="Creative Commons" />
          </a>
        </div>
    

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016-2019 
		
		<a href="/about" target="_blank" title="whatbeg">whatbeg</a>
		
		<br>
		<span class="post-count">Total words: <span style="color:orange">329.1k</span></span>
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">
        &nbsp;&nbsp;Total visits:&nbsp;<span style="color:orange" id="busuanzi_value_site_pv"></span>
        </span>
        <span id="busuanzi_container_site_uv">
        &nbsp;&nbsp;You are Visitor No.<span style="color:orange" id="busuanzi_value_site_uv"></span>
        </span>
        </br>
		</p>
		
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    $('#toc.toc-aside').css('display', 'block').addClass('fadeIn');  //侧边栏显示文章目录
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');   //侧边栏显示widget
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>





<script type="text/javascript">

var disqus_shortname = 'whatbeg';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1258390595'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1258390595%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->
<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
  </body>
</html>


