
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版 | Whatbeg&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="whatbeg">
    

    
    <meta name="description" content="事前各软件版本：NVIDIA驱动：390.25CUDA: 9.1
现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9.1，但是安装目录下cuda软连接指向cuda-8.0即可。
卸载CUDA 9.1 （可选）12cd /usr/local/cuda-9.1/binsudo">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版">
<meta property="og:url" content="http://whatbeg.com/2018/03/17/cudainstall.html">
<meta property="og:site_name" content="Whatbeg's blog">
<meta property="og:description" content="事前各软件版本：NVIDIA驱动：390.25CUDA: 9.1
现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9.1，但是安装目录下cuda软连接指向cuda-8.0即可。
卸载CUDA 9.1 （可选）12cd /usr/local/cuda-9.1/binsudo">
<meta property="og:image" content="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/xshell.jpg">
<meta property="og:updated_time" content="2018-03-18T06:31:26.936Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版">
<meta name="twitter:description" content="事前各软件版本：NVIDIA驱动：390.25CUDA: 9.1
现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9.1，但是安装目录下cuda软连接指向cuda-8.0即可。
卸载CUDA 9.1 （可选）12cd /usr/local/cuda-9.1/binsudo">
<meta name="twitter:image" content="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/xshell.jpg">

    
    <link rel="alternative" href="/atom.xml" title="Whatbeg&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/w.ico">
    
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Whatbeg&#39;s blog">Whatbeg&#39;s blog</a></h1>
				<h2 class="blog-motto">当你的才华撑不起你的野心时，就应该静下心来好好学习。</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页(Home)</a></li>
					
						<li><a href="/archives">归档(Archives)</a></li>
					
						<li><a href="/tags">标签(Tags)</a></li>
					
						<li><a href="/categories">分类(Categories)</a></li>
					
						<li><a href="/about">关于(About)</a></li>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/17/cudainstall.html" title="CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版" itemprop="url">CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="whatbeg" target="_blank" itemprop="author">whatbeg</a>
		
  <p class="article-time">
    <time datetime="2018-03-17T08:46:42.000Z" itemprop="datePublished"> 发表于 2018-03-17</time>
    <span id="busuanzi_container_page_pv">
    总阅读<span id="busuanzi_value_page_pv"></span>次
    </span>
  </p>

</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#卸载CUDA-9-1-（可选）"><span class="toc-number">1.</span> <span class="toc-text">卸载CUDA 9.1 （可选）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装CUDA-8-0"><span class="toc-number">2.</span> <span class="toc-text">安装CUDA 8.0</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装cuDNN"><span class="toc-number">3.</span> <span class="toc-text">安装cuDNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#添加环境变量"><span class="toc-number">4.</span> <span class="toc-text">添加环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装Tensorflow"><span class="toc-number">5.</span> <span class="toc-text">安装Tensorflow</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#进一步的例子：CIFAR10多GPU训练"><span class="toc-number">6.</span> <span class="toc-text">进一步的例子：CIFAR10多GPU训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#本地查看远程服务器Tensorboard-Windows-Linux"><span class="toc-number">7.</span> <span class="toc-text">本地查看远程服务器Tensorboard (Windows, Linux)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装VNC-Server-amp-Viewer"><span class="toc-number">8.</span> <span class="toc-text">安装VNC (Server & Viewer)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">9.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">10.</span> <span class="toc-text">References</span></a></li></ol>
		
		</div>
		
		<p>事前各软件版本：<br>NVIDIA驱动：390.25<br>CUDA: 9.1</p>
<p>现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9.1，但是安装目录下cuda软连接指向cuda-8.0即可。</p>
<h2 id="卸载CUDA-9-1-（可选）"><a href="#卸载CUDA-9-1-（可选）" class="headerlink" title="卸载CUDA 9.1 （可选）"></a>卸载CUDA 9.1 （可选）</h2><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> /usr/<span class="keyword">local</span>/cuda-9.1/bin</span><br><span class="line">sudo ./uninstall_cuda_toolkit_9.1.<span class="keyword">pl</span></span><br></pre></td></tr></table></figure>
<h2 id="安装CUDA-8-0"><a href="#安装CUDA-8-0" class="headerlink" title="安装CUDA 8.0"></a>安装CUDA 8.0</h2><p>从官网下载<a href="https://developer.nvidia.com/cuda-80-ga2-download-archive" target="_blank" rel="external">CUDA 8.0 ToolKit</a>。<br>这里我下载的是<code>cuda_8.0.61_375.26_linux.run</code>，并下载补丁<code>cuda_8.0.61.2_linux.run</code>。</p>
<p>进入root用户，将上述两个文件拷贝到<code>/root</code>（或其他地方），直接用root用户较方便。</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chmod +x cuda_8<span class="number">.0</span><span class="number">.61</span>*  <span class="comment"># 加上执行权限</span></span><br><span class="line">./cuda_8<span class="number">.0</span><span class="number">.61</span>_375<span class="number">.26</span>_linux.<span class="built_in">run</span></span><br><span class="line">第一个问题，是否安装NVIDIA驱动，选n（不安装）</span><br><span class="line">其他问题自己决定，默认装到/usr/<span class="keyword">local</span>即可</span><br></pre></td></tr></table></figure>
<p>然后可以到Samples目录，先make编译，然后到bin下找到<code>deviceQuery</code>，执行<code>./deviceQuery</code>，<br>如果安装成功应该会显示类似如下信息：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...(省略)</span><br><span class="line">deviceQuery, CUDA <span class="attr">Driver</span> = CUDART, CUDA Driver <span class="attr">Version</span> = <span class="number">9.1</span>, CUDA Runtime <span class="attr">Version</span> = <span class="number">8.0</span>, <span class="attr">NumDevs</span> = <span class="number">2</span>, <span class="attr">Device0</span> = Tesla K80, <span class="attr">Device0</span> = Tesla K80</span><br><span class="line"><span class="attr">Result</span> = PASS</span><br></pre></td></tr></table></figure></p>
<h2 id="安装cuDNN"><a href="#安装cuDNN" class="headerlink" title="安装cuDNN"></a>安装cuDNN</h2><p>cuDNN是NVIDIA专为Deep Learning应用开发的支持库。<br>我们打算安装Tensorflow 1.4.0，该版本要求<code>libcudnn.so.6</code>，所以下载v6版本的cuDNN。<br>到<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="external">这里下载</a></p>
<p>下载：<code>cudnn-8.0-linux-x64-v6.0.tgz</code>。</p>
<p>将其传到<code>/usr/local</code>目录下，然后解压即可：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">tar</span> <span class="selector-tag">-zxvf</span> <span class="selector-tag">cudnn-8</span><span class="selector-class">.0-linux-x64-v6</span><span class="selector-class">.0</span><span class="selector-class">.tgz</span></span><br></pre></td></tr></table></figure></p>
<p>这样就成功安装了CUDA 8.0这一套，但是驱动仍然用的高版本驱动390.25，不过应该没关系的吧。</p>
<h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">添加：</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-<span class="number">8.0</span>/lib64:/usr/local/cuda-<span class="number">8.0</span>/extras/CUPTI/lib64:$LD_LIBRARY_PATH</span><br><span class="line">export CUDA_HOME=/usr/local/cuda-<span class="number">8.0</span></span><br><span class="line">export PATH=$CUDA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
<h2 id="安装Tensorflow"><a href="#安装Tensorflow" class="headerlink" title="安装Tensorflow"></a>安装Tensorflow</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> tensorflow-gpu==<span class="number">1.4</span>.<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>试一把，import tensorflow成功即说明CUDA，cuDNN安装完成，且版本没问题。</p>
<p>运行两个GPU的例子：<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow <span class="keyword">as</span> tf</span><br><span class="line">c = []</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> [<span class="string">'/device:GPU:0'</span>, <span class="string">'/device:GPU:1'</span>]:</span><br><span class="line">    <span class="keyword">with</span> tf.device(d):</span><br><span class="line">        <span class="keyword">a</span> = tf.<span class="built_in">constant</span>([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">        b = tf.<span class="built_in">constant</span>([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">        c.append(tf.matmul(<span class="keyword">a</span>, b))</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    <span class="built_in">sum</span> = tf.add_n(c)</span><br><span class="line"><span class="comment"># Creates a session with log_device_placement set to True.</span></span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br><span class="line"><span class="comment"># Runs the op.</span></span><br><span class="line">print(sess.run(<span class="built_in">sum</span>))</span><br></pre></td></tr></table></figure></p>
<p>输出：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">MatMul_1:</span> (MatMul): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759031</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] MatMul_1: (MatMul)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="string">MatMul:</span> (MatMul): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759079</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] MatMul: (MatMul)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line"><span class="string">AddN:</span> (AddN): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">CPU:</span><span class="number">0</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759100</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] AddN: (AddN)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">CPU:</span><span class="number">0</span></span><br><span class="line"><span class="string">Const_3:</span> (Const): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759126</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] Const_3: (Const)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="string">Const_2:</span> (Const): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759145</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] Const_2: (Const)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">1</span></span><br><span class="line"><span class="string">Const_1:</span> (Const): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759167</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] Const_1: (Const)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line"><span class="string">Const:</span> (Const): <span class="regexp">/job:localhost/</span><span class="string">replica:</span><span class="number">0</span><span class="regexp">/task:0/</span><span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">19</span>:<span class="number">22</span>:<span class="number">00.759185</span>: I tensorflow<span class="regexp">/core/</span>common_runtime<span class="regexp">/placer.cc:874] Const: (Const)/</span><span class="string">job:</span>localhost<span class="regexp">/replica:0/</span><span class="string">task:</span><span class="number">0</span>/<span class="string">device:</span><span class="string">GPU:</span><span class="number">0</span></span><br><span class="line">[[ <span class="number">44.</span>  <span class="number">56.</span>]</span><br><span class="line"> [ <span class="number">98.</span> <span class="number">128.</span>]]</span><br></pre></td></tr></table></figure></p>
<p>从输出结果看，确实使用了两块GPU，基本说明可以同时使用两块GPU。</p>
<h2 id="进一步的例子：CIFAR10多GPU训练"><a href="#进一步的例子：CIFAR10多GPU训练" class="headerlink" title="进一步的例子：CIFAR10多GPU训练"></a>进一步的例子：CIFAR10多GPU训练</h2><p>进一步地，我们采用Tensorflow的tutorial中的一个例子来验证多块GPU卡带来的加速效果。</p>
<p>Tutorial地址见<a href="https://www.tensorflow.org/tutorials/deep_cnn" target="_blank" rel="external">这里</a>。<br>具体model训练程序在<a href="https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10" target="_blank" rel="external">这里</a>。</p>
<p>运行cifar10多GPU训练，<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python cifar10_multi_gpu_train<span class="selector-class">.py</span> --num_gpus=<span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>可以用如下命令设置每隔一秒查看一下GPU状态：<br><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">nvidia</span>-<span class="keyword">smi </span>-l <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>或者使用gpustat工具，更简洁的观察GPU动态状态变化：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> gpustat</span><br><span class="line">watch <span class="comment">--color -n1 gpustat -cpu</span></span><br></pre></td></tr></table></figure></p>
<p>可见在两块Tesla P100上，训练吞吐率大约为 34000 image/sec 左右，在单块 GPU 上，训练吞吐率大约最高为 19000 image/sec。从目前结果看来，虽然两块GPU能够大大加速训练，但是毕竟还是无法做到标准的线性的加速。</p>
<h2 id="本地查看远程服务器Tensorboard-Windows-Linux"><a href="#本地查看远程服务器Tensorboard-Windows-Linux" class="headerlink" title="本地查看远程服务器Tensorboard (Windows, Linux)"></a>本地查看远程服务器Tensorboard (Windows, Linux)</h2><p>核心思想是利用SSH的转发/隧道机制。Tensorboard起在远程服务器本地6006端口，我们本地用一个端口去访问比如16006，我们建立一个隧道，将我们对16006端口的访问转发到远程服务器的6006端口即可。</p>
<p>一般本地和远程在一个局域网内，可以如下做：</p>
<ul>
<li>在Lunux下:</li>
</ul>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ssh</span> <span class="selector-tag">-L</span> 16006<span class="selector-pseudo">:127.0.0.1</span><span class="selector-pseudo">:6006</span> <span class="selector-tag">user</span>@<span class="keyword">server.address</span></span><br><span class="line">tensorboard –logdir=”tensorboard”</span><br><span class="line">在本地主机访问 http://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">16006</span>/</span><br></pre></td></tr></table></figure>
<p>建立本地16006端口到服务器6006端口的正向转发</p>
<ul>
<li>Windows下：</li>
</ul>
<p>Windows 10中除了一个开发者模式，内嵌一个linux系统，可以进入如上做。但是一般我们在Windows下还是用putty，Xshell，MobaXterm等远程登录软件为主，这里以Xshell为例。</p>
<p>步骤为：<br>1、新建一个会话指向服务器，设置属性，点“隧道”，然后点中间的“添加”，添加的信息如下：</p>
<p><img src="https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/xshell.jpg" alt=""></p>
<p>X11转移那里打钩，也必须保证远程服务器允许X11转发，具体的，在<code>/etc/ssh/sshd_config</code>中设置<code>X11forwarding</code>为<code>yes</code>。</p>
<p>这样即建立了一个隧道。然后在服务器上启动Tensorboard，在本地浏览器打开<code>http://127.0.0.1:16006</code>即可访问TensorBoard。</p>
<ul>
<li>客户端位于外网</li>
</ul>
<p>当然还有一种情况就是客户端位于外网，无法直接建立隧道。</p>
<p>此种情况下 [1]，服务器可以通过IP地址寻址客户端，所以在服务器端建立与客户端的反向链接。通过-N -f后台运行。具体命令为：</p>
<p>在服务器主机上执行：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -NR &lt;client_port&gt;<span class="symbol">:localhost</span><span class="symbol">:&lt;server_port&gt;</span> [username@]&lt;client_ip_address&gt;</span><br></pre></td></tr></table></figure></p>
<p>除了本地查看Tensorboard，也可以启动服务器桌面来直接看Tensorboard。具体可以安装VNC Server和Viewer。</p>
<h2 id="安装VNC-Server-amp-Viewer"><a href="#安装VNC-Server-amp-Viewer" class="headerlink" title="安装VNC (Server &amp; Viewer)"></a>安装VNC (Server &amp; Viewer)</h2><p>1、服务器安装VNC Server: <code>yum -y install tigervnc-server</code></p>
<p>2、配置分辨率和用户登录信息<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># vim <span class="regexp">/lib/</span>systemd<span class="regexp">/system/</span>vncserver@.service</span><br><span class="line">写入</span><br><span class="line">VNCSERVERS=<span class="string">"2:root"</span></span><br><span class="line">VNCSERVERARGS[<span class="number">2</span>]=<span class="string">"-geometry 1024x768"</span></span><br></pre></td></tr></table></figure></p>
<p>3、下载VNC Viewer，VNC Viewer连接，可能出现Timeout的问题，可能是服务器设置了防火墙，如下命令关闭：<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iptables -I INPUT -p tcp --dport <span class="number">5801</span> -j ACCEPT  <span class="comment"># 浏览器</span></span><br><span class="line">iptables -I INPUT -p tcp --dport <span class="number">5901</span> -j ACCEPT  <span class="comment"># VNC Viewer</span></span><br><span class="line">或者进入/etc/sysconfig/iptables添加一行：</span><br><span class="line">-A INPUT -m <span class="keyword">state</span> --state NEW -m tcp -p tcp --dport <span class="number">5900</span>:<span class="number">5903</span> -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<p>黑屏解决方案：<br>在<code>/root/.vnc/xtartup</code>文件中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># unset SESSION_MANAGER </span></span><br><span class="line"><span class="comment"># exec /etc/X11/xinit/xinitrc</span></span><br><span class="line">注释掉以上两行，添加如下几行：</span><br><span class="line">[ -x /etc/.vnc/xstartup ] &amp;&amp; <span class="built_in">exec</span> /etc/.vnc/xstartup</span><br><span class="line">[ -r <span class="variable">$HOME</span>/.Xresources ] &amp;&amp; xrdb <span class="variable">$HOME</span>/.Xresources </span><br><span class="line">xsetroot -solid grey <span class="comment">#vncconfig -iconic &amp; </span></span><br><span class="line">xterm -geometry 80x24+10+10 -ls -title <span class="string">"<span class="variable">$VNCDESKTOP</span> Desktop"</span> &amp;</span><br><span class="line">twm &amp; </span><br><span class="line">gnome-session &amp;</span><br></pre></td></tr></table></figure></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要讲述了CUDA 8.0的安装细节，TensorFlow的安装，多GPU训练实例，以及远程服务器TensorBoard查看，以及VNC（Virtual Network Console）的服务端和客户端的安装。<br>更多的一些错误及解决方案因为目前还解决不全，一律放到后面的<a href="">《TensorFlow, GPU错误及优化集锦》</a></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="http://blog.csdn.net/silent56_th/article/details/69367446" target="_blank" rel="external">[1] 远程使用内网服务器的tensorboard和jupyter notebook</a></p>
<p><a href="http://www.cnblogs.com/-chaos/p/3378564.html" target="_blank" rel="external">[2] ssh -D -L -R 差异</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/31457591" target="_blank" rel="external">[3] 跑深度学习代码在linux服务器上的常用操作(ssh,screen,tensorboard,jupyter notebook)</a></p>
<p><a href="http://www.xshellcn.com/wenti/xsh-ssh.html" target="_blank" rel="external">[4] 如何在xshell中创建一个SSH隧道</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/31558973" target="_blank" rel="external">[5] 科普帖：深度学习中GPU和显存分析</a></p>
  
	</div>


    
	<!-- css -->
	<style type="text/css">
	    .center {
	        text-align: center;
	    }
	    .hidden {
	        display: none;
	    }
		.donate_bar a.btn_donate{
			display: inline-block;
			width: 82px;
			height: 82px;
			background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;
			_background: url("http://7xsl28.com1.z0.glb.clouddn.com/btn_reward.gif") no-repeat;

			<!-- http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif
			     因为本 hexo 生成的博客所用的 theme 的 a:hover 带动画效果，
				 为了在让打赏按钮显示效果正常 而 添加了以下几行 css，
				 嵌入其它博客时不一定要它们。 -->
			-webkit-transition: background 0s;
			-moz-transition: background 0s;
			-o-transition: background 0s;
			-ms-transition: background 0s;
			transition: background 0s;
			<!-- /让打赏按钮的效果显示正常 而 添加的几行 css 到此结束 -->
		}

		.donate_bar a.btn_donate:hover{ background-position: 0px -82px;}
		.donate_bar .donate_txt {
			display: block;
			color: #9d9d9d;
			font: 14px/2 "Microsoft Yahei";
		}
		.bold{ font-weight: bold; }
	</style>
	<!-- /css -->

    <!-- Donate Module -->
    <div id="donate_module">

	<!-- btn_donate & tips -->
	<div id="donate_board" class="donate_bar center">
	    <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
		<a id="btn_donate" class="btn_donate" target="_self" href="javascript:;" title="Donate 打赏"></a>
		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>
			
		
	</div>
	<!-- /btn_donate & tips -->

	<!-- donate guide -->
    
	<div id="donate_guide" class="donate_bar center hidden">
        <br>
	    ------------------------------------------------------------------------------------------------------------------------------
	    <br>
	    
	    <div width="100%" align="center"><div name="dashmain" id="dash-main-id-87895f" class="dash-main-3 87895f-0.99"></div></div>
		<script type="text/javascript" charset="utf-8" src="http://www.dashangcloud.com/static/ds.js"></script>
		

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="用微信扫一扫哦~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/wechatpay.png" title="微信打赏 Donate" height="190px" width="auto"/>
		</a>
        
        &nbsp;&nbsp;

		<a href="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="用支付宝扫一扫即可~" class="fancybox" rel="article0">
			<img src="http://7xsl28.com1.z0.glb.clouddn.com/alipay.jpg" title="支付宝打赏 Donate" height="190px" width="auto"/>
		</a>

		<span class="donate_txt">
			我要小额赞助，助作者写出更好的文章！
		</span>

	</div>
	<!-- /donate guide -->

	<!-- donate script -->
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function() {
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}

		function donate_on_web(){
			$('#donate').submit();
        }

		var original_window_onload = window.onload;
        window.onload = function () {
            if (original_window_onload) {
                original_window_onload();
            }
            document.getElementById('donate_board_wdg').className = 'hidden';
		}
	</script>
	<!-- /donate script -->
</div>
<!-- /Donate Module -->
   

		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  
  <span></span> <a href="/categories/错误解决与优化-Err-Opt/">错误解决与优化 | Err&Opt</a>
  </div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/TensorFlow/">TensorFlow</a><a href="/tags/GPU/">GPU</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"husuche## e.g. 2176287895 Your weibo id,It will be used in share button."},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=2094149
2094149" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/12/05/jupyternotebook-1.html" title="远程访问二跳节点的Jupyter Notebook">
  <strong>上一篇：</strong><br/>
  <span>
  远程访问二跳节点的Jupyter Notebook</span>
</a>
</div>


<div class="next">
<a href="/2018/03/15/caffeinstall.html"  title="CentOS 7.x 安装Caffe GPU版本全过程">
 <strong>下一篇：</strong><br/> 
 <span>CentOS 7.x 安装Caffe GPU版本全过程
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <aside class="clearfix">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#卸载CUDA-9-1-（可选）"><span class="toc-number">1.</span> <span class="toc-text">卸载CUDA 9.1 （可选）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装CUDA-8-0"><span class="toc-number">2.</span> <span class="toc-text">安装CUDA 8.0</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装cuDNN"><span class="toc-number">3.</span> <span class="toc-text">安装cuDNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#添加环境变量"><span class="toc-number">4.</span> <span class="toc-text">添加环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装Tensorflow"><span class="toc-number">5.</span> <span class="toc-text">安装Tensorflow</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#进一步的例子：CIFAR10多GPU训练"><span class="toc-number">6.</span> <span class="toc-text">进一步的例子：CIFAR10多GPU训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#本地查看远程服务器Tensorboard-Windows-Linux"><span class="toc-number">7.</span> <span class="toc-text">本地查看远程服务器Tensorboard (Windows, Linux)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装VNC-Server-amp-Viewer"><span class="toc-number">8.</span> <span class="toc-text">安装VNC (Server & Viewer)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">9.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">10.</span> <span class="toc-text">References</span></a></li></ol>
 
 </aside>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="about">
    <p class="asidetitle">Short bio</p>
    <div class="clearfix">
        <!-- <img src="http://7xsl28.com1.z0.glb.clouddn.com/niuzai.jpg" height="74px" width="74px" id="about-image" alt> -->
        <span style="font-size: medium; font-family: Calibri Light, Open Sans, Microsoft YaHei Light">
        whatbeg.com is written by Qiu Hu. He is living in Nanjing, P.R. China.
        <br>
        You can contact Qiu Hu with email.
        <br>
        Just enjoy your reading here!
        <br>
        Comments are always welcome:)
        <br>
        Some interesting non-technical articles can be seen in his WeChat official account: 
        </span>
        <br>
        <img src="https://gitee.com/whyseek/blogimages/raw/master/qrcode.jpg" height="124px" width="124px" id="qrcode" alt>
    </div>
</div>


  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/大数据-Big-Data/" title="大数据 | Big Data">大数据 | Big Data<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/大数据系统与技术-Big-Data/" title="大数据系统与技术 | Big Data">大数据系统与技术 | Big Data<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/成长之路-Biography/" title="成长之路 | Biography">成长之路 | Biography<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/数据科学-Data-Science/" title="数据科学 | Data Science">数据科学 | Data Science<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/机器学习-Mac-Learning/" title="机器学习 | Mac.Learning">机器学习 | Mac.Learning<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/机器学习系统-ML-Sys/" title="机器学习系统 | ML Sys.">机器学习系统 | ML Sys.<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/深度学习-Deep-Learning/" title="深度学习 | Deep Learning">深度学习 | Deep Learning<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/源码阅读-Source/" title="源码阅读 | Source">源码阅读 | Source<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法-Algorithm/" title="算法 | Algorithm">算法 | Algorithm<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/编程语言-Program-Lang/" title="编程语言 | Program Lang.">编程语言 | Program Lang.<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/计算机相关-CS-Related/" title="计算机相关 | CS.Related">计算机相关 | CS.Related<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/译文-Translation/" title="译文 | Translation">译文 | Translation<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书-Reading/" title="读书 | Reading">读书 | Reading<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/错误解决与优化-Err-Opt/" title="错误解决与优化 | Err&amp;Opt">错误解决与优化 | Err&amp;Opt<sup>13</sup></a></li>
		  
		
		  
			<li><a href="/categories/随笔-Essays/" title="随笔 | Essays">随笔 | Essays<sup>7</sup></a></li>
		  
		
		</ul>
</div>


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">23</span></li></ul>
  </div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">标签云</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/C/" style="font-size: 11px;">C++</a> <a href="/tags/CS/" style="font-size: 17px;">CS</a> <a href="/tags/Deep-Learning/" style="font-size: 17px;">Deep Learning</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Git/" style="font-size: 11px;">Git</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Latex/" style="font-size: 11px;">Latex</a> <a href="/tags/Linux/" style="font-size: 14px;">Linux</a> <a href="/tags/Python/" style="font-size: 19px;">Python</a> <a href="/tags/Scala/" style="font-size: 10px;">Scala</a> <a href="/tags/Spark/" style="font-size: 12px;">Spark</a> <a href="/tags/Summary/" style="font-size: 16px;">Summary</a> <a href="/tags/TensorFlow/" style="font-size: 12px;">TensorFlow</a> <a href="/tags/Web/" style="font-size: 12px;">Web</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/人文社科/" style="font-size: 10px;">人文社科</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/历史/" style="font-size: 11px;">历史</a> <a href="/tags/吃喝玩乐/" style="font-size: 10px;">吃喝玩乐</a> <a href="/tags/大数据/" style="font-size: 17px;">大数据</a> <a href="/tags/工具使用/" style="font-size: 10px;">工具使用</a> <a href="/tags/影视/" style="font-size: 11px;">影视</a> <a href="/tags/数据分析/" style="font-size: 16px;">数据分析</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 18px;">深度学习</a> <a href="/tags/源码阅读/" style="font-size: 12px;">源码阅读</a> <a href="/tags/算法/" style="font-size: 13px;">算法</a> <a href="/tags/系统/" style="font-size: 10px;">系统</a> <a href="/tags/论文阅读/" style="font-size: 12px;">论文阅读</a> <a href="/tags/译文/" style="font-size: 12px;">译文</a> <a href="/tags/读书/" style="font-size: 19px;">读书</a> <a href="/tags/错误解决/" style="font-size: 12px;">错误解决</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a>
    </div>
  </div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://www.cnblogs.com/whatbeg/" target="_blank" title="Old Blog">Old Blog</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/whatbeg" target="_blank" title="My Github">My Github</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.matrix67.com/blog/" target="_blank" title="Matrix67">Matrix67</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.liaoxuefeng.com/" target="_blank" title="廖雪峰">廖雪峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.ruanyifeng.com/blog/" target="_blank" title="阮一峰">阮一峰</a>
            
          </li>
        
          <li>
            
            	<a href="http://mindhacks.cn/" target="_blank" title="刘未鹏">刘未鹏</a>
            
          </li>
        
          <li>
            
            	<a href="http://machinelearningmastery.com/blog/" target="_blank" title="ML MYSTERY">ML MYSTERY</a>
            
          </li>
        
          <li>
            
            	<a href="http://freemind.pluskid.org/" target="_blank" title="Free Mind">Free Mind</a>
            
          </li>
        
          <li>
            
            	<a href="http://blog.csdn.net/zouxy09/" target="_blank" title="zouxy机器学习">zouxy机器学习</a>
            
          </li>
        
          <li>
            
            	<a href="http://coolshell.cn" target="_blank" title="酷壳">酷壳</a>
            
          </li>
        
    </ul>
</div>

  <table height=30 cellSpacing=0 cellPadding=0 width=180 border=0>
<form action="http://www.sogou.com/web" target="_blank">
<tr style='font-size:12px;color:#000000'>
<td align="center" width=100><input type="text" name="query" size=14 style='BORDER-RIGHT: #999 1px solid; BORDER-TOP: #999 1px solid; BORDER-LEFT: #999	1px	solid; BORDER-BOTTOM: #999 1px solid; HEIGHT: 19px; BACKGROUND-COLOR: #fff'>
<input type="hidden" name="insite" value="whatbeg.com">
<input type="hidden" name="insite2" value="whatbeg.com"></td>
<td align="left" width=45><input type="submit" name="sogou_submit" value="搜索">
</td></tr></form>
</table>



  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="rsspart">
	<a href="http://eepurl.com/cHO5An" target="_blank" title="email">Email 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
        

	    
		
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/by-nc-nd/4.0" class="cc-opacity" target="_blank">
            <img src="/img/cc-by-nc-nd.svg" alt="Creative Commons" />
          </a>
        </div>
    

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016-2019 
		
		<a href="/about" target="_blank" title="whatbeg">whatbeg</a>
		
		<br>
		<span class="post-count">Total words: <span style="color:orange">358.8k</span></span>
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">
        &nbsp;&nbsp;Total visits:&nbsp;<span style="color:orange" id="busuanzi_value_site_pv"></span>
        </span>
        <span id="busuanzi_container_site_uv">
        &nbsp;&nbsp;You are Visitor No.<span style="color:orange" id="busuanzi_value_site_uv"></span>
        </span>
        </br>
		</p>
		
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    $('#toc.toc-aside').css('display', 'block').addClass('fadeIn');  //侧边栏显示文章目录
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');   //侧边栏显示widget
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>





<script type="text/javascript">

var disqus_shortname = 'whatbeg';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1258390595'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1258390595%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->
<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
  </body>
</html>


