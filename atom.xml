<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Whatbeg&#39;s blog</title>
  <subtitle>当你的才华撑不起你的野心时，就应该静下心来好好学习。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://whatbeg.com/"/>
  <updated>2018-12-17T14:25:32.163Z</updated>
  <id>http://whatbeg.com/</id>
  
  <author>
    <name>whatbeg</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Latex 错误集锦及使用技巧</title>
    <link href="http://whatbeg.com/2018/12/17/latexerror.html"/>
    <id>http://whatbeg.com/2018/12/17/latexerror.html</id>
    <published>2018-12-17T14:24:28.000Z</published>
    <updated>2018-12-17T14:25:32.163Z</updated>
    
    <content type="html">&lt;p&gt;本文记录LaTeX编译，使用过程中的一些错误及其解决方案。&lt;/p&gt;
&lt;p&gt;另外，还包括一些使用技巧，常见的元素使用方法等等。&lt;/p&gt;
&lt;p&gt;便于自己以及后来人查阅解决。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;h3 id=&quot;Latex-“Error-Extra-alignment-tab-has-been-changed-to-cr-“&quot;&gt;&lt;a href=&quot;#Latex-“Error-Extra-alignment-tab-has-been-changed-to-cr-“&quot; class=&quot;headerlink&quot; title=&quot;Latex “Error: Extra alignment tab has been changed to \cr. “&quot;&gt;&lt;/a&gt;Latex “Error: Extra alignment tab has been changed to \cr. “&lt;/h3&gt;&lt;p&gt;是因为&lt;code&gt;\begin{tabular}&lt;/code&gt;后面的参数指定为 A 列，而实际排列了 B 列数据。（A!=B）&lt;/p&gt;
&lt;p&gt;解决方案：检查&lt;code&gt;\begin{tabular}&lt;/code&gt;后面的&lt;code&gt;r|c|l&lt;/code&gt;数量够不够实际列数。&lt;/p&gt;
&lt;h3 id=&quot;File-ended-while-scanning-use-of-writefile&quot;&gt;&lt;a href=&quot;#File-ended-while-scanning-use-of-writefile&quot; class=&quot;headerlink&quot; title=&quot;File ended while scanning use of \@writefile&quot;&gt;&lt;/a&gt;File ended while scanning use of \@writefile&lt;/h3&gt;&lt;p&gt;&lt;code&gt;.aux&lt;/code&gt;不完整，可能是上次编译没通过。&lt;/p&gt;
&lt;p&gt;解决方案：删除掉.aux文件，重新编译；如果依然不行，将.tex和其他图像文件、参考文献保留外，由系统编译生成的文件通通删掉，重新编译。&lt;/p&gt;
&lt;p&gt;使用技巧&lt;/p&gt;
&lt;h3 id=&quot;批量注释、取消注释&quot;&gt;&lt;a href=&quot;#批量注释、取消注释&quot; class=&quot;headerlink&quot; title=&quot;批量注释、取消注释&quot;&gt;&lt;/a&gt;批量注释、取消注释&lt;/h3&gt;&lt;p&gt;Ctrl+Shift+Alt+Right：批量注释&lt;/p&gt;
&lt;p&gt;Ctrl+Shift+Alt+Left：取消注释&lt;/p&gt;
&lt;h3 id=&quot;表格注释&quot;&gt;&lt;a href=&quot;#表格注释&quot; class=&quot;headerlink&quot; title=&quot;表格注释&quot;&gt;&lt;/a&gt;表格注释&lt;/h3&gt;&lt;figure class=&quot;highlight tex&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;table*&amp;#125;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;[htbp]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;caption&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;xx&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;center&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;scalebox&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;0.6&amp;#125;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		\begin&amp;#123;tabular&amp;#125;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;rccccccccccc&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;comment&quot;&gt;%\toprule&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;hline&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;multirow&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;2&amp;#125;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;*&amp;#125;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;xx&amp;#125;&lt;/span&gt;&lt;/span&gt;  &amp;amp; xx &amp;amp;...  &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;\&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			... &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;tnote&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;*&amp;#125;&lt;/span&gt;&lt;/span&gt;   &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;\&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;comment&quot;&gt;%\midrule&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;hline&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			xxx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;hline&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;comment&quot;&gt;%\bottomrule&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;tabular&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;tablenotes&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;footnotesize&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;[*]&lt;/span&gt;&lt;/span&gt; * the note you wanna add&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;tablenotes&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;xx&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;center&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;\&lt;span class=&quot;name&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&amp;#123;table*&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;本文记录LaTeX编译，使用过程中的一些错误及其解决方案。&lt;/p&gt;
&lt;p&gt;另外，还包括一些使用技巧，常见的元素使用方法等等。&lt;/p&gt;
&lt;p&gt;便于自己以及后来人查阅解决。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;h3 id=&quot;Latex-“Error-E
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="Latex" scheme="http://whatbeg.com/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>Scala语法简摘</title>
    <link href="http://whatbeg.com/2018/12/17/scalagrammar.html"/>
    <id>http://whatbeg.com/2018/12/17/scalagrammar.html</id>
    <published>2018-12-17T12:42:02.000Z</published>
    <updated>2018-12-17T12:47:09.674Z</updated>
    
    <content type="html">&lt;p&gt;本文摘录Scala语言的一些语法和关键概念，不成系统，可看做学习笔记罢。&lt;/p&gt;
&lt;h2 id=&quot;类型推断&quot;&gt;&lt;a href=&quot;#类型推断&quot; class=&quot;headerlink&quot; title=&quot;类型推断&quot;&gt;&lt;/a&gt;类型推断&lt;/h2&gt;&lt;p&gt;&lt;code&gt;for (arg &amp;lt;- args)&lt;/code&gt;中&lt;code&gt;arg&lt;/code&gt;一定是val类型，循环中不能改变其值。&lt;/p&gt;
&lt;p&gt;Scala程序员的平衡感：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;崇尚val，不可变对象和没有副作用的方法&lt;/li&gt;
&lt;li&gt;首先想到他们，只有在特定需要或权衡后才选择var，可变对象或者带副作用方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Scala 伴生对象，是一个单例对象，可以看做Java中可能用到的静态方法工具类&lt;/p&gt;
&lt;h2 id=&quot;基本类型&quot;&gt;&lt;a href=&quot;#基本类型&quot; class=&quot;headerlink&quot; title=&quot;基本类型&quot;&gt;&lt;/a&gt;基本类型&lt;/h2&gt;&lt;p&gt;任何方法都可以是操作符，任何操作符都是方法。&lt;/p&gt;
&lt;h2 id=&quot;函数式对象&quot;&gt;&lt;a href=&quot;#函数式对象&quot; class=&quot;headerlink&quot; title=&quot;函数式对象&quot;&gt;&lt;/a&gt;函数式对象&lt;/h2&gt;&lt;p&gt;辅助构造器，关键词this指向当前执行方法被调用的对象实例&lt;br&gt;如果使用在构造器里的话，就是指正在构建的实例&lt;/p&gt;
&lt;p&gt;辅助构造器使用&lt;code&gt;def this(..)&lt;/code&gt;定义，每个Scala构造器调用终将结束于对主构造器的调用。因为主构造器是类的唯一入口点。&lt;/p&gt;
&lt;p&gt;重载操作符，重载后仍然按照原来的优先级，比如* &amp;gt; +&lt;/p&gt;
&lt;p&gt;字面量标识符 &lt;code&gt;yield&lt;/code&gt;可以作为一个变量/常量名&lt;/p&gt;
&lt;h2 id=&quot;函数和闭包&quot;&gt;&lt;a href=&quot;#函数和闭包&quot; class=&quot;headerlink&quot; title=&quot;函数和闭包&quot;&gt;&lt;/a&gt;函数和闭包&lt;/h2&gt;&lt;p&gt;本地函数：函数定义在函数中，本地函数可以随意访问包含它的函数的参数&lt;/p&gt;
&lt;p&gt;函数字面量&lt;br&gt;例子： &lt;code&gt;(x: Int) =&amp;gt; x + 1&lt;/code&gt;&lt;br&gt;在&lt;code&gt;foreach&lt;/code&gt;，&lt;code&gt;filter&lt;/code&gt;等许多函数中会使用到，x的类型往往可以被推断，所以通常也可写成： &lt;code&gt;x =&amp;gt; x + 1&lt;/code&gt;&lt;br&gt;函数字面量存在于源代码，而函数值作为对象存在于运行期。&lt;/p&gt;
&lt;p&gt;更简单的，可以使用占位符语法，用下划线当做一个或者多个参数的占位符，只要每个参数在函数字面量内只出现一次即可，第n个下划线代表第n个参数&lt;br&gt;如&lt;code&gt;filter(_ &amp;gt; 0)&lt;/code&gt;，调用时，用参数来填补下划线，也即&lt;code&gt;filter(x &amp;gt; 0)&lt;/code&gt;&lt;br&gt;如&lt;code&gt;reduce(_ + _)&lt;/code&gt;，调用时，分别填补，也即&lt;code&gt;reduce(l+r)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;偏函数（部分应用函数），一个下划线代替所有参数&lt;/p&gt;
&lt;p&gt;闭包：函数字面量中包含了自由变量的绑定，运行时必须捕获其绑定。&lt;br&gt;如&lt;code&gt;val addMore = (x: Int) =&amp;gt; x + more&lt;/code&gt;，&lt;code&gt;more&lt;/code&gt;是自由变量&lt;br&gt;注意，闭包是一个非常重要的概念，我们时常会想要在循环体，比如foreach,map中加入一些对外部变量的修改，这是我们在其他语言养成的习惯。&lt;br&gt;直觉上，Scala在运行时会捕获自由变量本身，而不是变量指向的值。&lt;br&gt;比如&lt;br&gt;&lt;code&gt;(x: Int) =&amp;gt; x + more&lt;/code&gt;&lt;br&gt;此时创建的闭包可以看到闭包外部对more的改变，同样，闭包对捕获变量做出的修改在闭包外部也可见，比如：&lt;br&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;val someNumber = &lt;span class=&quot;keyword&quot;&gt;List&lt;/span&gt;(-11, -10, 0, 10)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;sum&lt;/span&gt; = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;someNumber.&lt;span class=&quot;keyword&quot;&gt;foreach&lt;/span&gt;(x =&amp;gt; &lt;span class=&quot;keyword&quot;&gt;sum&lt;/span&gt; += x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;scala&lt;/span&gt;&amp;gt; &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;res: Int = -11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;但是如果读者用过Spark的话，一定会了解到Spark的闭包和Scala的闭包是不一样的，原因就在于Spark是分布式环境下运行的。&lt;br&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/rdd-programming-guide.html#understanding-closures-a-nameclosureslinka&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;有Spark官方对closure的描述。&lt;/p&gt;
&lt;p&gt;还是上面那个例子&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;var&lt;/span&gt; sum = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;var&lt;/span&gt; rdd = sc.parallelize(someNumbers)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Wrong: Don&#39;t do this!!&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rdd.foreach(x =&amp;gt; sum += x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Counter value: &quot;&lt;/span&gt; + counter)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// counter = 0, because driver cannot feel the change of counter&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;众所周知，在分布式环境下，rdd的操作形成一个闭包，闭包会先序列化，然后被调度到各个executor执行，且每个executor拿到的其实是序列化后的sum，相当于driver端的一个copy，executor对sum的操作对driver来说不可见，driver的sum对各个executor来说也不可见，所以在driver端，counter始终是0。这就是scala闭包和spark闭包概念的一个最大不同。&lt;/p&gt;
&lt;p&gt;重复参数，即可变参数，尾部加&lt;code&gt;*&lt;/code&gt;号即可，如：&lt;br&gt;&lt;code&gt;def echo(args: String*)&lt;/code&gt;&lt;br&gt;&lt;code&gt;args&lt;/code&gt;其实是&lt;code&gt;Array[String]&lt;/code&gt;类型，但是仍然不能真的传入一个&lt;code&gt;Array[String]&lt;/code&gt;类型的参数，比如要传入&lt;code&gt;arr&lt;/code&gt;，你需要&lt;code&gt;echo(arr: _*)&lt;/code&gt;这么写，意思是告诉编译器把每个元素当参数而不是把arr当做单一参数。&lt;/p&gt;
&lt;p&gt;尾递归：在最后一个动作调用自己的函数。注意只能是单纯的调用自己，不能有多余的表达式，也不能通过其它函数中转&lt;/p&gt;
&lt;p&gt;Scala的核心：简洁，简洁，简洁！&lt;/p&gt;
&lt;h2 id=&quot;控制抽象&quot;&gt;&lt;a href=&quot;#控制抽象&quot; class=&quot;headerlink&quot; title=&quot;控制抽象&quot;&gt;&lt;/a&gt;控制抽象&lt;/h2&gt;&lt;p&gt;柯里化，传名参数&lt;/p&gt;
&lt;h2 id=&quot;组合与继承&quot;&gt;&lt;a href=&quot;#组合与继承&quot; class=&quot;headerlink&quot; title=&quot;组合与继承&quot;&gt;&lt;/a&gt;组合与继承&lt;/h2&gt;&lt;p&gt;组合指一个类持有另一个的引用，借助被引用的类完成任务。&lt;/p&gt;
&lt;p&gt;不带参数，且没有副作用的方法可以不写括号&lt;/p&gt;
&lt;p&gt;“脆基类”问题：意外的方法重写&lt;/p&gt;
&lt;p&gt;多态的重新理解：父类型引用可以指向子类型对象 =&amp;gt; 父类对象可有多种形式 =&amp;gt; 多态&lt;/p&gt;
&lt;p&gt;动态绑定：被调用的实际方法取决于运行期对象基于的类型&lt;/p&gt;
&lt;h2 id=&quot;Scala-层级&quot;&gt;&lt;a href=&quot;#Scala-层级&quot; class=&quot;headerlink&quot; title=&quot;Scala 层级&quot;&gt;&lt;/a&gt;Scala 层级&lt;/h2&gt;&lt;p&gt;所有类的父类是Any类，下辖两个子类，AnyRef（所有引用类的父类）和AnyVal（所有值类的父类）&lt;br&gt;底层有Nothing类和Null类，Null类是所有引用类的子类，不兼容子类型，而Nothing是所有类的子类。&lt;br&gt;scala的==对值类型为自然相等，对引用类型来说被视为equals方法的别名，equals初始定义为引用相等，但许多子类都会重写它以实现自然意义上的相等。&lt;br&gt;要比较引用相等，可以使用eq方法（反面是ne方法）&lt;/p&gt;
&lt;h2 id=&quot;特质-trait&quot;&gt;&lt;a href=&quot;#特质-trait&quot; class=&quot;headerlink&quot; title=&quot;特质(trait)&quot;&gt;&lt;/a&gt;特质(trait)&lt;/h2&gt;&lt;p&gt;特质类似Java中的接口，混入特质可以使用extends或者with&lt;/p&gt;
&lt;p&gt;特质像是带有具体方法的Java接口，并且可以声明字段和维持状态值，特质可以做类定义所能做的事&lt;br&gt;但与类定义有两点不同：&lt;br&gt;1） 特质不能有参数（传递给主构造器）&lt;br&gt;2）super调用时动态绑定的&lt;/p&gt;
&lt;p&gt;胖接口：拥有更多方法的接口&lt;br&gt;特质的一个用法就是把瘦接口变成胖接口&lt;/p&gt;
&lt;p&gt;需要排序比较时，可以混入（mixin）Ordered特质&lt;br&gt;步骤：混入Ordered特质，实现compare方法，可以自动拥有大多数比较方法，但是不会有equals方法  =&amp;gt; 类型擦除&lt;/p&gt;
&lt;p&gt;特质的第二个用法：为类提供可堆叠的改变&lt;/p&gt;
&lt;p&gt;混入多个特质，最右边的特质最先起作用&lt;/p&gt;
&lt;p&gt;不同的组合，不同的次序混入特质，可以依靠少量的特质得到多个不同的类&lt;/p&gt;
&lt;p&gt;特质线性化地解释super&lt;/p&gt;
&lt;p&gt;特质，用还是不用？&lt;br&gt;1） 如果行为不会被重用，那做成具体类&lt;br&gt;2）如果要在多个不相关的类中重用，那就做成特质&lt;br&gt;3）如果希望从Java代码继承，那就是用抽象类 （只含有抽象成员的scala特质会被直接翻译成Java接口）&lt;br&gt;4）如果计划以编译后的方式发布，或者希望外部组织继承它，更倾向使用抽象类&lt;br&gt;5）如果效率很重要，倾向于使用类&lt;/p&gt;
&lt;h2 id=&quot;包和引用&quot;&gt;&lt;a href=&quot;#包和引用&quot; class=&quot;headerlink&quot; title=&quot;包和引用&quot;&gt;&lt;/a&gt;包和引用&lt;/h2&gt;&lt;p&gt;&lt;code&gt;_root_&lt;/code&gt;顶层包：所有你能写出来的顶层包都是&lt;code&gt;_root_&lt;/code&gt;的成员，可以用&lt;code&gt;_root_.yourpack&lt;/code&gt;来访问&lt;/p&gt;
&lt;p&gt;scala应用灵活在于：&lt;br&gt;1）可以随处import&lt;br&gt;2）可以指对象或包&lt;br&gt;3）可以重命名或者隐藏&lt;/p&gt;
&lt;p&gt;每个scala源文件都隐含引用java.lang包，scala包以及单例对象Predef&lt;/p&gt;
&lt;p&gt;访问修饰符：protected比Java中的更加严格：仅限子类访问，同一包中的类不能访问&lt;/p&gt;
&lt;p&gt;访问修饰符限定规则：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;private[X] method/class&lt;/code&gt; 此类或方法对X下所有类和对象可见&lt;/p&gt;
&lt;p&gt;&lt;code&gt;protected[X] method/class&lt;/code&gt; 对此类或子类或修饰符所在的包，类或对象X可见  （？）&lt;/p&gt;
&lt;h2 id=&quot;断言和单元测试&quot;&gt;&lt;a href=&quot;#断言和单元测试&quot; class=&quot;headerlink&quot; title=&quot;断言和单元测试&quot;&gt;&lt;/a&gt;断言和单元测试&lt;/h2&gt;&lt;p&gt;&lt;code&gt;assert&lt;/code&gt;:&lt;br&gt;&lt;code&gt;assert(ele.width === 2)&lt;/code&gt; 三等号，如果不等，会报告&lt;code&gt;“3 dit not equal to 2”&lt;/code&gt;&lt;br&gt;或&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;expect (&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ele&lt;span class=&quot;selector-class&quot;&gt;.width&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;intercept检查是否抛出了期待的异常&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;intercept&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(class[IllegalArgumentException])&lt;/span&gt;&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  elem(&lt;span class=&quot;string&quot;&gt;&#39;x&#39;&lt;/span&gt;, -&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;scala中的一些测试方法：&lt;br&gt;1)  ScalaTest&lt;br&gt;2)  Suite:&lt;br&gt;3)  JUnit&lt;br&gt;4)  TestNG&lt;br&gt;5)  Specs 规格测试， a should be … 具有描述部分和规格部分&lt;br&gt;ScalaCheck 属性测试，测试代码具有属性&lt;/p&gt;
&lt;h2 id=&quot;样例类和模式匹配&quot;&gt;&lt;a href=&quot;#样例类和模式匹配&quot; class=&quot;headerlink&quot; title=&quot;样例类和模式匹配&quot;&gt;&lt;/a&gt;样例类和模式匹配&lt;/h2&gt;&lt;p&gt;样例类 &lt;code&gt;case class CLSNAME(argA: argAType, ...)&lt;/code&gt;&lt;br&gt;最大的好处是他们可以支持模式匹配&lt;/p&gt;
&lt;p&gt;模式有很多种，包括通配，常量模式，变量模式，构造器模式，序列模式，元组模式，类型模式，更高级的还有变量绑定&lt;br&gt;使用类型模式应注意类型擦除，擦除规则不适用于数组&lt;/p&gt;
&lt;p&gt;编译器会为&lt;code&gt;case class&lt;/code&gt;自动生成伴生对象&lt;br&gt;编译器也会为该伴生对象自动生成&lt;code&gt;apply&lt;/code&gt;,&lt;code&gt;unapply&lt;/code&gt;方法&lt;/p&gt;
&lt;p&gt;模式守卫&lt;/p&gt;
&lt;h2 id=&quot;列表：List&quot;&gt;&lt;a href=&quot;#列表：List&quot; class=&quot;headerlink&quot; title=&quot;列表：List&quot;&gt;&lt;/a&gt;列表：List&lt;/h2&gt;&lt;p&gt;List是协变的，意味着，如果S是T的子类，List[S]就是List[T]的子类，故而 &lt;code&gt;List[Nothing]&lt;/code&gt; 是 &lt;code&gt;List[String]&lt;/code&gt; 的子类，故可以&lt;code&gt;val List[String] = List()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;::&lt;/code&gt; 元素与List连接，元素与元素连接&lt;br&gt;&lt;code&gt;:::&lt;/code&gt; List与List连接&lt;/p&gt;
&lt;p&gt;计算长度&lt;code&gt;.length&lt;/code&gt;方法需要遍历整个列表，所以如果判断长度为0的话最好使用&lt;code&gt;.isEmpty&lt;/code&gt;方法&lt;br&gt;访问头部：&lt;code&gt;init&lt;/code&gt;方法，访问除了最后一个元素外的子列表， &lt;code&gt;head&lt;/code&gt;方法：访问第一个元素&lt;br&gt;访问尾部：&lt;code&gt;last&lt;/code&gt;方法，访问最后一个元素， &lt;code&gt;tail&lt;/code&gt;方法：访问除第一个元素外的列表&lt;br&gt;更一般的，&lt;code&gt;drop&lt;/code&gt;, &lt;code&gt;take&lt;/code&gt;方法&lt;/p&gt;
&lt;p&gt;&lt;code&gt;copyToArray&lt;/code&gt;: 把列表元素复制到目标数组的一段连续空间&lt;br&gt;&lt;code&gt;elements&lt;/code&gt;方法：返回迭代器&lt;/p&gt;
&lt;p&gt;其他的List高阶方法：&lt;br&gt;&lt;figure class=&quot;highlight swift&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;map&lt;/span&gt;,flatMap,foreach&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;过滤：&lt;span class=&quot;built_in&quot;&gt;filter&lt;/span&gt;,&lt;span class=&quot;built_in&quot;&gt;partition&lt;/span&gt;,&lt;span class=&quot;built_in&quot;&gt;find&lt;/span&gt;,takeWhile,dropWhile,span&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;论断：forall,exists&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;折叠：/: 和 :\&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;翻转&lt;span class=&quot;built_in&quot;&gt;reverse&lt;/span&gt;，排序sortWith&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;List对象的方法:&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;List&lt;span class=&quot;selector-class&quot;&gt;.apply&lt;/span&gt;,List&lt;span class=&quot;selector-class&quot;&gt;.range&lt;/span&gt;,List.make(&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;a&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;List&lt;span class=&quot;selector-class&quot;&gt;.unzip&lt;/span&gt; 解除啮合&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;连接： List&lt;span class=&quot;selector-class&quot;&gt;.flatten&lt;/span&gt;, List.concat&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;区别在于前者用列表的列表做参数，后者可以直接用多个列表作为参数（以可变参数的方式）&lt;/p&gt;
&lt;p&gt;Scala类型推断&lt;br&gt;Scala采用局部的，基于流的类型推断算法&lt;/p&gt;
&lt;p&gt;通常，一旦有需要推断多态方法类型参数的任务时，类型推断器只会参考第一个参数列表中所有的值参数类型，而不会参考之后的参数。&lt;br&gt;库方法设计原则：&lt;br&gt;如果需要把参数设计为若干非函数值即一个函数值的某种多态方法，需要把函数参数独自放在柯里化参数列表的最后面。&lt;br&gt;即，在柯里化方法中，方法类型仅取决于第一段参数。&lt;br&gt;同样的，一种快速解决类型错误问题的方法：&lt;br&gt;添加明确的类型标注&lt;/p&gt;
&lt;h2 id=&quot;集合与映射&quot;&gt;&lt;a href=&quot;#集合与映射&quot; class=&quot;headerlink&quot; title=&quot;集合与映射&quot;&gt;&lt;/a&gt;集合与映射&lt;/h2&gt;&lt;figure class=&quot;highlight dart&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;Set&lt;/span&gt;, Seq, &lt;span class=&quot;built_in&quot;&gt;Map&lt;/span&gt; -&amp;gt; &lt;span class=&quot;built_in&quot;&gt;Iterable&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;SortedSet&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;SynchronizedMap&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果元素数量不多，不可变集合比可变集合存储更紧凑，空间更加节省。&lt;/p&gt;
&lt;p&gt;可变状态的对象&lt;/p&gt;
&lt;p&gt;状态与var变量常常一起出现，但并不具有严格的关系。&lt;br&gt;类即使没有定义或继承var变量，也可以由于把方法调用传递给其他具有可变状态的对象而带有状态，（有点拗口）&lt;br&gt;类即使包含了var变量也可以仍是纯函数的&lt;/p&gt;
&lt;p&gt;Scala中，对象的每个非私有的var类型成员变量都隐含定义了&lt;code&gt;getter&lt;/code&gt;和&lt;code&gt;setter&lt;/code&gt;方法。&lt;br&gt;&lt;code&gt;getter&lt;/code&gt;方法为&lt;code&gt;x&lt;/code&gt;&lt;br&gt;&lt;code&gt;setter&lt;/code&gt;方法为&lt;code&gt;x_&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;类中字段初始化为0/false/null，&lt;br&gt;&lt;code&gt;var x = _&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;不可以省略 “= _”，否则var x: Float 为抽象变量，而不是未初始化的变量&lt;/p&gt;
&lt;h2 id=&quot;类型参数化（重头戏）&quot;&gt;&lt;a href=&quot;#类型参数化（重头戏）&quot; class=&quot;headerlink&quot; title=&quot;类型参数化（重头戏）&quot;&gt;&lt;/a&gt;类型参数化（重头戏）&lt;/h2&gt;&lt;p&gt;类型参数化让我们能够编写泛型和特质&lt;br&gt;信息隐藏：&lt;br&gt;隐藏主构造器： private加载类名的后面，类参数列表的前面：&lt;br&gt;&lt;figure class=&quot;highlight kotlin&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Queue&lt;/span&gt;[&lt;span class=&quot;title&quot;&gt;T&lt;/span&gt;] &lt;span class=&quot;title&quot;&gt;private&lt;/span&gt; &lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;val&lt;/span&gt; leading&lt;/span&gt;: List[T],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;val&lt;/span&gt; tailing&lt;/span&gt;: List[T]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;那么如何构造对象呢？&lt;/p&gt;
&lt;p&gt;方法1：定义辅助构造器&lt;br&gt;&lt;figure class=&quot;highlight gradle&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;() = &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;(Nil, Nil)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;(elem: T*) = &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;(elem.&lt;span class=&quot;keyword&quot;&gt;toList&lt;/span&gt;, Nil)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;方法2：在伴生对象中编写apply工厂方法&lt;br&gt;&lt;figure class=&quot;highlight markdown&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;object Queue &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  def apply[&lt;span class=&quot;string&quot;&gt;T&lt;/span&gt;](&lt;span class=&quot;link&quot;&gt;xs: T*&lt;/span&gt;) = new Queue[&lt;span class=&quot;string&quot;&gt;T&lt;/span&gt;](&lt;span class=&quot;link&quot;&gt;xs.toList, Nil&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;（注意，scala没有全局方法，方法必须包含在类或对象中）&lt;/p&gt;
&lt;p&gt;另一种信息隐藏的方法，直接把类本身通过暴露特质(trait)而隐藏掉&lt;/p&gt;
&lt;p&gt;如果类或者特质声明时带类型参数，那么创建变量时也要制定具体的参数化的类型&lt;br&gt;如&lt;br&gt;&lt;figure class=&quot;highlight lasso&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;Queue&lt;/span&gt;&lt;span class=&quot;meta&quot;&gt;[&lt;/span&gt;T&lt;span class=&quot;meta&quot;&gt;]&lt;/span&gt; &amp;#123; .. &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Queue是特质， Queue&lt;span class=&quot;meta&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;built_in&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;meta&quot;&gt;]&lt;/span&gt;是类型&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;泛型：通过一个能够广泛适用的类或特质，定义了许多特定的类型&lt;/p&gt;
&lt;p&gt;在scala中，泛型类默认是非协变的子类型化&lt;br&gt;如果要表明参数的子类型化是协变的，需要变成如下形式：&lt;br&gt;&lt;code&gt;trait Queue[+T] { .. }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;加上-号表示需要逆变的子类型化&lt;/p&gt;
&lt;p&gt;只要泛型的参数类型被当做方法参数的类型，那么包含它的类或特质就有可能不能与这个类型参数一起协变&lt;br&gt;&lt;figure class=&quot;highlight ruby&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Queue&lt;/span&gt;[+&lt;span class=&quot;title&quot;&gt;T&lt;/span&gt;] &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;symbol&quot;&gt;x:&lt;/span&gt; T)&lt;/span&gt;&lt;/span&gt; = ...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;下界和上界&lt;br&gt;&lt;code&gt;def append[U&amp;gt;: T](x: U) = new Queue[U](leading, x :: tailing)&lt;/code&gt;&lt;br&gt;语法&lt;code&gt;U &amp;gt;: T&lt;/code&gt;定义了T为U的下界，结果U必须是T的超类型，append的参数现在为U而不是T，返回类型也变成了&lt;code&gt;Queue[U]&lt;/code&gt;，不过，自身即是自身的超类型又是自身的子类型，所以是类似小于等于的关系。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;def orderedMergeSort[T &amp;lt;: Ordered[T]](xs: List[T]): List[T] = ...&lt;/code&gt;&lt;br&gt;语法&lt;code&gt;T &amp;lt;: Ordered[T]&lt;/code&gt;定义了类型参数T具有上界&lt;code&gt;Ordered[T]&lt;/code&gt;，即传递给&lt;code&gt;orderedMergeSort&lt;/code&gt;的参数必须是&lt;code&gt;Ordered[T]&lt;/code&gt;的子类型。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文摘录Scala语言的一些语法和关键概念，不成系统，可看做学习笔记罢。&lt;/p&gt;
&lt;h2 id=&quot;类型推断&quot;&gt;&lt;a href=&quot;#类型推断&quot; class=&quot;headerlink&quot; title=&quot;类型推断&quot;&gt;&lt;/a&gt;类型推断&lt;/h2&gt;&lt;p&gt;&lt;code&gt;for (arg &amp;lt
    
    </summary>
    
      <category term="编程语言 | Program Lang." scheme="http://whatbeg.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-Program-Lang/"/>
    
    
      <category term="Scala" scheme="http://whatbeg.com/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow 错误集锦</title>
    <link href="http://whatbeg.com/2018/12/05/tensorflowtips.html"/>
    <id>http://whatbeg.com/2018/12/05/tensorflowtips.html</id>
    <published>2018-12-05T15:19:18.000Z</published>
    <updated>2018-12-08T15:11:17.843Z</updated>
    
    <content type="html">&lt;p&gt;本文记录笔者在Tensorflow使用上的一些错误的集锦，方便后来人迅速查阅解决问题。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;h3 id=&quot;CreateSession-still-waiting-for-response-from-worker-job-worker-replica-0-task-0&quot;&gt;&lt;a href=&quot;#CreateSession-still-waiting-for-response-from-worker-job-worker-replica-0-task-0&quot; class=&quot;headerlink&quot; title=&quot;CreateSession still waiting for response from worker: /job:worker/replica:0/task:0&quot;&gt;&lt;/a&gt;CreateSession still waiting for response from worker: /job:worker/replica:0/task:0&lt;/h3&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;24.565303&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job ps -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3376&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;24.565372&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job worker -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3330&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3331&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;24.569212&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_server_lib.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;381&lt;/span&gt;] Started server with &lt;span class=&quot;string&quot;&gt;target:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;grpc:&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;//localhost:3376&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;26.170901&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job ps -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3376&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;26.170969&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job worker -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3330&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3331&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;26.174856&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_server_lib.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;381&lt;/span&gt;] Started server with &lt;span class=&quot;string&quot;&gt;target:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;grpc:&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;//localhost:3330&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;27.177003&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job ps -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3376&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;27.177071&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_channel.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;222&lt;/span&gt;] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job worker -&amp;gt; &amp;#123;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3330&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; -&amp;gt; &lt;span class=&quot;string&quot;&gt;localhost:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;3331&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;27.180980&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/rpc/&lt;/span&gt;grpc_server_lib.&lt;span class=&quot;string&quot;&gt;cc:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;381&lt;/span&gt;] Started server with &lt;span class=&quot;string&quot;&gt;target:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;grpc:&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;//localhost:3331&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;34.625459&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;worker&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;34.625513&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;worker&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;36.231936&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;ps&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;36.231971&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;worker&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;37.235899&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;ps&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-05&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;37.235952&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;distributed_runtime&lt;span class=&quot;regexp&quot;&gt;/master.cc:267] CreateSession still waiting for response from worker: /&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;worker&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;首先保证&lt;code&gt;job_name,task_index,ps_hosts,worker_hosts&lt;/code&gt;这四个参数都是正确的,考虑以下这种情况是不正确的：&lt;br&gt;在一个IP为192.168.1.100的机器上启动ps或worker进程：&lt;br&gt;&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;--job_name&lt;/span&gt;=worker&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;--task_index&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;--ps_hosts&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;1.100&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;2222&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;1.101&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;2222&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;--worker_hosts&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;1.100&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;2223&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;1.101&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;2223&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;因为该进程启动位置是192.168.1.100，但是运行参数中指定的task_index为1，对应的IP地址是ps_hosts或worker_hosts的第二项（第一项的task_index为0)，也就是192.168.1.101，和进程本身所在机器的IP不一致。&lt;/p&gt;
&lt;p&gt;另外一种情况也会导致该问题的发生，从TensorFlow-1.4开始，分布式会自动使用环境变量中的代理去连接，如果运行的节点之间不需要代理互连，那么将代理的环境变量移除即可，在脚本的开始位置添加代码：&lt;br&gt;注意这段代码必须写在import tensorflow as tf或者import moxing.tensorflow as mox之前&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;import os&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;os&lt;span class=&quot;selector-class&quot;&gt;.enrivon&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.pop&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&#39;http_proxy&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;os&lt;span class=&quot;selector-class&quot;&gt;.enrivon&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.pop&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&#39;https_proxy&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;— 摘自(&lt;a href=&quot;https://bbs.huaweicloud.com/blogs/463145f7a1d111e89fc57ca23e93a89f&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://bbs.huaweicloud.com/blogs/463145f7a1d111e89fc57ca23e93a89f&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&quot;ImportError-lib64-libstdc-so-6-version-CXXABI-1-3-9’-not-found&quot;&gt;&lt;a href=&quot;#ImportError-lib64-libstdc-so-6-version-CXXABI-1-3-9’-not-found&quot; class=&quot;headerlink&quot; title=&quot;ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found&quot;&gt;&lt;/a&gt;ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found&lt;/h3&gt;&lt;figure class=&quot;highlight qml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/home/experiment/huqiu/anaconda3/lib/python3&lt;span class=&quot;number&quot;&gt;.6&lt;/span&gt;/site-packages/h5py/&lt;span class=&quot;attribute&quot;&gt;__init__.py&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;36&lt;/span&gt;: &lt;span class=&quot;attribute&quot;&gt;FutureWarning&lt;/span&gt;: Conversion &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; the second argument &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; issubdtype from &lt;span class=&quot;string&quot;&gt;`float`&lt;/span&gt; to &lt;span class=&quot;string&quot;&gt;`np.floating`&lt;/span&gt; is deprecated. In future, it will be treated &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`np.float64 == np.dtype(float).type`&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  from ._conv &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; register_converters as _register_converters&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Traceback (most recent call last):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  File &lt;span class=&quot;string&quot;&gt;&quot;trainer.py&quot;&lt;/span&gt;, line &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;&lt;span class=&quot;built_in&quot;&gt;module&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; sklearn.datasets&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  File &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/sklearn/__init__.py&quot;&lt;/span&gt;, line &lt;span class=&quot;number&quot;&gt;134&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;&lt;span class=&quot;built_in&quot;&gt;module&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    from .base &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; clone&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  File &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/sklearn/base.py&quot;&lt;/span&gt;, line &lt;span class=&quot;number&quot;&gt;11&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;&lt;span class=&quot;built_in&quot;&gt;module&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    from scipy &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; sparse&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  File &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/scipy/sparse/__init__.py&quot;&lt;/span&gt;, line &lt;span class=&quot;number&quot;&gt;229&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;&lt;span class=&quot;built_in&quot;&gt;module&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    from .csr &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; *&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  File &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py&quot;&lt;/span&gt;, line &lt;span class=&quot;number&quot;&gt;15&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;&lt;span class=&quot;built_in&quot;&gt;module&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    from ._sparsetools &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; csr_tocsc, csr_tobsr, csr_count_blocks, \&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;ImportError&lt;/span&gt;: /lib64/libstdc++.so&lt;span class=&quot;number&quot;&gt;.6&lt;/span&gt;: version &lt;span class=&quot;string&quot;&gt;`CXXABI_1.3.9&#39; not found (required by /home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;系统的库文件较老，不含CXXABI_1.3.9，可将&lt;code&gt;&amp;lt;Anaconda_PATH&amp;gt;/lib&lt;/code&gt;加入&lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;中，像这样：&lt;br&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;export LD_LIBRARY_PATH=&lt;span class=&quot;regexp&quot;&gt;/home/&lt;/span&gt;../anaconda3/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;:$&lt;span class=&quot;title&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如此，系统会先找到anaconda里面的lib，从而满足要求。&lt;/p&gt;
&lt;p&gt;参考：Stackoverflow. &lt;a href=&quot;https://stackoverflow.com/questions/49875588/importerror-lib64-libstdc-so-6-version-cxxabi-1-3-9-not-found&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;问题2&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;分布式Tensorflow-ps端运行出现tensorflow-python-framework-errors-impl-UnavailableError-OS-Error&quot;&gt;&lt;a href=&quot;#分布式Tensorflow-ps端运行出现tensorflow-python-framework-errors-impl-UnavailableError-OS-Error&quot; class=&quot;headerlink&quot; title=&quot;分布式Tensorflow, ps端运行出现tensorflow.python.framework.errors_impl.UnavailableError: OS Error&quot;&gt;&lt;/a&gt;分布式Tensorflow, ps端运行出现tensorflow.python.framework.errors_impl.UnavailableError: OS Error&lt;/h3&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;2018-12-07 15:40:05.167922: I tensorflow/core/distributed_runtime/rpc/grpc_channel.&lt;span class=&quot;keyword&quot;&gt;cc&lt;/span&gt;:222] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job ps -&amp;gt; &amp;#123;0 -&amp;gt; localhost:3333&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2018-12-07 15:40:05.167970: I tensorflow/core/distributed_runtime/rpc/grpc_channel.&lt;span class=&quot;keyword&quot;&gt;cc&lt;/span&gt;:222] Initialize GrpcChannelCache &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; job worker -&amp;gt; &amp;#123;0 -&amp;gt; 192.168.100.36:3333, 1 -&amp;gt; 192.168.100.37:3333&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2018-12-07 15:40:05.171857: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.&lt;span class=&quot;keyword&quot;&gt;cc&lt;/span&gt;:381] Started server with target: grpc:&lt;span class=&quot;comment&quot;&gt;//localhost:3333&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Parameter server: waiting &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;cluster&lt;/span&gt; connection...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2018-12-07 15:40:05.213496: &lt;span class=&quot;keyword&quot;&gt;E&lt;/span&gt; tensorflow/core/distributed_runtime/master.&lt;span class=&quot;keyword&quot;&gt;cc&lt;/span&gt;:315] CreateSession failed because worker /job:worker/replica:0/task:0 returned &lt;span class=&quot;keyword&quot;&gt;error&lt;/span&gt;: Unavailable: OS &lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2018-12-07 15:40:05.213645: &lt;span class=&quot;keyword&quot;&gt;E&lt;/span&gt; tensorflow/core/distributed_runtime/master.&lt;span class=&quot;keyword&quot;&gt;cc&lt;/span&gt;:315] CreateSession failed because worker /job:worker/replica:0/task:1 returned &lt;span class=&quot;keyword&quot;&gt;error&lt;/span&gt;: Unavailable: OS &lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Traceback (most recent call last):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1334, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _do_call&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; fn(*&lt;span class=&quot;keyword&quot;&gt;args&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1317, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _run_fn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    self._extend_graph()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1352, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _extend_graph&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    tf_session.ExtendSession(self._session)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensorflow.python.framework.errors_impl.UnavailableError: OS &lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;During handling of the above exception, another exception occurred:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Traceback (most recent call last):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;trainer.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 364, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &amp;lt;module&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    tf.&lt;span class=&quot;keyword&quot;&gt;app&lt;/span&gt;.&lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;(main=main, argv=[sys.argv[0]] + unparsed)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 125, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    _sys.&lt;span class=&quot;keyword&quot;&gt;exit&lt;/span&gt;(main(argv))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;trainer.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 70, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; main&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    num_classes=num_classes)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;trainer.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 138, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; parameter_server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sess.&lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;(tf.report_uninitialized_variables())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 929, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    run_metadata_ptr)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1152, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _run&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    feed_dict_tensor, options, run_metadata)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1328, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _do_run&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    run_metadata)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;/home/experiment/huqiu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py&quot;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;line&lt;/span&gt; 1348, &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; _do_call&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    raise &lt;span class=&quot;keyword&quot;&gt;type&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;e&lt;/span&gt;)(node_def, op, message)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensorflow.python.framework.errors_impl.UnavailableError: OS &lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如上所示，运行多机分布式 tensorflow 的 parameter server 进程时，出现这个错误。&lt;br&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/17852#issuecomment-414470314&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;说道：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This has been troubling me for a while. I found out that the problem&lt;br&gt;is that GRPC uses the native “epoll” polling engine for communication.&lt;br&gt;Changing this to a portable polling engine solved this issue for me.&lt;br&gt;The way to do is to set the environment variable,&lt;br&gt;“GRPC_POLL_STRATEGY=poll” before running the tensorflow programs. This&lt;br&gt;solved this issue for me. For reference, see,&lt;br&gt;&lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/environment_variables.md&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/grpc/grpc/blob/master/doc/environment_variables.md&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;按照其所属，在环境变量中新增一条：&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;export&lt;/span&gt; GRPC_POLL_STRATEGY=&lt;span class=&quot;literal&quot;&gt;poll&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;成功解决问题。&lt;/p&gt;
&lt;h2 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=&quot;headerlink&quot; title=&quot;参考文献&quot;&gt;&lt;/a&gt;参考文献&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://bbs.huaweicloud.com/blogs/463145f7a1d111e89fc57ca23e93a89f&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;问题1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/shenqixiaojiang/distributeTensorflow/issues/2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;问题1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文记录笔者在Tensorflow使用上的一些错误的集锦，方便后来人迅速查阅解决问题。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;p&gt;我是留白。&lt;/p&gt;
&lt;h3 id=&quot;CreateSession-still-waiting-for-response-from-worker-jo
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="大数据" scheme="http://whatbeg.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="TensorFlow" scheme="http://whatbeg.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>远程访问二跳节点的Jupyter Notebook</title>
    <link href="http://whatbeg.com/2018/12/05/jupyternotebook-1.html"/>
    <id>http://whatbeg.com/2018/12/05/jupyternotebook-1.html</id>
    <published>2018-12-05T15:13:49.000Z</published>
    <updated>2018-12-08T15:10:31.452Z</updated>
    
    <content type="html">&lt;p&gt;用 Jupyter Notebook 运行 Python 程序时，本机有些吃力，于是想转向集群的服务器来运行。&lt;/p&gt;
&lt;p&gt;可是本机和集群服务器之间还有一个跳板机，横加阻隔，较为麻烦，最终经过一段时间的摸索，决定采用两边各进一步的方法：服务端 jupyter notebook 远程访问 + 本机端端口转发。&lt;/p&gt;
&lt;p&gt;为便于说明，设本机为A，跳板机B，目标运行服务器C。我们的 notebook 将在C上运行。&lt;/p&gt;
&lt;p&gt;首先配置C上的notebook，使得可以被内网别的机器（如B）直接访问。&lt;/p&gt;
&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;. 登陆远程服务器&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;.生成配置文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;variable&quot;&gt;$ &lt;/span&gt;jupyter notebook --generate-config&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;. 修改默认配置文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;variable&quot;&gt;$ &lt;/span&gt;vim ~&lt;span class=&quot;regexp&quot;&gt;/.jupyter/jupyter&lt;/span&gt;_notebook_config.py&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;进行如下修改：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;c.NotebookApp.ip = &lt;span class=&quot;string&quot;&gt;&#39;0.0.0.0&#39;&lt;/span&gt;      &lt;span class=&quot;comment&quot;&gt;# 支持其它IP访问，关键&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;c.NotebookApp.port = &lt;span class=&quot;number&quot;&gt;8888&lt;/span&gt;         &lt;span class=&quot;comment&quot;&gt;# Jupyter Notebook 惯用端口&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;. 启动jupyter notebook：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;variable&quot;&gt;$ &lt;/span&gt;jupyter notebook&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;启动后如下图所示，&lt;br&gt;&lt;img src=&quot;https://gitee.com/whyseek/blogimages/raw/master/jupyter_notebook.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;记住图中的&lt;code&gt;http://0.0.0.0:8888/?token&lt;/code&gt;后面的token, 后面认证需要用。&lt;/p&gt;
&lt;p&gt;这样我们第一步就做完了，这时，在跳板机B上可以随便访问C的8888端口，即其jupyter notebook。&lt;/p&gt;
&lt;p&gt;第二部就是建立端口转发，使得我们在本地浏览器中输入&lt;code&gt;localhost:xxxx&lt;/code&gt;即可以经过跳板机访问&lt;code&gt;C:8888&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;通过ssh可以建立本地转发。&lt;br&gt;&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ssh -f -NL &lt;span class=&quot;number&quot;&gt;16888&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&amp;lt;C_ip&amp;gt;&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;8888&lt;/span&gt; [username@]&amp;lt;B_ip&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样意味着我们访问&lt;code&gt;localhost:16888&lt;/code&gt;端口时可以通过B转发到&lt;c_ip&gt;:8888，也即我们可以访问C的notebook啦。&lt;/c_ip&gt;&lt;/p&gt;
&lt;p&gt;最开始的时候会让输入密码，在最下面输入刚说的token，然后设置新密码即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;用 Jupyter Notebook 运行 Python 程序时，本机有些吃力，于是想转向集群的服务器来运行。&lt;/p&gt;
&lt;p&gt;可是本机和集群服务器之间还有一个跳板机，横加阻隔，较为麻烦，最终经过一段时间的摸索，决定采用两边各进一步的方法：服务端 jupyter notebo
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="工具使用" scheme="http://whatbeg.com/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7 卸载CUDA 9.1 安装CUDA8.0 并安装Tensorflow GPU版</title>
    <link href="http://whatbeg.com/2018/03/17/cudainstall.html"/>
    <id>http://whatbeg.com/2018/03/17/cudainstall.html</id>
    <published>2018-03-17T08:46:42.000Z</published>
    <updated>2018-03-18T06:31:26.936Z</updated>
    
    <content type="html">&lt;p&gt;事前各软件版本：&lt;br&gt;NVIDIA驱动：390.25&lt;br&gt;CUDA: 9.1&lt;/p&gt;
&lt;p&gt;现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9.1，但是安装目录下cuda软连接指向cuda-8.0即可。&lt;/p&gt;
&lt;h2 id=&quot;卸载CUDA-9-1-（可选）&quot;&gt;&lt;a href=&quot;#卸载CUDA-9-1-（可选）&quot; class=&quot;headerlink&quot; title=&quot;卸载CUDA 9.1 （可选）&quot;&gt;&lt;/a&gt;卸载CUDA 9.1 （可选）&lt;/h2&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; /usr/&lt;span class=&quot;keyword&quot;&gt;local&lt;/span&gt;/cuda-9.1/bin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ./uninstall_cuda_toolkit_9.1.&lt;span class=&quot;keyword&quot;&gt;pl&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装CUDA-8-0&quot;&gt;&lt;a href=&quot;#安装CUDA-8-0&quot; class=&quot;headerlink&quot; title=&quot;安装CUDA 8.0&quot;&gt;&lt;/a&gt;安装CUDA 8.0&lt;/h2&gt;&lt;p&gt;从官网下载&lt;a href=&quot;https://developer.nvidia.com/cuda-80-ga2-download-archive&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CUDA 8.0 ToolKit&lt;/a&gt;。&lt;br&gt;这里我下载的是&lt;code&gt;cuda_8.0.61_375.26_linux.run&lt;/code&gt;，并下载补丁&lt;code&gt;cuda_8.0.61.2_linux.run&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;进入root用户，将上述两个文件拷贝到&lt;code&gt;/root&lt;/code&gt;（或其他地方），直接用root用户较方便。&lt;/p&gt;
&lt;figure class=&quot;highlight applescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;chmod +x cuda_8&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.61&lt;/span&gt;*  &lt;span class=&quot;comment&quot;&gt;# 加上执行权限&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./cuda_8&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.61&lt;/span&gt;_375&lt;span class=&quot;number&quot;&gt;.26&lt;/span&gt;_linux.&lt;span class=&quot;built_in&quot;&gt;run&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;第一个问题，是否安装NVIDIA驱动，选n（不安装）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;其他问题自己决定，默认装到/usr/&lt;span class=&quot;keyword&quot;&gt;local&lt;/span&gt;即可&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后可以到Samples目录，先make编译，然后到bin下找到&lt;code&gt;deviceQuery&lt;/code&gt;，执行&lt;code&gt;./deviceQuery&lt;/code&gt;，&lt;br&gt;如果安装成功应该会显示类似如下信息：&lt;br&gt;&lt;figure class=&quot;highlight nix&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;...(省略)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deviceQuery, CUDA &lt;span class=&quot;attr&quot;&gt;Driver&lt;/span&gt; = CUDART, CUDA Driver &lt;span class=&quot;attr&quot;&gt;Version&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;9.1&lt;/span&gt;, CUDA Runtime &lt;span class=&quot;attr&quot;&gt;Version&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;8.0&lt;/span&gt;, &lt;span class=&quot;attr&quot;&gt;NumDevs&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;attr&quot;&gt;Device0&lt;/span&gt; = Tesla K80, &lt;span class=&quot;attr&quot;&gt;Device0&lt;/span&gt; = Tesla K80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Result&lt;/span&gt; = PASS&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装cuDNN&quot;&gt;&lt;a href=&quot;#安装cuDNN&quot; class=&quot;headerlink&quot; title=&quot;安装cuDNN&quot;&gt;&lt;/a&gt;安装cuDNN&lt;/h2&gt;&lt;p&gt;cuDNN是NVIDIA专为Deep Learning应用开发的支持库。&lt;br&gt;我们打算安装Tensorflow 1.4.0，该版本要求&lt;code&gt;libcudnn.so.6&lt;/code&gt;，所以下载v6版本的cuDNN。&lt;br&gt;到&lt;a href=&quot;https://developer.nvidia.com/rdp/cudnn-download&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里下载&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载：&lt;code&gt;cudnn-8.0-linux-x64-v6.0.tgz&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;将其传到&lt;code&gt;/usr/local&lt;/code&gt;目录下，然后解压即可：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;-zxvf&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;cudnn-8&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0-linux-x64-v6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.tgz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样就成功安装了CUDA 8.0这一套，但是驱动仍然用的高版本驱动390.25，不过应该没关系的吧。&lt;/p&gt;
&lt;h2 id=&quot;添加环境变量&quot;&gt;&lt;a href=&quot;#添加环境变量&quot; class=&quot;headerlink&quot; title=&quot;添加环境变量&quot;&gt;&lt;/a&gt;添加环境变量&lt;/h2&gt;&lt;figure class=&quot;highlight xquery&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vim ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;添加：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export LD_LIBRARY_PATH=/usr/local/cuda-&lt;span class=&quot;number&quot;&gt;8.0&lt;/span&gt;/lib64:/usr/local/cuda-&lt;span class=&quot;number&quot;&gt;8.0&lt;/span&gt;/extras/CUPTI/lib64:$LD_LIBRARY_PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export CUDA_HOME=/usr/local/cuda-&lt;span class=&quot;number&quot;&gt;8.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export PATH=$CUDA_HOME/bin:$PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;source .bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装Tensorflow&quot;&gt;&lt;a href=&quot;#安装Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;安装Tensorflow&quot;&gt;&lt;/a&gt;安装Tensorflow&lt;/h2&gt;&lt;figure class=&quot;highlight cmake&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; tensorflow-gpu==&lt;span class=&quot;number&quot;&gt;1.4&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;试一把，import tensorflow成功即说明CUDA，cuDNN安装完成，且版本没问题。&lt;/p&gt;
&lt;p&gt;运行两个GPU的例子：&lt;br&gt;&lt;figure class=&quot;highlight livecodeserver&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;import tensorflow &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;c = []&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; d &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; [&lt;span class=&quot;string&quot;&gt;&#39;/device:GPU:0&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;/device:GPU:1&#39;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; tf.device(d):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;a&lt;/span&gt; = tf.&lt;span class=&quot;built_in&quot;&gt;constant&lt;/span&gt;([&lt;span class=&quot;number&quot;&gt;1.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;6.0&lt;/span&gt;], shape=[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        b = tf.&lt;span class=&quot;built_in&quot;&gt;constant&lt;/span&gt;([&lt;span class=&quot;number&quot;&gt;1.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5.0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;6.0&lt;/span&gt;], shape=[&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        c.append(tf.matmul(&lt;span class=&quot;keyword&quot;&gt;a&lt;/span&gt;, b))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; tf.device(&lt;span class=&quot;string&quot;&gt;&#39;/cpu:0&#39;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt; = tf.add_n(c)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Creates a session with log_device_placement set to True.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Runs the op.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(sess.run(&lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出：&lt;br&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;MatMul_1:&lt;/span&gt; (MatMul): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759031&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] MatMul_1: (MatMul)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;MatMul:&lt;/span&gt; (MatMul): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759079&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] MatMul: (MatMul)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;AddN:&lt;/span&gt; (AddN): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;CPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759100&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] AddN: (AddN)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;CPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;Const_3:&lt;/span&gt; (Const): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759126&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] Const_3: (Const)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;Const_2:&lt;/span&gt; (Const): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759145&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] Const_2: (Const)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;Const_1:&lt;/span&gt; (Const): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759167&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] Const_1: (Const)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;Const:&lt;/span&gt; (Const): &lt;span class=&quot;regexp&quot;&gt;/job:localhost/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;replica:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/task:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-03&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00.759185&lt;/span&gt;: I tensorflow&lt;span class=&quot;regexp&quot;&gt;/core/&lt;/span&gt;common_runtime&lt;span class=&quot;regexp&quot;&gt;/placer.cc:874] Const: (Const)/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;job:&lt;/span&gt;localhost&lt;span class=&quot;regexp&quot;&gt;/replica:0/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;task:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;/&lt;span class=&quot;string&quot;&gt;device:&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;GPU:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[[ &lt;span class=&quot;number&quot;&gt;44.&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;56.&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; [ &lt;span class=&quot;number&quot;&gt;98.&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;128.&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;从输出结果看，确实使用了两块GPU，基本说明可以同时使用两块GPU。&lt;/p&gt;
&lt;h2 id=&quot;进一步的例子：CIFAR10多GPU训练&quot;&gt;&lt;a href=&quot;#进一步的例子：CIFAR10多GPU训练&quot; class=&quot;headerlink&quot; title=&quot;进一步的例子：CIFAR10多GPU训练&quot;&gt;&lt;/a&gt;进一步的例子：CIFAR10多GPU训练&lt;/h2&gt;&lt;p&gt;进一步地，我们采用Tensorflow的tutorial中的一个例子来验证多块GPU卡带来的加速效果。&lt;/p&gt;
&lt;p&gt;Tutorial地址见&lt;a href=&quot;https://www.tensorflow.org/tutorials/deep_cnn&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;。&lt;br&gt;具体model训练程序在&lt;a href=&quot;https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;运行cifar10多GPU训练，&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;python cifar10_multi_gpu_train&lt;span class=&quot;selector-class&quot;&gt;.py&lt;/span&gt; --num_gpus=&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以用如下命令设置每隔一秒查看一下GPU状态：&lt;br&gt;&lt;figure class=&quot;highlight armasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;nvidia&lt;/span&gt;-&lt;span class=&quot;keyword&quot;&gt;smi &lt;/span&gt;-l &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;或者使用gpustat工具，更简洁的观察GPU动态状态变化：&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; gpustat&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;watch &lt;span class=&quot;comment&quot;&gt;--color -n1 gpustat -cpu&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可见在两块Tesla P100上，训练吞吐率大约为 34000 image/sec 左右，在单块 GPU 上，训练吞吐率大约最高为 19000 image/sec。从目前结果看来，虽然两块GPU能够大大加速训练，但是毕竟还是无法做到标准的线性的加速。&lt;/p&gt;
&lt;h2 id=&quot;本地查看远程服务器Tensorboard-Windows-Linux&quot;&gt;&lt;a href=&quot;#本地查看远程服务器Tensorboard-Windows-Linux&quot; class=&quot;headerlink&quot; title=&quot;本地查看远程服务器Tensorboard (Windows, Linux)&quot;&gt;&lt;/a&gt;本地查看远程服务器Tensorboard (Windows, Linux)&lt;/h2&gt;&lt;p&gt;核心思想是利用SSH的转发/隧道机制。Tensorboard起在远程服务器本地6006端口，我们本地用一个端口去访问比如16006，我们建立一个隧道，将我们对16006端口的访问转发到远程服务器的6006端口即可。&lt;/p&gt;
&lt;p&gt;一般本地和远程在一个局域网内，可以如下做：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在Lunux下:&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;-L&lt;/span&gt; 16006&lt;span class=&quot;selector-pseudo&quot;&gt;:127.0.0.1&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:6006&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;user&lt;/span&gt;@&lt;span class=&quot;keyword&quot;&gt;server.address&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensorboard –logdir=”tensorboard”&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;在本地主机访问 http://&lt;span class=&quot;number&quot;&gt;127.0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0.1&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;16006&lt;/span&gt;/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;建立本地16006端口到服务器6006端口的正向转发&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows下：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Windows 10中除了一个开发者模式，内嵌一个linux系统，可以进入如上做。但是一般我们在Windows下还是用putty，Xshell，MobaXterm等远程登录软件为主，这里以Xshell为例。&lt;/p&gt;
&lt;p&gt;步骤为：&lt;br&gt;1、新建一个会话指向服务器，设置属性，点“隧道”，然后点中间的“添加”，添加的信息如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/xshell.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;X11转移那里打钩，也必须保证远程服务器允许X11转发，具体的，在&lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;中设置&lt;code&gt;X11forwarding&lt;/code&gt;为&lt;code&gt;yes&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这样即建立了一个隧道。然后在服务器上启动Tensorboard，在本地浏览器打开&lt;code&gt;http://127.0.0.1:16006&lt;/code&gt;即可访问TensorBoard。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端位于外网&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然还有一种情况就是客户端位于外网，无法直接建立隧道。&lt;/p&gt;
&lt;p&gt;此种情况下 [1]，服务器可以通过IP地址寻址客户端，所以在服务器端建立与客户端的反向链接。通过-N -f后台运行。具体命令为：&lt;/p&gt;
&lt;p&gt;在服务器主机上执行：&lt;br&gt;&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ssh -f -NR &amp;lt;client_port&amp;gt;&lt;span class=&quot;symbol&quot;&gt;:localhost&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&amp;lt;server_port&amp;gt;&lt;/span&gt; [username@]&amp;lt;client_ip_address&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;除了本地查看Tensorboard，也可以启动服务器桌面来直接看Tensorboard。具体可以安装VNC Server和Viewer。&lt;/p&gt;
&lt;h2 id=&quot;安装VNC-Server-amp-Viewer&quot;&gt;&lt;a href=&quot;#安装VNC-Server-amp-Viewer&quot; class=&quot;headerlink&quot; title=&quot;安装VNC (Server &amp;amp; Viewer)&quot;&gt;&lt;/a&gt;安装VNC (Server &amp;amp; Viewer)&lt;/h2&gt;&lt;p&gt;1、服务器安装VNC Server: &lt;code&gt;yum -y install tigervnc-server&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2、配置分辨率和用户登录信息&lt;br&gt;&lt;figure class=&quot;highlight gradle&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# vim &lt;span class=&quot;regexp&quot;&gt;/lib/&lt;/span&gt;systemd&lt;span class=&quot;regexp&quot;&gt;/system/&lt;/span&gt;vncserver@.service&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;写入&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;VNCSERVERS=&lt;span class=&quot;string&quot;&gt;&quot;2:root&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;VNCSERVERARGS[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;]=&lt;span class=&quot;string&quot;&gt;&quot;-geometry 1024x768&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3、下载VNC Viewer，VNC Viewer连接，可能出现Timeout的问题，可能是服务器设置了防火墙，如下命令关闭：&lt;br&gt;&lt;figure class=&quot;highlight pf&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;iptables -I INPUT -p tcp --dport &lt;span class=&quot;number&quot;&gt;5801&lt;/span&gt; -j ACCEPT  &lt;span class=&quot;comment&quot;&gt;# 浏览器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iptables -I INPUT -p tcp --dport &lt;span class=&quot;number&quot;&gt;5901&lt;/span&gt; -j ACCEPT  &lt;span class=&quot;comment&quot;&gt;# VNC Viewer&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;或者进入/etc/sysconfig/iptables添加一行：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;-A INPUT -m &lt;span class=&quot;keyword&quot;&gt;state&lt;/span&gt; --state NEW -m tcp -p tcp --dport &lt;span class=&quot;number&quot;&gt;5900&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;5903&lt;/span&gt; -j ACCEPT&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;黑屏解决方案：&lt;br&gt;在&lt;code&gt;/root/.vnc/xtartup&lt;/code&gt;文件中：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# unset SESSION_MANAGER &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# exec /etc/X11/xinit/xinitrc&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;注释掉以上两行，添加如下几行：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[ -x /etc/.vnc/xstartup ] &amp;amp;&amp;amp; &lt;span class=&quot;built_in&quot;&gt;exec&lt;/span&gt; /etc/.vnc/xstartup&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[ -r &lt;span class=&quot;variable&quot;&gt;$HOME&lt;/span&gt;/.Xresources ] &amp;amp;&amp;amp; xrdb &lt;span class=&quot;variable&quot;&gt;$HOME&lt;/span&gt;/.Xresources &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;xsetroot -solid grey &lt;span class=&quot;comment&quot;&gt;#vncconfig -iconic &amp;amp; &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;xterm -geometry 80x24+10+10 -ls -title &lt;span class=&quot;string&quot;&gt;&quot;&lt;span class=&quot;variable&quot;&gt;$VNCDESKTOP&lt;/span&gt; Desktop&quot;&lt;/span&gt; &amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;twm &amp;amp; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gnome-session &amp;amp;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;本文主要讲述了CUDA 8.0的安装细节，TensorFlow的安装，多GPU训练实例，以及远程服务器TensorBoard查看，以及VNC（Virtual Network Console）的服务端和客户端的安装。&lt;br&gt;更多的一些错误及解决方案因为目前还解决不全，一律放到后面的&lt;a href=&quot;&quot;&gt;《TensorFlow, GPU错误及优化集锦》&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/silent56_th/article/details/69367446&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[1] 远程使用内网服务器的tensorboard和jupyter notebook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/-chaos/p/3378564.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[2] ssh -D -L -R 差异&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31457591&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[3] 跑深度学习代码在linux服务器上的常用操作(ssh,screen,tensorboard,jupyter notebook)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.xshellcn.com/wenti/xsh-ssh.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[4] 如何在xshell中创建一个SSH隧道&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31558973&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[5] 科普帖：深度学习中GPU和显存分析&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;事前各软件版本：&lt;br&gt;NVIDIA驱动：390.25&lt;br&gt;CUDA: 9.1&lt;/p&gt;
&lt;p&gt;现在Tensorflow不支持CUDA 9.1，所以采用降级的办法来解决，将CUDA降为8.0，由于NVIDIA驱动可以向下兼容，所以不用卸载NVIDIA驱动。当然也可以不卸载9
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://whatbeg.com/tags/TensorFlow/"/>
    
      <category term="GPU" scheme="http://whatbeg.com/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7.x 安装Caffe GPU版本全过程</title>
    <link href="http://whatbeg.com/2018/03/15/caffeinstall.html"/>
    <id>http://whatbeg.com/2018/03/15/caffeinstall.html</id>
    <published>2018-03-15T14:09:46.000Z</published>
    <updated>2018-03-20T13:33:28.955Z</updated>
    
    <content type="html">&lt;p&gt;本文假设已经安装好了CUDA 8.0，NVIDIA GPU驱动以及cuDNN且读者主机可以连接互联网。&lt;/p&gt;
&lt;p&gt;CUDA 8.0的安装也可见&lt;a href=&quot;http://whatbeg.com/2018/03/17/cudainstall.html&quot;&gt;《CentOS 7 卸载CUDA 9.1 安装CUDA8.0》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;建议先通读本文再决定安装步骤，直接按照本文一步一步来并不是最佳实践，因为本文踩过一些坑。&lt;/p&gt;
&lt;h2 id=&quot;安装一些通用的依赖：&quot;&gt;&lt;a href=&quot;#安装一些通用的依赖：&quot; class=&quot;headerlink&quot; title=&quot;安装一些通用的依赖：&quot;&gt;&lt;/a&gt;安装一些通用的依赖：&lt;/h2&gt;&lt;figure class=&quot;highlight mipsasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo yum &lt;span class=&quot;keyword&quot;&gt;install &lt;/span&gt;protobuf-devel leveldb-devel snappy-devel opencv-devel &lt;span class=&quot;keyword&quot;&gt;boost-devel &lt;/span&gt;hdf5-devel&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;~~&lt;/p&gt;
&lt;p&gt;我&lt;/p&gt;
&lt;p&gt;是&lt;/p&gt;
&lt;p&gt;空&lt;/p&gt;
&lt;p&gt;行&lt;/p&gt;
&lt;p&gt;~~&lt;/p&gt;
&lt;h2 id=&quot;安装cmake&quot;&gt;&lt;a href=&quot;#安装cmake&quot; class=&quot;headerlink&quot; title=&quot;安装cmake&quot;&gt;&lt;/a&gt;安装cmake&lt;/h2&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget https:&lt;span class=&quot;comment&quot;&gt;//cmake.org/files/v3.6/cmake-3.6.0.tar.gz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd cmake-&lt;span class=&quot;number&quot;&gt;3.6&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.tar&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.gz&lt;/span&gt;/ &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./bootstrap &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gmake&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gmake install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装glog-gflags-lmdb：&quot;&gt;&lt;a href=&quot;#安装glog-gflags-lmdb：&quot; class=&quot;headerlink&quot; title=&quot;安装glog, gflags, lmdb：&quot;&gt;&lt;/a&gt;安装glog, gflags, lmdb：&lt;/h2&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# glog&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//storage.googleapis.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/google-code-archive-downloads/v2/code.google.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/google-glog/glog-&lt;span class=&quot;number&quot;&gt;0.3&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar zxvf glog-&lt;span class=&quot;number&quot;&gt;0.3&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; glog-&lt;span class=&quot;number&quot;&gt;0.3&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./configure&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; &amp;amp;&amp;amp; &lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# gflags&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//github.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/schuhschuh/gflags/archive/master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;unzip master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; gflags-master&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;mkdir&lt;/span&gt; build &amp;amp;&amp;amp; &lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export CXXFLAGS=&lt;span class=&quot;string&quot;&gt;&quot;-fPIC&quot;&lt;/span&gt; &amp;amp;&amp;amp; cmake .. &amp;amp;&amp;amp; &lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; VERBOSE=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; &amp;amp;&amp;amp; &lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# lmdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git clone http&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//github.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/LMDB/lmdb.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; lmdb/libraries/liblmdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;或&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//github.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/LMDB/lmdb/archive/mdb.master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;unzip mdb.master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; lmdb-mdb.master/libraries/liblmdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; &amp;amp;&amp;amp; &lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装atlas&quot;&gt;&lt;a href=&quot;#安装atlas&quot; class=&quot;headerlink&quot; title=&quot;安装atlas&quot;&gt;&lt;/a&gt;安装atlas&lt;/h2&gt;&lt;figure class=&quot;highlight cmake&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; atlas-devel&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装NCCL&quot;&gt;&lt;a href=&quot;#安装NCCL&quot; class=&quot;headerlink&quot; title=&quot;安装NCCL&quot;&gt;&lt;/a&gt;安装NCCL&lt;/h2&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;https&lt;/span&gt;://github.com/NVIDIA/nccl.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd nccl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;或&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget https://github.com/NVIDIA/nccl/archive/&lt;span class=&quot;literal&quot;&gt;master&lt;/span&gt;.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;unzip &lt;span class=&quot;literal&quot;&gt;master&lt;/span&gt;.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd nccl-&lt;span class=&quot;keyword&quot;&gt;master&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;title&quot;&gt;make&lt;/span&gt; install -j4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装Caffe&quot;&gt;&lt;a href=&quot;#安装Caffe&quot; class=&quot;headerlink&quot; title=&quot;安装Caffe&quot;&gt;&lt;/a&gt;安装Caffe&lt;/h2&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget https:&lt;span class=&quot;comment&quot;&gt;//github.com/BVLC/caffe/archive/1.0.tar.gz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf &lt;span class=&quot;number&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.tar&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.gz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd caffe-&lt;span class=&quot;number&quot;&gt;1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp Makefile&lt;span class=&quot;selector-class&quot;&gt;.config&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.example&lt;/span&gt; Makefile&lt;span class=&quot;selector-class&quot;&gt;.config&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;vim Makefile&lt;span class=&quot;selector-class&quot;&gt;.config&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)取消对行 USE_CUDNN := &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; 的注释。这可以启用 cuDNN 加速。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)取消对行 USE_NCCL := &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; 的注释。这可以启用在多个 GPU 上运行Caffe 所需的 NCCL。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)取消BLAS_LIB的注释，写上BLAS的路径（比如atlas安装在/usr/lib64/atlas下，那就写BLAS_LIB := /usr/lib64/atlas）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make all -j4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;HDF5没有装好，在-usr-include中无法找到，如果能找到但报错：&quot;&gt;&lt;a href=&quot;#HDF5没有装好，在-usr-include中无法找到，如果能找到但报错：&quot; class=&quot;headerlink&quot; title=&quot;HDF5没有装好，在/usr/include中无法找到，如果能找到但报错：&quot;&gt;&lt;/a&gt;HDF5没有装好，在&lt;code&gt;/usr/include&lt;/code&gt;中无法找到，如果能找到但报错：&lt;/h2&gt;&lt;figure class=&quot;highlight dts&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;src&lt;span class=&quot;meta-keyword&quot;&gt;/caffe/&lt;/span&gt;layers/hdf5_data_layer.cpp:&lt;span class=&quot;number&quot;&gt;13&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;: fatal error: hdf5.h: No such file or                                                                 directory&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;hdf5.h&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                  ^&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;compilation terminated.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;make:&lt;/span&gt; *** [.build_release&lt;span class=&quot;meta-keyword&quot;&gt;/src/&lt;/span&gt;caffe&lt;span class=&quot;meta-keyword&quot;&gt;/layers/&lt;/span&gt;hdf5_data_layer.o] Error &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;make:&lt;/span&gt; *** Waiting for unfinished jobs....&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;那就修改一下&lt;code&gt;Makefile.config&lt;/code&gt;如下：&lt;br&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt; /&lt;span class=&quot;title&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;lib&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;---&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt; /usr/&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt;/hdf5/&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt;/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt; /&lt;span class=&quot;title&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;lib&lt;/span&gt; /&lt;span class=&quot;title&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;include&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;hdf5&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;lib&lt;/span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(具体路径需要看系统)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;重装HDF5&quot;&gt;&lt;a href=&quot;#重装HDF5&quot; class=&quot;headerlink&quot; title=&quot;重装HDF5&quot;&gt;&lt;/a&gt;重装HDF5&lt;/h2&gt;&lt;figure class=&quot;highlight smali&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget https://support.hdfgroup.org/ftp/HDF5/current18/src/hdf5-1.8.20.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf hdf5-1.8.20.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;.&lt;/span&gt;/configure --prefix=/usr/include/hdf5  &lt;span class=&quot;comment&quot;&gt;#安装路径&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;span class=&quot;built_in&quot;&gt; check &lt;/span&gt;               &lt;span class=&quot;comment&quot;&gt;# run test suite.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;span class=&quot;built_in&quot;&gt; check-install &lt;/span&gt;       &lt;span class=&quot;comment&quot;&gt;# verify installation.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;第二个找不到的依赖：&quot;&gt;&lt;a href=&quot;#第二个找不到的依赖：&quot; class=&quot;headerlink&quot; title=&quot;第二个找不到的依赖：&quot;&gt;&lt;/a&gt;第二个找不到的依赖：&lt;/h2&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt;/caffe/util/db_leveldb.hpp:7:24: fatal &lt;span class=&quot;keyword&quot;&gt;error&lt;/span&gt;: leveldb/&lt;span class=&quot;keyword&quot;&gt;db&lt;/span&gt;.&lt;span class=&quot;keyword&quot;&gt;h&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;No&lt;/span&gt; such &lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt; or directory&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; #&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;leveldb/db.h&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                        ^&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;compilation terminated.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过如下命令发现也没装上：&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ yum &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; leveldb-devel&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Loaded plugins: fastestmirror, langpacks&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Loading mirror speeds &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; cached hostfile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; * base: centos.ustc.edu.cn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; * extras: mirror.&lt;span class=&quot;built_in&quot;&gt;bit&lt;/span&gt;.edu.cn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; * updates: centos.ustc.edu.cn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;No&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;package&lt;/span&gt; leveldb-devel available.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装leveldb&quot;&gt;&lt;a href=&quot;#安装leveldb&quot; class=&quot;headerlink&quot; title=&quot;安装leveldb&quot;&gt;&lt;/a&gt;安装leveldb&lt;/h2&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget &lt;span class=&quot;symbol&quot;&gt;https:&lt;/span&gt;/&lt;span class=&quot;regexp&quot;&gt;/github.com/google&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/leveldb/archive&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;unzip master.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd leveldb-master&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r include/leveldb&lt;/span&gt; /usr/&lt;span class=&quot;keyword&quot;&gt;include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp libleveldb.so.&lt;span class=&quot;number&quot;&gt;1.18&lt;/span&gt; /usr/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd /usr/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ln -s libleveldb.so.&lt;span class=&quot;number&quot;&gt;1.18&lt;/span&gt; libleveldb.so.&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ln -s libleveldb.so.&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; libleveldb.so&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ldconfig  &lt;span class=&quot;comment&quot;&gt;# 将动态链接库加到缓存中，这样系统才能真正使用这个动态链接库。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;网上的流程是上面这么说的，但是make完之后居然没有&lt;code&gt;libleveldb.so.1.18&lt;/code&gt;这个东西。&lt;/p&gt;
&lt;h2 id=&quot;修复yum没有hdf5-leveldb等package的问题&quot;&gt;&lt;a href=&quot;#修复yum没有hdf5-leveldb等package的问题&quot; class=&quot;headerlink&quot; title=&quot;修复yum没有hdf5, leveldb等package的问题&quot;&gt;&lt;/a&gt;修复yum没有hdf5, leveldb等package的问题&lt;/h2&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; epel-&lt;span class=&quot;keyword&quot;&gt;release&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;然后再安装leveldb-devel, hdf5-devel就可以了，简直神器&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;据说，leveldb 已经被 caffe 推荐不使用了，可以在 Makefile.config 中将 USE_LEVELDB := 0 注释掉，就不用安装了&lt;a href=&quot;http://blog.leanote.com/post/fishing_piggy/caffe-%E5%AE%89%E8%A3%85%EF%BC%88centos-7%EF%BC%89&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;【1】&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;atlas有问题，MKL挺麻烦，换openblas&quot;&gt;&lt;a href=&quot;#atlas有问题，MKL挺麻烦，换openblas&quot; class=&quot;headerlink&quot; title=&quot;atlas有问题，MKL挺麻烦，换openblas&quot;&gt;&lt;/a&gt;atlas有问题，MKL挺麻烦，换openblas&lt;/h2&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget http&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//github.&lt;span class=&quot;keyword&quot;&gt;com&lt;/span&gt;/xianyi/OpenBLAS/archive/v0.&lt;span class=&quot;number&quot;&gt;2.20&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf v0.&lt;span class=&quot;number&quot;&gt;2.20&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; OpenBLAS-&lt;span class=&quot;number&quot;&gt;0.2&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; PREFIX=/usr/local install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后在&lt;code&gt;Makefile.config&lt;/code&gt;中改为&lt;code&gt;BLAS := open&lt;/code&gt;即可。&lt;/p&gt;
&lt;h2 id=&quot;最后执行：&quot;&gt;&lt;a href=&quot;#最后执行：&quot; class=&quot;headerlink&quot; title=&quot;最后执行：&quot;&gt;&lt;/a&gt;最后执行：&lt;/h2&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; all -j4  &lt;span class=&quot;meta&quot;&gt;# 4线程同时编译，可调&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;检测编译是否成功：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; test&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; runtest&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;运行make-runtest那步出现一些so文件找不到的问题，比如：&quot;&gt;&lt;a href=&quot;#运行make-runtest那步出现一些so文件找不到的问题，比如：&quot; class=&quot;headerlink&quot; title=&quot;运行make runtest那步出现一些so文件找不到的问题，比如：&quot;&gt;&lt;/a&gt;运行&lt;code&gt;make runtest&lt;/code&gt;那步出现一些so文件找不到的问题，比如：&lt;/h2&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;.build_release/tools/caffe: &lt;span class=&quot;keyword&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; loading shared libraries: libglog.&lt;span class=&quot;keyword&quot;&gt;so&lt;/span&gt;.0: cannot &lt;span class=&quot;keyword&quot;&gt;open&lt;/span&gt; shared object &lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;No&lt;/span&gt; such &lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt; or directory&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make: *** [&lt;span class=&quot;keyword&quot;&gt;runtest&lt;/span&gt;] &lt;span class=&quot;keyword&quot;&gt;Error&lt;/span&gt; 127&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;以及libcudart找不到等。&lt;/p&gt;
&lt;p&gt;对于cuda相关的so文件找不到的问题，我们首先看环境变量是否添加了&lt;br&gt;安装CUDA必要添加环境变量的三行，如果有的话试试source一下。&lt;/p&gt;
&lt;p&gt;对于glog, gflags等依赖so文件缺失的问题，首先要检查环境变量，因为前面我们自己make编译安装的这些以来，好像默认为安装到&lt;code&gt;/usr/local/lib&lt;/code&gt;中，如果这个路径不在环境变量中或者不在&lt;code&gt;Makefild.config&lt;/code&gt;中，就有可能找不到so文件。奇怪的是，我的&lt;code&gt;Makefild.config&lt;/code&gt;中有LIBRARY路径&lt;code&gt;/usr/local/lib&lt;/code&gt;，却还是会报这些so文件找不到，很奇怪。那就在环境变量中添加吧。&lt;/p&gt;
&lt;h2 id=&quot;又提示没有libhdf5-hl-so-10这个文件&quot;&gt;&lt;a href=&quot;#又提示没有libhdf5-hl-so-10这个文件&quot; class=&quot;headerlink&quot; title=&quot;又提示没有libhdf5_hl.so.10这个文件&quot;&gt;&lt;/a&gt;又提示没有&lt;code&gt;libhdf5_hl.so.10&lt;/code&gt;这个文件&lt;/h2&gt;&lt;p&gt;直接yum再安装一下，发现还不行，原因是yum安装的是&lt;code&gt;libhdf5_hl.so.10&lt;/code&gt;，这个so在我们之前源码安装的时候是装在&lt;code&gt;/usr/include/hdf5/lib&lt;/code&gt;中的，所以加一条环境&lt;code&gt;LIBRARY_PATH&lt;/code&gt;到这个地址是比较简便的方法了。&lt;/p&gt;
&lt;h2 id=&quot;不临时的方法修改LIBRARY-PATH&quot;&gt;&lt;a href=&quot;#不临时的方法修改LIBRARY-PATH&quot; class=&quot;headerlink&quot; title=&quot;不临时的方法修改LIBRARY_PATH&quot;&gt;&lt;/a&gt;不临时的方法修改&lt;code&gt;LIBRARY_PATH&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;为了不总在环境变量里面加路径，可以有另外一个方法&lt;br&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;进入/etc/ld.so.conf.d&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;新建一个conf文件：/etc/ld.so.conf.d/glog.conf，里面写：/usr/local/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;再新建一个conf文件：/etc/ld.so.conf.d/hdf5.conf，里面写：/usr/local/hdf5-&lt;span class=&quot;number&quot;&gt;1.8&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;最后执行：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/sbin/ldconfig -v&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;重新编译&quot;&gt;&lt;a href=&quot;#重新编译&quot; class=&quot;headerlink&quot; title=&quot;重新编译&quot;&gt;&lt;/a&gt;重新编译&lt;/h2&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; clean&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; all&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; test &lt;span class=&quot;meta&quot;&gt;#4分钟&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; runtest &lt;span class=&quot;meta&quot;&gt;#1分钟&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; pycaffe &lt;span class=&quot;meta&quot;&gt;#40秒&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;make-runtest&quot;&gt;&lt;a href=&quot;#make-runtest&quot; class=&quot;headerlink&quot; title=&quot;make runtest&quot;&gt;&lt;/a&gt;make runtest&lt;/h2&gt;&lt;p&gt;最终，&lt;code&gt;make runtest&lt;/code&gt;语句终于能走通了。&lt;br&gt;&lt;figure class=&quot;highlight scheme&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;name&quot;&gt;----------&lt;/span&gt;] &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; tests from EuclideanLossLayerTest/3, where TypeParam = caffe::GPUDevice&amp;lt;double&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[ RUN      ] EuclideanLossLayerTest/3.TestGradient&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[       OK ] EuclideanLossLayerTest/3.TestGradient (&lt;span class=&quot;name&quot;&gt;23&lt;/span&gt; ms)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[ RUN      ] EuclideanLossLayerTest/3.TestForward&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[       OK ] EuclideanLossLayerTest/3.TestForward (&lt;span class=&quot;name&quot;&gt;1&lt;/span&gt; ms)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;name&quot;&gt;----------&lt;/span&gt;] &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; tests from EuclideanLossLayerTest/3 (&lt;span class=&quot;name&quot;&gt;24&lt;/span&gt; ms total)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;name&quot;&gt;----------&lt;/span&gt;] Global test environment tear-down&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;name&quot;&gt;==========&lt;/span&gt;] &lt;span class=&quot;number&quot;&gt;2101&lt;/span&gt; tests from &lt;span class=&quot;number&quot;&gt;277&lt;/span&gt; test cases ran. (&lt;span class=&quot;name&quot;&gt;614680&lt;/span&gt; ms total)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[  PASSED  ] &lt;span class=&quot;number&quot;&gt;2101&lt;/span&gt; tests.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;验证caffe是否正确安装，以MNIST为例&quot;&gt;&lt;a href=&quot;#验证caffe是否正确安装，以MNIST为例&quot; class=&quot;headerlink&quot; title=&quot;验证caffe是否正确安装，以MNIST为例&quot;&gt;&lt;/a&gt;验证caffe是否正确安装，以MNIST为例&lt;/h2&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo sh data&lt;span class=&quot;regexp&quot;&gt;/mnist/&lt;/span&gt;get_mnist.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;会下载如下数据到data&lt;span class=&quot;regexp&quot;&gt;/mnist/&lt;/span&gt;目录：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;train-images-idx3-&lt;span class=&quot;string&quot;&gt;ubyte:&lt;/span&gt;  训练集样本 (&lt;span class=&quot;number&quot;&gt;9912422&lt;/span&gt; bytes) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;train-labels-idx1-&lt;span class=&quot;string&quot;&gt;ubyte:&lt;/span&gt;  训练集对应标注 (&lt;span class=&quot;number&quot;&gt;28881&lt;/span&gt; bytes) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;t10k-images-idx3-&lt;span class=&quot;string&quot;&gt;ubyte:&lt;/span&gt;   测试集图片 (&lt;span class=&quot;number&quot;&gt;1648877&lt;/span&gt; bytes) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;t10k-labels-idx1-&lt;span class=&quot;string&quot;&gt;ubyte:&lt;/span&gt;   测试集对应标注 (&lt;span class=&quot;number&quot;&gt;4542&lt;/span&gt; bytes)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;这些数据不能在caffe中直接使用，需要转换成LMDB数据：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo sh examples&lt;span class=&quot;regexp&quot;&gt;/mnist/&lt;/span&gt;create_mnist.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;输出：&lt;br&gt;&lt;figure class=&quot;highlight dns&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sh examples/mnist/create_mnist.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Creating lmdb...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;16.962158&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8318&lt;/span&gt; db_lmdb.cpp:&lt;span class=&quot;number&quot;&gt;35&lt;/span&gt;] Opened lmdb examples/mnist/mnist_train_lmdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;16.963549&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8318&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;88&lt;/span&gt;] &lt;span class=&quot;keyword&quot;&gt;A&lt;/span&gt; total of &lt;span class=&quot;number&quot;&gt;60000&lt;/span&gt; items.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;16.963567&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8318&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;89&lt;/span&gt;] Rows: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; Cols: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;20.275429&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8318&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;108&lt;/span&gt;] Processed &lt;span class=&quot;number&quot;&gt;60000&lt;/span&gt; files.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;23.038358&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8341&lt;/span&gt; db_lmdb.cpp:&lt;span class=&quot;number&quot;&gt;35&lt;/span&gt;] Opened lmdb examples/mnist/mnist_test_lmdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;23.038920&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8341&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;88&lt;/span&gt;] &lt;span class=&quot;keyword&quot;&gt;A&lt;/span&gt; total of &lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; items.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;23.038970&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8341&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;89&lt;/span&gt;] Rows: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; Cols: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;23.549976&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8341&lt;/span&gt; convert_mnist_data.cpp:&lt;span class=&quot;number&quot;&gt;108&lt;/span&gt;] Processed &lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; files.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Done.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【以下来自&lt;a href=&quot;https://www.cnblogs.com/denny402/p/5075490.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe学习系列(9)：运行caffe自带的两个简单例子&lt;/a&gt;】&lt;br&gt;转换成功后，会在 &lt;code&gt;examples/mnist/&lt;/code&gt;目录下，生成两个文件夹，分别是&lt;code&gt;mnist_train_lmdb&lt;/code&gt;和&lt;code&gt;mnist_test_lmdb&lt;/code&gt;，里面存放的&lt;code&gt;data.mdb&lt;/code&gt;和&lt;code&gt;lock.mdb&lt;/code&gt;，就是我们需要的运行数据。&lt;/p&gt;
&lt;p&gt;接下来是修改配置文件，如果你有GPU且已经完全安装好，这一步可以省略，如果没有，则需要修改solver配置文件。&lt;/p&gt;
&lt;p&gt;需要的配置文件有两个，一个是&lt;code&gt;lenet_solver.prototxt&lt;/code&gt;，另一个是&lt;code&gt;train_lenet.prototxt&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;首先打开&lt;code&gt;lenet_solver_prototxt&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight dts&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ sudo vi examples&lt;span class=&quot;meta-keyword&quot;&gt;/mnist/&lt;/span&gt;lenet_solver.prototxt&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;根据需要，在&lt;code&gt;max_iter&lt;/code&gt;处设置最大迭代次数，以及决定最后一行&lt;code&gt;solver_mode&lt;/code&gt;,是否要改成CPU。&lt;/p&gt;
&lt;p&gt;保存退出后，就可以运行这个例子了：&lt;/p&gt;
&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ sudo time &lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; examples/mnist/train_lenet.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;CPU运行时候大约13分钟，GPU运行时间大约4分钟，GPU+cudnn运行时候大约40秒，精度都为99%左右&lt;/p&gt;
&lt;p&gt;【以上就是&lt;a href=&quot;https://www.cnblogs.com/denny402/p/5075490.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe学习系列(9)：运行caffe自带的两个简单例子&lt;/a&gt;】&lt;/p&gt;
&lt;h2 id=&quot;运行成功，最终结果部分如下：&quot;&gt;&lt;a href=&quot;#运行成功，最终结果部分如下：&quot; class=&quot;headerlink&quot; title=&quot;运行成功，最终结果部分如下：&quot;&gt;&lt;/a&gt;运行成功，最终结果部分如下：&lt;/h2&gt;&lt;figure class=&quot;highlight dns&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;.....&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:10&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;01.473722&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8369&lt;/span&gt; solver.cpp:&lt;span class=&quot;number&quot;&gt;397&lt;/span&gt;]     Test net output #&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;: accuracy = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;9906&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:10&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;01.473759&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8369&lt;/span&gt; solver.cpp:&lt;span class=&quot;number&quot;&gt;397&lt;/span&gt;]     Test net output #&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;: loss = &lt;span class=&quot;number&quot;&gt;0.029267&lt;/span&gt; (* &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;0.029267&lt;/span&gt; loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:10&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;01.473793&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8369&lt;/span&gt; solver.cpp:&lt;span class=&quot;number&quot;&gt;315&lt;/span&gt;] Optimization Done.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I&lt;span class=&quot;number&quot;&gt;0316 00:10&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;01.473810&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;8369&lt;/span&gt; caffe.cpp:&lt;span class=&quot;number&quot;&gt;259&lt;/span&gt;] Optimization Done.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;real    &lt;span class=&quot;number&quot;&gt;0m&lt;/span&gt;43.&lt;span class=&quot;number&quot;&gt;368&lt;/span&gt;s&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;user    &lt;span class=&quot;number&quot;&gt;0m&lt;/span&gt;34.&lt;span class=&quot;number&quot;&gt;830&lt;/span&gt;s&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sys     &lt;span class=&quot;number&quot;&gt;0m&lt;/span&gt;8.&lt;span class=&quot;number&quot;&gt;584&lt;/span&gt;s&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;花费40s左右。精度99.06%，其实不高。&lt;/p&gt;
&lt;h2 id=&quot;CIFAR10-例子&quot;&gt;&lt;a href=&quot;#CIFAR10-例子&quot; class=&quot;headerlink&quot; title=&quot;CIFAR10 例子&quot;&gt;&lt;/a&gt;CIFAR10 例子&lt;/h2&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; data/cifar10/get_cifar10.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; examples/cifar10/create_cifar10.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;time &lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; examples/cifar10/train_quick.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;到此，Caffe的安装告完结。&lt;/p&gt;
&lt;h2 id=&quot;编译pycaffe&quot;&gt;&lt;a href=&quot;#编译pycaffe&quot; class=&quot;headerlink&quot; title=&quot;编译pycaffe&quot;&gt;&lt;/a&gt;编译pycaffe&lt;/h2&gt;&lt;p&gt;编译python的caffe接口需要安装boost依赖：&lt;br&gt;&lt;figure class=&quot;highlight armasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;yum&lt;/span&gt; install &lt;span class=&quot;keyword&quot;&gt;boost-devel&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;或者&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;wget&lt;/span&gt; http://dl.&lt;span class=&quot;keyword&quot;&gt;bintray.com/boostorg/release/1.65.0/source/boost_1_65_0.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;tar&lt;/span&gt; -zxvf &lt;span class=&quot;keyword&quot;&gt;boost_1_65_0.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;boost_1_65_0/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;./&lt;span class=&quot;keyword&quot;&gt;bootstrap.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;./&lt;span class=&quot;keyword&quot;&gt;b2 &lt;/span&gt;cxxflags=&lt;span class=&quot;string&quot;&gt;&quot;-I /home/hadoop/anaconda3/include/python3.6m/&quot;&lt;/span&gt;                              # python3如此编译&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;sudo&lt;/span&gt; ./&lt;span class=&quot;keyword&quot;&gt;b2 &lt;/span&gt;install --prefix=/usr cxxflags=&lt;span class=&quot;string&quot;&gt;&quot;-I /home/hadoop/anaconda3/include/python3.6m/&quot;&lt;/span&gt;   # python3如此安装&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;因为我们想在python中直接&lt;code&gt;import caffe&lt;/code&gt;，在环境变量中加上：&lt;br&gt;&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;export PYTHONPATH=&lt;span class=&quot;variable&quot;&gt;$PYTHONPATH&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:/home/hadoop/caffe-&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;1.0&lt;/span&gt;/python&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;后来发现编译pycaffe还需要安装protobuf依赖，原来anaconda装的不行。&lt;/p&gt;
&lt;p&gt;安装protobuf，&lt;a href=&quot;https://github.com/google/protobuf/releases&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;下载地址&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf protobuf-cpp-&lt;span class=&quot;number&quot;&gt;3.2&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; protobuf-&lt;span class=&quot;number&quot;&gt;3.2&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./configure&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; check&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;make&lt;/span&gt; install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ldconfig&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf protobuf-&lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;3.2&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt; setup.&lt;span class=&quot;keyword&quot;&gt;py&lt;/span&gt; build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt; setup.&lt;span class=&quot;keyword&quot;&gt;py&lt;/span&gt; test&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt; setup.&lt;span class=&quot;keyword&quot;&gt;py&lt;/span&gt; install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;Matlab安装及Caffe编译。&quot;&gt;&lt;a href=&quot;#Matlab安装及Caffe编译。&quot; class=&quot;headerlink&quot; title=&quot;Matlab安装及Caffe编译。&quot;&gt;&lt;/a&gt;Matlab安装及Caffe编译。&lt;/h2&gt;&lt;p&gt;安装默认读者具有三个文件：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;R2017a_glnxa64_dvd1&lt;span class=&quot;selector-class&quot;&gt;.iso&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;R2017a_glnxa64_dvd2&lt;span class=&quot;selector-class&quot;&gt;.iso&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Matlab+&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;a+Linux64+Crack目录，由rar解压而来&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装步骤：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /data/matlab/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt;       # 新建目录以供挂载&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo &lt;span class=&quot;keyword&quot;&gt;mount&lt;/span&gt; -o &lt;span class=&quot;keyword&quot;&gt;loop&lt;/span&gt; R2017a_glnxa64_dvd1.iso /&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt;  # 挂载DVD1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt;/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; -destinationFolder /&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/Matlab2017a/ -fileInstallationKey &lt;span class=&quot;number&quot;&gt;09806&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-07443&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-53955&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-64350&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-21751&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;-41297&lt;/span&gt; -agreeToLicense yes -outputFile /&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/Matlab2017a/matworks.&lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; -&lt;span class=&quot;keyword&quot;&gt;mode&lt;/span&gt; silent -activationPropertiesFile /home/hadoop/Matlab+&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;a+Linux64+Crack/license_standalone.lic  # 正式安装&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DVD1安装完成后会一直提示 eject dvd1 &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; dvd2 &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; continue&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;开另一个Shell：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo umount -l /&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt;  # 取消之前的挂载&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo &lt;span class=&quot;keyword&quot;&gt;mount&lt;/span&gt; -o &lt;span class=&quot;keyword&quot;&gt;loop&lt;/span&gt; R2017a_glnxa64_dvd2.iso /&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/matlab/&lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt;  # 挂载DVD2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;第一台shell会自动开始安装&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;等待安装完成&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo cp Matlab+&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;a+Linux64+Crack/R2017a/&lt;span class=&quot;keyword&quot;&gt;bin&lt;/span&gt;/glnxa64&lt;span class=&quot;comment&quot;&gt;/* /data/matlab/Matlab2017a/bin/glnxa64/  # 拷贝&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo cp Matlab+2017a+Linux64+Crack/license_standalone.lic /data/matlab/Matlab2017a/licenses/   # 拷贝&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo umount -l /data/matlab/install  # 解挂&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd /data/matlab/Matlab2017a/bin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./matlab                             # 运行&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后编译Matcaffe：&lt;br&gt;&lt;figure class=&quot;highlight livecodeserver&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# make matcaffe -j16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MEX matlab/+caffe/&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt;/caffe_.cpp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Building &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;g++&#39;&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MEX completed successfully.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;所以总结一下，能够联网的CentOS服务器上安装Caffe的步骤如下(root用户)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yum install epel-release&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yum install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-devel hdf5-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yum install gflags-devel glog-devel lmdb-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;NCCL安装&lt;/li&gt;
&lt;li&gt;OpenBLAS安装&lt;/li&gt;
&lt;li&gt;Caffe安装&lt;/li&gt;
&lt;li&gt;进入&lt;code&gt;/etc/ld.so.conf.d&lt;/code&gt;新建&lt;code&gt;nccl.conf&lt;/code&gt;，填写&lt;code&gt;/usr/local/lib&lt;/code&gt;，然后&lt;code&gt;ldconfig -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;make test, make runtest测试Caffe安装是否成功&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;涉及的命令本文以上部分都有。&lt;/p&gt;
&lt;p&gt;感谢网上众多资料的作者提供经验，特列出参考文献如下聊表感激：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://caffe.berkeleyvision.org/install_yum.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe. RHEL / Fedora / CentOS Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.nvidia.cn/object/caffe-installation-cn.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;如何在 NVIDIA GPU 上下载并安装Caffe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/sinat_35188997/article/details/73530434&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;呕心沥血一个月之caffe安装与配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/denny402/p/5075490.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe学习系列(9)：运行caffe自带的两个简单例子&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zybuluo.com/hanxiaoyang/note/364680&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;linux(CentOS)下的caffe编译安装简易手册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/u011713358/article/details/69659265&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;在Ubuntu 16.04下安装Matlab 2017a&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/1d338f1c6bce&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu16.04配置caffe（with cuda8.0）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zziahgf/article/details/72900948&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe - Ubuntu 安装及问题解决&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000011147642&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Elam的caffe笔记之配置篇（六）：Centos6.5下编译caffe及caffe的python3.6接口&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/fariver/p/7455433.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Linux下的GPU版Caffe安装方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文假设已经安装好了CUDA 8.0，NVIDIA GPU驱动以及cuDNN且读者主机可以连接互联网。&lt;/p&gt;
&lt;p&gt;CUDA 8.0的安装也可见&lt;a href=&quot;http://whatbeg.com/2018/03/17/cudainstall.html&quot;&gt;《CentOS
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Linux" scheme="http://whatbeg.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Ray 论文解读</title>
    <link href="http://whatbeg.com/2018/03/15/ray-paper.html"/>
    <id>http://whatbeg.com/2018/03/15/ray-paper.html</id>
    <published>2018-03-15T06:26:53.000Z</published>
    <updated>2018-03-18T07:59:51.303Z</updated>
    
    <content type="html">&lt;p&gt;Ray是UC.Berkerly去年（2017）提出来的一个分布式执行引擎。Ray主要面向未来交互式的AI，如强化学习，提供任务并行和高速的任务调度。用户可以借助Ray迅速的进行任务并行来加速模型训练和推理。本文对Ray论文进行解读，以进一步地剖析了解Ray的运作原理，灵感来源，优缺点，在分布式机器学习框架中所处的位置，以及论文的写作，阐述过程等等。希望能给大家带来一些启发和思考。&lt;/p&gt;
&lt;h2 id=&quot;摘要（Abstract）&quot;&gt;&lt;a href=&quot;#摘要（Abstract）&quot; class=&quot;headerlink&quot; title=&quot;摘要（Abstract）&quot;&gt;&lt;/a&gt;摘要（Abstract）&lt;/h2&gt;&lt;p&gt;摘要部分简洁明了。首先说下一代的AI应用会持续地与环境进行交互，即走向交互式学习，在交互中学习，故而对支持AI的底层系统提出了新要求。论文阐述了这些要求（如性能，灵活性方面的要求），并提出Ray这一框架来满足这些要求。Ray实现了动态任务图计算（dynamic task graph computation），支持任务并行（task-parallel）和Actor编程模型。&lt;/p&gt;
&lt;p&gt;为了满足性能（Performance）要求，Ray提出了一种逻辑中心控制状态板的概念，采用分片的分布式存储系统（Redis）来实现，以及提供了一种新颖的自底向上的分布式调度器。&lt;/p&gt;
&lt;p&gt;实验表明，Ray可以实现次毫秒级的任务调度延迟，任务吞吐量大，在很多challenging的benchmark上得到了加速，并且自然且高效地适配新兴的一类强化学习应用与算法。&lt;/p&gt;
&lt;p&gt;摘要部分的逻辑非常清晰，首先说明问题，问题提出的新要求，为了解决问题，满足要求，我们提出xx，xx具有…的性质，提出了…idea，实验表明，xx具有良好的效果。简单来说就是：&lt;strong&gt;问题-方法-效果&lt;/strong&gt;三大块，看起来很舒服。&lt;/p&gt;
&lt;h2 id=&quot;介绍（Introduction）&quot;&gt;&lt;a href=&quot;#介绍（Introduction）&quot; class=&quot;headerlink&quot; title=&quot;介绍（Introduction）&quot;&gt;&lt;/a&gt;介绍（Introduction）&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;(Situation)&lt;/strong&gt; AI目前风生水起，应用广泛。过去主要集中在监督学习上，离线训练在线部署，如今领域(AI,ML)逐渐成熟，呈现新需求：AI系统需要在动态环境中不断响应变化，与环境交互来学习。这种模式天生与强化学习契合。强化学习应用也取得了一些很好的效果。&lt;/p&gt;
&lt;p&gt;强化学习与监督学习有三点不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强化学习依赖大量的模拟动作&lt;/li&gt;
&lt;li&gt;强化学习的计算图是异构的，动态演化的，每部分的计算时间可能差别很大&lt;/li&gt;
&lt;li&gt;需要快速作出响应&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;(Question)&lt;/strong&gt; 总的来说，我们需要这样一个计算框架：支持异构的、动态的计算图，每秒处理百万级任务数，且只有毫秒级的延迟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Conflict)&lt;/strong&gt; 已有的集群计算框架无法充分满足这些要求。&lt;/p&gt;
&lt;p&gt;MapReduce, Spark, Dryad, Dask, CIEL 既不能提供强化学习应用需要的吞吐量，也不能达到其要求的延迟。&lt;/p&gt;
&lt;p&gt;Tensorflow, Naiad, MPI, Canary 通常假设计算图是静态的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Answer)&lt;/strong&gt; 本文提出Ray，一个新的满足这些条件的集群计算框架。&lt;/p&gt;
&lt;p&gt;为了满足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;条件1：异构动态工作流 =&amp;gt; Ray实现了动态任务图计算模型，类似于CIEL，并在CIEL的任务并行之上提供了一个actor编程模型，actor抽象使得Ray能够支持有状态组件，封装第三方服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【什么是actor抽象？】actor可以理解为一个第三方服务的代理，或者一个类，类中包含了成员变量和方法，成员方法可以调用某些第三方服务，故而actor相当于对第三方服务的一个封装和一个抽象，真正的实现可以是各种第三方服务。在编程语言中的实现就是像类一样实现，只不过在类定义前加一个&lt;code&gt;@ray.remote&lt;/code&gt;而已。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;条件2：高性能 =&amp;gt; 采用一种新的分布式架构，可以实现良好的水平扩展。主要基于两个idea：&lt;br&gt;1）中央控制板，系统的所有控制状态都属中央控制，各个组件可以实现无状态，从而实现良好的水平扩展和容错。&lt;br&gt;2）自底向上的分布式调度器。即有一个全局调度器(global scheduler)，每个节点有本地调度器(local scheduler)，本地调度器可以选择本地调度，也可以将任务转发给global scheduler，让global scheduler来进行调度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【问题一】看到这里，读者可能会问，何时决定选择本地调度还是往上层转发呢？采何种标准决定到底是本地调度还是往上层转发呢？这是后续需要回答的问题。&lt;/p&gt;
&lt;p&gt;可以看到，介绍部分的基本逻辑清晰，我们采用SCQA/SQCA分析法来分析，首先介绍现在的处境(Situation)，然后提出问题（我们需要xxx）(Question)，然后是冲突(Conflict)，即现在没有满足这些条件的框架，最后是答案(Answer)，即我们提出Ray…。这种写法可以叫SQCA法，也可以调一下顺序，按SCQA的顺序来写。&lt;/p&gt;
&lt;p&gt;论文有如下贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出当前AI系统的一些要求&lt;/li&gt;
&lt;li&gt;提出了actor抽象&lt;/li&gt;
&lt;li&gt;提出具有高度水平扩展性的一种架构，并构建Ray来实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【问题二】水平扩展的方式，能否支撑大数据？&lt;/p&gt;
&lt;p&gt;Ray的架构：&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;th colspan=&quot;3&quot;&gt;&lt;center&gt;Application Layer&lt;/center&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;center&gt;global control state&lt;/center&gt;&lt;/td&gt;&lt;td&gt;&lt;center&gt;distributed scheduler&lt;/center&gt;&lt;/td&gt;&lt;td&gt;&lt;center&gt;distributed object store&lt;/center&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2 id=&quot;Motivation-and-Requirements&quot;&gt;&lt;a href=&quot;#Motivation-and-Requirements&quot; class=&quot;headerlink&quot; title=&quot;Motivation and Requirements&quot;&gt;&lt;/a&gt;Motivation and Requirements&lt;/h2&gt;&lt;p&gt;强化学习工作流是Ray设计的主要动机，也是本文重点。&lt;br&gt;以强化学习为例，本文将新型系统的要求分为三大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flexibility&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Flexibility又分为几个方面：&lt;br&gt;一个是并发任务的异构性，有以下三种，功能不同，时长不同以及资源类型不同。如视频的处理和文本的处理就不是同一个功能，在一个时长，执行的计算也不一样。资源类型指的是GPU或者CPU等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/ray-01.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另一个是执行图的通用性和动态性。&lt;/p&gt;
&lt;p&gt;上面这些要求，BSP的模型（如Hadoop MapReduce, Apache Spark）是无法满足的。&lt;br&gt;在BSP模型中，每个Stage执行的计算通常是相同的，故而计算所需的时间也相似。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;机器人与环境交互的场景中，需要在ms级别采取反应给出action，所以调度最好在1ms内完成，否则会成为一块拖累。鉴于集群中核数达几百几千甚为常见，调度吞吐量应该要很大。&lt;/p&gt;
&lt;p&gt;所以其实Ray对任务的快速调度做得比较好，能够做到非常快速的调度，因为就是针对这个需求设计的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ease of Deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;写并行程序本来就不容易。简化开发对于一个系统的成功来说是至关重要的。&lt;br&gt;易用性包括几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;确定型的重放以及容错机制。&lt;/li&gt;
&lt;li&gt;已有算法易并行。包括对Python语言的支持，以及提供第三方服务的紧密集成，这方面采用actor抽象来封装第三方服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;编程模型和计算模型（Programming-and-Computation-Model）&quot;&gt;&lt;a href=&quot;#编程模型和计算模型（Programming-and-Computation-Model）&quot; class=&quot;headerlink&quot; title=&quot;编程模型和计算模型（Programming and Computation Model）&quot;&gt;&lt;/a&gt;编程模型和计算模型（Programming and Computation Model）&lt;/h2&gt;&lt;p&gt;不同于其他系统，Ray提供了actor和task-parallel两重编程抽象。&lt;br&gt;不像CIEL，只提供任务并行抽象，或Orleans，只提供actor抽象。&lt;/p&gt;
&lt;h3 id=&quot;编程模型&quot;&gt;&lt;a href=&quot;#编程模型&quot; class=&quot;headerlink&quot; title=&quot;编程模型&quot;&gt;&lt;/a&gt;编程模型&lt;/h3&gt;&lt;p&gt;当一个带有&lt;code&gt;@remote&lt;/code&gt;注解的remote函数被调用，会立即返回一个&lt;code&gt;future&lt;/code&gt;对象，然后调用&lt;code&gt;ray.get&lt;/code&gt;即可得到结果。&lt;/p&gt;
&lt;p&gt;比如说&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; time&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; ray&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ray.init()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@ray.remote&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    time.sleep(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Execute f in parallel.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;object_ids = [f.remote() &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; range(&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;)]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;results = ray.get(object_ids)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;f.remote()&lt;/code&gt;调用运行时，将返回一个&lt;code&gt;future&lt;/code&gt;对象，存储在&lt;code&gt;object_ids&lt;/code&gt;中，调用&lt;code&gt;ray.get(object_ids)&lt;/code&gt;可以得到返回值的列表。&lt;/p&gt;
&lt;p&gt;remote函数操作的数据是不可变的对象，remote函数是无状态，无副作用的，使得幂等性得以保证，从而简化了容错的处理。&lt;/p&gt;
&lt;p&gt;为了满足一些条件，Ray所提出了的编程模型如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;处理不同时长的任务，采用了&lt;code&gt;ray.wait()&lt;/code&gt;，这个调用的意思是，运行很多的task后，可以设定等待的个数，当一定个数的任务执行完成时，其他不再执行，整个调用也结束，返回“等待的”一些&lt;code&gt;future&lt;/code&gt;的子集。思想类似于Spark的backup机制，即运行同样的多个任务，哪个先完成就用哪个的结果，其他的马上停止，不再考虑。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为了解决资源异构任务，在Ray中，开发者可以自己制定remote函数所需的资源量，资源种类有CPU，GPU（官方支持），以及自定义的resources。同样地，Actor也可以制定资源，但是目前Ray在调度Actor的时候，只根据GPU资源来调度。&lt;a href=&quot;http://ray.readthedocs.io/en/latest/resources.html#current-limitations&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;见这里&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为了提升flexibility，在Ray中，remote函数可以相互嵌套，即在remote函数中可以调用remote函数，这样可以充分提高可扩展性，同样提高灵活性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为了容易部署和保证高效性，Ray中涉及了Actor抽象，可以用来封装第三方服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;计算模型&quot;&gt;&lt;a href=&quot;#计算模型&quot; class=&quot;headerlink&quot; title=&quot;计算模型&quot;&gt;&lt;/a&gt;计算模型&lt;/h3&gt;&lt;p&gt;Ray采用了动态计算图机制，即一旦输入准备好了，就自动触发remote函数或者actor方法执行。&lt;/p&gt;
&lt;p&gt;那么Ray是如何将一个用户程序转换成计算图的呢？&lt;/p&gt;
&lt;p&gt;不考虑actor的情况下，整个计算图的节点只包含两种类型的对象，数据对象和remote函数调用，或者称为task。&lt;/p&gt;
&lt;p&gt;计算图有两种类型的边，数据边(data edge)和控制边(control edge)。&lt;/p&gt;
&lt;p&gt;具体如下：&lt;br&gt;数据对象用D表示，task用T表示。&lt;br&gt;如果任务T产生输出D，那么T-&amp;gt;D建一条边&lt;br&gt;如果D是T的输入，那么D-&amp;gt;T有一条边&lt;br&gt;如果T1中调用了T2，那么T1-&amp;gt;T2有一条边&lt;/p&gt;
&lt;p&gt;考虑actor的情况下，增加一种数据对象即actor的方法(Method)，增加一种边，叫做有状态边(stateful edge)，表示一种执行的先后顺序。&lt;br&gt;因为同一个actor中，方法的执行是顺序的，无法并行，Mi-&amp;gt;Mj的边即表示先执行方法Mi，再执行方法Mj。&lt;/p&gt;
&lt;p&gt;有状态边有两种好处，一是使得我们可以把actor嵌入到无状态的任务图中，因为actor维护着自己的一个调用链和状态。二是，有状态边可以用来维护世系(lineage)信息，世系可以帮助Ray重建数据对象，包括remote function创建的或是actor method创建的。&lt;/p&gt;
&lt;h2 id=&quot;架构（Architecture）&quot;&gt;&lt;a href=&quot;#架构（Architecture）&quot; class=&quot;headerlink&quot; title=&quot;架构（Architecture）&quot;&gt;&lt;/a&gt;架构（Architecture）&lt;/h2&gt;&lt;p&gt;架构包括两层，应用层(Application Layer)和系统层(System Layer)。&lt;/p&gt;
&lt;h3 id=&quot;应用层&quot;&gt;&lt;a href=&quot;#应用层&quot; class=&quot;headerlink&quot; title=&quot;应用层&quot;&gt;&lt;/a&gt;应用层&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/ray-02.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;应用层包含三种进程，Driver，Worker，Actor。&lt;/p&gt;
&lt;p&gt;Driver用来执行用户程序，即&lt;code&gt;python xx.py&lt;/code&gt;产生的进程。&lt;/p&gt;
&lt;p&gt;Worker用来执行task，task（remote function）可以由driver或者是其他worker调用，每个机器上运行&lt;code&gt;ray start&lt;/code&gt;后会启动0个或多个Worker【待详述】。Worker是无状态的，由系统层指配task。&lt;br&gt;当一个remote函数声明的时候，函数会自动发布到所有worker。【待详述】&lt;/p&gt;
&lt;p&gt;Actor是一个有状态的进程，当其方法被调用时执行，Actor一经启动在某个节点上，则负责执行所有该actor的方法调用。&lt;br&gt;Actor是有driver或者worker显式地初始化得到的，即采用&lt;code&gt;actor_name.remote()&lt;/code&gt;的方式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/ray-03.jpg&quot; alt=&quot;Ray架构与自底向上调度器示意图&quot;&gt;&lt;/p&gt;
&lt;p&gt;系统层而言，提供了三个组件，每个组件都具有水平可扩展性以及容错机制，来保证前述性能目标和容错目标。&lt;/p&gt;
&lt;p&gt;三个组件分别是：全局控制状态(global control state)，分布式自底向上调度器(distributed bottom-up scheduler)，分布式对象存储(distributed object store)。&lt;/p&gt;
&lt;h3 id=&quot;系统层-Global-Control-State&quot;&gt;&lt;a href=&quot;#系统层-Global-Control-State&quot; class=&quot;headerlink&quot; title=&quot;系统层-Global Control State&quot;&gt;&lt;/a&gt;系统层-Global Control State&lt;/h3&gt;&lt;p&gt;全局控制状态（GCS）是一个中心化的存储，使用Redis实现，负责存储task描述，remote方法代码，计算图，对象的位置，以及每个调度事件。&lt;br&gt;将所用控制状态集中存储，有这么几个好处：&lt;br&gt;1）使得集群中其他组件、节点可以无状态。这样的话可以大大提升水平扩展的能力。&lt;br&gt;2）简化了容错。&lt;br&gt;3）方便对程序debug，profile。&lt;/p&gt;
&lt;p&gt;当然，集中式存储带来的隐忧就是瓶颈问题，基于Redis，可以做分片(sharding)来缓解单点瓶颈。并且为每个分片提供热副本(hot replica)【是什么？】来容错。&lt;br&gt;鉴于在Ray中，每个task, object, method等都有一个唯一的伪随机ID与其一一对应，使得分片间能够更好地负载均衡。&lt;/p&gt;
&lt;h3 id=&quot;系统层-Distributed-Bottom-Up-Scheduler&quot;&gt;&lt;a href=&quot;#系统层-Distributed-Bottom-Up-Scheduler&quot; class=&quot;headerlink&quot; title=&quot;系统层-Distributed Bottom-Up Scheduler&quot;&gt;&lt;/a&gt;系统层-Distributed Bottom-Up Scheduler&lt;/h3&gt;&lt;p&gt;分布式自底向上调度器（distributed bottom-up scheduler），负责任务的调度。Ray启动时，会启动一个全局的调度器global scheduler，实现上是一个redis server，会在每个从节点上启动一个local scheduler，每个节点上提交的task率先提交给各自的local scheduler进行调度，如果local scheduler调度不了，则上推给global scheduler，进行集群全局范围的调度。&lt;br&gt;Ray这样设计的目标是调度可扩展性以及快速，低延迟的调度。这样设计带来的好处就是Ray调度任务非常之快。&lt;/p&gt;
&lt;p&gt;那么Ray这样设计的灵感来自于哪里呢？&lt;/p&gt;
&lt;p&gt;通常的分布式集群计算框架实现的都是中心化，集中式的调度，如Hadoop, Spark, CIEL, Dryad等。这种方式虽然简化了设计，但是扩展性不好。&lt;/p&gt;
&lt;p&gt;提升调度扩展性有几种方式：&lt;br&gt;1）批量调度。调度器批量提交任务给worker节点，以摊销提交任务带来的固定开销。Drizzle框架实现的就是这种。&lt;br&gt;2）层次调度。即全局调度器(global scheduler)将任务图划分到各个节点的本地调度器(local scheduler)。Canary框架实现了这种调度。&lt;br&gt;3）并行调度。多个全局调度器同时进行任务调度。这是Sparrow框架所做的。&lt;/p&gt;
&lt;p&gt;但是他们都有各自的缺陷。&lt;br&gt;批量调度仍然需要一个全局调度器来处理所有任务。&lt;br&gt;层次调度假设任务图是已知的，即假设任务图是静态的。&lt;br&gt;并行调度假设每个全局调度器调度独立的作业。&lt;/p&gt;
&lt;p&gt;Ray希望做到的是高可扩展性，处理动态任务图，并且可能处理来自同一个作业的任务。&lt;/p&gt;
&lt;p&gt;Ray的自底向上调度器类似层次调度，不同的是，一个节点生成的task首先提交到各自的local scheduler，由local scheduler进行调度。除非本地节点过载了，或者本地节点不能满足task的资源需求，或者task的输入不在本地节点等因素出现，否则本地节点可以完成调度。&lt;/p&gt;
&lt;p&gt;其实最后一条，task的输入不再本地，仍有方式在本地调度，因为object store可以实现快速的数据对象转运。&lt;/p&gt;
&lt;p&gt;看到这里，读者可能想问，Ray的local scheduler是怎样判断是否该调度到本地节点还是上推到global scheduler呢？&lt;/p&gt;
&lt;p&gt;Ray是这样处理的，local scheduler会维护一个任务队列（task queue），每次调度任务时它会检查当前任务队列的长度，如果超过一定的阈值，那么认为本机过载了，不在调度当前任务而是将其转给上层全局调度器。&lt;/p&gt;
&lt;p&gt;这个阈值为0，则调度为集中式的调度，全靠global scheduler负责。&lt;br&gt;这个阈值为无穷大，则调度为去中心化的分布式调度，所有任务都有本地节点负责。&lt;/p&gt;
&lt;p&gt;在框架设计上，local scheduler每隔一段时间会发送心跳包给GCS，注意不是直接发送给global scheduler，心跳包中会包含local scheduler的负载信息，GCS收到以后记录此信息，转发给global scheduler。&lt;br&gt;当收到local scheduler转发来的任务时，global scheduler使用最新的负载信息，以及人物的输入数据对象的位置和大小，来决定将task分发到哪个节点去运行。&lt;/p&gt;
&lt;p&gt;如果global scheduler成为了瓶颈，那么采用多个副本，local scheduler随机选择一个global scheduler去转发任务。&lt;/p&gt;
&lt;h3 id=&quot;系统层-Distributed-Object-Store&quot;&gt;&lt;a href=&quot;#系统层-Distributed-Object-Store&quot; class=&quot;headerlink&quot; title=&quot;系统层-Distributed Object Store&quot;&gt;&lt;/a&gt;系统层-Distributed Object Store&lt;/h3&gt;&lt;p&gt;remote函数（task）的输入和输出数据都存储在Distributed Object Store中。&lt;br&gt;调用一个函数时，其输入首先被隐式执行&lt;code&gt;ray.put&lt;/code&gt;，存储object store中，其输出也会被放入object store中，函数返回一个object id为该输出数据的唯一id，调用&lt;code&gt;ray.get(object_id)&lt;/code&gt;才可获得任务返回的实际数据。&lt;/p&gt;
&lt;p&gt;同一个节点上使用共享内存(shared memory)来实现object store，这使得两个不同的worker进程或者driver和worker之间能够零拷贝(zero copy)地访问共同的数据。具体实现采用了Apache Arrow中的plasma store。&lt;a href=&quot;http://arrow.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Apache Arrow&lt;/a&gt;是一种跨平台的内存数据交换格式。可参看介绍&lt;a href=&quot;https://www.cnblogs.com/smartloli/p/6367719.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;/a&gt;，&lt;a href=&quot;http://www.infoq.com/cn/articles/apache-arrow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;/a&gt;等。&lt;/p&gt;
&lt;p&gt;如果一个task，其输入不在本地，那么object store会把数据从所在地拷贝到本地，这样可以避免热数据带来的瓶颈，同时可以加快程序执行速度，因为直接在本地内存中操作。当然，数据的传送开销也是免不了的。这也将提升计算受限工作流的吞吐量，计算受限是许多AI应用共有的特征。&lt;/p&gt;
&lt;p&gt;为了简化系统设计，简化容错，Ray像其它内存计算系统如Spark, Dryad一样，其操作的数据是不可变的(immutable)，即存储在object store中的数据不能改变，如RDD一般。&lt;/p&gt;
&lt;p&gt;Ray同时也不支持分布式对象，如分布式大矩阵，当然可以通过在应用层自行实现（通过一系列的futures）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对象重建&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;像Spark，CIEL一样，Ray根据世系来重建对象。除此之外，Ray还支持有状态操作算子(Actor)的重建。&lt;/p&gt;
&lt;p&gt;要注意的是，如果世系中包含有状态边，则可能涉及到Actor的重新初始化，并且可能涉及到很长一条世系链的重放。对于某些应用，Ray为了减少Actor的重建时间，加入了checkpoint机制，从checkpoint进行恢复。&lt;/p&gt;
&lt;p&gt;为了保证低延迟，如果plasma store满了以后，会通过LRU机制剔除陈旧的对象到磁盘。【到磁盘哪里？】&lt;br&gt;在Ray中，plasma store即object store挂载在Linux属于tmpfs文件系统的&lt;code&gt;/dev/shm&lt;/code&gt;目录上，该目录不在磁盘上，而在内存里。已经存入&lt;code&gt;/dev/shm&lt;/code&gt;中的对象不能被其他应用程序使用，但是&lt;code&gt;/dev/shm&lt;/code&gt;没被使用的部分可被其他应用程序使用。&lt;br&gt;&lt;code&gt;/dev/shm&lt;/code&gt;区域的大小一般是总内存的1/2。即如果你的机器是64G内存，那么此区域只有32G可用，Ray会再保留一点余量，大概用于object store的空间只有26-27GB左右，也就是说，如果Ray处理的数据过大，大到object store都装不下或者在运行时需要频繁evict甚至evict掉其他必要数据的时候，往往程序就会崩溃。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/ray-04.jpg&quot; alt=&quot;Ray执行任务示意简图1&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/ray-05.jpg&quot; alt=&quot;Ray执行任务示意简图2&quot;&gt;&lt;br&gt;&lt;/center&gt;

&lt;h2 id=&quot;相关工作&quot;&gt;&lt;a href=&quot;#相关工作&quot; class=&quot;headerlink&quot; title=&quot;相关工作&quot;&gt;&lt;/a&gt;相关工作&lt;/h2&gt;&lt;p&gt;下表对相关工作与Ray的相似点与不同点做一总结。&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;比较的系统框架&lt;/th&gt;&lt;th&gt;相似点&lt;/th&gt;&lt;th&gt;不同点&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot;&gt;动态任务图&lt;/th&gt;&lt;td&gt;CIEL&lt;/td&gt;&lt;td&gt;动态任务图机制，futures抽象，通过世系容错&lt;/td&gt;&lt;td&gt;Ray还提供Actor抽象，并实现了全局控制面板，自底向上调度器和采用了内存对象存储而不是文件存储，扩展到Python语言&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dask&lt;/td&gt;&lt;td&gt;支持动态任务图，wait原语，futures抽象，Python语言&lt;/td&gt;&lt;td&gt;Dask是中心化调度方式，不提供actor抽象，不提供容错&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th rowspan=&quot;3&quot;&gt;数据流系统&lt;/th&gt;&lt;td&gt;Hadoop/Spark&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Hadoop/Spark计算模型更加限定，实现了BSP执行模型，假设同一阶段的task执行同样的计算，并有着相似的执行时间。Ray还提供Actor抽象，并实现了全局控制面板和调度器。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dryad&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Dryad放松了Spark的假设，但是也没有实现动态计算图。Ray还提供Actor抽象，并实现了全局控制面板和调度器。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Naiad&lt;/td&gt;&lt;td&gt;对于一些工作流提升了可扩展性。&lt;/td&gt;&lt;td&gt;只支持静态计算图。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th rowspan=&quot;3&quot;&gt;Actor系统&lt;/th&gt;&lt;td&gt;Orleans&lt;/td&gt;&lt;td&gt;提供虚拟actor-based抽象。&lt;/td&gt;&lt;td&gt;Orleans可以使actor的多个实例同时运行。需要显式checkpoint，提供at-least-once语义。而Ray提供exactly-once语义。[注]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Erlang&lt;/td&gt;&lt;td&gt;Actor抽象。&lt;/td&gt;&lt;td&gt;需显式处理容错。Erlang的全局状态存储不适合共享大对象。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C++ Actor Framework&lt;/td&gt;&lt;td&gt;Actor抽象。&lt;/td&gt;&lt;td&gt;需显式处理容错。不支持数据共享。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th rowspan=&quot;7&quot;&gt;全局控制状态和调度&lt;/th&gt;&lt;td&gt;SDN&lt;/td&gt;&lt;td&gt;全局控制状态&lt;/td&gt;&lt;td&gt;Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Distributed File System，如GFS&lt;/td&gt;&lt;td&gt;全局控制状态&lt;/td&gt;&lt;td&gt;Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Distributed Frameworks (如MapReduce, BOOM)&lt;/td&gt;&lt;td&gt;全局控制状态&lt;/td&gt;&lt;td&gt;与BOOM相比，Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Resource Management (Omega)&lt;/td&gt;&lt;td&gt;全局共享状态&lt;/td&gt;&lt;td&gt;Ray增加了两层调度器来均衡负载，面向毫秒级别的任务调度&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Sparrow&lt;/td&gt;&lt;td&gt;去中心化调度&lt;/td&gt;&lt;td&gt;各调度器自行其是，独立决策&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Mesos&lt;/td&gt;&lt;td&gt;两级层次调度&lt;/td&gt;&lt;td&gt;顶层调度器可能成为瓶颈&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Canary&lt;/td&gt;&lt;td&gt;去中心化调度&lt;/td&gt;&lt;td&gt;Canary每个调度器负责计算图的一部分，但不支持动态计算图&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th rowspan=&quot;3&quot;&gt;机器学习框架&lt;/th&gt;&lt;td&gt;Tensorflow&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;面向深度学习，对CPU、GPU资源利用很好，不支持更通用的计算工作流，Tensorflow Fold提供对动态计算图的一些支持，但仍无法全部支持执行时对任务执行进度，任务完成时间和错误的响应而编辑DAG图。支持底层消息传输和同步原语，但是过于底层使得用起来有点像MPI。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MXNet&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;同Tensorflow&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;OpenMPI&lt;/td&gt;&lt;td&gt;高性能&lt;/td&gt;&lt;td&gt;很难编程，需要显式处理异构和动态任务图，需要程序员显式处理容错&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;[注] 实时计算/流式计算的三种语义：&lt;br&gt;At-most-once：每条记录最多只能被处理一次&lt;br&gt;At-least-once：每条记录最少要被处理一次&lt;br&gt;Exactly-once：每条记录有且仅被处理一次&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;蓬勃发展的AI应用对计算框架提出了一些挑战性的需求，为了应对这些需求，本文提出了Ray，实现了全局控制存储和自底向上的调度器，且实现了动态任务图。支持Actor编程和任务并行。这种编程灵活性对于强化学习RL应用尤其重要，因其具有诸多方面的异构性，如执行时间，资源等。Ray提供了一个灵活高性能且易于使用的框架来应对未来的AI应用。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Ray是UC.Berkerly去年（2017）提出来的一个分布式执行引擎。Ray主要面向未来交互式的AI，如强化学习，提供任务并行和高速的任务调度。用户可以借助Ray迅速的进行任务并行来加速模型训练和推理。本文对Ray论文进行解读，以进一步地剖析了解Ray的运作原理，灵感来
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://whatbeg.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
      <category term="系统" scheme="http://whatbeg.com/tags/%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>神经网络一阶优化算法手记</title>
    <link href="http://whatbeg.com/2018/03/11/optimizationAlgos.html"/>
    <id>http://whatbeg.com/2018/03/11/optimizationAlgos.html</id>
    <published>2018-03-11T09:03:38.000Z</published>
    <updated>2018-03-18T06:21:21.212Z</updated>
    
    <content type="html">&lt;p&gt;关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。&lt;/p&gt;
&lt;h2 id=&quot;Notations&quot;&gt;&lt;a href=&quot;#Notations&quot; class=&quot;headerlink&quot; title=&quot;Notations&quot;&gt;&lt;/a&gt;Notations&lt;/h2&gt;&lt;p&gt;$\theta$ : parameters&lt;/p&gt;
&lt;p&gt;$J$ : objective function&lt;/p&gt;
&lt;p&gt;$\nabla J(\theta) = J’$ w.r.t parameter&lt;/p&gt;
&lt;p&gt;$\eta$ : learning rate&lt;/p&gt;
&lt;h2 id=&quot;从SGD说起&quot;&gt;&lt;a href=&quot;#从SGD说起&quot; class=&quot;headerlink&quot; title=&quot;从SGD说起&quot;&gt;&lt;/a&gt;从SGD说起&lt;/h2&gt;&lt;p&gt;SGD(Stochastic Gradient Descent)是目前最流行的机器学习，深度学习优化算法之一，现在通常所说的SGD指的是Mini-batch gradient descent，更新规则如下，&lt;/p&gt;
&lt;p&gt;$$\theta_{t+1} = \theta_{t} - \eta \nabla J(\theta_{t}; x_{i:i+m}; y_{i:i+m})$$&lt;/p&gt;
&lt;p&gt;每次采用一小批数据计算梯度来更新paramter，既能够缓解每次单个样本的SGD带来的剧烈波动问题，又能够加快训练速度，所以受到了machine learning和neural network训练的喜爱。&lt;/p&gt;
&lt;p&gt;但是SGD有如下几个不足[1]：&lt;br&gt;1）learning rate很难选取&lt;br&gt;2）schedule策略需要预先选定，无法自适应&lt;br&gt;3）参数的每一维使用相同的学习率&lt;br&gt;4）SGD在鞍点或者pleatu区域容易陷入困境，难以逃离&lt;/p&gt;
&lt;p&gt;根据这些不足，人们设计了许多SGD的改进算法。&lt;/p&gt;
&lt;h2 id=&quot;Momentum&quot;&gt;&lt;a href=&quot;#Momentum&quot; class=&quot;headerlink&quot; title=&quot;Momentum&quot;&gt;&lt;/a&gt;Momentum&lt;/h2&gt;&lt;p&gt;为了加速SGD的训练，以及改善面对“峡谷”型目标函数的鲁棒性，人们将物理学中的Momentum概念加入优化中。实验证明，Momentum SGD[2]能够有效地抑制函数值震荡的现象。&lt;br&gt;Momentum的更新公式如下：&lt;/p&gt;
&lt;p&gt;$v_t = \rho v_{t-1} + \eta \nabla J(\theta)$&lt;/p&gt;
&lt;p&gt;$\theta = \theta - v_t$&lt;/p&gt;
&lt;p&gt;where $\rho$ 控制着前面诸参数更新的衰减率。&lt;br&gt;有了Momentum，SGD能够收敛的更快，并且震荡会减弱。&lt;/p&gt;
&lt;h2 id=&quot;Nesterov-Accelerated-Gradient-NAG&quot;&gt;&lt;a href=&quot;#Nesterov-Accelerated-Gradient-NAG&quot; class=&quot;headerlink&quot; title=&quot;Nesterov Accelerated Gradient(NAG)&quot;&gt;&lt;/a&gt;Nesterov Accelerated Gradient(NAG)&lt;/h2&gt;&lt;p&gt;接着，Nesterov提出了一种无约束凸优化方法，称为Nesterov accelerated gradient(NAG)[3]，这种方法预先估计下一个位置，然后看看该位置的梯度，根据对该“未来”梯度的判断，来调整自己的预期步长，使得更加智能的往局部最优点走去。NAG的更新式与Momentum只有一丝细微的差别：&lt;/p&gt;
&lt;p&gt;$v_t = \rho v_{t-1} + \eta \nabla J(\theta-\rho v_{t-1})$&lt;/p&gt;
&lt;p&gt;$\theta = \theta - v_t$&lt;/p&gt;
&lt;h2 id=&quot;Adagrad&quot;&gt;&lt;a href=&quot;#Adagrad&quot; class=&quot;headerlink&quot; title=&quot;Adagrad&quot;&gt;&lt;/a&gt;Adagrad&lt;/h2&gt;&lt;p&gt;虽然我们对SGD进行了加速，并且非常智能地调整好了方向，我们的参数向量各个维度更新幅度仍然是一样的，（在有些时候，尤其是稀疏场景中，对于出现极少次数的特征维，我们不会想只更新一个很小的幅度，这样会使得这个维度学习很差。）&lt;/p&gt;
&lt;p&gt;另一种思路是使得参数向量$\theta$的各个维以不同步调来差异化地调整。&lt;br&gt;Adagrad就是其中一种，由Duchi et. al[4]在2011年提出。Ada means Adaptive，代表着它能够自适应地为参数调整学习率，非常适合稀疏数据，这种方法将梯度平方的累积值加入梯度更新中，更新方式如下：&lt;/p&gt;
&lt;p&gt;$g_{t,i} = \nabla J(\theta_i)$&lt;/p&gt;
&lt;p&gt;$\theta_{t+1, i} = \theta_{t, i} - \frac {\eta} {\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}$&lt;/p&gt;
&lt;p&gt;$G_t \in {\mathbb R}^{d \times d}$ is a diagonal matrix that each diagonal element is sum of the squares of the gradient w.r.t $w_i$ up to time step t [4].&lt;br&gt;$\epsilon$ is just a smoothing term avoiding division by zero, usually 1e-8.&lt;br&gt;我们也可以写成向量形式：&lt;br&gt;$$\theta_{t+1} = \theta_{t} - \frac {\eta} {\sqrt{G_{t} + \epsilon}} \odot g_{t}$$&lt;br&gt;$\odot$ means element-wise matrix-vector multiplication.&lt;/p&gt;
&lt;h2 id=&quot;RMSprop&quot;&gt;&lt;a href=&quot;#RMSprop&quot; class=&quot;headerlink&quot; title=&quot;RMSprop&quot;&gt;&lt;/a&gt;RMSprop&lt;/h2&gt;&lt;p&gt;随着梯度平方的累积，Adagrad会自适应地降低频繁更新的参数的学习率，使得你无需去手动指定learning rate schedule策略来调试学习率，但是Adagrad的一大缺点就是它的学习率会随着训练中不断增长的累计梯度平方和而单调下降到任意小，甚至导致学习的停滞。&lt;/p&gt;
&lt;p&gt;RMSprop[5]和Adadelta[6]是提出来解决上述Adagrad学习率降到任意小问题的，RMSprop的基本思想是，instead of 除以所有梯度平方的累积，RMSprop将学习率除以梯度平方的指数衰减平均$E[g^2]$，梯度平方的指数衰减平均$E[g^2]$可以表示前w个平方梯度的累积，又避免了直接存储前w个平方梯度的存储开销，这样能够有效防止无限小的，单调下降的，diminishing的learning rate问题，RMSprop更新规则如下：&lt;br&gt;$g_t$代表time step t时刻的梯度向量。&lt;/p&gt;
&lt;p&gt;$E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho)g_t^2 $&lt;/p&gt;
&lt;p&gt;$\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_{t,i} = \theta_t - \frac {\eta} {RMS[g]_t} \cdot g_{t,i}$&lt;/p&gt;
&lt;h2 id=&quot;Adadelta&quot;&gt;&lt;a href=&quot;#Adadelta&quot; class=&quot;headerlink&quot; title=&quot;Adadelta&quot;&gt;&lt;/a&gt;Adadelta&lt;/h2&gt;&lt;p&gt;Adadelta[6]为与RMSprop几乎同一时间提出来的，可以看做在RMSprop的基础上做了进一步的改进的版本。其与RMSprop的关键区别就在于Adadelta统一了$\Delta \theta$与$\theta$的单位(unit)。&lt;br&gt;作者指出，在原来的$$\Delta \theta = - \frac {\eta} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_{t,i}$$中，$\Delta \theta$的单位与$\theta$是不匹配的，在SGD，Momentum或者Adagrad中也是如此，所以Adadelta通过引入$\Delta \theta^2$的指数衰减平均，来使得单位统一。故Adadelta的更新式为：&lt;br&gt;$E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho)g_t^2$&lt;/p&gt;
&lt;p&gt;$\theta_{t+1} = \theta_t - \frac {\sqrt {E[\Delta \theta^2]_{t-1} + \epsilon}} {\sqrt{E[g^2]_t + \epsilon}} \cdot g_t$&lt;/p&gt;
&lt;p&gt;$E[\Delta \theta^2]_t = \rho E[\Delta \theta^2]_{t-1} + (1-\rho)\Delta \theta_t^2$&lt;/p&gt;
&lt;p&gt;where $\rho$ 是类似于Momentum中的衰减率常数。&lt;br&gt;Adadelta有两个重要的优点，1) 解决了学习率随着训练持续减小的问题 2) 无需预先设置学习率超参&lt;br&gt;[6]指出，在MNIST数据集上，Adadelta的参数敏感性好于SGD,Momentum和Adagrad等算法。&lt;/p&gt;
&lt;h2 id=&quot;Adam&quot;&gt;&lt;a href=&quot;#Adam&quot; class=&quot;headerlink&quot; title=&quot;Adam&quot;&gt;&lt;/a&gt;Adam&lt;/h2&gt;&lt;p&gt;另一个现在用的较多的自适应学习率方法是Adam(Adaptive Moment Estimation)[7]，Adam结合了RMSprop和Momentum的思想，不过Adam不仅维护过去一阶梯度的指数衰减平均$m_t$(exponentially decaying average of past gradients)，而且还维护二阶梯度的指数衰减平均$v_t$，并且加入了bias-correction步骤，以纠正$m_t, v_t$初始化为0带来的偏差(bias)，由是可得到Adam的更新规则如下：&lt;/p&gt;
&lt;p&gt;$m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t $&lt;/p&gt;
&lt;p&gt;$v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2 $&lt;/p&gt;
&lt;p&gt;$\hat{m}_t = \frac {m_t} {1-\beta_1^t} $&lt;/p&gt;
&lt;p&gt;$\hat{v}_t = \frac {v_t} {1-\beta_2^t}$&lt;/p&gt;
&lt;p&gt;$\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v}_t} + \epsilon} \cdot \hat{m}_t $&lt;/p&gt;
&lt;p&gt;where $\beta_1, \beta_2$ is exponential decay rates of moment estimates.&lt;br&gt;[7]中推荐参数设置为$\eta = 0.001, \beta_1 = 0.9, \beta_2 = 0.999 \&lt;br&gt; and \ \epsilon = 1e-8$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Actually, Adam algorithm works well in practice, not only in acedemia but industry. Empirical results show that Adam consistantly outperforms other methods for a variety of models and datasets, and it’s a versatile algorithm that scales to large-scale high-dimensional machine learning problems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Optimization-Algorithms-Relationship&quot;&gt;&lt;a href=&quot;#Optimization-Algorithms-Relationship&quot; class=&quot;headerlink&quot; title=&quot;Optimization Algorithms Relationship&quot;&gt;&lt;/a&gt;Optimization Algorithms Relationship&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://blog-image-1256228880.cos.ap-beijing.myqcloud.com/optimization.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;p&gt;[1] &lt;a href=&quot;https://arxiv.org/pdf/1609.04747.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Sebastian Ruder. An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;br&gt;[2] &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.5612&amp;amp;rep=rep1&amp;amp;type=pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ning Qian. On the Momentum Term in Gradient Descent Learning Algorithms&lt;/a&gt;&lt;br&gt;[3] &lt;a href=&quot;https://scholar.google.com/citations?user=DJ8Ep8YAAAAJ&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Y. Nestrov. A method of solving a convex programming problem with convergence rate O (1/k2)&lt;/a&gt;&lt;br&gt;[4] &lt;a href=&quot;http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;John Duchi et.al. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization&lt;/a&gt;&lt;br&gt;[5] &lt;a href=&quot;http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Geoffrey Hinton et.al Lecture 6. RMSprop&lt;/a&gt;&lt;br&gt;[6] &lt;a href=&quot;http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Matthew D. Zeiler. ADADELTA: AN ADAPTIVE LEARNING RATE METHOD&lt;/a&gt;&lt;br&gt;[7] &lt;a href=&quot;https://arxiv.org/pdf/1412.6980.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Diederik P. Kingma et.al. ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;关于神经网络一阶优化算法，网上已经有很多资料了，本文为笔者很久之前做的一份梳理，整理了一下一些popular的一阶优化算法及他们的逻辑线，优缺点等。读者自行甄别，自取所需，大神直接过即可。&lt;/p&gt;
&lt;h2 id=&quot;Notations&quot;&gt;&lt;a href=&quot;#Notations
    
    </summary>
    
      <category term="机器学习 | Mac.Learning" scheme="http://whatbeg.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Mac-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
      <category term="优化" scheme="http://whatbeg.com/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning读书笔记（6）--【卷积神经网络】</title>
    <link href="http://whatbeg.com/2018/03/07/deeplearningbook-06.html"/>
    <id>http://whatbeg.com/2018/03/07/deeplearningbook-06.html</id>
    <published>2018-03-07T08:36:20.000Z</published>
    <updated>2018-03-07T08:37:21.022Z</updated>
    
    <content type="html">&lt;p&gt;本章写卷积神经网络，本文摘其中的要点稍作梳理。&lt;/p&gt;
&lt;p&gt;个人觉得，看完本章应该获得如下的take home message：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷积和卷积神经网络的基本概念&lt;/li&gt;
&lt;li&gt;卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&lt;/li&gt;
&lt;li&gt;池化及其背后的idea和意义&lt;/li&gt;
&lt;li&gt;随机/无监督特征&lt;/li&gt;
&lt;li&gt;神经科学基础与卷积网络的密切关系&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;卷积和卷积神经网络的基本概念&quot;&gt;&lt;a href=&quot;#卷积和卷积神经网络的基本概念&quot; class=&quot;headerlink&quot; title=&quot;卷积和卷积神经网络的基本概念&quot;&gt;&lt;/a&gt;卷积和卷积神经网络的基本概念&lt;/h2&gt;&lt;p&gt;卷积网络的基本概念默认本文读者已知。&lt;br&gt;“卷积”这个词笔者第一次听到是在《信号与系统》课程中，在计算机领域主要是离散的卷积。&lt;br&gt;卷积网络的工作过程网上已经讲的很多了，众多资料中又数July写的&lt;a href=&quot;http://blog.csdn.net/v_july_v/article/details/51812459&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《通俗理解卷积神经网络（cs231n与5月dl班课程笔记）》&lt;/a&gt;尤为通俗易懂，推荐阅读。&lt;br&gt;总的来说，卷积网络尤其适合处理具有类似网格结构的数据，如具有序列结构的时间序列数据，就可以看做一维网格，具有空间结构的图像数据等即可看做二维网格。&lt;/p&gt;
&lt;h2 id=&quot;卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&quot;&gt;&lt;a href=&quot;#卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&quot; class=&quot;headerlink&quot; title=&quot;卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&quot;&gt;&lt;/a&gt;卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&lt;/h2&gt;&lt;p&gt;重点在于此节。此节的三种重要概念是卷积网络能够发挥现在如此大作用的内在原因。&lt;br&gt;讲述以图片数据为例。&lt;/p&gt;
&lt;p&gt;稀疏交互，指的是在处理图像时，卷积网络上层每个神经元的状态并不取决于整张图片，而是取决于一个局部感受野（如一张人脸图片，某个神经元的状态取决于下巴的那一小块区域），对局部感受野进行提取的小矩阵称为卷积核。&lt;br&gt;原来对图片进行处理，通常是通过稠密矩阵相乘等方法来做，即图像矩阵乘以一个权重矩阵，然后预测，训练此权重矩阵，这样的方式和全连接相差无几，效率不高，且分类预测效果不佳。&lt;br&gt;所以，“稀疏”是指相对于全连接来说，用比原来小得多的卷积核矩阵来代替全连接矩阵，相当于除卷积核之外的连接权重全为0.&lt;br&gt;通过卷积核可以对一些小的特征进行提取，比如检测图像边缘信息。通过多个卷积核可以提取多种图像特征信息。&lt;br&gt;稀疏的交互大大减小了存储开销，提高计算效率，从而也推进了算法的研究，使得卷积网络可以往更深层次走。&lt;/p&gt;
&lt;p&gt;参数共享，指的是，比如对于100x100的图像，一个大小10x10的卷积核，固定具有10x10=100个参数，不管这个卷积核在与图像的哪一部分进行卷积，这些参数都是相对一致的。不同于全连接，会有100x100=10000个参数，整个神经网络的参数量瞬间缩减了100倍。当然这也导致了一个卷积核只能提取一种特征，为了提取多种特征，我们需要采用多个卷积核，这多个卷积核的参数就通常不会相同了。参数共享，也使得存储开销，计算效率提高，硬件压力越小，从而推进算法研究。&lt;/p&gt;
&lt;p&gt;等变表示，指的是，图像中某一元素/成分的移动，在上层神经元中也表现为一定的移动。这是由参数共享直接带来的，因为移动过程中卷积核的参数不变。这种等变表示使得图像的平移不会对分类预测结果产生太大的影响，使得学习算法能够对相同内容不同位置的图像较为准确的识别。&lt;/p&gt;
&lt;h2 id=&quot;池化及其背后的idea和意义&quot;&gt;&lt;a href=&quot;#池化及其背后的idea和意义&quot; class=&quot;headerlink&quot; title=&quot;池化及其背后的idea和意义&quot;&gt;&lt;/a&gt;池化及其背后的idea和意义&lt;/h2&gt;&lt;p&gt;池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。&lt;br&gt;池化操作有点类似于降低图像分辨率，最大池化用最突出的像素表示该像素周围一小块像素区域的总体。除此之外还有平均池化。&lt;br&gt;在生活中，池化类似于通常的“代表”，通常话语权细化到每个人会非常的繁琐，低效，从而从一个群体中选取一个“代表”来为整个群体说话就成为意见很自然的事情。&lt;br&gt;池化具有局部平移不变性，由于最后局部的像素会聚集，所以图像微小的平移有时并不会对池化的结果产生影响。通常当我们只关心某些特征是否出现而不关心其出现在何位置时池化显得非常有用。因为池化过后存储需求又进一步降低了，计算效率再次提升。&lt;/p&gt;
&lt;p&gt;卷积和池化可以理解为两个无限强的先验。&lt;br&gt;卷积是这样的先验：该层应该学得的函数只包含局部连接关系且对平移具有等变性。&lt;br&gt;池化则是这样的先验：每一个单元都具有对少量平移的不变性。&lt;/p&gt;
&lt;h2 id=&quot;随机-无监督特征&quot;&gt;&lt;a href=&quot;#随机-无监督特征&quot; class=&quot;headerlink&quot; title=&quot;随机/无监督特征&quot;&gt;&lt;/a&gt;随机/无监督特征&lt;/h2&gt;&lt;p&gt;卷积核的确定有几种方式，一种是随机确定，一种是手动指定，另一种是采用无监督的标准来学习到一个卷积核。&lt;br&gt;通常允许底层的特征确定和上层的分类相分离，即底层采用无监督方法来学习特征，构造供高层使用的训练集，然后高层采用一个分类算法（可非神经网络）来进行分类。&lt;/p&gt;
&lt;h2 id=&quot;神经科学基础与卷积网络的密切关系&quot;&gt;&lt;a href=&quot;#神经科学基础与卷积网络的密切关系&quot; class=&quot;headerlink&quot; title=&quot;神经科学基础与卷积网络的密切关系&quot;&gt;&lt;/a&gt;神经科学基础与卷积网络的密切关系&lt;/h2&gt;&lt;p&gt;卷积网络是受神经科学启发，成功应用于机器学习领域一个范例。&lt;br&gt;卷积网络有其神经科学的基础在。&lt;br&gt;比如卷积即使模拟初级视觉皮层的简单细胞，其活动可概括为在一个小的空间位置感受野内的图像的线性函数。&lt;br&gt;池化则启发自初级视觉皮层的复杂细胞，其对特征位置的微小偏移具有不变性。&lt;/p&gt;
&lt;p&gt;类似从神经科学中启发出来的还有注意力机制，目前在NLP领域应用比较成功，在视觉领域则未见大成。卷积网络目前仍然主要集中于视觉。&lt;/p&gt;
&lt;p&gt;Hinton在1988年提出了基于反向传播的时延神经网络(time delay neural network, TDNN)，主要用于一维的时间序列分析，此后LeCun在1998年左右将反向传播应用到二维图像的识别，成功发明了LeNet并开启了现代卷积网络的大门。&lt;/p&gt;
&lt;p&gt;卷积网络也是第一批能使用反向传播进行有效训练的深度网络之一。&lt;br&gt;一般的反向传播网络被认为是失败的，但是卷积网络加上反向传播奇迹般的发挥了很好的效果。&lt;br&gt;本书作者认为，可能是卷积网络的计算效率更高，能够快速运行实验并进行调参的原因。。&lt;/p&gt;
&lt;p&gt;总的来说，卷积网络是神经网络的一种特化，这种特化在具有空间/序列等网格结构拓扑上表现良好，实际上，卷积网络的杀手级应用还是在二维图像方面。一维的序列处理（时间序列，文本序列等）主要被另一种神经网络的特化–循环神经网络所占领。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本章写卷积神经网络，本文摘其中的要点稍作梳理。&lt;/p&gt;
&lt;p&gt;个人觉得，看完本章应该获得如下的take home message：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷积和卷积神经网络的基本概念&lt;/li&gt;
&lt;li&gt;卷积网络背后的三个重要概念：稀疏交互，参数共享，等变表示&lt;/li&gt;

    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>湖南农村个体经营所面临的形势变迁考（2008-2018）</title>
    <link href="http://whatbeg.com/2018/03/01/countrysideretail.html"/>
    <id>http://whatbeg.com/2018/03/01/countrysideretail.html</id>
    <published>2018-03-01T02:02:29.000Z</published>
    <updated>2018-03-01T02:05:35.255Z</updated>
    
    <content type="html">&lt;p&gt;近十年来（2008-2018）中国经济仍然以较高的速度发展，人均可支配收入稳步提升，带来了消费的提升和消费结构明显的变化，给包括城市和农村在内的个体经营带来了很大的影响。那我们能否对此种变化做一种合理的解释，并能够启发我们对未来农村个体经济形势的合理预测呢？&lt;/p&gt;
&lt;p&gt;本文决定考察农村消费模式和消费结构十年间（2008-2018）的变迁。&lt;/p&gt;
&lt;p&gt;限于笔者的经历，本文以湖南某农村为例，经济体上选取该农村某个体经营户A为例。A商户位于村中心区域，毗邻一所农村中学（初中），2008年该校学生500人左右，2018年该校学生150人左右。该区域有商户3家，卫生院一家，屠宰店一家，修理店一家，以及周边住户数户。村庄无自然资源相关产业，外出务工人员较多。&lt;/p&gt;
&lt;p&gt;我们将要研究的消费大致分为三种，年节消费，日常消费以及特殊日消费。&lt;/p&gt;
&lt;p&gt;年节消费是指春节前后等重要传统节日期间的消费，这期间随着外出务工人员的返乡，农村活动人口增加，拉动消费增长。&lt;/p&gt;
&lt;p&gt;日常消费是指一年中非年节或重要日期的消费，主要消费人群为周边住户，以及学生群体，后续会详细介绍。&lt;/p&gt;
&lt;p&gt;特殊日消费是指重要事件造成的消费，比如因红白喜事或生日等各种宴请之日的消费。&lt;/p&gt;
&lt;h2 id=&quot;年节消费&quot;&gt;&lt;a href=&quot;#年节消费&quot; class=&quot;headerlink&quot; title=&quot;年节消费&quot;&gt;&lt;/a&gt;年节消费&lt;/h2&gt;&lt;p&gt;十年前：&lt;/p&gt;
&lt;p&gt;由于十年前交通不如现在发达，村民乘用车的持有量非常小，交通不便，外出务工人员返乡只能搭乘公共交通，辗转不便，且周边大型超市较少，到村中商户进行年货采购者所占多数。十年前，年货主要销售量由烟花爆竹，糖果炒货，烟酒槟榔，饮料支撑，春节期间主要销售为礼品（烟酒，奶制品等）所支撑。商户在春节前后应接不暇，总体销售量大。&lt;/p&gt;
&lt;p&gt;十年后：&lt;/p&gt;
&lt;p&gt;随着社会经济的飞速发展，农村大型超市个数逐渐增多，且离村不到10公里路程，搭乘公共汽车只需12分钟时间，而且超市的批量低价，且常有的促销活动逐渐抢占了部分农村个体商户的日常食品用品的零售业务；再者，村民乘用车持有量逐渐增加，该村离省城长沙具有70多公里，十年间一条高速开通，将去往省城长沙的时间由3个小时缩短到1个小时左右，大大方便了来回的村民，况且在长沙务工的人员所在多有，往来携带商品也司空见惯，交通的便利带来了对农村消费的冲击。综合以上两点，年节消费中的糖果炒货的消费被挤占殆尽，几近于无。故而如今的年货消费以烟花爆竹，烟酒槟榔以及饮料，礼品为主要成分。原因在于，政府部门由于安全问题频发，山火等频发，逐渐限制烟花爆竹的销售和燃放，实行许可证机制，在城市中只有极少的商户经营此类，在乡村中也需要具有符合一定安全条件的库房者才可经营，且由于烟花爆竹体量大，运输不便，所以城市的烟花爆竹消费对农村影响甚微。由于烟花爆竹在农村人眼中仍为年节必需品，故而烟花爆竹类消费比重逐渐增加到了极高点。未来烟花爆竹类商品的销售可能会被严格限紧，此类消费一经禁止，那么农村商户的年节经营利润下降一大截。其次是烟酒槟榔，这种商品受众固定，且价格不具弹性，即在何处购买都是一个价，故而此类消费收到的影响也极小。其次，饮料为年节餐桌上必不可少的一种消费品，且其重量大，也不便携带，受到的影响也不是很大。春节期间的消费主要为各种礼品所占，销售额的大头又为烟酒所占，这二者价格并不低廉，所以能够支撑一定的消费额。以烟来说，一条软白沙的价格在45左右，一条盒白沙的价格在50左右，一条精白沙的价格在80左右，一条芙蓉王的价格在225左右。以酒来说，一对（两瓶）礼品白酒的价格在40-200元不等。其次的一些主要礼品为礼盒装水果，由于其质量难以保证，重量大不便携带，只被少数消费者青睐，近年来已逐渐淡出该村市场。其次有提装奶制品，营养品等赠送老人小孩的佳品，销售量所在较大。据推测，中高档礼品烟酒的销售可能也受到了城市经济的冲击。&lt;/p&gt;
&lt;p&gt;综上，农村商户年货的销售额的大头已逐渐为烟酒和烟花爆竹所占，在烟花爆竹这一块的利润极不稳定，有被完全清除的风险，农村商户年节的销售可能还会面临紧缩，必须采取一定措施，另辟蹊径，找到其他的稳定盈利点。&lt;/p&gt;
&lt;h2 id=&quot;日常消费&quot;&gt;&lt;a href=&quot;#日常消费&quot; class=&quot;headerlink&quot; title=&quot;日常消费&quot;&gt;&lt;/a&gt;日常消费&lt;/h2&gt;&lt;p&gt;十年前：&lt;/p&gt;
&lt;p&gt;日常消费的消费者主要分为两大块，一是农村常住人口，衣食住行，食和用大量都靠本地商店提供，同样也是由于交通不发达，且农村经济落后，大超市少，竞争少，农村个体商户拥有着良好的盈利空间。二是其他人口，如毗邻中学的学生。十年前，该中学还是如日中天，吸引着来自多个邻村的众多适龄学生人口，该校共有4届学生，包括6年级，初中1,2,3年级，每个年级一般为两个班，每班50-60人左右，大概每届有100多人，全校400-500人。且学校允许通学，即允许离家近的同学不在学校住宿，每周末放两天假。由此，每天的流动学生较多，当时A商户在零售之外开早餐副业，经营米粉，包点和烧烤等业务，吸引学生不计其数，每天早上生意兴隆，且以周五下午和周一早上人尤多，生意尤胜，早餐之外，大量销售食品，文具等南杂百货。&lt;/p&gt;
&lt;p&gt;十年后：&lt;/p&gt;
&lt;p&gt;日常消费逐渐由农村常住人口所主导，且受到了村镇大超市的冲击，生意与十年前相差径庭。&lt;br&gt;一方面，农村常住人口乘用车，摩托车等非常常见，与镇中心的交通时间缩短，与发达邻镇的距离也大大缩短，大型超市林立，超市商品种类众多，不是小型个体户所能比拟，从而严重冲击这农村本地商户的日用品，小食品，百货等的销售。&lt;br&gt;另一方面，为了安全起见，毗邻的中学早已全面实行寄宿制，学生外出活动被严格限制，且学校学生人数大量减少，因为大量家长更愿意把他们的孩子送往县里更优秀的初级中学就读，加之农村适龄学生本来就在减少，于是该校总学生数由十年前的500多人减少到现在的约100-200人（具体数字不详），不甚萧条。这也导致了商品零售业务不断地走下坡路。&lt;/p&gt;
&lt;p&gt;综上，农村商户的日常销售主要受到农村活动人口减少以及大型超市的冲击这两方面的因素，导致境况大大不如以前。农村个体户经营主要走的是熟人经济，消费者主要还是老顾客，很难拓宽客户，这就给农村商户的破局带来了更多的挑战。如果不能找出良好的破局方法，那么最终农村商户的销售将会被挤压到一个下线，维持基本客观的盈利将遥遥无期，最终可能会造成多个商户的退出。&lt;/p&gt;
&lt;h2 id=&quot;特殊日消费&quot;&gt;&lt;a href=&quot;#特殊日消费&quot; class=&quot;headerlink&quot; title=&quot;特殊日消费&quot;&gt;&lt;/a&gt;特殊日消费&lt;/h2&gt;&lt;p&gt;特殊日的消费主要包括红白喜事，宴请，庆典等活动带来的大批量订购，一般价格也会有所优惠，这种形式也决定了订购的商品种类很有限。&lt;/p&gt;
&lt;p&gt;十年间，此种消费模式并未收到多大影响，因其具有非常强的本地性。&lt;/p&gt;
&lt;p&gt;但无论如何，此种消费可遇而不可求，且不可多求，纵使其单次订购量大，也根本无法充当主要的销售量，充其量不过是销售中的调味剂罢了。在农村商户中，零售仍为其主要。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;所以，笔者大致推测，如今以上三种消费所占农村个体商户的销售额比重大致为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;年节消费：日常消费：特殊日消费 = 20% : 75% : 5%&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;（笔者臆测，可能失准）&lt;/p&gt;
&lt;p&gt;由此看来，作为农村个体经营户，主要销售额和利润仍然来自于日常的销售，仍然需要将重点着眼于日常销售。可当前农村个体经营户面临的最大的几个挑战在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;农村常住人口稀少，顾客客源少&lt;/li&gt;
&lt;li&gt;客户比较固定，较难扩展&lt;/li&gt;
&lt;li&gt;大型零售超市的竞争&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;笔者猜测，如何有效应对这三个挑战，是当前所有中国农村个体商户所面临的重大问题，这关乎生存问题，不可不察，不可不思危，不可不思变。且面临的问题已经到了一个极严重的地步，值得所有农村个体商户做深入的思考，未雨绸缪，否则只能走向关门的境地。&lt;/p&gt;
&lt;p&gt;至于解决之道，本文暂且不表，读者可发挥才智，自谋良策。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;近十年来（2008-2018）中国经济仍然以较高的速度发展，人均可支配收入稳步提升，带来了消费的提升和消费结构明显的变化，给包括城市和农村在内的个体经营带来了很大的影响。那我们能否对此种变化做一种合理的解释，并能够启发我们对未来农村个体经济形势的合理预测呢？&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="随笔 | Essays" scheme="http://whatbeg.com/categories/%E9%9A%8F%E7%AC%94-Essays/"/>
    
    
      <category term="随笔" scheme="http://whatbeg.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
      <category term="人文社科" scheme="http://whatbeg.com/tags/%E4%BA%BA%E6%96%87%E7%A4%BE%E7%A7%91/"/>
    
  </entry>
  
  <entry>
    <title>如何着手你的第一篇paper</title>
    <link href="http://whatbeg.com/2018/02/04/writefirstpaper.html"/>
    <id>http://whatbeg.com/2018/02/04/writefirstpaper.html</id>
    <published>2018-02-04T03:25:11.000Z</published>
    <updated>2018-02-04T03:28:55.246Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;原文： Elena D. Kallestinova 《How to Write Your First Research Paper》 Yale University.&lt;br&gt;原文地址： &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3178846/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3178846/&lt;/a&gt;&lt;br&gt;译者： whatbeg, Google translation&lt;br&gt;译文地址： &lt;a href=&quot;http://whatbeg.com&quot;&gt;http://whatbeg.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;对于许多新手作者来说，撰写科学研究手稿是一个令人生畏的过程。其中一个绊脚石就是流程的开始和第一稿的创建。本文介绍了如何启动写作过程和起草一个研究手稿的每个章节的准则。本文讨论了能够使作者为出版物提交一份结构良好、内容全面的稿件的七条规则。此外，作者列出了成功修订的不同策略。这些策略中的每一个都代表了修订过程中的一个步骤，应该有助于作者提高稿件的质量。这篇论文可以看作是出版的一本简短手册。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;这是深夜。你一年来一直在为你的项目苦苦挣扎。你生成了大量有趣的数据。你的移液管感觉像是你的手的延伸，进行免疫印迹分析已经成为你日常工作的一部分，类似于刷牙。你的同事们认为你已经准备好写一篇论文了，而你的实验室的同事们也会为你的写作进展“缓慢”而挑逗。然而，时光流逝，你不能强迫自己坐下来写作。你有一段时间没有写任何东西（实验报告不算），你觉得你已经失去了耐力。写作过程如何进行？你怎么能把你的写作融入实验的日程呢？你应该从哪一部分开始？一个好的研究报告和一个坏的报告有什么区别？你应该如何修改你的文件？这些和其他许多问题在你的脑海中嗡嗡作响，让你感到压力。结果，你拖延了。在本文中，我将讨论与科学论文写作过程有关的问题。具体而言，我将重点介绍开始撰写科学论文的最佳方法，撰写各部分的提示以及最佳修订策略。&lt;/p&gt;
&lt;h2 id=&quot;在Outlook中安排你的写作时间&quot;&gt;&lt;a href=&quot;#在Outlook中安排你的写作时间&quot; class=&quot;headerlink&quot; title=&quot;在Outlook中安排你的写作时间&quot;&gt;&lt;/a&gt;在Outlook中安排你的写作时间&lt;/h2&gt;&lt;p&gt;无论你是否写了100篇论文，或者你正在努力工作，开始这个过程是最困难的部分，除非你有一个严格的写作时间表。写作很难。这是一个非常困难的过程，集中精力和大脑的工作。正如Hayes的写作研究框架所述：“这是一种需要动机的生成性活动，它是一种需要认知过程和记忆的智力活动”[1]。保罗·西尔维亚（Paul Silvia）在他的“如何写作：生产性学术写作的实用指南”一书中说，对于某些人来说，“保存尸体更容易，而不是写一篇关于它的文章”[2]。就像任何艰苦的工作一样，除非你经常练习，否则你将不会成功。如果你一年没有做过体育锻炼，只有定期锻炼才能让你恢复健康。同样的经常性练习，或者我称之为“写作练习”，都需要成为一个富有成效的作者。在日常工作时间表中选择1到2小时的块，并将其视为不可取消的约会。在确定要写入哪些时间块时，应该选择最适合此类工作的时间。对于很多人来说，早晨更富有成效。一位耶鲁大学研究生从上午8点到上午9点写了一个学期的论文，当时她的实验室是空的。在学期结束的时候，她感到非常惊讶，因为论文的完成完全没有打断他的正常实验时间。另外，一天的第一件事情是做最困难的事情，在一天中的其余时间里都会有成就感。这种积极的情绪渗透到我们的工作和生活中，对我们的整体态度有非常积极的影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则1：在日历中创建常规时间块作为写作时间，并保留这些日程。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;从大纲开始&quot;&gt;&lt;a href=&quot;#从大纲开始&quot; class=&quot;headerlink&quot; title=&quot;从大纲开始&quot;&gt;&lt;/a&gt;从大纲开始&lt;/h2&gt;&lt;p&gt;现在你已经预定了时间，你需要决定如何开始写作。 最好的策略是从一个大纲开始。 这不会是你习惯的大纲，每个部分用罗马数字表示，主题句子和支持点并排列出。 这个大纲将类似于你的论文模板。 最初，大纲将为你的论文形成一个结构; 这将有助于产生想法和制定假设。 根据George M. Whitesides的建议，“。。。 从一张空白的纸张开始，以任何顺序写下所有关于论文的重要想法“[3]。 使用表1作为大纲的起点。 包括你的视觉效果（数字，表格，公式，方程和算法），并列出你的发现。 这些将构成你的大纲的第一层，随着你的阐述，这些内容将最终扩展。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/writepaper01.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;下一个阶段是添加上下文和结构。 在这里，你将把所有想法分为几个部分：介绍，方法，结果和讨论/结论（表2）。 这一步将有助于增加工作的连贯性并筛选你的想法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/writepaper02.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在你已经扩展了你的大纲，你准备好了下一步：与你的同事和导师讨论你的论文的想法。 许多大学都有写作中心，研究生可以安排个别咨询，并接受他们的论文草稿。 在草稿的早期阶段获得反馈可以节省大量时间。 通过思想进行交谈，人们可以将思想概念化并组织起来，而不会浪费时间在不必要的写作上。 大纲是沟通你的想法和交流想法的最有效的方式。 而且，这也是决定你要提交论文的出版物的最佳阶段。 许多人提出了三个选择，并与导师和同事讨论。 如果你的论文被拒绝，列出期刊优先级列表可以帮助你快速重新提交论文。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则2：制定详细的大纲，并与导师和同行讨论。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;继续完善草稿&quot;&gt;&lt;a href=&quot;#继续完善草稿&quot; class=&quot;headerlink&quot; title=&quot;继续完善草稿&quot;&gt;&lt;/a&gt;继续完善草稿&lt;/h2&gt;&lt;p&gt;当你得到足够的反馈意见，并决定你将提交的期刊，真正的写作过程开始。将大纲复制到单独的文件中，并展开每个要点，添加数据并详细说明。当你创建初稿时，不要屈服于编辑的诱惑。不要放慢速度来选择一个更好的词或更好的词组;不要停下来改善你的句子结构。把你的想法写进论文中，稍后修改和编辑。正如保罗·西尔维娅（Paul Silvia）所解释的那样：“在创建文本时进行修改就像在清晨喝不含咖啡因的咖啡：崇高的想法，错误的时间”[2]。&lt;/p&gt;
&lt;p&gt;许多学生抱怨说，他们不是生产性的作家，因为他们经历了作家的阻塞。盯着一个空的屏幕是令人沮丧的，但你的屏幕并不是真的是空的：你有一个你的文章的模板，所有你需要做的是填补空白。事实上，作家的阻塞是一个科学家的逻辑谬误 - 这只是一个拖延的借口。当科学家开始撰写研究论文时，他们已经有了数据文件，实验室记录，材料和实验设计，一些视觉效果和有结果的表格。他们所需要做的就是审视这些作品，并把它们放在一个综合性的论文中。&lt;/p&gt;
&lt;h2 id=&quot;从材料和方法部分开始&quot;&gt;&lt;a href=&quot;#从材料和方法部分开始&quot; class=&quot;headerlink&quot; title=&quot;从材料和方法部分开始&quot;&gt;&lt;/a&gt;从材料和方法部分开始&lt;/h2&gt;&lt;p&gt;如果你仍然难以开始撰写论文，请先写下材料和方法部分。既然你有所有的笔记，那么描述实验设计和程序就不会有问题了。本节中最重要的目标是尽可能明确地提供足够的细节和参考资料。最后，本节的目的是让其他研究人员评估和重复你的工作。所以不要和（1）中的句子作者一样遇到同样的问题：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;1A。细菌通过离心沉淀。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;1B。为了分离T细胞，收集淋巴结。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;正如你所看到的，缺少关键的信息：（1a）中离心细菌的速度，时间和温度; （b）中收集淋巴结的来源。如（2a）和（2b）所示，在添加信息时可以改进句子：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2A。在25℃以3000g离心15分钟沉淀细菌。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2B。为了分离T细胞，在用ovabumin免疫后第7天收集来自Balb / c小鼠的纵隔和肠系膜淋巴结。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;如果你的方法之前已经发表并且是众所周知的，那么你应该只提供参考文献，如（3a）所示。如果你的方法未发布，那么你需要确保提供所有基本的细节，如（3b）所示。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;3A。根据约翰逊[23]，干细胞被分离出来。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;3B。使用涂布有抗CD34抗体的生物素化碳纳米管分离干细胞。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;而且，在这一部分，凝聚力和流畅度是至关重要的。如（4）所示，导致流畅性中断的不当行为之一是在同一段落内从被动语态转换为主动语态，反之亦然。这种转换会误导读者。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;4.研究1的行为计算机实验通过使用E-Prime进行编程。通过使用视觉模拟量表（SI方法），患者听到喜欢的音乐和不良音乐，我们对乐趣，情绪和兴奋进行评分。音乐的首选和不受欢迎的地位是沿着愉悦的连续体来实现的[4]。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;（4）的问题是，读者必须从实验的角度（被动语态）转换到实验者的观点（主动语态）。这个开关引起第一句和第三句中的动作表演者的混淆。为了提高上述段落的连贯性和流畅性，你应该在选择观点上保持一致：第一人称“我们”或被动语态[5]。 （5）中考虑两个修改后的例子。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;5A。我们通过使用E-Prime来编程研究1的基于行为计算机的实验。我们采用视觉模拟评分法（SI方法）对患者的喜悦，情绪和兴奋进行评分，听患者喜欢听音乐和听音乐。我们沿着愉悦的连续性实现了音乐的首选和不重要的地位。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;5B。研究1的行为计算机实验通过使用E-Prime进行编程。当患者通过使用视觉模拟量表（SI方法）听取喜欢的愉悦音乐和不良音乐时，享受乐趣，情绪和唤醒的评级。音乐的首选和不受欢迎的状态是沿着愉快的连续性进行的。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;如果你选择实验者的观点，那么你最终可能会重复“我们这样做”的句子。对于很多读者来说，句子全部以“我们”开头的段落也可能听起来有破坏性。所以，如果你选择主动句子，你需要保持“我们”主题的数量最少，并改变句子的开始[6]。&lt;/p&gt;
&lt;p&gt;有趣的是，最近的研究已经报道，材料和方法部分是研究论文中的唯一部分，其中被动语态主要覆盖了主动语态的使用[5,7,8,9]。例如，Martínez在“生物科学”的实验性全文研究文章[1]的100万字的语料库的基础上，显示了方法部分主动语音使用的显着下降[7]。笔者认为，以“我们”为模板的主动语态只是在设计和执行实验工作中，作为一个工具来揭示个人对程序决策的责任。这意味着，虽然研究论文的所有其他部分使用主动语态，但被动语态仍然是材料和方法部分中最主要的部分。&lt;/p&gt;
&lt;p&gt;写作材料和方法部分是一个细致和耗时的任务要求极端的准确性和清晰度。这就是为什么当你完成你的草稿时，你应该尽可能多地从你的同事那里得到反馈。本节众多读者将帮助你找出缺失的环节，提高本节的技术风格。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则3：在描述材料和方法时要细致和准确。不要在一个段落内改变观点。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;撰写结果部分-Results&quot;&gt;&lt;a href=&quot;#撰写结果部分-Results&quot; class=&quot;headerlink&quot; title=&quot;撰写结果部分(Results)&quot;&gt;&lt;/a&gt;撰写结果部分(Results)&lt;/h2&gt;&lt;p&gt;对于许多作者而言，编写“结果”部分比编写“材料和方法”部分更令人生畏。如果人们对你的论文感兴趣，他们对你的结果感兴趣。这就是为什么使用你所有的写作技巧来客观地用有说服力的材料和文本以有序和合乎逻辑的顺序来呈现你的主要发现是至关重要的。&lt;/p&gt;
&lt;p&gt;你的结果应该被组织成不同的部分或者小节，每个部分或者小节里都有实验的目的，你的实验方法，包括文本和视觉材料（表格，图形，原理图，算法和公式）和数据评论的数据。对于大多数期刊，你的数据评论将包括对视觉材料中呈现的数据的有意义的总结，并对最重要的发现进行解释。这个数据表示不应该重复在视觉上的数据，而是突出最重要的一点。在“标准”研究论文的方法中，你的结果部分应该排除数据解释，留给讨论部分。然而，这些解释逐渐隐秘地渗入到研究论文中：“减少数据，归纳数据，突出科学案例都是高度解释的过程。现在应该清楚，我们不让研究报告中的资料自己说话，在总结我们的结果时，我们将其为读者解读“[10]。因此，包括“实验医学杂志”和“临床调查杂志”在内的许多期刊使用联合的结果/讨论部分，其结果紧接着是解释。&lt;/p&gt;
&lt;p&gt;这部分的另一个重要方面是创建一个全面和支持的论点或一个研究得很好的案例。这意味着你应该有选择性地呈现数据，只选择那些你的读者理解你的发现所必需的实验细节。你可能已经进行了20次实验并收集了大量记录，但这并不意味着你应该在论文中提供所有这些记录。你需要将你的结果与你的数据区分开来，并且能够放弃过多的实验细节，这些细节可能会分散读者的注意力并使其混淆。但是，不应该将图片或论点与数据操纵或伪造混淆，这是数据和结果的故意扭曲。如果你的一些发现与你的想法相矛盾，你必须提到这一点，并找出矛盾的合理解释。&lt;/p&gt;
&lt;p&gt;另外，你的文本不应该包含不相关的和外围的信息，包括概述句，如（6）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为了展示我们的结果，我们首先介绍实验系统的所有组件，然后描述感染的结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;实际上，文字繁冗的句子会让读者隐瞒你的想法。一个常见的词条来源是不必要的增强器。 “清楚”，“基本”，“相当”，“基本上”，“相当”，“相当”，“真正”，“虚拟”等副词强化词不仅增加了句子的冗长度，信誉。 （7）中的常见例子，它们吸引读者的情感，但却降低了客观性：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;7a. Table 3 clearly shows that …&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;7b. It is obvious from figure 4 that …&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;词义的另一个来源是名词化，即来自动词和形容词的名词与弱动词配对，包括“be”，“have”，“do”，“make”，“cause”，“provide”，“get”如“有”。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;8a. We tested the hypothesis that there is a disruption of membrane asymmetry.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;8b. In this paper we provide an argument that stem cells repopulate injured organs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在上面的句子中，抽象的名词化“破坏”和“论证”并没有促进句子的清晰度，而是用无用的词汇来混淆词汇，从而分散了词汇的含义。为了改进你的句子，避免不必要的名词化，把被动动词和结构变成主动和直接的句子。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;9a. We tested the hypothesis that the membrane asymmetry is disrupted.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;9b. In this paper we argue that stem cells repopulate injured organs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;你的结果部分是你的论文的核心，代表你一年或更多的日常研究。因此，通过编写直接，简明和明确的句子，引导读者阅读故事。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则4：在描述你的结果时要清楚，简洁，客观。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;现在是时候编写Introduction了&quot;&gt;&lt;a href=&quot;#现在是时候编写Introduction了&quot; class=&quot;headerlink&quot; title=&quot;现在是时候编写Introduction了&quot;&gt;&lt;/a&gt;现在是时候编写Introduction了&lt;/h2&gt;&lt;p&gt;现在起草研究报告已经完成接近一半了，现在是更新大纲的时候了。 在描述你的方法和结果的同时，你们中许多人偏离原来的大纲，重新集中你的想法。 因此，在继续创建简介之前，请重新阅读“方法和结果”部分，并更改大纲以符合研究重点。 更新后的大纲将帮助你回顾你的论文的总体情况，主题，主要思想和目的，这对于撰写你的介绍非常重要。&lt;br&gt;构建你的介绍的最好方法是遵循表3所示的三步法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/writepaper03.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;大纲中的举措和信息可以帮助你有效地创建Introduction，而不会错过任何步骤。这些行动是交通标志，引导读者通过你的想法的道路。每一招都在你的论文中起着重要的作用，应该深思熟虑。当你建立领土的时候，你把研究放在背景下，突出你研究课题的重要性。通过找到利基，你勾勒出你的研究问题的范围，并进入科学对话。最后一步，“占领利基”，就是你简要介绍研究的地方，突出你的论文的意义。这三个步骤可以让读者评估他们对论文的兴趣，并在论文评审过程中发挥重要作用，从而确定你的论文评论者。&lt;/p&gt;
&lt;p&gt;一些学者作者假定读者“应该按照论文”来找到你的方法和你的发现的答案。因此，许多新手作者不会提出他们的实验方法和主要发现，错误地认为读者将在稍后阅读后续章节时找到必要的信息[5]。然而，这种“悬念”的方式不适合科学写作。为了引起读者的兴趣，科学作者应该直截了当，直截了当地提出结果和方法的信息性的一句话总结。&lt;/p&gt;
&lt;p&gt;另一个问题是作家低估了Introduction的重要性。许多新的研究者错误地认为所有的读者都明白研究问题的重要性，而忽略了这一部分。然而，这个假设是错误的，因为这一部分的目的不是评估一般研究问题的重要性。目标是展示你的研究贡献和你的发现的重要性。因此，在描述本文的益处时，应该明确而清楚地说明。&lt;/p&gt;
&lt;p&gt;Introduction不应该太长。事实上，对于大多数期刊而言，这是一个非常简短的部分，大约有250到600个单词，但是由于它的重要性，它可能是最困难的部分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则5：通过发信号通知所有元素并陈述作品的新颖性，引导读者对其感兴趣。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;对结果（Results）的讨论-–-Discussion编写&quot;&gt;&lt;a href=&quot;#对结果（Results）的讨论-–-Discussion编写&quot; class=&quot;headerlink&quot; title=&quot;对结果（Results）的讨论 – Discussion编写&quot;&gt;&lt;/a&gt;对结果（Results）的讨论 – Discussion编写&lt;/h2&gt;&lt;p&gt;对于许多科学家来说，撰写讨论部分与撰写论文一样可怕。恐惧的大部分来自该部分的变化。由于每篇论文都有其独特的结果和发现，讨论部分的长度，形状和结构各不相同。但是，写这部分的一些基本原则依然存在。了解这些规则或“动作”可以改变你对本节的态度，并帮助你对结果进行全面的解释。&lt;/p&gt;
&lt;p&gt;讨论部分的目的是把你的研究结果放在研究背景下，“解释研究结果的含义以及为什么它们很重要，不带有傲慢，居高临下或者要人领情”[11]。前两个动作的结构几乎是介绍中的一个反映。在介绍中，你可以从一般到特定以及从背景到你的研究问题进行放大;在“讨论”部分中，你可以将研究发现的摘要缩小到研究上下文中，如表4所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/writepaper04.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;讨论部分的开头段落是许多作者面临的最大挑战。遵循表1中的步骤，最好的选择是从研究的主要研究结果开始，这些研究结果为你介绍中的研究问题提供了答案。最常见的起始短语是“我们的发现证明。 。 “或”在这项研究中，我们已经证明了这一点。 。 “或”我们的结果表明。 。 “然而，在某些情况下，提醒读者关于研究问题，甚至提供一个简短的背景，然后说出答案会更有意义。在研究者提出一些发现或提出多个研究问题的情况下，这一点很重要。你对研究主要发现的总结应该在你介绍这些发现的重要性之后进行。新手作家最常犯的错误之一就是假定他的发现的重要性。即使你的重要性是明确的，你的读者可能不明显。将研究结果及其重要性摘要与你的研究问题一样重要。&lt;/p&gt;
&lt;p&gt;另一个有用的策略是通过对结果的替代解释进行预测和评论来采取积极主动的行动。解决潜在的疑惑将会使你免于痛苦的关于你对结果的错误解释的评论，并将使你看起来像一个深思熟虑的体贴研究者。而且，对其他解释的评估可能会帮助你为讨论部分的下一步行动创造一个合乎逻辑的步骤：研究背景。&lt;/p&gt;
&lt;p&gt;研究背景移动的目标是展示你的发现如何符合当前研究的总体情况，以及你如何对该主题的现有知识做出贡献。这也是讨论任何差异和意外发现的地方，否则这些发现可能会扭曲你论文的总体情况。此外，通过显示局限性，弱点和假设来概括研究范围是必不可少的，并为你作为科学家的形象增添了谦虚。但是，请确保你不会因为覆盖你的调查结果的问题而结束你的论文。尝试提出可行的解释和解决方案。&lt;/p&gt;
&lt;p&gt;如果你的提交不需要单独的结论部分，那么添加另一段关于“take-home message”是必须的。这应该是一个一般的声明，重申你对这个研究问题的回答，并增加它的科学含义，实际应用或建议。正如在你的论文的所有其他部分，清晰准确的语言和简洁的综合句子是至关重要的。但是，除此之外，你的写作应该传达信心和权威。说明你的语气最简单的方法是使用主动语态和第一人称代词。伴随着清晰和简洁，这些工具是最好的说服你的读者你的观点和你的想法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则6：以简洁而令人信服的语气表达原则，关系和概括。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;选择最佳的工作修改策略&quot;&gt;&lt;a href=&quot;#选择最佳的工作修改策略&quot; class=&quot;headerlink&quot; title=&quot;选择最佳的工作修改策略&quot;&gt;&lt;/a&gt;选择最佳的工作修改策略&lt;/h2&gt;&lt;p&gt;现在你已经制定了第一稿，你的写作态度应该有所改善。此外，你应该对自己能够在合理的时间内完成项目并提交论文更有信心。你也已经制定了你的写作时间表，并精确地遵循。不要停下来 - 你只是在你的目的地的中点。正如最好的和最宝贵的钻石不过是一个没有吸引力的石头，只有经过培训的专业人士才能认识到，如果你的想法和结果没有被抛光和掠过，你的想法和结果可能会被忽视。尽管你试图以合乎逻辑和全面的方式表达你的想法，但初稿通常是一团糟。使用保罗·西尔维亚（Paul Silvia）的建议：“你的第一份草案应该听起来像是他们被冰岛人以非母语人士的语言急匆匆地翻译过来的。”[2]。你的成功程度将取决于你如何修改和编辑你的论文。&lt;/p&gt;
&lt;p&gt;可以在宏观结构和微观结构水平上进行修改[13]。宏观结构修订包括组织，内容和流程的修订。微观层面包括单词，句子结构，语法，标点符号和拼写。&lt;/p&gt;
&lt;p&gt;处理宏观结构修改的最好方法是通过你论文中的想法概述。在最后一次更新大纲之前，在撰写介绍和讨论之前。现在你已经有了开始和结论，你可以对整张纸进行鸟瞰。大纲将允许你查看你的论文的观点是否连贯，如果你的结果在逻辑上构建，并且讨论与“导论”中的研究问题相关联。你将能够看到任何部分是否缺少某些内容，或者是否需要重新排列信息以表达你的观点。&lt;/p&gt;
&lt;p&gt;下一步是从一开始就修改每个部分。理想情况下，你应该限制自己一次只能在大约五页的小部分上工作[14]。在这些短小的部分之后，你的眼睛会习惯于你的写作，而你发现问题的效率会下降。在阅读内容和组织时，应该控制自己编辑论文结构和语法的要求，只关注你的想法和演示逻辑的流程。经验丰富的研究人员所做的修改往往是新手作者的三倍[15,16]。修改是一个困难但有用的技能，学术作家经过多年的实践获得。&lt;/p&gt;
&lt;p&gt;与宏观结构修正相比，宏观结构修正是一个线性过程，通常通过详细的轮廓和分段来完成，微观结构修正是一个非线性过程。虽然宏观结构修订的目标是分析你的想法和逻辑，微观结构编辑的目标是仔细审视你的想法的形式：段落，句子和文字。你不需要，也不建议按照纸张的顺序执行此类修订。你可以从最后或从不同的部分开始。你甚至可以通过逐句，逐句逐句阅读句子来修改。&lt;/p&gt;
&lt;p&gt;在写作中心咨询过程中经常使用的微观结构修订策略之一是大声朗读论文[17]。你可以大声朗读给自己，录音机，或同事或朋友。在阅读和听取你的论文的时候，你更容易注意到流畅性被打乱的地方，以及由于句子很长，不清楚或者连接错误而导致你跌倒的地方。&lt;/p&gt;
&lt;p&gt;另一个修订策略是学习你的常见错误，并对它们进行有针对性的搜索[13]。所有作家都有一组特定的问题，即他们的写作特质。记住这些问题对学术作家和记住朋友的生日一样重要。创建一个这些特质的列表，并使用你的文字处理器运行这些问题的搜索。如果你的问题是没有总结性单词的指示性代词，那么在你的文本中搜索“this / these / those”，并检查你是否适当地使用了这个单词。如果你使用增强词有问题，则搜索“真正”或“非常”，并从文本中删除它们。可以进行相同的有针对性的搜索以消除冗赘。搜索“有”或“和”可以帮助你避免庞大的句子。&lt;/p&gt;
&lt;p&gt;最后的策略是使用硬拷贝和铅笔。打印字号为14的双倍空间复印件，并分几步重新读取纸张。尝试阅读你的纸张线，其余部分用一张纸覆盖。当你被迫只看到你的一小部分写作，你不太可能分心，更容易发现问题。你最终会发现更多不必要的词语，错误的词组或者不平行的结构。&lt;/p&gt;
&lt;p&gt;在你应用所有这些策略之后，你已经准备好和你的同事分享你的写作了。&lt;/p&gt;
&lt;h2 id=&quot;是时候提交了&quot;&gt;&lt;a href=&quot;#是时候提交了&quot; class=&quot;headerlink&quot; title=&quot;是时候提交了&quot;&gt;&lt;/a&gt;是时候提交了&lt;/h2&gt;&lt;p&gt;这是深夜。 你仍然在你的实验室完成修订并准备好提交论文。 你感到高兴 - 你终于完成了一年的工作。 你明天将提交论文，不管结果如何，你都知道你可以做到。 如果一本杂志没有接收你的论文，你会利用反馈，并再次提交。 你总会把它出版，这是最重要的成就。&lt;/p&gt;
&lt;p&gt;更重要的是，你有你预定的写作时间，你将保留你将来的出版物，阅读和记笔记，写作补助金和审查文件。 这次你不会失去耐力，你会成为一个有生产力的科学家。 但现在，让我们庆祝这篇文章的结尾。&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;p&gt;Hayes JR. In: The Science of Writing: Theories, Methods, Individual Differences, and Applications. Levy CM, Ransdell SE, editors. Mahwah, NJ: Lawrence Erlbaum; 1996. A new framework for understanding cognition and affect in writing; pp. 1–28.&lt;br&gt;Silvia PJ. How to Write a Lot. Washington, DC: American Psychological Association; 2007.&lt;br&gt;Whitesides GM. Whitesides’ Group: Writing a Paper. Adv Mater. 2004;16(15):1375–1377.&lt;br&gt;Soto D, Funes MJ, Guzmán-García A, Warbrick T, Rotshtein T, Humphreys GW. Pleasant music overcomes the loss of awareness in patients with visual neglect. Proc Natl Acad Sci USA. 2009;106(14):6011–6016. [PMC free article] [PubMed]&lt;br&gt;Hofmann AH. Scientific Writing and Communication. Papers, Proposals, and Presentations. New York: Oxford University Press; 2010.&lt;br&gt;Zeiger M. Essentials of Writing Biomedical Research Papers. 2nd edition. San Francisco, CA: McGraw-Hill Companies, Inc.; 2000.&lt;br&gt;Martínez I. Native and non-native writers’ use of first person pronouns in the different sections of biology research articles in English. Journal of Second Language Writing. 2005;14(3):174–190.&lt;br&gt;Rodman L. The Active Voice In Scientific Articles: Frequency And Discourse Functions. Journal Of Technical Writing And Communication. 1994;24(3):309–331.&lt;br&gt;Tarone LE, Dwyer S, Gillette S, Icke V. On the use of the passive in two astrophysics journal papers with extensions to other languages and other fields. English for Specific Purposes. 1998;17:113–132.&lt;br&gt;Penrose AM, Katz SB. Writing in the sciences: Exploring conventions of scientific discourse. New York: St. Martin’s Press; 1998.&lt;br&gt;Swales JM, Feak CB. Academic Writing for Graduate Students. 2nd edition. Ann Arbor: University of Michigan Press; 2004.&lt;br&gt;Hess DR. How to Write an Effective Discussion. Respiratory Care. 2004;29(10):1238–1241. [PubMed]&lt;br&gt;Belcher WL. Writing Your Journal Article in 12 Weeks: a guide to academic publishing success. Thousand Oaks, CA: SAGE Publications; 2009.&lt;br&gt;Single PB. Demystifying Dissertation Writing: A Streamlined Process of Choice of Topic to Final Text. Virginia: Stylus Publishing LLC; 2010.&lt;br&gt;Faigley L, Witte SP. Analyzing revision. Composition and Communication. 1981;32:400–414.&lt;br&gt;Flower LS, Hayes JR, Carey L, Schriver KS, Stratman J. Detection, diagnosis, and the strategies of revision. College Composition and Communication. 1986;37(1):16–55.&lt;br&gt;Young BR. In: A Tutor’s Guide: Helping Writers One to One. Rafoth B, editor. Portsmouth, NH: Boynton/Cook Publishers; 2005. Can You Proofread This? pp. 140–158.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;原文： Elena D. Kallestinova 《How to Write Your First Research Paper》 Yale University.&lt;br&gt;原文地址： &lt;a href=&quot;https://www.ncbi.nlm.n
    
    </summary>
    
      <category term="译文 | Translation" scheme="http://whatbeg.com/categories/%E8%AF%91%E6%96%87-Translation/"/>
    
    
      <category term="译文" scheme="http://whatbeg.com/tags/%E8%AF%91%E6%96%87/"/>
    
      <category term="论文阅读" scheme="http://whatbeg.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>用Jupyter Notebook编写、运行集群程序</title>
    <link href="http://whatbeg.com/2018/01/02/jupyternotebook.html"/>
    <id>http://whatbeg.com/2018/01/02/jupyternotebook.html</id>
    <published>2018-01-02T14:21:49.000Z</published>
    <updated>2018-12-05T15:26:29.918Z</updated>
    
    <content type="html">&lt;p&gt;本文简要描述一下用jupyter notebook编写程序，然后在集群上运行的过程。这样我们无须每次将程序传到集群上去运行，而可以通过notebook实现即时运行。&lt;/p&gt;
&lt;p&gt;一般使用Jupyter Notebook时，需要用到辅助软件Apache toree。&lt;/p&gt;
&lt;p&gt;1.在集群上安装&lt;code&gt;jupyter&lt;/code&gt;，&lt;code&gt;Apache toree&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2.用&lt;code&gt;putty&lt;/code&gt;或者&lt;code&gt;MobaXterm&lt;/code&gt;开启SSH tunnel到集群Gateway(跳板机)&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;valinor&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;Dynamic&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ForwardPort&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:12345&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;SSH&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;Server&lt;/span&gt;: &lt;span class=&quot;selector-attr&quot;&gt;[user@跳板机IP]&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:22&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;gondolin&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;Dynamic&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ForwardPort&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:23456&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;SSH&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;Server&lt;/span&gt;: &lt;span class=&quot;selector-attr&quot;&gt;[user@跳板机IP]&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:22&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.脚本&lt;/p&gt;
&lt;p&gt;编写脚本&lt;code&gt;start.app.toree.sh&lt;/code&gt;并运行：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#!/bin/bash&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#setup paths&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;source&lt;/span&gt; /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; SPARK_HOME=/opt/work/spark-2.1.0-bin-hadoop2.7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; SPARK_MASTER=&lt;span class=&quot;string&quot;&gt;&quot;spark://172.168.0.21:7077&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PYSPARK_DRIVER_PYTHON_OPTS=&lt;span class=&quot;string&quot;&gt;&quot;notebook --notebook-dir=/home/huqiu/notebooks --ip=* --port=12345 --no-browser --NotebookApp.token=&#39;&#39; --allow-root&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; JAR=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;APP_HOME&amp;#125;&lt;/span&gt;/dist/lib/app-&lt;span class=&quot;variable&quot;&gt;$&amp;#123;APP_VERSION&amp;#125;&lt;/span&gt;-jar-with-dependencies.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PY_ZIP=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;APP_HOME&amp;#125;&lt;/span&gt;/dist/lib/app-&lt;span class=&quot;variable&quot;&gt;$&amp;#123;APP_VERSION&amp;#125;&lt;/span&gt;-python-api.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; CONF=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;APP_HOME&amp;#125;&lt;/span&gt;/dist/conf/xxx.conf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; NOTEBOOK_DIR=&lt;span class=&quot;string&quot;&gt;&quot;./notebooks&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PORT=12345&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; SPARK_OPTS=&lt;span class=&quot;string&quot;&gt;&quot;--master local[12] --driver-memory 4g --properties-file &lt;span class=&quot;variable&quot;&gt;$&amp;#123;CONF&amp;#125;&lt;/span&gt; --jars &lt;span class=&quot;variable&quot;&gt;$&amp;#123;JAR&amp;#125;&lt;/span&gt; --conf spark.driver.extraClassPath=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;JAR&amp;#125;&lt;/span&gt; --conf spark.executor.extraClassPath=&lt;span class=&quot;variable&quot;&gt;$JAR&lt;/span&gt;&amp;#125; --driver-java-options=&#39;-Dhttp.proxyHost=xxx.com -Dhttp.proxyPort=913 -Dhttps.proxyHost=xxx.com -Dhttps.proxyPort=913 -Djava.awt.headless=true&#39;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$SPARK_HOME&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$SPARK_OPTS&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PYTHONPATH=&lt;span class=&quot;string&quot;&gt;&quot;&lt;span class=&quot;variable&quot;&gt;$&amp;#123;SPARK_HOME&amp;#125;&lt;/span&gt;/python:&lt;span class=&quot;variable&quot;&gt;$&amp;#123;SPARK_HOME&amp;#125;&lt;/span&gt;/python/lib/py4j-0.10.4-src.zip:&lt;span class=&quot;variable&quot;&gt;$&amp;#123;PY_ZIP&amp;#125;&lt;/span&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$PYTHONPATH&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jupyter toree install --interpreters=Scala,PySpark --spark_home=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;SPARK_HOME&amp;#125;&lt;/span&gt; --spark_opts=&lt;span class=&quot;string&quot;&gt;&#39;$&amp;#123;SPARK_OPTS&amp;#125;&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jupyter notebook --notebook-dir=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;NOTEBOOK_DIR&amp;#125;&lt;/span&gt; --ip=* --port=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;PORT&amp;#125;&lt;/span&gt; --no-browser --NotebookApp.token=&lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt; --allow-root&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;4.打开浏览器&lt;code&gt;http://集群具体机器IP:PORT&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;5.编写notebook，运行即可&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文简要描述一下用jupyter notebook编写程序，然后在集群上运行的过程。这样我们无须每次将程序传到集群上去运行，而可以通过notebook实现即时运行。&lt;/p&gt;
&lt;p&gt;一般使用Jupyter Notebook时，需要用到辅助软件Apache toree。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="Spark" scheme="http://whatbeg.com/tags/Spark/"/>
    
      <category term="大数据" scheme="http://whatbeg.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>2017这一年</title>
    <link href="http://whatbeg.com/2018/01/01/annualsummary2017.html"/>
    <id>http://whatbeg.com/2018/01/01/annualsummary2017.html</id>
    <published>2018-01-01T06:36:05.000Z</published>
    <updated>2018-02-04T03:29:40.183Z</updated>
    
    <content type="html">&lt;h2 id=&quot;引子&quot;&gt;&lt;a href=&quot;#引子&quot; class=&quot;headerlink&quot; title=&quot;引子&quot;&gt;&lt;/a&gt;引子&lt;/h2&gt;&lt;p&gt;又到了年关，该写点什么了。&lt;/p&gt;
&lt;p&gt;说快也快，2017眨个眼的工夫就过去了，写了好几年总结，今年却有点不知怎么下笔，随意写点好了。&lt;/p&gt;
&lt;p&gt;去年的年终总结题目是&lt;a href=&quot;http://whatbeg.com/2016/12/31/annualsummary2016.html&quot;&gt;《那不平凡的2016》&lt;/a&gt;，今年似乎只需改一个字，叫《那平凡的2017》。&lt;/p&gt;
&lt;p&gt;工作学习生活逐渐安定了下来，上半年还需上课，下半年课都没有了，整天也就是宿舍-实验室-食堂三点一线，不过，且行且珍惜吧，毕竟这样多的自主时间当真是不多了。既然平凡，那就享受平凡吧。&lt;/p&gt;
&lt;h2 id=&quot;关于学习&quot;&gt;&lt;a href=&quot;#关于学习&quot; class=&quot;headerlink&quot; title=&quot;关于学习&quot;&gt;&lt;/a&gt;关于学习&lt;/h2&gt;&lt;p&gt;今年的学习（工作）分为几大块，一是与师兄合作的论文，而是暑期短暂的实习，三是自己的科研。&lt;/p&gt;
&lt;p&gt;今年3月开始跟着师兄参与一个组内与公司的合作研究，在BigDL平台上做一些深度学习优化方面的工作。&lt;/p&gt;
&lt;p&gt;7月份，刚刚学期结束，最后一门考试完，大师兄说整理一篇论文吧，说投个A试试，OK嘛，写了一个月论文，包括补实验，赶在31号提交了，当时心里也知道没戏，想着算了，就当练手吧。果然在11月底收到reject。评审确实给出了一些中肯的意见。不管怎样，吸取经验，下次应该可以做得更好罢。&lt;/p&gt;
&lt;p&gt;说到写论文，推荐一个语法检查器，一个叫Grammarly的Chrome插件，可以帮你避免很多的语法错误，简直是神器:D&lt;/p&gt;
&lt;p&gt;第二个，暑期的时候，利用假期去上海某友司做了一段时间，团队的人还是挺牛的，人也都很好，学到了许多新的东西，认识了许多新朋友，还是挺开心的。&lt;/p&gt;
&lt;p&gt;第三个就是自己的科研了，下学期晚回来了10多天到学校，开始的比较晚，中间在正式调研阶段，到10月中旬，博士师兄给到一个课题，说可以做一下，然后到现在大概两个多月了，其中有一些辛酸，有一些失败，也有一些豁然开朗的瞬间，总之，科研这条路，谁走谁清楚。&lt;/p&gt;
&lt;p&gt;不过深刻的感觉是，研究生阶段与本科生阶段有着很大的不同，本科生着重于学习基础知识，着重在于输入，磨练基本功，而研究生着重在于自己对知识的运用，探索，融会贯通，同时对一个问题有着深入地理解，并作出自己的贡献。所以说，成绩这个事情，很容易让成绩好的人觉得自己科研也好，但其实并不是，如果一个学习者不能顺利地将心态，状态转变为输出者，创造者的心态，那么仍然很难做出很棒的工作。&lt;/p&gt;
&lt;h2 id=&quot;关于读书&quot;&gt;&lt;a href=&quot;#关于读书&quot; class=&quot;headerlink&quot; title=&quot;关于读书&quot;&gt;&lt;/a&gt;关于读书&lt;/h2&gt;&lt;p&gt;读书的话，见&lt;a href=&quot;https://github.com/whatbeg/ReadingList&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;2017 Reading List&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;今年看的书比较少，读完的不到10本，还有许多技术书籍，没有涉及到的部分就没再看了。&lt;/p&gt;
&lt;p&gt;哲学方面，《道德经》看了一遍，但是没留下什么影响，老子的思想没能够打动我，可能是我level还不够？或者心态不同罢，这个以后再看试试。&lt;/p&gt;
&lt;p&gt;科学方面，《科学研究的艺术》，《暗时间》都是两本比较好的书，两者我都写了读书笔记：&lt;a href=&quot;http://whatbeg.com/2017/06/07/artofresearch.html&quot;&gt;读《科学研究的艺术》&lt;/a&gt;，&lt;a href=&quot;http://whatbeg.com/2017/02/20/darktime.html&quot;&gt;《暗时间》读书笔记&lt;/a&gt;，有兴趣可以看看。反正我又看了两遍，感觉常看常新。&lt;/p&gt;
&lt;p&gt;技术方面，下半年看得比较多，因为需要用Scala和Spark，所以系统地学习了下Scala，以及Java。&lt;/p&gt;
&lt;p&gt;看了下《Head First Java》，比较通俗易懂，还记得当年本科刚学Java时嫌她比C++麻烦太多，一直不待见她，现在重新看来，Java中富含的思想也很丰富，而且觉得这门语言根本没有C++麻烦，反而有些习惯了想Java，Scala这样的JVM语言，虽然他们的一切皆对象思想以及并不多么高效的垃圾回收确实让我对她们在大规模数据处理上面的信心不足。&lt;/p&gt;
&lt;p&gt;不过纵观编程语言来看，Java和C++这几年都没有什么太大的变化，都是在之前的基础上小修小改，可能也到一个瓶颈期了，用户群趋于固定。现在火热的都是跟着人工智能(AI)火起来的Python，数据分析语言R，以及Google大力主推的Go语言，以及移动开发新锐Kotlin等语言（没错，我不是PHP程序员:D）。&lt;/p&gt;
&lt;p&gt;所以说，其实每种编程语言都有自己的一些独特的特点，没有适合所有场景的编程语言，所以这会使得，语言随着其适合的问题的趋势而波动，试看当年火爆的Objective-C现在境况就知道现实是多么残酷…&lt;/p&gt;
&lt;p&gt;文学方面，看了《围城》和《王小波文集》，由于去年听了苗怀明老师的红楼梦课，买了《红楼梦》来读，这次读到了第十九回，然后就因为没时间搁置了，其实以前也有看过，不过总是在数回之后就做罢，这次已经是创新高了。王小波文集中包含了以前没看过的许多文章，读来依旧是那么的过瘾。&lt;/p&gt;
&lt;p&gt;今年历史读的是业余书籍中偏多的了，蒋廷黻先生的《中国近代史》很脍炙人口，以前那点近代史知识大部分是从中学历史书上得来的，而中学历史书大家都知道，学过以后只记得几几年签了哪个什么条约，条约细则是什么，赔了多少万两白银，被割占了哪哪哪，虽然这些也很重要，但是去死记硬背这些东西并不会带来什么进益。我觉得学历史最是不能死记硬背，历史的花样太多了，是背不完的，更重要的是要吸取历史中的教训，参悟历史中的规律，形成一种唯物史观。你背的条约细则今天还能记得多少呢？相比具体的细则，这些条约细则背后有着什么样一些考虑才更值得探讨。这是我今年读历史书籍得到的最大的一个收获。&lt;/p&gt;
&lt;p&gt;除了《中国近代史》，《全球通史》也读了一些，虽然上册还没看完（囧）。发现其实世界历史上也有很多有意思的事情，丝毫不逊于中国二十四朝的历史，以后可以再看看。&lt;/p&gt;
&lt;p&gt;读书方面大概就这么多。明年的读书计划的话，希望有时间的时候把新买的那些小说看看，比如《万历十五年》，《巨人的陨落》，《禅与摩托车维修技术》，《西游记》等等。由于要找工作，技术书自然也不能少。尽力而为吧。&lt;/p&gt;
&lt;h2 id=&quot;关于处事&quot;&gt;&lt;a href=&quot;#关于处事&quot; class=&quot;headerlink&quot; title=&quot;关于处事&quot;&gt;&lt;/a&gt;关于处事&lt;/h2&gt;&lt;p&gt;处事方面，最大的一个感触就是，我们真的“长大”了，角色在变，思维也在变，行为也需要做出改变，责任慢慢在变重，毕竟，最后一批90后也将迎来他们的18岁，我们“老”了，把青春年华交给00后，10后，逐渐要接过80后，70后的担子。我们这一代的年轻人，并不比80后要好过，以致最近流行一些丧系流行语，比如“佛系”，“油腻”等等，但是历史总是惊人的相似，多数时代的年轻人都没那么过，但是境况也没有想得那么坏，关键还是在自己有没有破局的能力和一些运气。&lt;/p&gt;
&lt;p&gt;可有时候，自己还是会遵循多年的行为习惯，习惯于接受给予，习惯于索取，可能为了维持这些给予，在生活中又会不自觉的注意维护自己的形象，建立自己的高地，这样做的过程中可能会伤害到他人。&lt;/p&gt;
&lt;p&gt;讲的比较抽象，总的来说就是，我们不再能够一直做接受给予的小孩子了，我们羽翼渐丰，我们需要更多的往外输出我们的贡献，我们的关怀，我们的话语等等。这是我们的独立带来的副产品。&lt;/p&gt;
&lt;h2 id=&quot;关于2017的计划&quot;&gt;&lt;a href=&quot;#关于2017的计划&quot; class=&quot;headerlink&quot; title=&quot;关于2017的计划&quot;&gt;&lt;/a&gt;关于2017的计划&lt;/h2&gt;&lt;p&gt;去年的总结里，列了这样一些计划&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;把论文发掉&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;好吧，这个没有做到&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定期运动，注意健康饮食&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意了运动，但是并不定期，每周会抽出时间跑跑步打打羽毛球。饮食上的一个巨大变化就是开始注重蔬菜水果的摄入了，饮食上整体都清淡了许多，当然很大程度上要归功于cycy小姐，带我吃各种水果，现在每顿饭不打个蔬菜都觉得有点不得劲，饮食不像以前，自己想吃什么就吃什么，最终导致什么口味重吃什么，幸好改正还来得及。这些生活习惯改变后，最大的得益就是痘少了，有这个都够了:D…&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;简约生活&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;尽量做了，但是有些事情还是不好判断是否符合简约的标准。总之，以后，买东西前问自己三问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是否喜欢？&lt;/li&gt;
&lt;li&gt;是否需要？&lt;/li&gt;
&lt;li&gt;是否合适？&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Continue Feeling, Thinking, Reading and Writing&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;continue…&lt;/p&gt;
&lt;h2 id=&quot;关于未来&quot;&gt;&lt;a href=&quot;#关于未来&quot; class=&quot;headerlink&quot; title=&quot;关于未来&quot;&gt;&lt;/a&gt;关于未来&lt;/h2&gt;&lt;p&gt;即将到来的2018年，又将是一个巨大变化发生的一年，未来的事情注意波谲云诡，但又有一定规律可寻，着重讲一点对未来IT界的看法吧。&lt;/p&gt;
&lt;p&gt;2016年深度学习呈现爆发增长，2017年这个词稍微冷了一点，AI这个词热起来了，明年不知道哪个词又会热起来。但是AI技术应该会进一步的进入人们的生活，智慧城市，无人驾驶，人工智能像互联网那样可以“+”很多东西，强化学习应该会更加火热，量子计算也让人拭目以待，有一些人的工作确实将会被取代。&lt;/p&gt;
&lt;p&gt;在大数据分析上，众所周知，当年大数据的火热在于数据体量(Volume)的巨大增长，而如今大数据已是很多公司的默认配置了，大数据分析在如今又呈现了一些微妙的变化，比如，数据来源(Variety)，复杂性(Complexity)的增长，由于数据采集的广泛应用，我们拥有各类数据类型和来源，而这些异源数据的协同处理是一个难题，时间上，视频数据的处理时间和普通数据库数据的处理时间是不一样的，再一个就是，处理各种数据的模型也不一样，这些体现了我们数据的“广度”在增加，可能以后“广度学习”这个词也会火起来。&lt;/p&gt;
&lt;p&gt;再一个就是AI技术往移动端做的趋势也会增加，毕竟，真正做到移动端才能使AI技术产生更加深远，广泛的影响，才能从身边影响我们的生活。当然这也对算力和模型的简化度有一些要求。在2018年，我们的各种设备将逐渐继承AI技术。&lt;/p&gt;
&lt;p&gt;从自己来看，被大师兄的一番安利，未来决定往偏系统的方向走了，主要精力会放在分布式机器学习这块了。希望能在这方面做出一些成绩，至于以后工作找在哪方面那又是后话。&lt;/p&gt;
&lt;h2 id=&quot;关于其它&quot;&gt;&lt;a href=&quot;#关于其它&quot; class=&quot;headerlink&quot; title=&quot;关于其它&quot;&gt;&lt;/a&gt;关于其它&lt;/h2&gt;&lt;p&gt;今年写了20多篇文章，产量有所下降，且有很多是一些零碎的错误处理，实践经验等等，主要原因自然是时间不够，其次是觉得不是什么都值得写了，得对读者负责任，所以会更加审慎。并且很多东西是技能型的，比较零散，不好整理成文。&lt;/p&gt;
&lt;p&gt;今年3月开的一个坑：&lt;a href=&quot;http://whatbeg.com/2017/02/27/deeplearning0.html&quot;&gt;Deep Learning读书笔记系列写作计划&lt;/a&gt;，当初计划1年写完，2018年三月写完，看来也是无法做到了，有一些准备出的文章，要点写在了本子上，也没有时间或者记性去把它总结成文，评论区说要跳票了，看来确实是。当初立一年的时限，也是为了给自己充足的时间，但是没有料到，后面的工作重心会有所转移，导致停顿了Deep Learning book的阅读。&lt;/p&gt;
&lt;h2 id=&quot;关于2018的计划&quot;&gt;&lt;a href=&quot;#关于2018的计划&quot; class=&quot;headerlink&quot; title=&quot;关于2018的计划&quot;&gt;&lt;/a&gt;关于2018的计划&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;阅读20本书&lt;br&gt;做出两篇论文&lt;br&gt;拿到心仪offer&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2018年，还是继续深耕，积累吧，在这个过程中，有好的，新的感悟也会及时跟大家分享。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;引子&quot;&gt;&lt;a href=&quot;#引子&quot; class=&quot;headerlink&quot; title=&quot;引子&quot;&gt;&lt;/a&gt;引子&lt;/h2&gt;&lt;p&gt;又到了年关，该写点什么了。&lt;/p&gt;
&lt;p&gt;说快也快，2017眨个眼的工夫就过去了，写了好几年总结，今年却有点不知怎么下笔，随意写点好了。&lt;/
    
    </summary>
    
      <category term="成长之路 | Biography" scheme="http://whatbeg.com/categories/%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF-Biography/"/>
    
    
      <category term="Summary" scheme="http://whatbeg.com/tags/Summary/"/>
    
  </entry>
  
  <entry>
    <title>一次MAVEN事故</title>
    <link href="http://whatbeg.com/2017/12/24/mavenaccident.html"/>
    <id>http://whatbeg.com/2017/12/24/mavenaccident.html</id>
    <published>2017-12-24T07:49:59.000Z</published>
    <updated>2018-03-17T09:08:56.100Z</updated>
    
    <content type="html">&lt;p&gt;改动mllib中的&lt;code&gt;org.apache.spark.ml.tree.impl.DTStatsAggregator&lt;/code&gt;源码，加了一个原来没有的&lt;code&gt;allStats(): Array[Double] = ..&lt;/code&gt;的方法，然后打成MLlib包，替换maven库中的mllib包。&lt;/p&gt;
&lt;p&gt;报&lt;code&gt;IllegalAccessError&lt;/code&gt;：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Caused by: java&lt;span class=&quot;selector-class&quot;&gt;.lang&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.IllegalAccessError&lt;/span&gt;: tried to access method org&lt;span class=&quot;selector-class&quot;&gt;.apache&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.spark&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.ml&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.tree&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.impl&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.DTStatsAggregator&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.allStats&lt;/span&gt;()[D from class org&lt;span class=&quot;selector-class&quot;&gt;.apache&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.spark&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.ml&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.tree&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.impl&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.RandomForestImpl&lt;/span&gt;$&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight markdown&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;private[ml] val allStatSize&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;val allStats = new Array[&lt;span class=&quot;string&quot;&gt;Double&lt;/span&gt;](&lt;span class=&quot;link&quot;&gt;allStatSize&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;应该要能访问到&lt;/p&gt;
&lt;p&gt;是不是用的不是我的jar，或者用的不是我的jar中的class？&lt;/p&gt;
&lt;p&gt;运行jar包时设置&lt;br&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;--&lt;span class=&quot;keyword&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;&quot;spark.driver.extraJavaOptions=-XX:+TraceClassLoading -XX:+TraceClassUnloading&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;监测类的加载情况，果然发现有一条&lt;br&gt;&lt;figure class=&quot;highlight gradle&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[Loaded xxx &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt;:&lt;span class=&quot;regexp&quot;&gt;/home/&lt;/span&gt;huqiu&lt;span class=&quot;regexp&quot;&gt;/programs/&lt;/span&gt;spark&lt;span class=&quot;regexp&quot;&gt;/jars/&lt;/span&gt;spark-mllib_2.&lt;span class=&quot;number&quot;&gt;11&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;2.1&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;.jar&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这说明程序不从我打好的jar包中加载class，而从spark安装目录中的jars目录中读取了。&lt;/p&gt;
&lt;p&gt;为什么从spark本地读而不从打好的jar包中读？&lt;/p&gt;
&lt;p&gt;为了先解决问题，我把mllib包复制到SPARK_HOME的jars目录中，这下总能读到我的jar了吧。&lt;/p&gt;
&lt;p&gt;但是又出现一个问题：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;java&lt;span class=&quot;selector-class&quot;&gt;.lang&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.NoClassDefFoundError&lt;/span&gt;: Could not initialize class org&lt;span class=&quot;selector-class&quot;&gt;.apache&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.spark&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.ml&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.core&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.JNAScala&lt;/span&gt;$&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Caused by: java&lt;span class=&quot;selector-class&quot;&gt;.lang&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.ClassNotFoundException&lt;/span&gt;: com&lt;span class=&quot;selector-class&quot;&gt;.sun&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.jna&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.Native&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;原来是没找到jna的Native class，一看，确实没有打入mllib包中，那是什么原因呢？难道是谁把它exclude掉了？&lt;br&gt;重新编译一下，发现这么一条：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-attr&quot;&gt;[INFO]&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;Excluding&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.java&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.dev&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.jna&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:jna&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:jar&lt;/span&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;:4.2.2&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;shared&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;jar&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;说白了就是排除了net.java.dev.jna:jna:jar，所以写的代码中用到Native的都会找不到类。&lt;br&gt;后来发现是spark-parent排除的，且删掉spark-parent的exclude的语句也没用，根本原因在于mllib的打包方式不会把其依赖打入mllib的jar包中。&lt;/p&gt;
&lt;p&gt;解决的方法就是将此依赖打入mllib中，但是这样就会变成mllib-jar-with-dependencies，肯定不是我们想要的结果。&lt;/p&gt;
&lt;p&gt;这就涉及到了代码设计的层面了，一般情况下，不建议直接修改Mllib源码，更不要说在Mllib源码中还加入外部包了，这样太紧耦合了，比较建议的方法是自己建立一个project，建立于spark mllib同样的包路径即可，然后修改需要修改的文件，但缺点是改动文件需要改名字，不然系统会读取底层Mllib的同名文件而不会读取你项目中的。但是这样确是松耦合的。&lt;br&gt;目前还没有找到好的方法，最小程度上改动代码，增加或删除一些东西。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;改动mllib中的&lt;code&gt;org.apache.spark.ml.tree.impl.DTStatsAggregator&lt;/code&gt;源码，加了一个原来没有的&lt;code&gt;allStats(): Array[Double] = ..&lt;/code&gt;的方法，然后打成MLlib
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="Spark" scheme="http://whatbeg.com/tags/Spark/"/>
    
      <category term="错误解决" scheme="http://whatbeg.com/tags/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/"/>
    
  </entry>
  
  <entry>
    <title>IDE各种操作和玩法备忘</title>
    <link href="http://whatbeg.com/2017/12/24/ideplay.html"/>
    <id>http://whatbeg.com/2017/12/24/ideplay.html</id>
    <published>2017-12-24T07:39:59.000Z</published>
    <updated>2017-12-24T07:43:55.091Z</updated>
    
    <content type="html">&lt;h5 id=&quot;Codeblocks-批量注释&quot;&gt;&lt;a href=&quot;#Codeblocks-批量注释&quot; class=&quot;headerlink&quot; title=&quot;Codeblocks 批量注释&quot;&gt;&lt;/a&gt;Codeblocks 批量注释&lt;/h5&gt;&lt;figure class=&quot;highlight mipsasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Ctl + &lt;span class=&quot;keyword&quot;&gt;Shift &lt;/span&gt;+ C  &lt;span class=&quot;comment&quot;&gt;# 批量注释&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Ctl + &lt;span class=&quot;keyword&quot;&gt;Shift &lt;/span&gt;+ X  &lt;span class=&quot;comment&quot;&gt;# 批量取消&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;IDEA-Intellij-快捷键&quot;&gt;&lt;a href=&quot;#IDEA-Intellij-快捷键&quot; class=&quot;headerlink&quot; title=&quot;IDEA Intellij 快捷键&quot;&gt;&lt;/a&gt;IDEA Intellij 快捷键&lt;/h5&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/bluestorm/archive/2013/05/20/3087889.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;IDEA快捷键&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Codeblocks-批量注释&quot;&gt;&lt;a href=&quot;#Codeblocks-批量注释&quot; class=&quot;headerlink&quot; title=&quot;Codeblocks 批量注释&quot;&gt;&lt;/a&gt;Codeblocks 批量注释&lt;/h5&gt;&lt;figure class=&quot;highli
    
    </summary>
    
      <category term="计算机相关 | CS.Related" scheme="http://whatbeg.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9B%B8%E5%85%B3-CS-Related/"/>
    
    
      <category term="CS" scheme="http://whatbeg.com/tags/CS/"/>
    
  </entry>
  
  <entry>
    <title>Revisiting Java</title>
    <link href="http://whatbeg.com/2017/10/23/revisitingjava.html"/>
    <id>http://whatbeg.com/2017/10/23/revisitingjava.html</id>
    <published>2017-10-23T15:33:48.000Z</published>
    <updated>2017-10-23T15:38:18.567Z</updated>
    
    <content type="html">&lt;p&gt;最近在看一些工程代码，于是看了看设计模式，看设计模式之前发现Java是先修知识，又重新补了一遍Java，温故知新，获得一些新的体会。&lt;br&gt;本文不打算作为“Java知识点详细梳理”，“10分钟学会Java”之类的文章，仅作为博主自己的一个回顾，涉及的内容也无定法。&lt;/p&gt;
&lt;p&gt;Java应该是目前用的最多的编程语言，以前觉得Java老要点点点（调用方法），变量名也很长，C++/Python很少代码写完的东西Java可能要写很多行……&lt;br&gt;觉得挺麻烦的，不过Java风靡自有其风靡的理由，在面向对象语言中她是一个标杆，虽然繁琐，但比较清晰，比较简单。&lt;/p&gt;
&lt;p&gt;拿变量类型来说，Java只有两种变量类型，primitive主数据类型和引用数据类型。&lt;/p&gt;
&lt;p&gt;Java中最关键的概念是面向对象，面向对象最关键的东西就是类和对象，所有的Java程序都定义在类中，你不能像python那样，打开.py文件就开始写东西，就可以执行了，也不像C++，定义一个main函数即可运行。在Java中即使main函数也要包括在类中。&lt;/p&gt;
&lt;p&gt;为什么面向对象是核心内容？它的好处在哪呢？可以说，OO(面向对象)无处不在，OO使得我们很方便的扩展功能，而不需要重复写很多代码！另外，OO的设计思想其实是抽象思维的一种体现，它改变了我们设计程序的方式，我们不再是根据程序需要什么功能就开始从头到尾实现什么功能，我们更多考虑的是类和对象，程序包含几种类型的实体？有什么共同点？可以进行怎样的抽象？用继承还是接口？……&lt;/p&gt;
&lt;p&gt;说说类和对象，类是对象的模板，类定义好“像我这样的人应该有什么状态，特征，能够做到那些事”，而对象具体化了类，真正获得了具体的状态，具体的特征，以及做某些事的方法。&lt;/p&gt;
&lt;p&gt;我们说到，Java只有两种变量，primitive主数据类型和引用数据类型。主数据类型包括我们所指的int,double,float等等，这些不是对象。而引用变量是一个到对象的引用，相当于一个遥控器，指向堆上的某个对象，通过此引用可以获得对象，重新赋值此引用并不改变对象，只是引用指到了另一个对象上而已。没有对象变量，只有指向对象的引用变量。&lt;br&gt;==:  比较primitive主数据类型是否相同，或两个引用是否指向同一对象&lt;/p&gt;
&lt;p&gt;话题回到面向对象，提到面向对象，不得不提其三大特性，这也是面试中经常会问到的，即封装，继承和多态。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;封装(encapsulation)，即隐藏对象的属性和实现细节，仅对外公开接口，控制在程序中属性的读和修改的访问级别；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多态(polymorphism)，一句话，“接口的多种不同的实现方式即为多态”，但是这个不太好理解，甚至我觉得它不够准确，因为光说接口是不是有点不够？换一种说法，多态即允许将子类对象的引用赋值给父类对象的引用，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。因为：编译器根据引用类型来判断可以调用哪些方法，而不是根据确实的类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;继承(inheritance) 是指一个对象直接使用另一对象的属性和方法，很简单，父类是球，子类是足球，那么足球可以直接使用“滚动”这个方法，如果需要特殊的“滚”，那子类自己实现就好了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;之所以继承放在最后讲，是因为我们关于继承有更多要说的。&lt;/p&gt;
&lt;p&gt;【继承方法调用时的最近原则】调用对象引用的方法时，会调用到与该对象类型最接近的方法，就是说如果子类实现了某继承的方法，那就调用子类的，如果没有实现，那就往上找最近的实现的类的方法。&lt;/p&gt;
&lt;p&gt;继承的IS-A测试，即“足球”IS-A“球”，总得满足这样的关系才好说继承，就像你不太好意思继承隔壁王叔叔财产。&lt;/p&gt;
&lt;p&gt;继承的意义何在？这是显然的，首先避免了大量重复的程序代码，其次可以定义出一组共同的协议，所有继承者都需要满足这个协议，你知道，在很多时候大家遵守一些共同的规则是很重要的。&lt;/p&gt;
&lt;p&gt;继承的一些使用建议：&lt;br&gt;1） 当某个类会比其父类更具有特定意义时使用继承&lt;br&gt;2）行为程序需要被多个相同基本类型的类共享时，考虑使用继承&lt;br&gt;3）集成并不一定是达成重用行为程序的最佳方式，具体可参见设计模式&lt;br&gt;4）继承结构并不匹配两者的关系，不要用继承&lt;br&gt;5）不能通过IS-A测试一定不要用继承&lt;/p&gt;
&lt;p&gt;如果最高的父类不能抽象出一些对所有族类都使用的方法，或者不太好初始化，比如你不好新建一个“球”对象，它是啥球呢？地球还是足球？这样一些情况我们可以定义抽象类，它不能被初始化，只能被继承。。抽象类中可以定义抽象方法，抽象方法只存在于抽象类中，一个类只要有一个抽象方法，那他必是抽象类。&lt;/p&gt;
&lt;p&gt;有时候，你会想要继承多个父类，以便使用更多的已有代码，但是不幸的是Java并不支持多重继承，要多重继承请关闭本文，搜索”C++”关键词谢谢。&lt;/p&gt;
&lt;p&gt;为啥不支持多重继承呢？因为存在多重继承（继承多个类）的“致命方块”问题，即如果两个父类继承自同一个祖父类，都实现了某个方法，那么子类（如果没有实现该方法）该调用那个版本？&lt;/p&gt;
&lt;p&gt;解决“致命方块”问题？接口！&lt;/p&gt;
&lt;p&gt;接口是100%纯抽象类，每个方法都是抽象的，必须被实现。&lt;/p&gt;
&lt;p&gt;如果想要定义出类可以扮演的角色，使用接口。&lt;/p&gt;
&lt;p&gt;接下来从生物学的角度谈谈对象？什么是生物学角度？？即生老病死~&lt;/p&gt;
&lt;p&gt;对象生存在堆上（可以理解为垃圾堆，随时可能有人来回收…），引用变量或局部变量生存在栈上。&lt;/p&gt;
&lt;p&gt;一旦一个对象，它的引用没有了或者离弃了它，那么他就可以等待被回收了。Java有一套垃圾回收机制(GC)保证对象的回收来腾出堆空间，有时候，GC又常常被人诟病，在大数据应用中常常面临这大量的shuffle，大量的对象，有时候需要花费大量的时间来做GC，体验不佳。&lt;/p&gt;
&lt;p&gt;总的来说，对象的出生靠调用构造函数，生存在堆上，一旦没了引用，就向生命的终点走去，直到GC（黑白无常）带走了它。。&lt;/p&gt;
&lt;p&gt;新建对象时，父类的构造函数先于子类被调用，以此类推，Object的构造函数先被执行，然后往下推，直到目标对象类型&lt;br&gt;（先有父母才有你）&lt;br&gt;只有当完全没写构造函数时，Java才会自动帮你写一个无参构造函数。&lt;br&gt;super()调用父类的构造函数，this是对对象本身的引用&lt;/p&gt;
&lt;p&gt;谈谈实例变量，实例变量即对象的成员变量。&lt;/p&gt;
&lt;p&gt;JAVA的实例变量具有如下特点：&lt;br&gt;1）实例变量声明在一个类中，但在方法、构造方法和语句块之外；&lt;br&gt;2）当一个对象被实例化之后，每个实例变量的值就跟着确定；&lt;br&gt;3）实例变量在对象创建的时候创建，在对象被销毁的时候销毁；&lt;br&gt;4）实例变量的值应该至少被一个方法、构造方法或者语句块引用，使得外部能够通过这些方式获取实例变量信息；&lt;br&gt;5）实例变量可以声明在使用前或者使用后；&lt;br&gt;6）访问修饰符可以修饰实例变量；&lt;br&gt;7）实例变量对于类中的方法、构造方法或者语句块是可见的。一般情况下应该把实例变量设为私有。通过使用访问修饰符可以使实例变量对子类可见；&lt;br&gt;8）实例变量具有默认值。数值型变量的默认值是0，布尔型变量的默认值是false，引用类型变量的默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定；实例变量可以直接通过变量名访问。但在静态方法以及其他类中，就应该使用完全限定名：ObejectReference.VariableName。&lt;/p&gt;
&lt;p&gt;你可能想问，如果Java中只有对象和primitive主数据类型，那么我想定义全局变量或者常量怎么办？比如PI=3.141592653589..(后面忘了)&lt;br&gt;这时候，静态变量可以帮你。静态变量定义在类中，它属于类，不属于任何对象，但对象可以获得它。&lt;br&gt;类的静态变量由（该类的）所有对象所共享。&lt;br&gt;静态方法通过类名调用，静态变量通过类名存取 。&lt;br&gt;如果类只有静态方法，则可以将构造函数标记为private的，以免被初始化&lt;/p&gt;
&lt;p&gt;Java常量 = final static 的变量&lt;br&gt;final意味着不能被改变，static意味着是静态变量。&lt;/p&gt;
&lt;p&gt;插一句字符串的格式化：&lt;br&gt;String.format(格式化说明)&lt;br&gt;格式化说明包括5部分，%和type是必要的&lt;br&gt;%[argument number] [flags] [width] [.precision] type&lt;br&gt;如： %,6.1f 为6位逗号分隔，1位小数的浮点数&lt;/p&gt;
&lt;p&gt;谈谈异常吧，谁能保证自己的程序不出问题呢？与其系统运行的时候报一大堆乱七八糟的错误trace，早早地预见并处理一下，以自己的方式处理或者打印它，总要漂亮些吧？甚至可以在抓到异常后，给出“没关系，一个小错误，已经报告给开发者~”这样温和的语句，是不是显得b格很高？……&lt;br&gt;异常中要注意的点有：&lt;br&gt;可能会抛出异常的方法必须声明成throws Exception&lt;br&gt;catch捕获多个异常时，要从小排到大，因为大异常后面的小异常根本没有被catch的机会&lt;br&gt;在方法后加上throws xxException，没有try/catch块，表示可能会抛出异常，自己并不处理，需要调用方自己处理异常&lt;br&gt;所以&amp;gt;&amp;gt;&amp;gt;要么处理，要么声明（异常）&lt;/p&gt;
&lt;p&gt;序列化对象：有时候需要保存一下对象，以便于恢复，被调用，而不用重新生成，因为生成过程可能很麻烦。&lt;br&gt;要序列化的话，对象必须可序列化，且对象中实例变量所引用的对象甚至对象引用的对象…都必须可以序列化，简而言之，整个对象版图都必须可以序列化&lt;br&gt;如果某实例变量不需要或者不能被序列化，那可以把它标记为transient（瞬时）的。&lt;br&gt;解序列化时，transient变量会恢复成null对象引用或者0,false等primitive默认值&lt;br&gt;静态变量不会被序列化，对象被还原时，静态变量会维持类中原本的样子。因为所有对象共用一份静态变量。&lt;br&gt;读取对象的顺序必须与写入的顺序相同&lt;/p&gt;
&lt;p&gt;序列化对象：&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;FileOutputStream fileStream = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; FileOutputStream(&lt;span class=&quot;string&quot;&gt;&quot;MySer.ser&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ObjectOutputStream os = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; ObjectOutputStream(fileStream)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;os.writeObject(obj)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;os.&lt;span class=&quot;keyword&quot;&gt;close&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;或者不序列化，而是将信息写入文本文件：&lt;br&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BufferedWriter &lt;span class=&quot;built_in&quot;&gt;writer&lt;/span&gt; = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; BufferedWriter(&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; FileWriter(file))  &lt;span class=&quot;comment&quot;&gt;// file is a File object&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;writer&lt;/span&gt;.write(...)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以把File想象成文件的路径，代表磁盘上的某个文件，但并不是文件内容&lt;br&gt;&lt;figure class=&quot;highlight vhdl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BufferedWriter writer = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; BufferedWriter(&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; FileWriter(&lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt;))  // &lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;File&lt;/span&gt; object&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这句代码形成如下链接：&lt;br&gt;&lt;figure class=&quot;highlight xl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;字符串 --&amp;gt; B&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;ufferedWriter&lt;/span&gt; --&amp;gt;&lt;/span&gt; F&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;ileWriter&lt;/span&gt; --&amp;gt;&lt;/span&gt; File&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;对象序列化以后，类继续演进，这时会出现无法还原的情况。通过将serialVersionUID放在class中，让类在演化过程中维持同样的ID，可以保证还原的时候能够识别，从而正确还原出对象。但要注意有些修改会损害解序列化。&lt;/p&gt;
&lt;p&gt;好吧，先说到这，其实还有一些内容，网络，集合与泛型，以及许多高级特性，反射，虚拟机的深入理解等等，后面再说吧。&lt;/p&gt;
&lt;p&gt;Reference&lt;br&gt;*《Head First Java》&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在看一些工程代码，于是看了看设计模式，看设计模式之前发现Java是先修知识，又重新补了一遍Java，温故知新，获得一些新的体会。&lt;br&gt;本文不打算作为“Java知识点详细梳理”，“10分钟学会Java”之类的文章，仅作为博主自己的一个回顾，涉及的内容也无定法。&lt;/p&gt;

    
    </summary>
    
      <category term="编程语言 | Program Lang." scheme="http://whatbeg.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-Program-Lang/"/>
    
    
      <category term="Java" scheme="http://whatbeg.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop一些问题集锦【持续更新】</title>
    <link href="http://whatbeg.com/2017/10/23/hadooperror.html"/>
    <id>http://whatbeg.com/2017/10/23/hadooperror.html</id>
    <published>2017-10-23T02:47:34.000Z</published>
    <updated>2018-03-17T09:09:14.878Z</updated>
    
    <content type="html">&lt;p&gt;本文记录Hadoop，HDFS，YARN，HBase，Hive等Hadoop社区的系统使用中的一些问题及解决方案，&lt;br&gt;包括Hadoop集群构建及使用中的一些问题以及解决方案，&lt;br&gt;包括各种莫名其妙的安装问题，&lt;br&gt;配置问题，&lt;br&gt;运行问题，&lt;br&gt;运行中问题，&lt;br&gt;等等等等，&lt;br&gt;积累以备后查，&lt;br&gt;也方便后来者参考之。&lt;br&gt;如对大家有所帮助，&lt;br&gt;对笔者也是一份欣慰。&lt;/p&gt;
&lt;h2 id=&quot;错误集锦&quot;&gt;&lt;a href=&quot;#错误集锦&quot; class=&quot;headerlink&quot; title=&quot;错误集锦&quot;&gt;&lt;/a&gt;错误集锦&lt;/h2&gt;&lt;h3 id=&quot;HDFS：DataNode不在线，使得出现Namenode-in-safe-mode错误&quot;&gt;&lt;a href=&quot;#HDFS：DataNode不在线，使得出现Namenode-in-safe-mode错误&quot; class=&quot;headerlink&quot; title=&quot;HDFS：DataNode不在线，使得出现Namenode in safe mode错误&quot;&gt;&lt;/a&gt;HDFS：DataNode不在线，使得出现Namenode in safe mode错误&lt;/h3&gt;&lt;p&gt;打开Hadoop webUI可以看到类似情况：&lt;br&gt;&lt;figure class=&quot;highlight vbnet&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Security &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;off&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Safe mode &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt;. The reported blocks &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; needs additional &lt;span class=&quot;number&quot;&gt;178895&lt;/span&gt; blocks &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; reach the threshold &lt;span class=&quot;number&quot;&gt;0.9990&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; total blocks &lt;span class=&quot;number&quot;&gt;179074.&lt;/span&gt; The number &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; live datanodes &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; has reached the minimum number &lt;span class=&quot;number&quot;&gt;0.&lt;/span&gt; Safe mode will be turned &lt;span class=&quot;keyword&quot;&gt;off&lt;/span&gt; automatically once the thresholds have been reached.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;184051&lt;/span&gt; files &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; directories, &lt;span class=&quot;number&quot;&gt;179074&lt;/span&gt; blocks = &lt;span class=&quot;number&quot;&gt;363125&lt;/span&gt; total filesystem &lt;span class=&quot;built_in&quot;&gt;object&lt;/span&gt;(s).&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Heap Memory used &lt;span class=&quot;number&quot;&gt;297.78&lt;/span&gt; MB &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1.28&lt;/span&gt; GB Heap Memory. Max Heap Memory &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1.78&lt;/span&gt; GB.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Non Heap Memory used &lt;span class=&quot;number&quot;&gt;31.27&lt;/span&gt; MB &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;31.81&lt;/span&gt; MB Commited Non Heap Memory. Max Non Heap Memory &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;130&lt;/span&gt; MB.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【原因分析】&lt;br&gt;查看datanode日志出现:&lt;br&gt;&lt;figure class=&quot;highlight dns&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2017-10-23&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;09&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;15:33,336&lt;/span&gt; INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master&lt;span class=&quot;number&quot;&gt;01/115.212.0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;91&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;9000&lt;/span&gt;. Already tried &lt;span class=&quot;number&quot;&gt;9&lt;/span&gt; time(s)&lt;span class=&quot;comment&quot;&gt;; retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2017-10-23&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;09&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;15:33,337&lt;/span&gt; WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master&lt;span class=&quot;number&quot;&gt;01/115.212.0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;91&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;9000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;类似错误&lt;/p&gt;
&lt;p&gt;于是使用：&lt;code&gt;netstat -an | grep 9000&lt;/code&gt;查看端口&lt;/p&gt;
&lt;figure class=&quot;highlight accesslog&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;[root@master01 etc]&lt;/span&gt;# netstat -an | grep &lt;span class=&quot;number&quot;&gt;9000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;127.0.0.1:9000&lt;/span&gt;              &lt;span class=&quot;number&quot;&gt;0.0.0.0&lt;/span&gt;:*                   LISTEN&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;127.0.0.1:55294&lt;/span&gt;             &lt;span class=&quot;number&quot;&gt;127.0.0.1:9000&lt;/span&gt;              TIME_WAIT&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这表明，只有&lt;code&gt;127.0.0.1&lt;/code&gt;上的&lt;code&gt;9000&lt;/code&gt;端口启动了，故只有本机才能访问&lt;code&gt;127.0.0.1:9000&lt;/code&gt;了，故datanode无法联通namenode。&lt;/p&gt;
&lt;p&gt;查看&lt;code&gt;/etc/hosts&lt;/code&gt;文件，如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;127&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;   &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;      &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain&lt;/span&gt;   &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;::1&lt;/span&gt;         &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;      &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain6&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;115&lt;span class=&quot;selector-class&quot;&gt;.212&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.91&lt;/span&gt;  &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由hosts文件可以看到，&lt;code&gt;master01&lt;/code&gt;在赋值为&lt;code&gt;114.212.190.91&lt;/code&gt;之前被赋值到了&lt;code&gt;127.0.0.1&lt;/code&gt;，以及IPv6的&lt;code&gt;::1&lt;/code&gt;上。&lt;/p&gt;
&lt;p&gt;【解决方案】把前两行的master01删去，得到：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;127&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;        &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain&lt;/span&gt;   &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-pseudo&quot;&gt;::1&lt;/span&gt;              &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain6&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;115&lt;span class=&quot;selector-class&quot;&gt;.212&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.91&lt;/span&gt;  &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样启动的就会是&lt;code&gt;115.212.0.91:9000&lt;/code&gt;，datanode也可以连到namenode了。&lt;/p&gt;
&lt;p&gt;最后查看端口监听情况：&lt;br&gt;&lt;figure class=&quot;highlight accesslog&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;[hadoop@master01 sbin]&lt;/span&gt;$ netstat -an | grep &lt;span class=&quot;number&quot;&gt;9000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         &lt;span class=&quot;number&quot;&gt;0.0.0.0&lt;/span&gt;:*                   LISTEN&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         &lt;span class=&quot;number&quot;&gt;115.212.0.91:56574&lt;/span&gt;        ESTABLISHED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         &lt;span class=&quot;number&quot;&gt;192.168.1.18:35381&lt;/span&gt;          ESTABLISHED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         &lt;span class=&quot;number&quot;&gt;192.168.1.15:60196&lt;/span&gt;          ESTABLISHED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:56573&lt;/span&gt;        &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         TIME_WAIT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;115.212.0.91:9000&lt;/span&gt;         &lt;span class=&quot;number&quot;&gt;192.168.1.6:42243&lt;/span&gt;           ESTABLISHED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;........&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;成功。&lt;/p&gt;
&lt;h3 id=&quot;集群时间不同步问题&quot;&gt;&lt;a href=&quot;#集群时间不同步问题&quot; class=&quot;headerlink&quot; title=&quot;集群时间不同步问题&quot;&gt;&lt;/a&gt;集群时间不同步问题&lt;/h3&gt;&lt;p&gt;集群运行example程序出现时间不一致的问题。&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;17/10/23 10:50:24 INFO mapreduce.Job: Task Id : attempt_1508726229114_0001_m_000000_1, Status                  : FAILED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Container launch failed for container_1508726229114_0001_01_000007 : org.apache.hadoop.yarn.ex                 ceptions.YarnException: Unauthorized request to &lt;span class=&quot;keyword&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;container&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;This token &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; expired. &lt;span class=&quot;keyword&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1508729210138&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;found&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1508728023578&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Note: &lt;span class=&quot;keyword&quot;&gt;System&lt;/span&gt; times &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; machines may be &lt;span class=&quot;keyword&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;sync&lt;/span&gt;. &lt;span class=&quot;keyword&quot;&gt;Check&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;system&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; zones.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【解决方案1】手动同步时间，在每台机器上&lt;code&gt;date -s ...&lt;/code&gt;设置同样的时间&lt;/p&gt;
&lt;p&gt;【解决方案2】使用NTP时间服务器来同步时间（也需要所有机器上运行一次，但是后面可以一直按时同步）&lt;/p&gt;
&lt;p&gt;默认master和slaves都安装好了ntpd服务(centOS好像默认有)，可以通过如下命令查看：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-attr&quot;&gt;[root@node1 ~]&lt;/span&gt;# &lt;span class=&quot;selector-tag&quot;&gt;rpm&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ntp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;ntp-4&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.4p8-2&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.el6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.x86_64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;每个节点都需要配置NTP服务为自启动&lt;br&gt;&lt;figure class=&quot;highlight coffeescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@master ~]&lt;span class=&quot;comment&quot;&gt;# chkconfig ntpd on&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@master ~]&lt;span class=&quot;comment&quot;&gt;# chkconfig --list ntpd&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ntpd           &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;off&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;off&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;6&lt;/span&gt;:&lt;span class=&quot;literal&quot;&gt;off&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后在master上修改配置文件：&lt;br&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@&lt;span class=&quot;keyword&quot;&gt;master&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;~]# vim&lt;/span&gt; /etc/ntp.conf&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如下编辑，（如下是conf文件部分信息）&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;restrict 127.0.0.1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;restrict -6 ::1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Hosts on local network are less restricted.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;Use&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; servers &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; the pool.ntp.org &lt;span class=&quot;keyword&quot;&gt;project&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Please &lt;span class=&quot;keyword&quot;&gt;consider&lt;/span&gt; joining the pool (&lt;span class=&quot;keyword&quot;&gt;http&lt;/span&gt;://www.pool.ntp.org/&lt;span class=&quot;keyword&quot;&gt;join&lt;/span&gt;.html).&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;114.212&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.190&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.91&lt;/span&gt; prefer&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.&lt;/span&gt;rhel.pool.ntp.org&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1.&lt;/span&gt;rhel.pool.ntp.org&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2.&lt;/span&gt;rhel.pool.ntp.org&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;210.72&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.145&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.44&lt;/span&gt; perfer&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;202.112&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.10&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.36&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;59.124&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.196&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.83&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;   # 局域网NTP服务器的IP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#broadcast &lt;span class=&quot;number&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.255&lt;/span&gt; autokey        # broadcast &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#broadcastclient                        # broadcast &lt;span class=&quot;keyword&quot;&gt;client&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#broadcast &lt;span class=&quot;number&quot;&gt;224.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt; autokey            # multicast &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#multicastclient &lt;span class=&quot;number&quot;&gt;224.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;              # multicast &lt;span class=&quot;keyword&quot;&gt;client&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#manycastserver &lt;span class=&quot;number&quot;&gt;239.255&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.254&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.254&lt;/span&gt;         # manycast &lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#manycastclient &lt;span class=&quot;number&quot;&gt;239.255&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.254&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.254&lt;/span&gt; autokey # manycast &lt;span class=&quot;keyword&quot;&gt;client&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Undisciplined &lt;span class=&quot;keyword&quot;&gt;Local&lt;/span&gt; Clock. This &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; a fake driver intended &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;backup&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;no&lt;/span&gt; outside &lt;span class=&quot;keyword&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; synchronized &lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; available.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;server&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;127.127&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt;     # &lt;span class=&quot;keyword&quot;&gt;local&lt;/span&gt; clock&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fudge   &lt;span class=&quot;number&quot;&gt;127.127&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt; stratum &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;主要的修改有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;添加了&lt;code&gt;restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap&lt;/code&gt;表示192.168.1.1-192.168.1.255的IP地址都可以访问本NTP服务器。&lt;/li&gt;
&lt;li&gt;添加了&lt;code&gt;server 210.72.145.44 perfer&lt;/code&gt;开始的4行，尤其最后一个局域网NTP服务器的IP很重要，后面从节点的时间都要与此IP（master）来同步，相当于一个权威时间服务器。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;遇到的一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;slave上运行&lt;code&gt;ntpdate &amp;lt;masterIP&amp;gt;&lt;/code&gt;出现&lt;code&gt;bind() fails: Permission denied&lt;/code&gt;【解决方案】没有权限，用root做&lt;/li&gt;
&lt;li&gt;slave上运行&lt;code&gt;ntpdate &amp;lt;masterIP&amp;gt;&lt;/code&gt;出现&lt;code&gt;23 Oct 13:11:05 ntpdate[1454]: the NTP socket is in use, exiting&lt;/code&gt; 【解决方案】&lt;code&gt;lsof -i:123&lt;/code&gt; 然后 &lt;code&gt;kill -9 pid&lt;/code&gt; 再重新尝试即可&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;crontab自动同步，crontab是自动运行的服务，可以让机器自动按一定周期进行时间同步。&lt;br&gt;【方法】在每台机器上&lt;br&gt;&lt;figure class=&quot;highlight gherkin&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;crontab -u root -e   &lt;span class=&quot;comment&quot;&gt;# 新建root的crontab文件并编辑，写入如下语句&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt;/24 &lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt; /usr/sbin/ntpdate 192.168.1.1  &lt;span class=&quot;comment&quot;&gt;# 24小时同步一次&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样每24小时，所有的worker都会自动与时间服务器192.168.1.1上的时间同步一次，应该不会再出现时间不同步的问题了，除非机器重启可能会早造成设置改变等，还没有遇到，等遇到了再写。&lt;/p&gt;
&lt;h3 id=&quot;Hadoop-YARN-报-Unhealthy-Nodes&quot;&gt;&lt;a href=&quot;#Hadoop-YARN-报-Unhealthy-Nodes&quot; class=&quot;headerlink&quot; title=&quot;Hadoop YARN 报 Unhealthy Nodes&quot;&gt;&lt;/a&gt;Hadoop YARN 报 Unhealthy Nodes&lt;/h3&gt;&lt;p&gt;Healthy报告如下：&lt;br&gt;&lt;figure class=&quot;highlight armasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; local-dirs are &lt;span class=&quot;keyword&quot;&gt;bad: &lt;/span&gt;/&lt;span class=&quot;meta&quot;&gt;data&lt;/span&gt;/hadoop_tmp/nm-local-dir&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; log-dirs are &lt;span class=&quot;keyword&quot;&gt;bad: &lt;/span&gt;/&lt;span class=&quot;meta&quot;&gt;data&lt;/span&gt;/hadoop_logs/userlogs&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【原因分析】网上说最常见原因是由于节点上的磁盘使用率超出了&lt;code&gt;max-disk-utilization-per-disk-percentage&lt;/code&gt;（默认为90.0%）。&lt;br&gt;确实是这个原因，但是这个可能只是表面原因。可以通过增加磁盘利用率阈值来缓解问题：&lt;br&gt;在&lt;code&gt;yarn-site.xml&lt;/code&gt;中填写：&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;98.5&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;但是增加阈值的方法治标不治本，迟早有一天会超过你设置的98.5%。&lt;br&gt;所以最好是清理磁盘空间。&lt;br&gt;清理磁盘空间发现&lt;code&gt;/data&lt;/code&gt;目录用量极大，说明HDFS很满，用如下命令查看HDFS各目录大小：&lt;br&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@machine ~]$ hadoop fs -du -h /&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;12.1&lt;/span&gt; G  /data&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1.6&lt;/span&gt; T   /tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2.8&lt;/span&gt; T   /&lt;span class=&quot;keyword&quot;&gt;user&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;title&quot;&gt;0&lt;/span&gt;       /user41&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;发现&lt;code&gt;/tmp&lt;/code&gt;目录页用量巨大，再细看：&lt;br&gt;&lt;figure class=&quot;highlight dts&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@machine ~]$ hadoop fs -du -h /tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;55.2&lt;/span&gt; M   &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;st08&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;321.7&lt;/span&gt; M  &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;st22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;9.2&lt;/span&gt; K    &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;st26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;53.6&lt;/span&gt; M   &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;MF1733016&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;b.txt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;36&lt;/span&gt;       &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;files&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;17.7&lt;/span&gt; G   &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;hadoop-yarn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;255.9&lt;/span&gt; M  &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;input&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1.6&lt;/span&gt; T    &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;logs          &lt;span class=&quot;meta&quot;&gt;# logs极大&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;        &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;out&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1.5&lt;/span&gt; M    &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;out2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1.5&lt;/span&gt; M    &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;out3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;108.0&lt;/span&gt; M  &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;output&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;36&lt;/span&gt;       &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;test-in&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2.1&lt;/span&gt; M    &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;test.txt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;31.0&lt;/span&gt; M   &lt;span class=&quot;meta-keyword&quot;&gt;/tmp/&lt;/span&gt;twitter_graph_v2.txt&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由上可以发现，日志文件居然占据1.6T的空间，不可容许。&lt;br&gt;查看&lt;code&gt;yarn-site.xml&lt;/code&gt;，发现有两点：&lt;br&gt;1) 开启了log-aggregation:&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn.log-aggregation-enable&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;source&lt;/span&gt;&amp;gt;&lt;/span&gt;java.io.BufferedInputStream@1bf57bb&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;source&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;开启了日志聚合服务之后，用户程序运行生成的日志会自动传到HDFS的&lt;code&gt;/tmp&lt;/code&gt;目录下，如果不设置自动清空时间的话，日志将一直累积。&lt;br&gt;2）没有设置retain-seconds，即保存时间&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn.log-aggregation.retain-seconds&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;-1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;source&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn-default.xml&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;source&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;默认永久保存。&lt;/p&gt;
&lt;p&gt;但是其实发现集群并没有开启history-server服务，所以这些日志都白记录了。&lt;/p&gt;
&lt;p&gt;【解决方案】所以要么关闭log-aggregation，要么设置一定的保持时间，超过保持时间自动清除。&lt;br&gt;【总结】我们看到，有时其实表面原因下，隐藏着更深刻的问题，找到最关键的地方，治其本才是最一劳永逸的。&lt;/p&gt;
&lt;h3 id=&quot;Hadoop-YARN-执行Task时报-Connection-Refused&quot;&gt;&lt;a href=&quot;#Hadoop-YARN-执行Task时报-Connection-Refused&quot; class=&quot;headerlink&quot; title=&quot;Hadoop YARN 执行Task时报 Connection Refused.&quot;&gt;&lt;/a&gt;Hadoop YARN 执行Task时报 Connection Refused.&lt;/h3&gt;&lt;p&gt;遇到FAILED问题&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/yarn-connection-refused.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;master01:19888/jobhistory/...&lt;/code&gt;查看map task的log信息：&lt;br&gt;&lt;figure class=&quot;highlight oxygene&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2018&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;02&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;09&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;21&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;26&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;815&lt;/span&gt; WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.net.ConnectException: Call &lt;span class=&quot;keyword&quot;&gt;From&lt;/span&gt; slave015/&lt;span class=&quot;number&quot;&gt;127.0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;0.1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; slave015:&lt;span class=&quot;number&quot;&gt;38953&lt;/span&gt; failed &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; connection exception: java.net.ConnectException: Connection refused; &lt;span class=&quot;keyword&quot;&gt;For&lt;/span&gt; more details see:  http:&lt;span class=&quot;comment&quot;&gt;//wiki.apache.org/hadoop/ConnectionRefused&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Method&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sun&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;reflect&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;NativeConstructorAccessorImpl&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;newInstance&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(NativeConstructorAccessorImpl.java:57)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sun&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;reflect&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;DelegatingConstructorAccessorImpl&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;newInstance&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DelegatingConstructorAccessorImpl.java:45)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;java&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;lang&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;reflect&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Constructor&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;newInstance&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;Constructor&lt;/span&gt;.java:526)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;NetUtils&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;wrapWithMessage&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(NetUtils.java:792)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;NetUtils&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;wrapException&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(NetUtils.java:732)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:1480)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:1407)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;WritableRpcEngine&lt;/span&gt;$&lt;span class=&quot;title&quot;&gt;Invoker&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(WritableRpcEngine.java:242)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;com&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;sun&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;proxy&lt;/span&gt;.$&lt;span class=&quot;title&quot;&gt;Proxy7&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;getTask&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Unknown Source)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;mapred&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;YarnChild&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(YarnChild.java:132)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;title&quot;&gt;Caused&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;by&lt;/span&gt;:&lt;/span&gt; java.net.ConnectException: Connection refused&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	at sun.nio.ch.SocketChannelImpl.checkConnect(Native &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Method&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sun&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;nio&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ch&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;SocketChannelImpl&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;finishConnect&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(SocketChannelImpl.java:739)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;SocketIOWithTimeout&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(SocketIOWithTimeout.java:206)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;NetUtils&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(NetUtils.java:531)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;NetUtils&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(NetUtils.java:495)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;$&lt;span class=&quot;title&quot;&gt;Connection&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;setupConnection&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:609)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;$&lt;span class=&quot;title&quot;&gt;Connection&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;setupIOstreams&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:707)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;$&lt;span class=&quot;title&quot;&gt;Connection&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;access&lt;/span&gt;$2800&lt;span class=&quot;params&quot;&gt;(Client.java:370)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;getConnection&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:1529)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;title&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hadoop&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;ipc&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Client&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Client.java:1446)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	... 4 &lt;span class=&quot;title&quot;&gt;more&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【问题分析】&lt;br&gt;发现这么一条：&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Call&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;From&lt;/span&gt; slave015/&lt;span class=&quot;number&quot;&gt;127.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; localhost.localdomain:&lt;span class=&quot;number&quot;&gt;38953&lt;/span&gt;  &lt;span class=&quot;keyword&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exception&lt;/span&gt;.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在分布式集群中，一般遇到Connection refused问题，大概率是hosts解析有问题。&lt;/p&gt;
&lt;p&gt;查看&lt;code&gt;/etc/hosts&lt;/code&gt;文件如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;127&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;       &lt;span class=&quot;selector-tag&quot;&gt;slave015&lt;/span&gt;        &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain&lt;/span&gt;   &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#&lt;span class=&quot;selector-pseudo&quot;&gt;::1&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain6&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#&lt;span class=&quot;selector-pseudo&quot;&gt;::1&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;        &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain6&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#&lt;span class=&quot;selector-pseudo&quot;&gt;::1&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;        &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain6&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;localhost6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;115&lt;span class=&quot;selector-class&quot;&gt;.212&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.190&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.91&lt;/span&gt;  &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave002&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.3&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave003&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.4&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave004&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave005&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.6&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave006&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.7&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave007&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.8&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave008&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.9&lt;/span&gt;     &lt;span class=&quot;selector-tag&quot;&gt;slave009&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.10&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave010&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.11&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave011&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.12&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave012&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.13&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave013&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.14&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave014&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.15&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave015&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.16&lt;/span&gt;    &lt;span class=&quot;selector-tag&quot;&gt;slave016&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;注意第一行的，前三项依次代表内网IP，主机名，主机别名。&lt;br&gt;也就是说，主机是slave015把自己解析成127.0.0.1，同样地，别的机器也部分出现了这种情况，所以大概的一个错误原因分析如下：&lt;br&gt;在yarn集群中，一些主机会在一个临时端口(假如如上是38953)启动job tracker，然后任意主机的task tracker向此job tracker拉取任务时，job tracker会把自己的地址和端口发送给需求的task tracker，然后task tracker自己去此端口拉取任务。&lt;br&gt;如果job tracker的hosts设置错误，假如如上解析为本机地址，那么job tracker会将&lt;code&gt;127.0.0.1&lt;/code&gt;，即别名为&lt;code&gt;localhost.localdomain&lt;/code&gt;的地址发给task tracker(在本例为slave015)，所以slave015开始向&lt;code&gt;localhost.localdomain:38953&lt;/code&gt;去拉取任务或者信息，但是对于slave015而言，&lt;code&gt;localhost.localdomain&lt;/code&gt;是本机地址，而本机地址没有38953端口！所以会造成Connection refused。&lt;br&gt;当然可能造成这个的原因不止这一个，也可能不是这一个，我们可以在master:8088/cluster中查看log来判断解决。如果无法跳转到&lt;code&gt;master01:19888/jobhistory&lt;/code&gt;，那么需要在本机（webUI端）设置一条hosts规则：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;115&lt;span class=&quot;selector-class&quot;&gt;.212&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.190&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.91&lt;/span&gt;  &lt;span class=&quot;selector-tag&quot;&gt;master01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;【解决方案】&lt;br&gt;把所有设置错误的节点修正过来。删掉第二个条目(如slave015)。&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;127&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;        &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.localdomain&lt;/span&gt;   &lt;span class=&quot;selector-tag&quot;&gt;localhost&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其实之前的hosts设置是OK的，只不过机器硬件重启之后，hosts设置又还原了。在分布式集群中就是这样，很难保证机器全部非常健康的运转。&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/zjp719325616/p/6530705.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;hadoop集群时间同步&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文记录Hadoop，HDFS，YARN，HBase，Hive等Hadoop社区的系统使用中的一些问题及解决方案，&lt;br&gt;包括Hadoop集群构建及使用中的一些问题以及解决方案，&lt;br&gt;包括各种莫名其妙的安装问题，&lt;br&gt;配置问题，&lt;br&gt;运行问题，&lt;br&gt;运行中问题，&lt;b
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="大数据" scheme="http://whatbeg.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hadoop" scheme="http://whatbeg.com/tags/Hadoop/"/>
    
      <category term="错误解决" scheme="http://whatbeg.com/tags/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/"/>
    
  </entry>
  
  <entry>
    <title>利用Pytorch进行CNN详细剖析</title>
    <link href="http://whatbeg.com/2017/08/14/mnistCNN.html"/>
    <id>http://whatbeg.com/2017/08/14/mnistCNN.html</id>
    <published>2017-08-14T14:11:01.000Z</published>
    <updated>2017-08-14T14:43:43.870Z</updated>
    
    <content type="html">&lt;p&gt;本文缘起于一次CNN作业中的一道题，这道题涉及到了基本的CNN网络搭建，在MNIST数据集上的分类结果，Batch Normalization的影响，Dropout的影响，卷积核大小的影响，数据集大小的影响，不同部分数据集的影响，随机数种子的影响，以及不同激活单元的影响等，能够让人比较全面地对CNN有一个了解，所以想做一下，于是有了本文。&lt;/p&gt;
&lt;h2 id=&quot;工具&quot;&gt;&lt;a href=&quot;#工具&quot; class=&quot;headerlink&quot; title=&quot;工具&quot;&gt;&lt;/a&gt;工具&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;开源深度学习库： &lt;a href=&quot;http://pytorch.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数据集：&lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MNIST&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;实现&quot;&gt;&lt;a href=&quot;#实现&quot; class=&quot;headerlink&quot; title=&quot;实现&quot;&gt;&lt;/a&gt;实现&lt;/h2&gt;&lt;h3 id=&quot;初始要求&quot;&gt;&lt;a href=&quot;#初始要求&quot; class=&quot;headerlink&quot; title=&quot;初始要求&quot;&gt;&lt;/a&gt;初始要求&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;首先建立基本的BASE网络，在Pytorch中有如下code：&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(nn.Module)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        super(Net, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.conv2 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.fc1 = nn.Linear(&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.fc2 = nn.Linear(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, x)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(self.conv1(x), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(self.conv2(x), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = x.view(&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.relu(self.fc1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.fc2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; F.log_softmax(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这部分代码见&lt;code&gt;base.py&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;问题A：预处理&quot;&gt;&lt;a href=&quot;#问题A：预处理&quot; class=&quot;headerlink&quot; title=&quot;问题A：预处理&quot;&gt;&lt;/a&gt;问题A：预处理&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;即要求将MNIST数据集按照规则读取并且tranform到适合处理的格式。这里读取的代码沿用了BigDL Python Support的读取方式，无需细说，根据MNIST主页上的数据格式可以很快读出，关键block有读取32位比特的函数：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;_read32&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(bytestream)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    dt = numpy.dtype(numpy.uint32).newbyteorder(&lt;span class=&quot;string&quot;&gt;&#39;&amp;gt;&#39;&lt;/span&gt;)    &lt;span class=&quot;comment&quot;&gt;# 大端模式读取，最高字节在前(MSB first)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; numpy.frombuffer(bytestream.read(&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;), dtype=dt)[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;读出后是(N, 1, 28, 28)的tensor，每个像素是0-255的值，首先做一下归一化，将所有值除以255，得到一个0-1的值，然后再Normalize，训练集和测试集的均值方差都已知，直接做即可。由于训练集和测试集的均值方差都是针对归一化后的数据来说的，所以刚开始没做归一化，所以forward输出和grad很离谱，后来才发现是这里出了问题。&lt;/p&gt;
&lt;p&gt;这部分代码见&lt;code&gt;preprocessing.py&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;问题B：BASE模型&quot;&gt;&lt;a href=&quot;#问题B：BASE模型&quot; class=&quot;headerlink&quot; title=&quot;问题B：BASE模型&quot;&gt;&lt;/a&gt;问题B：BASE模型&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;将random seed设置为0，在前10000个训练样本上学习参数，最后看20个epochs之后的测试集错误率。最后结果为：&lt;/p&gt;
&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Test &lt;span class=&quot;string&quot;&gt;set:&lt;/span&gt; Average &lt;span class=&quot;string&quot;&gt;loss:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0014&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;Accuracy:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;9732&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;97.3&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到，BASE模型准确率并不是那么的高。&lt;/p&gt;
&lt;h3 id=&quot;问题C：Batch-Normalization-v-s-BASE&quot;&gt;&lt;a href=&quot;#问题C：Batch-Normalization-v-s-BASE&quot; class=&quot;headerlink&quot; title=&quot;问题C：Batch Normalization v.s BASE&quot;&gt;&lt;/a&gt;问题C：Batch Normalization v.s BASE&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN3.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在前三个block的卷积层之后加上Batch Normalization层，简单修改网络结构如下即可：&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(nn.Module)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        super(Net, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.conv2 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.fc1 = nn.Linear(&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.fc2 = nn.Linear(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.bn1 = nn.BatchNorm2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.bn2 = nn.BatchNorm2d(&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.bn3 = nn.BatchNorm1d(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, x)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.conv1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(self.bn1(x), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.conv2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(self.bn2(x), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = x.view(&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.fc1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.relu(self.bn3(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.fc2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; F.log_softmax(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;同样的参数run一下，得出加了BN的结果为：&lt;br&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Test &lt;span class=&quot;string&quot;&gt;set:&lt;/span&gt; Average &lt;span class=&quot;string&quot;&gt;loss:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0009&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;Accuracy:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;9817&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;98.2&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由此可见，有明显的效果提升。&lt;br&gt;关于Batch Normalization的更多资料参见[2],[5]。&lt;/p&gt;
&lt;h3 id=&quot;问题D：-Dropout-Layer&quot;&gt;&lt;a href=&quot;#问题D：-Dropout-Layer&quot; class=&quot;headerlink&quot; title=&quot;问题D： Dropout Layer&quot;&gt;&lt;/a&gt;问题D： Dropout Layer&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在最后一层即&lt;code&gt;fc2&lt;/code&gt;层后加一个&lt;code&gt;Dropout(p=0.5)&lt;/code&gt;后，在BASE和BN上的结果分别为：&lt;/p&gt;
&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BASE：Test &lt;span class=&quot;string&quot;&gt;set:&lt;/span&gt; Average &lt;span class=&quot;string&quot;&gt;loss:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0011&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;Accuracy:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;9769&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;97.7&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;BN：  Test &lt;span class=&quot;string&quot;&gt;set:&lt;/span&gt; Average &lt;span class=&quot;string&quot;&gt;loss:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0014&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;Accuracy:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;9789&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;97.9&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;观察得知，dropout能够对BASE模型起到一定提升作用，但是对BN模型却效果不明显反而降低了。&lt;br&gt;原因可能在于，BN模型中本身即包含了正则化的效果，再加一层Dropout显得没有必要反而可能影响结果。&lt;/p&gt;
&lt;h3 id=&quot;问题E：SK-model&quot;&gt;&lt;a href=&quot;#问题E：SK-model&quot; class=&quot;headerlink&quot; title=&quot;问题E：SK model&quot;&gt;&lt;/a&gt;问题E：SK model&lt;/h3&gt;&lt;p&gt;SK model: Stacking two 3x3 conv. layers to replace 5x5 conv. layer&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN5-1.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN5-2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;如此一番改动后，搭建的SK模型如下：&lt;br&gt;&lt;figure class=&quot;highlight ruby&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Net&lt;/span&gt;(&lt;span class=&quot;title&quot;&gt;nn&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Module&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;super&lt;/span&gt;(Net, &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;).__init_&lt;span class=&quot;number&quot;&gt;_&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv1_1 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv1_2 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv2 = nn.Conv2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, kernel_size=(&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;), stride=(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;), padding=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.fc1 = nn.Linear(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.fc2 = nn.Linear(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn1_1 = nn.BatchNorm2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn1_2 = nn.BatchNorm2d(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn2 = nn.BatchNorm2d(&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn3 = nn.BatchNorm1d(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.drop = nn.Dropout(p=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;, x)&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.relu(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn1_1(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv1_1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.relu(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn1_2(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv1_2(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(x, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.conv2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.max_pool2d(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn2(x), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = x.view(-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.fc1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = F.relu(&lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.bn3(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = &lt;span class=&quot;keyword&quot;&gt;self&lt;/span&gt;.fc2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; F.log_softmax(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在20个epoch后，结果如下，&lt;br&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;SK： Test &lt;span class=&quot;string&quot;&gt;set:&lt;/span&gt; Average &lt;span class=&quot;string&quot;&gt;loss:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0008&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;Accuracy:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;9848&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;10000&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;98.5&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;测试集准确率得到了少许的提高。&lt;br&gt;这里利用2个3x3的卷积核来代替大的5x5卷积核，参数个数由5x5=25变为了2x3x3=18。实践表明，这样使得计算更快了，并且小的卷积层之间的ReLU也很有帮助。&lt;br&gt;VGG中就使用了这种方法。&lt;/p&gt;
&lt;h3 id=&quot;问题F：Change-Number-of-channels&quot;&gt;&lt;a href=&quot;#问题F：Change-Number-of-channels&quot; class=&quot;headerlink&quot; title=&quot;问题F：Change Number of channels&quot;&gt;&lt;/a&gt;问题F：Change Number of channels&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN6.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过将特征图大小乘上一个倍数，再通过shell程序执行，得到如下结果：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;SK0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;：  97&lt;span class=&quot;selector-class&quot;&gt;.7&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;SK0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;：  98&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;SK1&lt;/span&gt;：    98&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;SK1&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;：  98&lt;span class=&quot;selector-class&quot;&gt;.6&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;SK2&lt;/span&gt;：    98&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;%  (&lt;span class=&quot;selector-tag&quot;&gt;max&lt;/span&gt; 98&lt;span class=&quot;selector-class&quot;&gt;.7&lt;/span&gt;%)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在特征图分别为4，10, 30, 40时，最终的准确度基本是往上提升的。这在一定程度上说明，在没有达到过拟合前，增大特征图的个数，即相当于提取了更多的特征，提取特征数的增加有助于精度的提高。&lt;br&gt;这部分代码见&lt;code&gt;SK_s.py&lt;/code&gt;和&lt;code&gt;runSK.sh&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;问题G：Use-different-training-set-sizes&quot;&gt;&lt;a href=&quot;#问题G：Use-different-training-set-sizes&quot; class=&quot;headerlink&quot; title=&quot;问题G：Use different training set sizes&quot;&gt;&lt;/a&gt;问题G：Use different training set sizes&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;同样通过脚本运行，增加参数&lt;br&gt;&lt;figure class=&quot;highlight go&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;parser.add_argument(&lt;span class=&quot;string&quot;&gt;&#39;--usedatasize&#39;&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;60000&lt;/span&gt;, metavar=&lt;span class=&quot;string&quot;&gt;&#39;SZ&#39;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    help=&lt;span class=&quot;string&quot;&gt;&#39;use how many training data to train network&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;表示使用的数据大小，从前往后取&lt;code&gt;usebatchsize&lt;/code&gt;个数据。&lt;br&gt;这部分程序见&lt;code&gt;SK_s.py&lt;/code&gt;和&lt;code&gt;runTrainingSize.sh&lt;/code&gt;。&lt;br&gt;运行的结果如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;500：   84&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1000：  92&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2000：  94&lt;span class=&quot;selector-class&quot;&gt;.3&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5000：  95&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10000： 96&lt;span class=&quot;selector-class&quot;&gt;.6&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20000： 98&lt;span class=&quot;selector-class&quot;&gt;.4&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60000： 99&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由此可以明显地看出，数据越多，结果的精度越大。&lt;br&gt;太少的数据无法准确反映数据的整体分布情况，而且容易过拟合，数据多到一定程度效果也会不明显，不过，大多数时候我们总还是嫌数据太少，而且更多的数据获取起来也有一定难度。&lt;/p&gt;
&lt;h3 id=&quot;问题H：Use-different-training-sets&quot;&gt;&lt;a href=&quot;#问题H：Use-different-training-sets&quot; class=&quot;headerlink&quot; title=&quot;问题H：Use different training sets&quot;&gt;&lt;/a&gt;问题H：Use different training sets&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN8.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用脚本完成，这部分程序见&lt;code&gt;SK_0.2.py&lt;/code&gt;和&lt;code&gt;diffTrainingSets.sh&lt;/code&gt;。&lt;br&gt;运行结果如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;    0&lt;span class=&quot;selector-tag&quot;&gt;-10000&lt;/span&gt;： 98&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10000&lt;span class=&quot;selector-tag&quot;&gt;-20000&lt;/span&gt;： 97&lt;span class=&quot;selector-class&quot;&gt;.8&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20000&lt;span class=&quot;selector-tag&quot;&gt;-30000&lt;/span&gt;： 97&lt;span class=&quot;selector-class&quot;&gt;.8&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30000&lt;span class=&quot;selector-tag&quot;&gt;-40000&lt;/span&gt;： 97&lt;span class=&quot;selector-class&quot;&gt;.4&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40000&lt;span class=&quot;selector-tag&quot;&gt;-50000&lt;/span&gt;： 97&lt;span class=&quot;selector-class&quot;&gt;.5&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50000&lt;span class=&quot;selector-tag&quot;&gt;-60000&lt;/span&gt;： 97&lt;span class=&quot;selector-class&quot;&gt;.7&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由此可见，采用不同的训练样本集合训练出来的网络有一定的差异，虽不是很大，但是毕竟显示出了不稳定的结果。&lt;/p&gt;
&lt;h3 id=&quot;问题I：Random-Seed’s-effects&quot;&gt;&lt;a href=&quot;#问题I：Random-Seed’s-effects&quot; class=&quot;headerlink&quot; title=&quot;问题I：Random Seed’s effects&quot;&gt;&lt;/a&gt;问题I：Random Seed’s effects&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN9.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用&lt;code&gt;runSeed.sh&lt;/code&gt;脚本完成，用到了全部60000个训练集。&lt;br&gt;运行的结果如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;      0：  98&lt;span class=&quot;selector-class&quot;&gt;.9&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;      1：  99&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;     12：  99&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;    123：  99&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;   1234：  99&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt;  12345：  99&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Seed&lt;/span&gt; 123456：  98&lt;span class=&quot;selector-class&quot;&gt;.9&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;事实上在用上整个训练集的时候，随机数生成器的种子设置对于最后结果的影响不大。&lt;/p&gt;
&lt;h3 id=&quot;问题J：ReLU-or-Sigmoid&quot;&gt;&lt;a href=&quot;#问题J：ReLU-or-Sigmoid&quot; class=&quot;headerlink&quot; title=&quot;问题J：ReLU or Sigmoid?&quot;&gt;&lt;/a&gt;问题J：ReLU or Sigmoid?&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/PRCNN10.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;将ReLU全部换成Sigmoid后，用全部60000个训练集训练，有对比结果如下：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;selector-tag&quot;&gt;ReLU&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;SK_0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;:  99&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;Sigmoid&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;SK_0&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;:  98&lt;span class=&quot;selector-class&quot;&gt;.6&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由此可以看出，在训练CNN时，使用ReLU激活单元比Sigmoid激活单元要更好一些。原因可能在于二者机制的差别，sigmoid在神经元输入值较大或者较小时，输出值会近乎0或者1，这使得许多地方的梯度几乎为0，权重几乎得不到更新。而ReLU虽然增加了计算的负担，但是它能够显著加速收敛过程，并且也不会有梯度饱和问题。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;本文利用PyTorch对几个CNN模型在MNIST数据集上的比较，以及一些参数的设置对模型效果的影响，从而对CNN的许多方面进行了一些详细的评估。&lt;br&gt;用过这么一次觉得PyTorch还是挺好用的，比较简单，其他模型不知道，反正卷积神经网络模型是如此。&lt;br&gt;项目具体代码见[7]。&lt;br&gt;由于笔者对CNN（卷积神经网络）研究不太深入，所以每个结果后的解释或有失偏颇，读者批判阅读即可。&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;[1] &lt;a href=&quot;https://cs.nju.edu.cn/wujx/paper/CNN.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Introduction to Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&quot;http://proceedings.mlr.press/v37/ioffe15.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Batch Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href=&quot;http://pytorch.org/docs/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PyTorch Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] &lt;a href=&quot;http://www.vlfeat.org/matconvnet/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MatConvNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[5] &lt;a href=&quot;https://www.zhihu.com/question/38102762&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;知乎-深度学习中 Batch Normalization为什么效果好？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[6] &lt;a href=&quot;http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Dropout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[7] &lt;a href=&quot;https://github.com/whatbeg/Data-Analysis-and-Mining/tree/master/CNN_for_Mnist&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github上的代码&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文缘起于一次CNN作业中的一道题，这道题涉及到了基本的CNN网络搭建，在MNIST数据集上的分类结果，Batch Normalization的影响，Dropout的影响，卷积核大小的影响，数据集大小的影响，不同部分数据集的影响，随机数种子的影响，以及不同激活单元的影响等，
    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning读书笔记（2）【深度学习的数学基础摘要】</title>
    <link href="http://whatbeg.com/2017/08/13/deeplearningbook-02.html"/>
    <id>http://whatbeg.com/2017/08/13/deeplearningbook-02.html</id>
    <published>2017-08-13T02:49:46.000Z</published>
    <updated>2017-08-14T13:22:02.752Z</updated>
    
    <content type="html">&lt;p&gt;深度学习需要的数学基础同机器学习所需的数学基础类似，包括三大块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线性代数&lt;/li&gt;
&lt;li&gt;概率论与数理统计&lt;/li&gt;
&lt;li&gt;信息论基础&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分三部分摘要如下，&lt;/p&gt;
&lt;h2 id=&quot;线性代数&quot;&gt;&lt;a href=&quot;#线性代数&quot; class=&quot;headerlink&quot; title=&quot;线性代数&quot;&gt;&lt;/a&gt;线性代数&lt;/h2&gt;&lt;h3 id=&quot;Scalar-Vectors-Matrices-Tensors的概念&quot;&gt;&lt;a href=&quot;#Scalar-Vectors-Matrices-Tensors的概念&quot; class=&quot;headerlink&quot; title=&quot;Scalar, Vectors, Matrices, Tensors的概念&quot;&gt;&lt;/a&gt;Scalar, Vectors, Matrices, Tensors的概念&lt;/h3&gt;&lt;p&gt;Scalar: 标量，可以看成一个数&lt;br&gt;Vector: 向量，可以看成一个一维数组&lt;br&gt;Matrix: 矩阵，可以看成二维数组&lt;br&gt;Tensor: 张量，三维或三维以上的数组的统称，维度不定&lt;/p&gt;
&lt;p&gt;很多时候我们处理的都是超过2维的数组，这时候叫矩阵(Matrix)又不太合适，因为一般提到矩阵都会想到二维的矩阵，所以采用Tensor来统一表示不定维的数组。这也是几乎所有深度学习框架的基本数据结构。”Tensorflow”名字中就包含了”Tensor”，于是向量可以称为1-D Tensor，一维张量，矩阵可以称为二维张量。&lt;/p&gt;
&lt;p&gt;这样，深度学习中包括数据，梯度，权重等等都可以用某维度的Tensor来表示了，底层数据结构的统一为上层编程带来了极大的方便。&lt;/p&gt;
&lt;h3 id=&quot;矩阵的基本操作&quot;&gt;&lt;a href=&quot;#矩阵的基本操作&quot; class=&quot;headerlink&quot; title=&quot;矩阵的基本操作&quot;&gt;&lt;/a&gt;矩阵的基本操作&lt;/h3&gt;&lt;p&gt;矩阵转置，相乘，矩阵与向量相乘&lt;br&gt;单位矩阵与逆矩阵&lt;br&gt;线性相关性&lt;br&gt;展开(Span)，一个向量集的展开定义为向量集中通过向量的线性组合能够得到的点&lt;/p&gt;
&lt;h3 id=&quot;奇异-Singular-矩阵和非奇异矩阵&quot;&gt;&lt;a href=&quot;#奇异-Singular-矩阵和非奇异矩阵&quot; class=&quot;headerlink&quot; title=&quot;奇异(Singular)矩阵和非奇异矩阵&quot;&gt;&lt;/a&gt;奇异(Singular)矩阵和非奇异矩阵&lt;/h3&gt;&lt;p&gt;奇异矩阵：存在线性相关的列的方阵或者行列式为0的方阵称为奇异矩阵&lt;br&gt;奇异矩阵不可逆&lt;br&gt;若n阶方阵A的行列式不为零，即$|A|≠0$，则称A为非奇异矩阵或满秩矩阵，存在逆矩阵&lt;/p&gt;
&lt;p&gt;要注意的是，即使A不是方阵或者A是方阵但是奇异，也是有可能解方程$Ax=b$的，只是不能通过求逆矩阵$A^{-1}$从而$x=A^{-1}b$来解而已。&lt;br&gt;线性方程组$Ax=b$有解的充分必要条件是: 增广矩阵的秩等于系数矩阵的秩，即$r(A,b) = r(A)$&lt;/p&gt;
&lt;h3 id=&quot;范数-Norm&quot;&gt;&lt;a href=&quot;#范数-Norm&quot; class=&quot;headerlink&quot; title=&quot;范数(Norm)&quot;&gt;&lt;/a&gt;范数(Norm)&lt;/h3&gt;&lt;p&gt;范数的作用是度量向量的大小，将向量映射为非负实数&lt;br&gt;$L^p$范数定义为：&lt;br&gt;$$||x||_p=(\Sigma_i {|x_i|^p})^{\frac 1 p}$$&lt;/p&gt;
&lt;p&gt;在正则化中常常用到范数，主要用到1-范数和2-范数。&lt;/p&gt;
&lt;p&gt;$x^{\top}x=||x||_2^2$&lt;/p&gt;
&lt;p&gt;Frobenius Norms:  $||A||_{F}=\sqrt{\Sigma_{i,j}A_{i,j}^2}$&lt;/p&gt;
&lt;p&gt;向量点积： $x^{\top}y=||x||_2||y||_2cos\theta$&lt;/p&gt;
&lt;h3 id=&quot;特殊矩阵&quot;&gt;&lt;a href=&quot;#特殊矩阵&quot; class=&quot;headerlink&quot; title=&quot;特殊矩阵&quot;&gt;&lt;/a&gt;特殊矩阵&lt;/h3&gt;&lt;p&gt;对角矩阵&lt;br&gt;实对称矩阵及其性质：&lt;br&gt;（1）A的特征值为实数，且其特征向量为实向量&lt;br&gt;（2）A的不同特征值对应的特征向量必定正交&lt;br&gt;（3）A一定有n个线性无关的特征向量，从而A相似于对角矩阵&lt;br&gt;正交矩阵的性质： $A^{-1}=A^{\top}$&lt;/p&gt;
&lt;h3 id=&quot;特征值分解&quot;&gt;&lt;a href=&quot;#特征值分解&quot; class=&quot;headerlink&quot; title=&quot;特征值分解&quot;&gt;&lt;/a&gt;特征值分解&lt;/h3&gt;&lt;p&gt;特征值分解的思想类似于因式分解的思想，对于一个数，我们想要分析它的性质，可能直接看看不出什么来，但是可以把它因式分解一下，再来分析。比如180，$180 = 2 \times 2 \times 3 \times 3 \times 5=2^2 \times 3^2 \times 5^1$，这样我们可以知道，180是2,3,5的倍数，也是6的倍数，15的倍数，等等，进而分析其它性质。&lt;br&gt;矩阵分解也是如此，面对一个复杂的矩阵，我们可能毫无头绪，但是将其分解为两个或者多个矩阵的乘积，我们可能就能收获很多的性质。&lt;br&gt;特征值分解 $A=Q \Lambda Q^{\top}$，将矩阵分解为特征值和特征向量，Q是由A的特征向量组成的正交矩阵，而$\Lambda$则为特征值组成的对角矩阵，$\Lambda_{i,i}$ 对应着 $Q_{:,i}$。&lt;/p&gt;
&lt;h3 id=&quot;奇异值分解-Singular-Value-Decomposition&quot;&gt;&lt;a href=&quot;#奇异值分解-Singular-Value-Decomposition&quot; class=&quot;headerlink&quot; title=&quot;奇异值分解(Singular Value Decomposition)&quot;&gt;&lt;/a&gt;奇异值分解(Singular Value Decomposition)&lt;/h3&gt;&lt;p&gt;$A=UDV^{-1}$，U称为左奇异向量，为$AA^{\top}$的特征向量，V称为右奇异向量，为$A^{\top}A$的特征向量。&lt;br&gt;非0奇异值是$A^{\top}A$的特征值的开根号&lt;/p&gt;
&lt;h3 id=&quot;Moore-Penrose-Pseudoinverse&quot;&gt;&lt;a href=&quot;#Moore-Penrose-Pseudoinverse&quot; class=&quot;headerlink&quot; title=&quot;Moore-Penrose Pseudoinverse&quot;&gt;&lt;/a&gt;Moore-Penrose Pseudoinverse&lt;/h3&gt;&lt;p&gt;通常意义上的逆矩阵只有在当A为n阶方阵，并且行列式不为0时才存在，但是有时候这个条件显得太苛刻了，于是人们将条件做一些放松，使得能够推广到不可逆的矩阵或者长方的矩阵上，Penrose给出了四个矩阵方程，即放松后的条件，满足所有或者部分这些条件的逆矩阵称之为广义逆矩阵。满足所有者四个条件的称之为Moore-Penrose伪逆。&lt;br&gt;四个方程分别为：&lt;br&gt;(1) $AXA = A$&lt;br&gt;(2) $XAX = X$&lt;br&gt;(3) $(AH)^H = AX$&lt;br&gt;(4) $(XA)^H = XA$&lt;br&gt;（$A^H$为共轭转置，即$\bar{A} ^ T$）&lt;br&gt;对于$A \in C^{m \times n}$，如果有$X \in C^{n \times m}$满足这四个方程的某几个或者全部，那么X就称为A的广义逆。&lt;br&gt;满足这四个方程则称为M-P伪逆。&lt;/p&gt;
&lt;h3 id=&quot;迹运算符-Trace&quot;&gt;&lt;a href=&quot;#迹运算符-Trace&quot; class=&quot;headerlink&quot; title=&quot;迹运算符(Trace)&quot;&gt;&lt;/a&gt;迹运算符(Trace)&lt;/h3&gt;&lt;p&gt;$ Tr(A) = {\Sigma}_i A_{i,i} $&lt;br&gt;迹运算符有许多性质，比如循环不变性等等&lt;/p&gt;
&lt;h3 id=&quot;行列式&quot;&gt;&lt;a href=&quot;#行列式&quot; class=&quot;headerlink&quot; title=&quot;行列式&quot;&gt;&lt;/a&gt;行列式&lt;/h3&gt;&lt;p&gt;行列式的绝对值度量了矩阵扩展或者空间收缩所包含的操作多少的度量。&lt;/p&gt;
&lt;h2 id=&quot;概率论&quot;&gt;&lt;a href=&quot;#概率论&quot; class=&quot;headerlink&quot; title=&quot;概率论&quot;&gt;&lt;/a&gt;概率论&lt;/h2&gt;&lt;p&gt;概率论也是很多领域包括计算机科学尤其是机器学习这块的基础学科。一般的计算机程序或者问题的求解是没有随机性的，按照一个确定的算法来即可。但是在机器学习中，经常会遇到不确定的量，比如说数据的采集，可能是随机采集的，或者说数据中包含随机噪声等等，而概率论则是量化各种不确定性的手段。&lt;br&gt;可以说，几乎所有的活动都要求参与者具有分析不确定性的出现的一些能力。&lt;br&gt;不确定性有三种可能的来源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;系统固有的随机性&lt;br&gt;比如说打牌的游戏，我们都会假设洗牌确实是能够将牌的顺序变的随机。&lt;/li&gt;
&lt;li&gt;不完备的观察&lt;br&gt;即使是一个确定的系统，当我们不能够观察到系统中所有驱动系统行为的变量时，也是会呈现出随机性的。&lt;/li&gt;
&lt;li&gt;不完备的建模&lt;br&gt;我们有时候建模时无法完美地使用所有信息，从而必须丢弃一些观察到的信息，丢弃的信息就会造成模型预测的不确定性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在概率论领域，有两种学派，一种是频率学派，一种是贝叶斯学派。关于这两个学派的观点，可以参看&lt;a href=&quot;https://www.zhihu.com/question/20587681&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;贝叶斯学派与频率学派有何不同？&lt;/a&gt;等。&lt;/p&gt;
&lt;h3 id=&quot;随机变量&quot;&gt;&lt;a href=&quot;#随机变量&quot; class=&quot;headerlink&quot; title=&quot;随机变量&quot;&gt;&lt;/a&gt;随机变量&lt;/h3&gt;&lt;p&gt;简单来说，随机变量就是&lt;strong&gt;能够随机的取不同值的变量&lt;/strong&gt;，又分为连续随机变量和离散随机变量，离散随机变量包含有限个或者可数无穷个状态，状态不必是整数。而连续随机变量则与一个实值相关联。&lt;/p&gt;
&lt;h3 id=&quot;概率分布&quot;&gt;&lt;a href=&quot;#概率分布&quot; class=&quot;headerlink&quot; title=&quot;概率分布&quot;&gt;&lt;/a&gt;概率分布&lt;/h3&gt;&lt;p&gt;一个或一组随机变量取到每个可能状态的可能性的描述即为概率分布。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;离散随机变量的概率分布称为概率质量函数(PMF, Probablity Mass Function)&lt;/li&gt;
&lt;li&gt;连续随机变量的概率分布称为概率密度函数(PDF, Probablity Density Function)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;边缘概率&quot;&gt;&lt;a href=&quot;#边缘概率&quot; class=&quot;headerlink&quot; title=&quot;边缘概率&quot;&gt;&lt;/a&gt;边缘概率&lt;/h3&gt;&lt;p&gt;原来变量集合的一个子集上的概率分布。&lt;br&gt;假设有离散型随机变量X,Y，在知道P(X,Y)的情况下，计算边缘分布如下：&lt;br&gt;$$&lt;br&gt;\forall x \in X, P(X=x) = \sum_y {P(X=x, Y=y)}&lt;br&gt;$$&lt;br&gt;连续的话就是求积分的方式：&lt;br&gt;$$&lt;br&gt;p(x)=\int p(x,y)dy&lt;br&gt;$$&lt;/p&gt;
&lt;h3 id=&quot;条件概率及其链式法则&quot;&gt;&lt;a href=&quot;#条件概率及其链式法则&quot; class=&quot;headerlink&quot; title=&quot;条件概率及其链式法则&quot;&gt;&lt;/a&gt;条件概率及其链式法则&lt;/h3&gt;&lt;p&gt;条件概率：&lt;br&gt;给定某个事件发生时，事件A发生的概率称为条件概率。&lt;br&gt;$$&lt;br&gt;P(Y=y | X=x) = \frac {P(Y=y,X=x)} {P(X=x)}  \ \ \ \ \ \ \ \ \ \ (P(X=x) &amp;gt; 0)&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;条件概率的链式法则：&lt;br&gt;多维随机变量联合概率分布分解成单变量条件概率相乘：&lt;br&gt;$$&lt;br&gt;P(x^{(1)}, x^{(2)}, …, x^{(n)}) = P(x^{(1)})\prod_{i=2}^n P(x^{(i)} | x^{(1)}, x^{(2)}, …, x^{(i-1)})&lt;br&gt;$$&lt;br&gt;这个式子比较重要，典型的应用出现在NLP中句子的n-gram模型。&lt;/p&gt;
&lt;h3 id=&quot;独立和条件独立&quot;&gt;&lt;a href=&quot;#独立和条件独立&quot; class=&quot;headerlink&quot; title=&quot;独立和条件独立&quot;&gt;&lt;/a&gt;独立和条件独立&lt;/h3&gt;&lt;p&gt;独立意味着联合概率等于各个变量的边缘概率的乘积。&lt;br&gt;$$&lt;br&gt;\forall x \in X, y \in Y, p(X=x, Y=y)=P(X=x)P(Y=y)&lt;br&gt;$$&lt;br&gt;两个随机变量在给定随机变量z是&lt;strong&gt;条件独立&lt;/strong&gt;的，是指&lt;br&gt;$$&lt;br&gt;\forall x \in X, y \in Y, z \in Z, p(X=x, Y=y | Z=z)=P(X=x | Z=z)P(Y=y | Z=z)&lt;br&gt;$$&lt;/p&gt;
&lt;h3 id=&quot;期望，方差与协方差&quot;&gt;&lt;a href=&quot;#期望，方差与协方差&quot; class=&quot;headerlink&quot; title=&quot;期望，方差与协方差&quot;&gt;&lt;/a&gt;期望，方差与协方差&lt;/h3&gt;&lt;p&gt;这几个概念是深度学习乃至机器学习中非常常用的概念，需要重点掌握。&lt;/p&gt;
&lt;p&gt;随机变量X的期望值，直觉的来说，是指&lt;code&gt;X的可能值与其概率值之积的累加和&lt;/code&gt;。&lt;br&gt;数学上来说，函数f(x)关于某分布P(x)的期望，指的是x由分布P产生时，f(x)的平均值。&lt;br&gt;对于离散型随机变量，&lt;br&gt;$$&lt;br&gt;\mathbb{E}[f(x)] = \sum_x P(x)f(x)&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;对于连续性随机变量则求积分得到：&lt;br&gt;$$&lt;br&gt;\mathbb{E}[f(x)] = \int p(x)f(x)dx&lt;br&gt;$$&lt;br&gt;当然这里有一个前提，就是当随机变量X取无穷个值的时候，离散型变量的期望满足&lt;br&gt;$$E(X)=\sum_{x}|f(x)|P(x) &amp;lt; \infty$$&lt;br&gt;积分也是类似。&lt;br&gt;只有满足这个条件，即级数收敛的条件，我们才说此随机变量的期望E存在。&lt;/p&gt;
&lt;p&gt;一般来说，数学期望其实是由随机变量的分布决定的，所以我们一般可以说某某分布的期望。&lt;/p&gt;
&lt;p&gt;期望E满足几个性质：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;若干个随机变量的期望之和等于各变量的期望之和&lt;br&gt;若干个独立随机变量之积的期望等于各变量的期望之积&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;方差衡量随机变量偏离均值的程度，即随机变量函数值呈现的差异大小。&lt;br&gt;$$&lt;br&gt;Var(X) = \mathbb{E}[(X-\mathbb{E}[X])^2]&lt;br&gt;$$&lt;br&gt;当方差很小时，X的值形成的簇比较接近他们的期望值。&lt;/p&gt;
&lt;p&gt;协方差给出的是两个变量线性相关性的一个度量。&lt;br&gt;$$&lt;br&gt;Cov(X,Y) = \mathbb{E}[(X-EX)(Y-EY)]&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;协方差的绝对值 $|Cov(X,Y)|$ 如果很大，说明变量值变化很大，并且他们同时距离各自的均值很远。&lt;br&gt;如果协方差是正的，那么两个变量都倾向于同时取得较大的值。&lt;br&gt;如果协方差是负的，那么两个变量倾向于在某一个取大值的时候，另一个取小值。&lt;/p&gt;
&lt;p&gt;随机向量${\bf{x}} \in \mathbb{R}^n$的协方差矩阵是一个$\mathbb{R}^{n \times n}$，并且满足&lt;br&gt;$$&lt;br&gt;Cov({\bf{x}})_{i,j} = Cov(x_i, x_j)&lt;br&gt;$$&lt;br&gt;协方差矩阵对角元是方差$Var(x_i)=Cov(x_i,x_i)$&lt;/p&gt;
&lt;h3 id=&quot;常用概率分布&quot;&gt;&lt;a href=&quot;#常用概率分布&quot; class=&quot;headerlink&quot; title=&quot;常用概率分布&quot;&gt;&lt;/a&gt;常用概率分布&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;贝努利分布&lt;/li&gt;
&lt;li&gt;多贝努利分布/多类分布&lt;/li&gt;
&lt;li&gt;高斯分布&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;高斯分布&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_gauss.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;多元高斯分布&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_multi_gauss.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指数分布&lt;/li&gt;
&lt;li&gt;拉普拉斯分布&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_laplace.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;狄拉克分布(Dirac)与经验分布&lt;/li&gt;
&lt;li&gt;混合分布&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;一些有用的性质和通用函数&quot;&gt;&lt;a href=&quot;#一些有用的性质和通用函数&quot; class=&quot;headerlink&quot; title=&quot;一些有用的性质和通用函数&quot;&gt;&lt;/a&gt;一些有用的性质和通用函数&lt;/h3&gt;&lt;p&gt;深度模型常用两个函数：&lt;/p&gt;
&lt;p&gt;Sigmoid函数：&lt;br&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_sigmoid.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;图像如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_sigmoid_graph.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Softplus函数：&lt;br&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_softplus.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;图像如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_softplus_graph.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;关于这两个函数需要记住的一些性质：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_remember01.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;center&gt; &lt;img src=&quot;http://image-whatbegblog.oss-cn-shanghai.aliyuncs.com/images/dlbook_02_remember02.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h3 id=&quot;贝叶斯规则&quot;&gt;&lt;a href=&quot;#贝叶斯规则&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯规则&quot;&gt;&lt;/a&gt;贝叶斯规则&lt;/h3&gt;&lt;p&gt;贝叶斯规则&lt;br&gt;也称为贝叶斯后验概率。&lt;br&gt;当我们知道$P(x)$和$P(y | x)$的信息的时候，我们如何知道$P(x | y)$呢？&lt;br&gt;比如说，我们知道糖尿病人发病率$P(x)$和糖尿病人以前喜欢吃甜食的概率$P(y|x)$，那么如何估算喜欢吃甜食的人将来患糖尿病的概率呢？&lt;br&gt;Reverend Thomas Bayes发明了贝叶斯公式，现在一般写成：&lt;br&gt;$$&lt;br&gt;P(x | y) = \frac {P(x)P(y | x)} {P(y)}&lt;br&gt;$$&lt;br&gt;$P(y)$如果不知道的话，可以以$P(y)=\sum_x P(y|x)P(x)$计算。&lt;/p&gt;
&lt;h2 id=&quot;信息论&quot;&gt;&lt;a href=&quot;#信息论&quot; class=&quot;headerlink&quot; title=&quot;信息论&quot;&gt;&lt;/a&gt;信息论&lt;/h2&gt;&lt;p&gt;信息论是应用数学的一个分支，主要研究对一个信号能够提供信息的多少。&lt;/p&gt;
&lt;p&gt;信息论的基本思想是，一个不太可能的事件发生比非常可能的事件发生，能提供更多的信息。&lt;/p&gt;
&lt;p&gt;量化信息的三个性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非常可能的事件信息量比较少，更不可能发生的事件具有更高的信息量&lt;/li&gt;
&lt;li&gt;独立事件应具有增量的信息。比如投两次硬币正面向上的信息，应该是投掷一次正面朝上的信息量的2倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;香农熵用来对整个概率分布中的不确定性总量进行量化。&lt;br&gt;$$&lt;br&gt;H(x) = \mathbb{E}_{x - P}[I(x)] = -\mathbb{E}_{x - P}[\log P(x)]&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;KL散度&lt;/p&gt;
&lt;p&gt;如果我们对于同一随机变量$\mathbb{x}$有两个单独的概率分布$P(x)$和$Q(x)$，我们使用KL散度(Kullback-Leibler divergence)来衡量分布的差异。&lt;br&gt;$$&lt;br&gt;D_{KL}(P||Q) = \mathbb{E}_{x - P}[\log {\frac {P(x)} {Q(x)}}] = \mathbb{E}_{x - P}[\log P(x) - \log Q(x)]&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;KL散度非负。在离散型变量情况下，KL散度为0当且仅当P,Q为相同分布。在连续型变量情况下，KL散度为0当且仅当P,Q“几乎处处相同”。&lt;br&gt;但KL散度不是真的距离因为它不是对称的，对于某两个分布P,Q，$D_{KL}(P||Q) \neq D_{KL}(Q||P)$。&lt;/p&gt;
&lt;p&gt;交叉熵$H(P,Q) = H(P) + D_{KL}(P||Q)$，也可以描述两个分布的差异。&lt;br&gt;$$&lt;br&gt;H(P,Q) = -\mathbb{E}_{x - P} {\log Q(x)}&lt;br&gt;$$&lt;/p&gt;
&lt;h2 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h2&gt;&lt;p&gt;深度学习需要掌握的数学基础主要包括线性代数，概率论，其他的包括微积分也是必不可少的，信息论则是计算机科学的基础之一。&lt;/p&gt;
&lt;h2 id=&quot;References&quot;&gt;&lt;a href=&quot;#References&quot; class=&quot;headerlink&quot; title=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://ogbh7uglm.bkt.clouddn.com/MatrixCookBook.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Matrix Cook Book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ogbh7uglm.bkt.clouddn.com/DeepLearningBook.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Deep Learning book&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;深度学习需要的数学基础同机器学习所需的数学基础类似，包括三大块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线性代数&lt;/li&gt;
&lt;li&gt;概率论与数理统计&lt;/li&gt;
&lt;li&gt;信息论基础&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分三部分摘要如下，&lt;/p&gt;
&lt;h2 id=&quot;线性代数&quot;&gt;&lt;a href=&quot;#线
    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://whatbeg.com/tags/Deep-Learning/"/>
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>三国大事年表</title>
    <link href="http://whatbeg.com/2017/08/01/threekingdomlist.html"/>
    <id>http://whatbeg.com/2017/08/01/threekingdomlist.html</id>
    <published>2017-08-01T07:03:57.000Z</published>
    <updated>2017-08-01T07:20:55.724Z</updated>
    
    <content type="html">&lt;style&gt;
table th:first-of-type {
    width: 100px;
}
&lt;/style&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;公元年份&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;朝代年号&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;大事记&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;184&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;2月  黄巾起义。玄德年二十八岁，刘关张桃园三结义。10月，张角病死。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;185&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;186&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;187&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操任东郡太守。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;188&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;189&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;中平六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;9月　董卓废少帝刘辩为弘农王，立九岁的陈留王刘协为帝，是为献帝。 　12月　曹操号召各镇诸侯共起讨伐董卓。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;190&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;初平元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1月　各路诸侯起兵反董卓。董卓令李儒毒死弘农王(少帝) 卒年15岁。 2月　董卓焚洛阳，迁都长安，洛阳古都残破。公孙度自立为辽东侯。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;191&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;初平二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;孙坚破董卓，斩华雄。袁绍夺州牧韩馥的冀州，自领州牧。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;192&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;初平三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;4月　王允设连环计，吕布杀死董卓。6月　李傕、郭汜围长安，杀王允，败吕布。曹操击败青州黄巾军，收编为“青州兵”，实力得以壮大。孙坚攻击刘表，战死。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;193&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;初平四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操东征徐州，大败陶谦。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;194&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;兴平元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;吕布攻击曹操。陶谦病亡，刘备领徐州牧。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;195&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;兴平二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;10月 曹操领兖州牧。孙策攻打江东大败刘繇。李傕、郭汜争夺献帝。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;196&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7月　献帝在杨奉等人护送下，回长安。吕布占徐州，刘备投曹操。曹操始兴屯田，将献帝劫持到许。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;197&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;袁术在寿春称帝。曹操讨伐张绣，失败。袁绍占领冀、幽、青、并四州。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;198&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;9月　吕布攻打刘备，破小沛。12月　曹操擒杀吕布。周瑜同小乔成亲。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;199&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;11月 张绣投降曹操。董承与王子服等密谋除曹操。孙策袭取庐江，败刘勋。刘备讨伐袁术，袁术病死。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;200&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操诛杀董承一伙。孙策遇刺身亡，孙权继位。陈琳撰写讨曹檄文，官渡之战开始。10月 曹操偷袭乌巢。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;201&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操败袁绍于仓亭。刘备投奔刘表。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;202&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安七年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;5月　袁绍病死。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;203&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安八年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;孙权讨伐黄祖。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;204&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安九年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操平定冀州。辽东公孙度死，子公孙康继位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;205&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操平定青州。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;206&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十一年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操平定并州。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;207&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;8月　曹操大破乌桓，消灭袁氏残余势力，统一了北方。刘备三顾茅庐请出诸葛亮。曹操从南匈奴赎回蔡文姬。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;208&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;6月　曹操封为汉丞相。7月　曹操南征刘表。8月　刘表病死。曹操杀孔融。9月　刘琮投降曹操。11月　赤壁之战，曹操被孙刘联军打败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;209&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;10月 刘备与孙权之妹成亲。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;210&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操建成铜雀台。周瑜亡。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;211&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操攻破马超。刘备入川。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;212&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十七年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;10月 曹操南下进攻濡须口。刘备驻扎霞萌关。孙权移治秣陵，改名建业。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;213&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十八年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;5月　汉献帝封曹操为魏公，加九锡。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;214&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安十九年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;5月　孙权攻破宛城。7月　孙权进攻合肥，被张辽击败。10月　献帝、伏后与国丈伏完密谋除曹操，事泄，曹操诛杀众人。刘璋投降刘备，刘备自领益州牧。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;215&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7月　曹操征张鲁。11月　张鲁降曹操。逍遙津之战。曹操在濡须打败孙权&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;216&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十一年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹操称魏王。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;217&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;2月　曹操进攻濡须口，孙权败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;218&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹彰大破乌桓军，鲜卑部落投降，北方平定。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;219&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7月　刘备进位汉中王。关羽水淹七军。 10月　关羽失荆州，被孙权杀害。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;220&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;建安二十五年 （魏黄初元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1月　曹操病亡。10月　&lt;strong&gt;曹丕称帝&lt;/strong&gt;，建魏国，改黄初元年。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;221&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初二年，蜀章武元年，&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;4月　&lt;strong&gt;刘备称帝&lt;/strong&gt;。刘备伐吴。张飞遇害。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;222&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初三年，吴黄武元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;孙权称吴王。彝陵之战，陆逊火烧连营，大败刘备。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;223&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初四年，蜀建兴元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;4月　刘备死于白帝城，刘禅继帝位。8月　曹丕五路伐蜀。蜀吴重修和好。雍闿叛乱。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;224&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;225&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛亮南征。诸葛亮七擒七纵孟获，平定蜀国南方。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;226&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏黄初七年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹丕病亡，曹睿继位。12月　曹睿封司马懿为骠骑大将军。孙权围攻江夏，兵败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;227&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛亮上书北伐。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;228&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛亮第一次北伐。姜维降蜀。马谡失街亭。周鲂诈降诱曹魏攻吴，陆逊大败曹休。诸葛亮第二次北伐。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;229&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和三年，吴黄龙元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;strong&gt;孙权称帝&lt;/strong&gt;。诸葛亮第三次北伐。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;230&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;吴派卫温、诸葛直航海到夷洲。诸葛亮第四次北伐。曹真病亡。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;231&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛亮第五次北伐。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;232&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和六年，吴嘉禾元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;233&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏太和七年 （魏青龙元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;234&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏青龙二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛亮六出祁山。8月　诸葛亮病逝于五丈原。吴大举攻魏合肥。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;235&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏青龙三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1月　曹睿封司马懿为太傅。马钧制造司南车和水转百戏。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;236&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏青龙四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;237&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏青龙五年 （魏景初元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;辽东公孙渊自立为燕王。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;238&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景初二年，蜀延熙元年，吴赤乌元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马懿平辽东，杀公孙渊。日本邪马台女王卑弥呼派使者到魏，魏封卑弥呼为“亲魏倭王”。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;239&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景初三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1月　曹睿亡，曹芳继位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;240&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;蜀将张嶷平定蛮族之乱。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;241&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏国在淮河兴修水利。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;242&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;孙权派军攻打海南岛。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;243&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;244&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;曹爽派兵攻打蜀汉不利，伤亡惨重。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;245&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;吴太子孙和与鲁王孙霸争权，陆逊因受牵连，忧愤而死。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;246&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始七年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;毌丘俭两度攻破高句丽。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;247&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始八年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;蜀姜维出陇右攻魏，接应附蜀的羌、胡部落。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;248&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始九年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马懿封为丞相。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;249&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正始十年 （魏嘉平元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1月　司马懿杀曹爽一伙。夏侯霸降蜀。姜维伐魏。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;250&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏嘉平二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;孙权废太子孙和为庶人，赐鲁王孙霸死，立孙亮为太子。姜维攻魏西平失败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;251&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏嘉平三年，吴太元元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏国太尉王凌阴谋叛变，被司马懿平定。7月　司马懿亡。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;252&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏嘉平四年，吴神凤元年（吴建兴元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马懿长子司马师为大将军。孙权亡，孙亮继位。司马昭攻吴，失败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;253&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏嘉平五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;诸葛恪进攻魏国，无功而返。姜维攻魏狄道失败。吴孙峻诛杀诸葛恪。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;254&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏嘉平六年 （魏正元元年），吴五凤元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;9月　司马师废曹芳。10月　曹髦继位。吴孙英谋杀孙峻未果。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;255&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正元二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;镇东将军毌丘俭与扬州刺史文钦讨伐司马师。司马师亡。司马昭为大将军。姜维攻魏狄道，先胜后败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;256&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏正元三年 （魏甘露元年），吴太平元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;4月　司马昭讨伐诸葛诞。姜维伐魏被邓艾击败。吴孙峻死，弟孙琳专吴政。孙綝杀死滕胤等人。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;257&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏甘露二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏诸葛诞与孙吴联合起兵反魏。姜维出骆谷攻魏失败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;258&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏甘露三年，蜀景耀元年，吴永安元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏军攻破寿春，斩诸葛诞。孙綝废吴帝孙亮为会稽王，立琅琊王孙休为帝。孙休与丁奉设计杀死孙綝。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;259&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏甘露四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;260&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏甘露五年 （魏景元元年）&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;5月　贾充、成济杀死曹髦。6月　曹奂继位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;261&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景元二年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;262&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景元三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;10月 姜维攻魏，被邓艾击败，退屯沓中。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;263&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景元四年，蜀炎兴元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马昭三路伐蜀，&lt;strong&gt;蜀亡&lt;/strong&gt;。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;264&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏景元五年 （咸熙元年），吴元兴元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;钟会和姜维密谋失败被杀。司马昭称晋王。孙休亡，孙皓继位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;265&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;魏咸熙二年 （晋泰始元年），吴甘露元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马昭亡，其子司马炎继任晋王。12月 司马炎废曹奂为陈留王，自称晋武帝，建立西晋，&lt;strong&gt;魏亡&lt;/strong&gt;。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;266&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始二年，吴宝鼎元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;267&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始三年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;268&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;269&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始五年，吴建衡元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;270&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;271&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始七年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;吴孙皓出兵攻晋，因士兵怨恨而止。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;272&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始八年，吴凤凰元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;司马炎派杨肇、羊祜等率军支持战略要地西陵。陆抗大败杨肇，杀步阐。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;273&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始九年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;274&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋泰始十年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;275&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁元年，吴天册元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;276&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁二年，吴天玺元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;277&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁三年，吴天纪元年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋文鸯击破鲜卑族。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;278&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁四年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;羊祜死、杜预驻扎襄阳。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;279&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁五年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;西晋出动六路兵马攻打吴国。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;280&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;晋咸宁六年&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;西晋消灭吴国，吴帝孙皓投降，&lt;strong&gt;吴亡&lt;/strong&gt;。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content>
    
    <summary type="html">
    
      &lt;style&gt;
table th:first-of-type {
    width: 100px;
}
&lt;/style&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;公元年份&lt;/th&gt;
&lt;th style=&quot;text-
    
    </summary>
    
      <category term="读书 | Reading" scheme="http://whatbeg.com/categories/%E8%AF%BB%E4%B9%A6-Reading/"/>
    
    
      <category term="三国" scheme="http://whatbeg.com/tags/%E4%B8%89%E5%9B%BD/"/>
    
  </entry>
  
</feed>
