<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Whatbeg&#39;s blog</title>
  <subtitle>路漫漫其修远兮，仍将上下而求索</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://whatbeg.com/"/>
  <updated>2017-03-06T11:48:09.838Z</updated>
  <id>http://whatbeg.com/</id>
  
  <author>
    <name>whatbeg</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>用信号量解决进程的同步与互斥探讨</title>
    <link href="http://whatbeg.com/2017/03/06/semaphore.html"/>
    <id>http://whatbeg.com/2017/03/06/semaphore.html</id>
    <published>2017-03-06T11:41:49.000Z</published>
    <updated>2017-03-06T11:48:09.838Z</updated>
    
    <content type="html">&lt;p&gt;本篇也是一篇老文，发布于2015年5月，文章比较长，算老博客看的比较多的了，贴到这儿与大家分享，以求多多交流探讨。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;现代操作系统采用多道程序设计机制，多个进程可以并发执行，CPU在进程之间来回切换，共享某些资源，提高了资源的利用率，但这也使得处理并发执行的多个进程之间的冲突和相互制约关系成为了一道难题。如果对并发进程的调度不当，则可能会出现运行结果与切换时间有关的情况，令结果不可再现，影响系统的效率和正确性，严重时还会使系统直接崩溃。就比如你只有一台打印机，有两个进程都需要打印文件，如果直接让他们简单地并发访问打印机，那么你很可能什么都打印不出来或者打印的文件是…anyway，我们需要增加一些机制来控制并发进程间的这种相互制约关系。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;进程间通信的很多问题的根本原因是我们不知道进程何时切换。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;p&gt;首先我们了解一下临界资源与临界区的概念：临界资源就是一次只允许一个进程访问的资源，一个进程在使用临界资源的时候，另一个进程是无法访问的，操作系统也不能够中途剥夺正在使用者的使用权利，正所谓“泼出去的女儿嫁出去的水”是也。即临界资源是不可剥夺性资源。那么临界区呢？所谓临界区就是进程中范文临界资源的那段程序代码，注意，是程序代码，不是内存资源了，这就是临界资源与临界区的区别。我们规定临界区的使用原则（也即同步机制应遵循的准则）十六字诀：“空闲让进，忙则等待，有限等待，让权等待”–strling。让我们分别来解释一下：&lt;/p&gt;
&lt;p&gt;（1）空闲让进：临界资源空闲时一定要让进程进入，不发生“互斥礼让”行为。&lt;br&gt;（2）忙则等待：临界资源正在使用时外面的进程等待。&lt;br&gt;（3）有限等待：进程等待进入临界区的时间是有限的，不会发生“饿死”的情况。&lt;br&gt;（4）让权等待：进程等待进入临界区是应该放弃CPU的使用。&lt;/p&gt;
&lt;p&gt;好了，我们进入下一部分。&lt;/p&gt;
&lt;p&gt;进程间通常存在着两种制约关系：直接制约关系和间接制约关系，就是我们通常所说的进程的同步与互斥。顾名思义，一个是合作关系，一个是互斥关系。进程互斥说白了就是“你用的时候别人都不能用，别人用的时候，你也不能去用”，是一种源于资源共享的间接制约关系。进程同步指的是“我们大家利用一些共同的资源区，大家一起合作，完成某些事情，但是我在干某些小事的时候，可能要等到你做完另一些小事”，是一种源于相互合作的直接制约关系。两者区别在于互斥的进程间没有必然的联系，属于竞争者关系，谁竞争到资源（的使用权），谁就使用它，直到使用完才归还。就比如洗衣房的洗衣机这个资源，去洗衣的同学并不需要有必然联系，你们可以互不认识，但是谁竞争到洗衣机的使用权，就可以使用，直到洗完走人。而同步的进程间是有必然联系的，即使竞争到使用权，如果合作者没有发出必要的信息，该进程依然不能执行。就比如排队打水，即使排到你了，如果水箱没水了，你就打不了水，说明你和水箱是有着必然联系的，你得从它里面取水，你们是同步关系，你们合作完成“打水”这个过程。&lt;/p&gt;
&lt;p&gt;那么先来讨论如何实现进程的互斥控制。有下列几种方法：严格轮换（每个进程每次都从头执行到尾，效率不高，可能等待很久），屏蔽中断（刚刚进入临界区时就屏蔽中断，刚要出临界区就打开中断），专用机器指令test_and_set,test_and_clear，加锁，软件方法，信号量机制。讲一下加锁和软件方法，加锁方法如下：设置一个锁标志K表示临界资源的状态，K=1表示临界资源正在被使用，K=0表示没有进程在访问临界资源。如果一个进程需要访问临界资源，那么先检查锁标志K：&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;K&lt;/span&gt; == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, 循环检测，直到&lt;span class=&quot;keyword&quot;&gt;K&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;K&lt;/span&gt; == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;，设置锁标志为&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;，进入临界区&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;离开临界区时设置锁标志K为0. 软件方法类似，如爱斯基摩人的小屋协议，爱斯基摩人的小屋很小，每次只能容纳一个人进入，小屋内有一个黑板，上面标志这能够进入临界区的进程。若进程申请进入临界区，则先进入小屋检查黑板标志，如果是自己，那么离开小屋进入临界区，执行完后进入小屋修改黑板标志为其他进程，离开小屋。如果小屋黑板标志不是自己，那么反复进入小屋考察黑板标志是不是自己。这两种方法都实现了互斥访问，但是都违反了四条原则之一：让权等待，都需要不断的循环重复检测标志，霸占了CPU资源，不是很好的方法。&lt;/p&gt;
&lt;p&gt;到后来，荷兰计算机科学家Dijkstra于1965年提出了解决进程同步与互斥问题的信号量机制，收到了很好的效果，被一直沿用至今，广泛应用与单处理机和多处理机系统以及计算机网络中。信号量机制就是说两个或者多个进程通过他们都可以利用的一个或多个信号来实现准确无误不冲突的并发执行。如果临界资源不够，就会有一个信号表示出来，如果进程此时想访问，那么就会阻塞到一个队列中，等待调度。当临界资源使用完毕，一个进程改变信号，并及时唤醒阻塞的进程，这就实现了进程间的同步和互斥问题。&lt;/p&gt;
&lt;p&gt;信号量分为整型信号量，记录型信号量，AND信号量以及信号量集。最初的信号量就是整型信号量，定义信号量为一个整型变量，仅能通过两个原子操作P,V来访问，所谓原子操作就是指一组相联的操作要么不间断地执行，要么不执行。这两个操作又称为wait和signal操作或者down和up操作。之所以叫P,V操作是因为Dijkstra是荷兰人，P指的是荷兰语中的“proberen”，意为“测试”，而V指的是荷兰语中的“verhogen”，意为“增加”。最初P,V操作被描述为：&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;P(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;):   &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;≤&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)  &amp;#123;&lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt; nothing&amp;#125;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;=&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;V(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;):   &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;=&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;但是这样明显违反了“让权等待的原则”，后来发展为记录型信号量，记录型信号量的数据结构是一个两元组，包含信号量的值value和关于此信号量的阻塞队列Q，value具有非负初值，一般反映了资源的数量，只能由P,V操作改变其值。（还有另一种定义，信号量由value和P组成，value为信号量的值，P为指向PCB队列的指针）。&lt;/p&gt;
&lt;p&gt;记录型信号量的P,V操作原语为：&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;P(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;):   &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value = &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value &amp;lt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           block(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;Q&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;V(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;):   &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value = &lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;.value &amp;lt;= &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            wakeup(&lt;span class=&quot;keyword&quot;&gt;S&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;Q&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;我们来详细解释一下这两个操作的含义：&lt;/p&gt;
&lt;p&gt;首先，P操作，首先将S.value减1，表示该进程需要一个临界资源，如果S.value&lt;0，那么说明原来的s.value &lt;=&quot;0，即已经没有资源可用了，于是将进程阻塞到与信号量S相关的阻塞队列中去，如果S.value&lt;0,那么|S.value|其实就表示阻塞队列的长度，即等待使用资源的进程数量。然后，V操作：首先S.value加1，表示释放一个资源，如果S.value&quot; 0，阻塞队列中是由进程的，于是唤醒该队列中的一个进程。那么，为什么s.value=&quot;&quot;&gt; 0时不唤醒进程呢，很简单，因为阻塞队列中没有进程了。&lt;/0，那么说明原来的s.value&gt;&lt;/p&gt;
&lt;p&gt;P操作相当于“等待一个信号”，而V操作相当于“发送一个信号”，在实现同步过程中，V操作相当于发送一个信号说合作者已经完成了某项任务，在实现互斥过程中，V操作相当于发送一个信号说临界资源可用了。实际上，在实现互斥时，P,V操作相当于申请资源和释放资源。&lt;/p&gt;
&lt;p&gt;我们将信号量初值设置为1时通常可实现互斥，因为信号量表示资源可用数目，互斥信号量保证只有一个进程访问临界资源，相当于只有一个访问权可用。设置为0或者N时可以用来实现同步。我们后面将会在生产者-消费者问题中看到这点。用P,V操作实现互斥类似于加锁的实现，在临界区之前加P操作，在临界区之后加V操作，即可互斥控制进程进入临界区，访问临界资源。记录型信号量由于引入了阻塞机制，消除了不让权等待的情况，提高了实现的效率。&lt;/p&gt;
&lt;h2 id=&quot;经典问题&quot;&gt;&lt;a href=&quot;#经典问题&quot; class=&quot;headerlink&quot; title=&quot;经典问题&quot;&gt;&lt;/a&gt;经典问题&lt;/h2&gt;&lt;p&gt;下面通过一些实例详细讲解如何使用信号量机制解决进程同步与互斥问题。先说明一条规律，即：同步与互斥实现的P,V操作虽然都是成对出现，但是互斥的P,V操作出现在同一个进程的程序里，而同步的P,V操作出现在不同进程的程序中。&lt;/p&gt;
&lt;h3 id=&quot;问题1：生产者-消费者问题&quot;&gt;&lt;a href=&quot;#问题1：生产者-消费者问题&quot; class=&quot;headerlink&quot; title=&quot;问题1：生产者-消费者问题&quot;&gt;&lt;/a&gt;问题1：生产者-消费者问题&lt;/h3&gt;&lt;p&gt;经典的同步互斥问题，也称作“有界缓冲区问题”。具体表现为：&lt;/p&gt;
&lt;p&gt;1.两个进程对同一个内存资源进行操作，一个是生产者，一个是消费者。&lt;br&gt;2.生产者往共享内存资源填充数据，如果区域满，则等待消费者消费数据。&lt;br&gt;3.消费者从共享内存资源取数据，如果区域空，则等待生产者填充数据。&lt;br&gt;4.生产者的填充数据行为和消费者的消费数据行为不可在同一时间发生。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://images.cnitblog.com/blog2015/591194/201504/301954238803051.jpg&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;生产者-消费者之间的同步关系表现为缓冲区空，则消费者需要等待生产者往里填充数据，缓冲区满则生产者需要等待消费者消费。两者共同完成数据的转移或传送。生产者-消费者之间的互斥关系表现为生产者往缓冲区里填充数据的时候，消费者无法进行消费，需要等待生产者完成工作，反之亦然。&lt;/p&gt;
&lt;p&gt;既然了解了互斥与同步关系，那么我们就来设置信号量：&lt;/p&gt;
&lt;p&gt;由于有互斥关系，所以我们应该设置一个互斥量mutex控制两者不能同时操作缓冲区。此外，为了控制同步关系，我们设置两个信号量empty和full来表示缓冲区的空槽数目和满槽数目，即有数据的缓冲区单元的个数。mutex初值为1，empty初值为n，即缓冲区容量，代表初始没有任何数据，有n个空的单元，类似的，full初值为0.&lt;/p&gt;
&lt;p&gt;下面进行生产者-消费者行为设计：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void Productor() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//制造数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(&amp;amp;empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(&amp;amp;mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//填充数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(&amp;amp;mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(&amp;amp;full)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void Consumer() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(&amp;amp;full)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(&amp;amp;mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//消费数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(&amp;amp;mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(&amp;amp;empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样我们的分析也就完成了，&lt;a href=&quot;http://www.cnblogs.com/whatbeg/p/4419979.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/whatbeg/p/4419979.html&lt;/a&gt; 这篇文章里有我用Windows API实现的用信号量实现生产者-消费者问题。&lt;/p&gt;
&lt;p&gt;下面，问题来了，我们的生产者和消费者里面都有两个P,两个V操作，那么两个P操作可否调换顺序呢？V操作呢？想一想。&lt;/p&gt;
&lt;p&gt;答案是P操作不可对换，V操作可以。为什么呢？想象一下这种情况，生产者执行P(mutex)把互斥量锁住，然后再P(empty),此时empty &amp;lt; 0，锁住，无法继续生产，等待消费者消费，消费者倒是也想消费，可是mutex被锁住了啊，于是两个人就等啊等，就成了等待戈多了。。但是V操作是可以随意调换的，因为V操作是解锁和唤醒，不会因为它锁住什么。&lt;/p&gt;
&lt;h3 id=&quot;问题2：读者-写者问题&quot;&gt;&lt;a href=&quot;#问题2：读者-写者问题&quot; class=&quot;headerlink&quot; title=&quot;问题2：读者-写者问题&quot;&gt;&lt;/a&gt;问题2：读者-写者问题&lt;/h3&gt;&lt;p&gt;第二个经典问题是读者-写着问题，它为数据库的访问建立了一个模型。规则如下：&lt;/p&gt;
&lt;p&gt;1.一个进程在读的时候，其他进程也可以读。&lt;br&gt;2.一个进程在读/写的时候，其他进程不能进行写/读。&lt;br&gt;3.一个进程在写的时候，其他进程不能写。&lt;/p&gt;
&lt;p&gt;我们来分析他们的关系，首先，这个问题没有明显的同步关系，因为在这个问题里，读和写并不要合作完成某些事情。但是是有互斥关系的，写者和写者，写者和读者是有互斥关系的，我们需要设置一个mutex来控制其访问，但是单纯一个信号量的话会出现读者和读者的互斥也出现了，因为我们可能有多个读者，所以我们设置一个变量ReadCount表示读者的数量，好，这个时候，对于ReadCount又要实现多个读者对他的互斥访问，所以还要设置一个RC_mutex。这样就好了。然后是行为设计：&lt;br&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void Reader&lt;span class=&quot;comment&quot;&gt;()&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(&amp;amp;RC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        rc = rc + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(rc == 1)&lt;/span&gt; P&lt;span class=&quot;comment&quot;&gt;(&amp;amp;mutex)&lt;/span&gt;;  &lt;span class=&quot;comment&quot;&gt;//如果是第一个读者，那么限制写者的访问&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(&amp;amp;RC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//读数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(&amp;amp;RC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        rc = rc - &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(rc == 0)&lt;/span&gt; V&lt;span class=&quot;comment&quot;&gt;(&amp;amp;mutex)&lt;/span&gt;;  &lt;span class=&quot;comment&quot;&gt;//如果是最后一个读者，那么释放以供写者或读者访问&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(&amp;amp;RC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void Writer&lt;span class=&quot;comment&quot;&gt;()&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(&amp;amp;mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//写数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(&amp;amp;mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其实，这个方法是有一定问题的，只要趁前面的读者还没读完的时候新一个读者进来，这样一直保持，那么写者会一直得不到机会，导致饿死。有一种解决方法就是在一个写者到达时，如果后面还有新的读者进来，那么先挂起那些读者，先执行写者，但是这样的话并发度和效率又会降到很低。有人提出了一种写者优先的解法，有点不好理解，这里给出实现：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//写者优先的读者-写者问题解法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore x = y = z = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;    //x控制ReadCount的互斥访问，y控制WriteCount的互斥访问&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore rsem = wsem = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;  //rsem,wsem分别表示对读和写的互斥控制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; ReadCount = WriteCount = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void Reader() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(z)&lt;span class=&quot;comment&quot;&gt;;                       //z保证写跳过读，做到写优先&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(rsem)&lt;span class=&quot;comment&quot;&gt;;                    //控制对读的访问，如果有写者，那么此处不成功&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(x)&lt;span class=&quot;comment&quot;&gt;;                       //对RC的互斥控制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ReadCount++&lt;span class=&quot;comment&quot;&gt;;                &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(ReadCount == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) P(wsem)&lt;span class=&quot;comment&quot;&gt;; //第一个读者出现后，锁住不让写&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(x)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(rsem)&lt;span class=&quot;comment&quot;&gt;;                    //释放读的访问，以使其他读者进入&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(z)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;//读数据...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(x)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ReadCount--&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(ReadCount == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) V(wsem)&lt;span class=&quot;comment&quot;&gt;; //如果是最后一个读者，释放对写的信号&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(x)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void Writer() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(y)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    WriteCount++&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(WriteCount == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) P(rsem)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(y)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(wsem)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;//写数据...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(wsem)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(y)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    WriteCount--&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(WriteCount == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) V(rsem)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(y)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;问题3：哲学家就餐问题&quot;&gt;&lt;a href=&quot;#问题3：哲学家就餐问题&quot; class=&quot;headerlink&quot; title=&quot;问题3：哲学家就餐问题&quot;&gt;&lt;/a&gt;问题3：哲学家就餐问题&lt;/h3&gt;&lt;p&gt;哲学家就餐问题描述如下：&lt;/p&gt;
&lt;p&gt;有五个哲学家，他们的生活方式是交替地进行思考和进餐，哲学家们共用一张圆桌，分别坐在周围的五张椅子上，在圆桌上有五个碗和五支筷子，平时哲学家进行思考，饥饿时便试图取其左、右最靠近他的筷子，只有在他拿到两支筷子时才能进餐，进餐完毕，放下筷子又继续思考。&lt;/p&gt;
&lt;p&gt;约束条件&lt;br&gt;(1)只有拿到两只筷子时，哲学家才能吃饭。&lt;br&gt;(2)如果筷子已被别人拿走，则必须等别人吃完之后才能拿到筷子。&lt;br&gt;(3)任一哲学家在自己未拿到两只筷子吃饭前，不会放下手中拿到的筷子。&lt;br&gt;(4)用完之后将筷子返回原处&lt;/p&gt;
&lt;p&gt;分析：筷子是临界资源，每次只被一个哲学家拿到，这是互斥关系。如果筷子被拿走，那么需要等待，这是同步关系。&lt;/p&gt;
&lt;p&gt;容易想到一种错误的解法，所以设置一个信号量表示一只筷子，有5只筷子，所以设置5个信号量，哲学家每次饥饿时先试图拿左边的筷子，再试图拿右边的筷子，拿不到则等待，拿到了就进餐，最后逐个放下筷子。这种情况可能会产生死锁，因为我们不知道进程何时切换（这也是很多IPC问题的根本原因），如果5个哲学家同时饥饿，同时试图拿起左边的筷子，也很幸运地都拿到了，那么他们拿右边的筷子的时候都会拿不到，而根据第三个约束条件，都不会放下筷子，这就产生了死锁。《现代操作系统》中记载的一种解法是仅当一个哲学家左右的筷子都可用时，才拿起筷子，将“试图获取两个筷子”作为临界资源，用一个互斥量mutex实现对其的互斥控制，然后用n个变量记录哲学家的状态（饥饿，进餐，思考&amp;lt;可有可无，因为除了前两者以外只会思考&amp;gt;），然后用一个同步信号量数组，每个信号量对应一个哲学家，来保证哲学家得不到自己所需筷子的时候阻塞。算法如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://images.cnitblog.com/blog2015/591194/201504/302312154437620.jpg&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;还有一种解法是让奇数号与偶数号的哲学家拿筷子的先后顺序不同，以破坏环路等待条件。还可以只允许4个哲学家同时进餐（4个人都拿起一只筷子的时候，第5个人不能再拿筷子，这样就会空出一只筷子）&lt;/p&gt;
&lt;h2 id=&quot;例子分析&quot;&gt;&lt;a href=&quot;#例子分析&quot; class=&quot;headerlink&quot; title=&quot;例子分析&quot;&gt;&lt;/a&gt;例子分析&lt;/h2&gt;&lt;p&gt;至此，我们已经可以总结出一点用信号量解决同步互斥问题的基本规律和一般步骤：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）分析各进程间的制约关系，从而得出同步与互斥关系&lt;br&gt;（2）根据（1）中的分析，设置信号量&lt;br&gt;（3）编写伪代码，实施P,V操作&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同步：多个进程在执行次序上的协调，相互等待消息&lt;br&gt;互斥：对临界资源的使用&lt;/p&gt;
&lt;p&gt;要注意的是，&lt;strong&gt;虽然P,V操作在每一个进程中都是成对出现的，但不一定是针对一个信号量。互斥信号量的P,V操作总是出现在一个进程中的临界区的前后，而同步信号量的P,V操作总是出现在具有同步关系的两个进程中，需要等待消息的一方执行P操作，发出消息的一方执行V操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面通过诸多例题来熟悉，掌握及训练用信号量解决同步与互斥问题的一般方法。&lt;/p&gt;
&lt;h3 id=&quot;问题4：放水果问题&quot;&gt;&lt;a href=&quot;#问题4：放水果问题&quot; class=&quot;headerlink&quot; title=&quot;问题4：放水果问题&quot;&gt;&lt;/a&gt;问题4：放水果问题&lt;/h3&gt;&lt;p&gt;桌上有一空盘，最多允许存放一只水果。爸爸可向盘中放一个苹果，妈妈可向盘中放一个桔子。&lt;br&gt;儿子专等吃盘中的桔子，女儿专等吃苹果。&lt;br&gt;试用P、V操作实现爸爸、妈妈、儿子、女儿四个并发进程的同步。&lt;/p&gt;
&lt;p&gt;分析：临界资源是盘子，放的时候不能取，取的时候不能放，取的时候不能再取。同步关系：爸爸、妈妈与盘子为空，儿子与盘中有桔，女儿与盘中有苹果。&lt;/p&gt;
&lt;p&gt;所以设置一个mutex互斥信号量来控制对盘子的访问，用empty，orange，apple分别代表以上同步关系。程序如下：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Semaphore mutex = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore empty = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, orange = apple = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mother:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//放入桔子&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(orange)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;father:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//放入苹果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(apple)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;son:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(orange)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(mutex)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//取桔子&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;daughter:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(apple)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(mutex)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//取苹果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(empty)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;问题5：读文件问题&quot;&gt;&lt;a href=&quot;#问题5：读文件问题&quot; class=&quot;headerlink&quot; title=&quot;问题5：读文件问题&quot;&gt;&lt;/a&gt;问题5：读文件问题&lt;/h3&gt;&lt;p&gt;四个进程A、B、C、D都要读一个共享文件F，系统允许多个进程同时读文件F。但限制是进程A和进程C不能同时读文件F，进程B和进程D也不能同时读文件F。为了使这四个进程并发执行时能按系统要求使用文件，现用P、V操作进行管理。&lt;/p&gt;
&lt;p&gt;分析：互斥关系：A和C读文件时互斥，B和D读文件时互斥，没有同步关系。&lt;/p&gt;
&lt;p&gt;所以设置两个互斥信号量：AC_mutex,BD_mutex即可。伪代码如下：&lt;br&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Semaphore AC_mutex = BD_mutex = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;A:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(AC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//read F&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(AC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;B:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(BD_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//read F&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(BD_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;C:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(AC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//read F&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(AC_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;D:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(1)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P&lt;span class=&quot;comment&quot;&gt;(BD_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//read F&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V&lt;span class=&quot;comment&quot;&gt;(BD_mutex)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;问题6：阅览室问题-图书馆问题&quot;&gt;&lt;a href=&quot;#问题6：阅览室问题-图书馆问题&quot; class=&quot;headerlink&quot; title=&quot;问题6：阅览室问题 / 图书馆问题&quot;&gt;&lt;/a&gt;问题6：阅览室问题 / 图书馆问题&lt;/h3&gt;&lt;p&gt;有一阅览室，读者进入时必须先在一张登记表上进行登记，该表为每一座位列一表目，包括座号和读者姓名。读者离开时要消掉登记信号&lt;br&gt;，阅览室中共有100个座位。用PV操作控制这个过程。&lt;/p&gt;
&lt;p&gt;分析：&lt;/p&gt;
&lt;p&gt;由于每个读者都会进行一样的操作：登记-&amp;gt;进入-&amp;gt;阅读-&amp;gt;撤销登记-&amp;gt;离开，所以建立一个读者模型即可。&lt;br&gt;临界资源有：座位，登记表&lt;br&gt;读者间有座位和登记表的互斥关系，所以设信号量empty表示空座位的数量，初始为100，mutex表示对登记表的互斥访问，初始为1。&lt;/p&gt;
&lt;p&gt;P,V操作如下：&lt;br&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Semaphore mutex = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, empty = &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Reader&lt;span class=&quot;comment&quot;&gt;()&lt;/span&gt;：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;While&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;(true)&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P&lt;span class=&quot;comment&quot;&gt;(empty)&lt;/span&gt;           &lt;span class=&quot;comment&quot;&gt;//申请空座位&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P&lt;span class=&quot;comment&quot;&gt;(mutex)&lt;/span&gt;           &lt;span class=&quot;comment&quot;&gt;//申请登记表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;//登记  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V&lt;span class=&quot;comment&quot;&gt;(mutex)&lt;/span&gt;           &lt;span class=&quot;comment&quot;&gt;//释放登记表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;//进入阅读&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P&lt;span class=&quot;comment&quot;&gt;(mutex)&lt;/span&gt;            &lt;span class=&quot;comment&quot;&gt;//申请登记表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;//撤销登记&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V&lt;span class=&quot;comment&quot;&gt;(mutex)&lt;/span&gt;            &lt;span class=&quot;comment&quot;&gt;//释放登记表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V&lt;span class=&quot;comment&quot;&gt;(empty)&lt;/span&gt;            &lt;span class=&quot;comment&quot;&gt;//释放座位&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;问题7：单行道问题&quot;&gt;&lt;a href=&quot;#问题7：单行道问题&quot; class=&quot;headerlink&quot; title=&quot;问题7：单行道问题&quot;&gt;&lt;/a&gt;问题7：单行道问题&lt;/h3&gt;&lt;p&gt;一段双向行驶的公路，由于山体滑坡，一小段路的一般车道被阻隔，该段每次只能容纳一辆车通过，一个方向的多个车辆可以紧接着通过，试用P,V操作控制此过程。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://images.cnitblog.com/blog2015/591194/201505/010058320368735.jpg&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;分析：&lt;br&gt;临界资源为一半被阻隔的一小段区域，所以需要Go_mutex,Come_mutex来控制每个方向车辆通过该路段，以及实现两个方向的同步关系，同步关系即为：当某方向已有车辆在通行时，另一方向的车辆必须等待，反之亦然。类似于读者-写者问题，车辆从两边通过相当于两个读者，我们设立两个计数器A和B分别代表两个方向的汽车数量，还要设置两个信号量A_mutex和B_mutex来实现对计数器的互斥访问，因为山体滑坡处只允许一辆车通过，所以还需设置一个互斥量mutex保证相同方向的车辆依次通过该处。&lt;/p&gt;
&lt;p&gt;于是程序如下（PV操作包含其中）：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;115&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &amp;lt;Windows.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;define&lt;/span&gt; N &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;define&lt;/span&gt; TRUE &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;typedef &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; Semaphore&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore A = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, B = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;HANDLE Go_mutex,Come_mutex&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;HANDLE A_mutex,B_mutex&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;HANDLE mutex&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void down(HANDLE handle) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    WaitForSingleObject(handle, INFINITE)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void up(HANDLE handle) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ReleaseSemaphore(handle, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DWORD WINAPI Come(LPVOID v) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(TRUE) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(Come_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(A_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        A = A+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(A == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            down(Go_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printf(&lt;span class=&quot;string&quot;&gt;&quot;                    &amp;lt;&amp;lt;&amp;lt;=====开始自东向西\n&quot;&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(A_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(Come_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//自东向西通过该路段&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        printf(&lt;span class=&quot;string&quot;&gt;&quot;                    &amp;lt;&amp;lt;&amp;lt;=====第%s辆车\n&quot;&lt;/span&gt;,(char *)v)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        printf(&lt;span class=&quot;string&quot;&gt;&quot;         END        &amp;lt;&amp;lt;&amp;lt;=====第%s辆车\n&quot;&lt;/span&gt;,(char *)v)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(A_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        A = A&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(A == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            up(Go_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printf(&lt;span class=&quot;string&quot;&gt;&quot;                    自东向西的所有车辆行驶完毕\n&quot;&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(A_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Sleep(&lt;span class=&quot;number&quot;&gt;2000&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DWORD WINAPI Go(LPVOID v) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(TRUE) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(Go_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(B_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        B = B+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(B == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            down(Come_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printf(&lt;span class=&quot;string&quot;&gt;&quot;开始自西向东====&amp;gt;\n&quot;&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(B_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(Go_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;//自西向东通过该路段&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        printf(&lt;span class=&quot;string&quot;&gt;&quot;第%s辆车=====&amp;gt;&amp;gt;&amp;gt;\n&quot;&lt;/span&gt;,(char *)v)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        printf(&lt;span class=&quot;string&quot;&gt;&quot;第%s辆车=====&amp;gt;&amp;gt;&amp;gt;     END\n&quot;&lt;/span&gt;,(char *)v)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        down(B_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        B = B&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(B == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            up(Come_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printf(&lt;span class=&quot;string&quot;&gt;&quot;自西向东的所有车辆行驶完毕\n&quot;&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        up(B_mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Sleep(&lt;span class=&quot;number&quot;&gt;2000&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; main()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    DWORD Tid&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    char AThread[&lt;span class=&quot;number&quot;&gt;12&lt;/span&gt;][&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;]&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    char BThread[&lt;span class=&quot;number&quot;&gt;12&lt;/span&gt;][&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;]&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    mutex      = CreateSemaphore(NULL, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    A_mutex    = CreateSemaphore(NULL, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    B_mutex    = CreateSemaphore(NULL, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Go_mutex   = CreateSemaphore(NULL, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Come_mutex = CreateSemaphore(NULL, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, NULL)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;i&amp;lt;4;i++) &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        AThread[i][&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;] = i+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;+&lt;span class=&quot;string&quot;&gt;&#39;0&#39;&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        AThread[i][&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;] = &lt;span class=&quot;string&quot;&gt;&#39;\0&#39;&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        CreateThread(NULL,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,Come,AThread[i],&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&amp;amp;Tid)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;i&amp;lt;8;i++) &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        BThread[i][&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;] = i+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;+&lt;span class=&quot;string&quot;&gt;&#39;0&#39;&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        BThread[i][&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;] = &lt;span class=&quot;string&quot;&gt;&#39;\0&#39;&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        CreateThread(NULL,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,Go,BThread[i],&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&amp;amp;Tid)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Sleep(&lt;span class=&quot;number&quot;&gt;20000&lt;/span&gt;)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://images0.cnblogs.com/blog2015/591194/201505/241529590481971.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;从其中可以看出，车辆正常交替顺序通过该路段。数字重复出现是因为线程被重复地调度执行。&lt;/p&gt;
&lt;h3 id=&quot;问题8：理发师问题&quot;&gt;&lt;a href=&quot;#问题8：理发师问题&quot; class=&quot;headerlink&quot; title=&quot;问题8：理发师问题&quot;&gt;&lt;/a&gt;问题8：理发师问题&lt;/h3&gt;&lt;p&gt;理发店理有一位理发师、一把理发椅和n把供等候理发的顾客坐的椅子 如果没有顾客，理发师便在理发椅上睡觉。 一个顾客到来时，它必须叫醒理发师，如果理发师正在理发时又有顾客来到，则如果有空椅子可坐，就坐下来等待，否则就离开。用PV操作管理该过程。&lt;/p&gt;
&lt;p&gt;分析：&lt;/p&gt;
&lt;p&gt;法1：首先设置一个count表示等待的人数（包括理发椅上的那个人），初值为0，以供后来者判断是否应该离开。同时对count的访问要保证互斥，所以设置mutex信号量来保证互斥，初值为1。&lt;br&gt;临界资源：凳子，理发椅。 分别设置waitchair,barchair信号量，初值分别为n和1，表示临界资源数量。&lt;br&gt;同步关系：顾客和理发师之间有同步关系，用ready和done信号量来表示，初值均为0，ready表示顾客有没有准备好，done表示理发师是否完成一次理发。&lt;br&gt;注意：&lt;strong&gt;并非每一个进程都需要while(1)无限循环，比如此例，顾客剪完一次头发就走了，不可能马上再来剪，而以前的生产者-消费者不同，他们都是可以不断生产消费的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;写出P,V操作如下：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Semaphore waitchair = n&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore barchair = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore ready = done = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; count = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore mutex = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;barber:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(ready)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        理发&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(done)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;consumer:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(count &amp;lt;= n) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        count = count + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        离开&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(waitchair)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(barchair)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(waitchair)&lt;span class=&quot;comment&quot;&gt;;   //离开等待椅去理发椅需要释放等待椅!&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(ready)&lt;span class=&quot;comment&quot;&gt;;       //准备好了&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(done)&lt;span class=&quot;comment&quot;&gt;;        //等待理发完成&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(barchair)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    count = count - &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    离开&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;法2：将凳子和理发椅看做同一种资源，因为只要理发椅空就一定会有人凑上去，所以相当于每个位置都是理发椅，理发师只需要去每个有人的座位理发即可。&lt;br&gt;还是设置count表示正在理发店中的人数，以便决定后来者是否离开。&lt;br&gt;同步关系仍用ready和done来表示。&lt;/p&gt;
&lt;p&gt;算法：&lt;br&gt;&lt;figure class=&quot;highlight mipsasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Semaphore ready = done = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int &lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Semaphore mutex = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;barber:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        P(ready)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        理发&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(done)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;consumer:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(&lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; &amp;lt;= n) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; = &lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        离开&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(ready)&lt;span class=&quot;comment&quot;&gt;;       //准备好了&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(done)&lt;span class=&quot;comment&quot;&gt;;        //等待理发完成&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P(mutex)&lt;span class=&quot;comment&quot;&gt;;      //也可由理发师来做count-1的操作&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; = &lt;span class=&quot;built_in&quot;&gt;count&lt;/span&gt; - &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    V(mutex)&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    离开&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;好了，先说这么多，例题会持续更新增加，感兴趣的朋友可以关注下。&lt;br&gt;鄙人学力有限，有不足或错误之处敬请指出，不胜感激。&lt;/p&gt;
&lt;h2 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=&quot;headerlink&quot; title=&quot;参考文献&quot;&gt;&lt;/a&gt;参考文献&lt;/h2&gt;&lt;p&gt;1.《现代操作系统》           –Andrew S. Tanenbaum&lt;br&gt;2.《操作系统设计与实现》 –Andrew S. Tanenbaum&lt;br&gt;3.《操作系统精髓与设计原理》  –Strling&lt;br&gt;4.《2015操作系统高分笔记》  –刘泱主编&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本篇也是一篇老文，发布于2015年5月，文章比较长，算老博客看的比较多的了，贴到这儿与大家分享，以求多多交流探讨。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;现代操作系
    
    </summary>
    
      <category term="计算机相关 | CS.Related" scheme="http://whatbeg.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9B%B8%E5%85%B3-CS-Related/"/>
    
    
      <category term="CS" scheme="http://whatbeg.com/tags/CS/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning读书笔记系列 写作计划</title>
    <link href="http://whatbeg.com/2017/02/27/deeplearning0.html"/>
    <id>http://whatbeg.com/2017/02/27/deeplearning0.html</id>
    <published>2017-02-27T14:48:25.000Z</published>
    <updated>2017-02-27T14:52:38.465Z</updated>
    
    <content type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前看了一些Bengio的《Deep Learning》，有许多收获和感触，但是由于缺乏回顾，反思与实践加以消化，许多东西已经忘记了，借这个契机，想写一套专门阐述自己阅读Deep Learning及Machine Learning相关资料的阅读心得或者读书笔记的文章，文章不拘深浅，不拘长短，只求能够阐述出自己的心得收获，便于加深理解，如果能够把一件事情讲明白，那就不会那么轻易地忘记了，知识在脑子里也会更加成系统，不然老是东一点西一点，拣了芝麻丢了西瓜，或是狗熊掰棒子，一路掰一路扔。&lt;br&gt;其次，实践也很重要，光看书始终是纸上谈兵，只有实实在在地利用深度学习去做一些事情，实现了某些效果，那样的感受才会更深切。总而言之，知行合一很重要。&lt;br&gt;当然，文章也不仅仅局限于对Bengio的《Deep Learning》的读书笔记，也包括相关书籍，文章，论文，也不必局限于DL这一个子领域，适当拓展到Machine Learning也是可以的。&lt;br&gt;虽然计划着，却仍有两个忧虑，一是怕没有时间，二是实在才疏学浅，写的浅不要紧，怕就怕出错，闹出笑话还误了读者朋友们，那可是要被骂惨的。但是反过来又提醒自己，“怕什么真理无穷，进一寸有进一寸的欢喜”，没时间不要紧，一点一滴慢慢做就是了，二一个实在有不妥之处相比读者们也会提出来的，所以就不要脸【捂脸】的先忽略这两个问题。&lt;/p&gt;
&lt;h2 id=&quot;写作计划&quot;&gt;&lt;a href=&quot;#写作计划&quot; class=&quot;headerlink&quot; title=&quot;写作计划&quot;&gt;&lt;/a&gt;写作计划&lt;/h2&gt;&lt;p&gt;写作计划暂时包括但不限于：&lt;/p&gt;
&lt;p&gt;× Deep Learning读书笔记（1）–开篇&lt;br&gt;× Deep Learning读书笔记（2）–数学基础简摘&lt;br&gt;× Deep Learning读书笔记（3）–数值计算&lt;br&gt;× Deep Learning读书笔记（4）–机器学习基础&lt;br&gt;× Deep Learning读书笔记（5）–关于机器学习的提纲（或机器学习总论）&lt;br&gt;× Deep Learning读书笔记（6）–神经网络&lt;br&gt;× Deep Learning读书笔记（7）–DL的优化&lt;br&gt;× Deep Learning读书笔记（8）–DL的正则化&lt;br&gt;× Deep Learning读书笔记（9）–实践方法论&lt;br&gt;× Deep Learning读书笔记（10）–DL前沿&lt;/p&gt;
&lt;p&gt;计划1年时间完成，即2018年3月1日前完成，希望能够有始有终，千万不要烂尾。。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前看了一些Bengio的《Deep Learning》，有许多收获和感触，但是由于缺乏回顾，反思与实践加以消化，许多东西已经忘记了，借这个
    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《暗时间》读书笔记</title>
    <link href="http://whatbeg.com/2017/02/20/darktime.html"/>
    <id>http://whatbeg.com/2017/02/20/darktime.html</id>
    <published>2017-02-20T07:57:39.000Z</published>
    <updated>2017-02-20T08:02:51.020Z</updated>
    
    <content type="html">&lt;p&gt;去年冬天在机缘巧合之下，开始阅读刘未鹏老师的这本《暗时间》，受益良多，得到了很多启发，觉得应该做做读书笔记，方不枉费读书的功夫。&lt;/p&gt;
&lt;p&gt;总的来说，《暗时间》是一本关于思维，学习的本质知识以及解题，如何解题等的一些想法，第一原则就是为了帮助读者提高思维能力，培养思考的习惯，从而能够充分利用我们身边的“暗时间”，在同样的生命中获得更多的收获。&lt;/p&gt;
&lt;p&gt;书中一些要点摘录如下，并做了自己的一些思考总结，以备翻看。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;说到对某件事投入时间，实际投入的是时间与效率的乘积&lt;/strong&gt;&lt;br&gt;不是说投入的绝对时间越多，收获就越多，进步就越大。即使程序员有时整天面对着电脑，但是如果心没有静下来，这里翻翻那里看看，这样的时间的效率就很低，基本上就算浪费了。所以说，专注地做1个小时事情可能比得上在那盲目地坐一下午强得多，这就是为什么有些人看似很努力，却得不到很好地效果的原因之一吧。记得有位大师说过，一个人一天只能够全神贯注的工作最多4个小时，这一天的绝大部分收获也在这4个小时，所以，并不是“显得很努力”就是最好的，与其在“无效时间”里面耗费精力做着各种“无聊”的事，倒不如对睡觉养足精神来的好。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;把要做的事情，要学习的东西，常驻脑中，利用“暗时间”（即我们做很多琐事的时间）去反刍与消化。&lt;/strong&gt;&lt;br&gt;书中指的暗时间包括吃饭，睡前，行走，上厕所等等琐碎的时间，在这段时间如果有一个问题在脑中，利用这些时间去思考这个问题，这些知识，就相当于有了比别人更加“充足”的时间，并且也增加了对该问题，该知识的深入，多角度思考，一举两得。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任务切换是有开销的，所以专注很重要。能不能做到高效学习，关键在于能不能够迅速进入专注状态以及能够保持专注状态多久。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设计自己的进度条，避免看不到尽头而产生放弃的心理。&lt;/strong&gt;&lt;br&gt;我们生活中很多事情都是三分钟热度，一个重要原因就是，我们在开始做某件事情后，发现“啥时候是个头啊”，看不到完成的希望，看不到达成目标的激励，让我们萌生放弃的想法。举个例子来说，去年我有一段很长的空闲时间，正好那时候有个很火的韩剧播出，于是我就决定去学学韩语，也坚持了一段时间，也享受过一点点进步的喜悦，看到电视剧中的很多句子居然能够听懂一些了，非常兴奋，但是当那个韩剧播完的时候，我渐渐的就提不起精神去学了，一大原因就是缺少了直接的激励，也没有什么明确地目标，或者进度条的概念，总觉得还有好多要学啊，加之别的事情又来了，于是就渐渐地扔下了。如果说真的确定要学，并且学好的话，我就可以定一个目标，比如说多久以后达到TOPIK多少级，然后定期地测试自己的学习成果，那么应该在这条路上会走的更远吧。归根结底，人类看不到激励的时候总是容易放弃，这是人的本性之一，所以说没有坚持有时候不是你自制力的问题，而是知识的问题，即你是否知道这一人类的本性，并且采取办法去抵抗这一本性，引导你的本性的问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过早退出是一切失败的根源。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兴趣遍地都是，真正稀缺的是专注和持之以恒。&lt;/strong&gt;&lt;br&gt;世界上有趣的东西很多，有好奇心的人也非常多，所有有很多兴趣是很正常的，也是很好的，这至少说明你对这个世界还抱有很多好奇心，可是只有一定的持之以恒才能真正把一份兴趣变成爱好，再加上一份专注，才能使之真正变成一份技能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;饿死在干草堆中的驴子。&lt;/strong&gt;&lt;br&gt;我们常常会进入一种焦虑状态，有时间，可以做的也很多，可是难以选择，做这个有这个的好处，做那个有那个的好处，然而两个没法兼顾，所以我们会一直纠结，然后时间过去了。。就像一只驴子，有很多干草，它却一直在纠结吃哪堆，结果饿死了。这时候唯一的方法就是通过自己的判断，迅速选择一件事，做下去再说，即使最后发现并不是你最想做的，或者说走了弯路，也不会白做，总会比在纠结焦虑中把时间消耗掉要强得多。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;记忆时，抽象出来得到范围更广的知识，来理解记忆，解决问题是，抽象出本质，便于找到解决方法。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;经常回顾所学知识，不管什么方式，最好能够抽象，推广和举一反三。&lt;/strong&gt;&lt;br&gt;常常回顾才能够逐渐融入到自己的知识结构中去，不然学完很快就忘了，就失去了这个知识的联想，遇到这方面问题时便想不起来学过的那个知识了，只有不断地捡起来，捡的多了，慢慢就内化了。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;让思考成为习惯，时刻有一个问题在脑中。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;趁着有热情，一股脑儿把开头熬过去。&lt;/strong&gt;&lt;br&gt;万事开头难，结束似乎也不容易。就算把开头熬过去，也不见得会将这件事坚持下去，但是熬过这段最难的开头，似乎对接下来的“熬”有帮助作用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重要的事情优先，无关紧要的琐事能不做就不做。&lt;/strong&gt;&lt;br&gt;节省精力，节省精力，节省精力，重说三，把精力花费在真正重要的事情上，产生更大的价值，当然，适当的娱乐和消遣也是必要。听老人们说，长寿的秘诀在于少操心。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;根据主题来查阅资料，而非反之。&lt;/strong&gt;&lt;br&gt;有两种解决问题或者学习的方式，一种是先把书过一遍，再看是否应用在这个问题上，一个问题可能关联很多知识，所以可能要看的书很多；另一种是先去做，遇到不会的才去看书，找这方面的知识帮助解决问题。第一种对于解决特定问题来说时间消耗有点大，除非是希望在这方面精通的，这时可以广泛地涉猎这方面的书籍，否则，为了解决一个问题要从基本理论学期也太慢了。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;带着问题学习。&lt;/strong&gt;&lt;br&gt;不错的学习方式，值得尝试。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有选择的阅读，而不是逐字逐句。&lt;/strong&gt;&lt;br&gt;不要做读书的强迫症，有些时候并不需要逐字逐句看完，生命宝贵。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;失败即成功，成功即失败。&lt;/strong&gt;&lt;br&gt;即使失败，却能够带来不少的信息，带来经验与教训，有利于下一次的实践。&lt;br&gt;而有时候太顺利的成功却会让我们忽略掉过程中的许多重要的点，并不是一件特别好的事。&lt;br&gt;把这个“成功”放到世俗意义上来讲，成功者在成功之后可能获得了丰厚的财富或者名誉或者权力，但是他背负的东西也更多了，责任也更多了，手脚逐渐被束缚起来，于是，许多成功者在成功之后也就逐渐变得“平庸”，所以也可以说，“成功即失败”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;从别人的错误中学习。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;客观意味着承认存在未知信息的可能性，理性意味着能够从对立面的视角去看问题和思考。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;改变即有的习惯，依靠的不是自制力，而是知识。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续学习和思考，只写你真正思考和总结之后的产物，其他的一切都会随之而来。（博客）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;困难的路越走越容易，容易的路越走越困难，遇到问题不必急着找捷径，在自己解决的过程中可能会有意想不到的收获。&lt;/strong&gt;&lt;br&gt;就像做题不会不要急着看答案，自己找找方法，多琢磨琢磨，收获可能比较大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个人核心竞争力是指自己独特的个性，背景，知识和经验的组合，如果这种组合 1)绝无仅有 2)在实践中有价值 3)具有可持续发展性，那么这就是核心竞争力。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;专业技能，跨领域技能，学习能力，性格要素（专注，持之以恒，好奇心，自省，自信，谦卑）。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“我是不是已经掌握了这个知识最深刻最本质的东西？”。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;手中有锤，心中无锤。&lt;/strong&gt;&lt;br&gt;看到问题，分析问题，再找解决问题的“锤子”（方法），而不是方法去套问题。**&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;理解本质才能做到难以忘却。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;已知-&amp;gt;可知， 结论-&amp;gt;须知， 寻找可知与须知的结合点，就能实现成功解决问题。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;去年冬天在机缘巧合之下，开始阅读刘未鹏老师的这本《暗时间》，受益良多，得到了很多启发，觉得应该做做读书笔记，方不枉费读书的功夫。&lt;/p&gt;
&lt;p&gt;总的来说，《暗时间》是一本关于思维，学习的本质知识以及解题，如何解题等的一些想法，第一原则就是为了帮助读者提高思维能力，培养思考的
    
    </summary>
    
      <category term="读书 | Reading" scheme="http://whatbeg.com/categories/%E8%AF%BB%E4%B9%A6-Reading/"/>
    
    
      <category term="读书" scheme="http://whatbeg.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>关于KMP算法的本质之思考</title>
    <link href="http://whatbeg.com/2017/02/18/kmpreview.html"/>
    <id>http://whatbeg.com/2017/02/18/kmpreview.html</id>
    <published>2017-02-18T09:47:43.000Z</published>
    <updated>2017-02-18T09:51:41.659Z</updated>
    
    <content type="html">&lt;p&gt;以前看KMP算法的时候，总是无法理解next函数以及next函数的求法以及匹配时j=next[j]的做法的直观意义。这次看《暗时间》这本书的时候谈到一个知识的本质问题，有提到KMP，于是就想着能不能够从本质的角度出发去重新理解下KMP呢？&lt;/p&gt;
&lt;p&gt;KMP的本质是什么？或者说，这个算法做了什么？以前的确从来没有问过自己这个问题。或许是习惯于在书上扫一眼KMP是干嘛的，具体怎么操作，怎么用，下次做字符串匹配时套一下模板就好了。但是现在，我要试着探寻一下KMP的内在本质。&lt;/p&gt;
&lt;p&gt;上面的问题不难回答，KMP是用来做字符串匹配的，但是，这个答案还不够完善，应该说KMP是能够在O(n+m)时间内完成字符串匹配的一个算法。后者强调了KMP的高效性，相比于朴素的字符串匹配中O(nm)的复杂度，这是一个巨大的提升。&lt;/p&gt;
&lt;p&gt;这里我不打算详述KMP算法过程，&lt;a href=&quot;http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;字符串匹配的KMP算法. 阮一峰&lt;/a&gt;这篇文章讲解得非常清楚，其实这篇文章是我认为所有的网上博文中解释最通俗易懂的。当然，我在这次的理解中配合了&lt;a href=&quot;http://blog.csdn.net/u011564456/article/details/20862555?utm_source=tuicool&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文章1&lt;/a&gt;和&lt;a href=&quot;http://blog.csdn.net/yutianzuijin/article/details/11954939/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文章2&lt;/a&gt;来完成理解。&lt;/p&gt;
&lt;p&gt;假设原串为S，长度为n，我们需要看字符串f（长度为m）是否在S中。&lt;br&gt;总的来说，当我们朴素地去进行字符串匹配时，首先将S和f对齐，从头开始匹配过去，我们是发现到哪里不匹配了，就把f右移一位再从头开始一个一个匹配，这样每次移动一位是完全正确的但是不够快，事实上，如果匹配了一些，假如f的前m-1位与S中的一段完全匹配(m-1长)，这是一个很好的消息！但最后一位不匹配，如果朴素地右移一位再重新匹配的话，前面m-1位完全匹配的喜人消息会被完全抛弃，那么为什么不利用起来呢？所以说，KMP最本质的思想就在于，&lt;strong&gt;利用已有的一些信息，来加快解空间的搜索&lt;/strong&gt;。说起来很简单，但是大道至简，简单的道理却蕴含着巨大的能量。&lt;/p&gt;
&lt;p&gt;如何利用呢？盗一张图来说，我们希望找到如图所示的结构：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/KMP1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;两块绿色的完全相等，这样的话我们移动f时就没必要一步一步移动了，可以直接像下面这样移动，&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/KMP2.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;这样大大节省了时间。而next数组就是来找出这样的结构的。&lt;br&gt;比如f串为&lt;code&gt;ABCDABD&lt;/code&gt;，它的next数组如下：&lt;br&gt;&lt;figure class=&quot;highlight dns&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;f    |  &lt;span class=&quot;keyword&quot;&gt;A&lt;/span&gt; B C D &lt;span class=&quot;keyword&quot;&gt;A&lt;/span&gt; B D&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;next | -&lt;span class=&quot;number&quot;&gt;1 0 0 0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;找出了两个对称的&lt;code&gt;AB&lt;/code&gt;，即如果匹配到最后的&lt;code&gt;D&lt;/code&gt;不匹配了，说明需要移动了，又因为&lt;code&gt;D&lt;/code&gt;之前的串有长度为2的后缀等于前缀，我们可以直接吧f的前缀移到后缀对齐的地方继续走，即&lt;br&gt;&lt;figure class=&quot;highlight autohotkey&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;移动长度=已匹配总长度-后缀的长度=已匹配长度-`D`对应的next值=&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/KMP3.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;&lt;br&gt;这也是代码中&lt;code&gt;j=next[j]&lt;/code&gt;的原因，上面那个例子中j=6，j=next[6]=2，说明下面一步就是，现在的i(i处为&lt;code&gt;C&lt;/code&gt;)和f的下标为j=2处的字符比较，即相当于右移了4位。&lt;/p&gt;
&lt;p&gt;一般的KMP核心算法包括以下两个部分：&lt;br&gt;&lt;figure class=&quot;highlight hsp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void getnext()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;next&lt;/span&gt;[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;] = &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,j = &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(i&amp;lt;m&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(j == &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt; || b[i] == b[j])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;next&lt;/span&gt;[++i] = ++j&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            j = &lt;span class=&quot;keyword&quot;&gt;next&lt;/span&gt;[j]&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; kmp()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;,j = &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(i&amp;lt;n &amp;amp;&amp;amp; j&amp;lt;m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(j == &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt; || a[i] == b[j])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            i++,j++&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            j = &lt;span class=&quot;keyword&quot;&gt;next&lt;/span&gt;[j]&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(j == m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; i-j+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;按照上面的思路，就不难理解了。&lt;/p&gt;
&lt;p&gt;归根结底一句话，我们要充分利用已经做过的工作中的一些收获和经验，来促进现有问题的解决。抽象到最顶端，KMP就不仅仅是一种算法，更意味着一种解决问题的方式方法了。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;以前看KMP算法的时候，总是无法理解next函数以及next函数的求法以及匹配时j=next[j]的做法的直观意义。这次看《暗时间》这本书的时候谈到一个知识的本质问题，有提到KMP，于是就想着能不能够从本质的角度出发去重新理解下KMP呢？&lt;/p&gt;
&lt;p&gt;KMP的本质是什么？
    
    </summary>
    
      <category term="算法 | Algorithm" scheme="http://whatbeg.com/categories/%E7%AE%97%E6%B3%95-Algorithm/"/>
    
    
      <category term="算法" scheme="http://whatbeg.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow白皮书阅读笔记</title>
    <link href="http://whatbeg.com/2017/01/11/tensorflowwhitepaper.html"/>
    <id>http://whatbeg.com/2017/01/11/tensorflowwhitepaper.html</id>
    <published>2017-01-11T06:48:19.000Z</published>
    <updated>2017-01-11T06:58:16.768Z</updated>
    
    <content type="html">&lt;p&gt;Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis,Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,Yangqing Jia, Rafal Józefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore,Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, Xiaoqiang Zheng:&lt;br&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.04467&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems&lt;/a&gt;. (2015.11)&lt;/p&gt;
&lt;h2 id=&quot;编程模型与基本概念&quot;&gt;&lt;a href=&quot;#编程模型与基本概念&quot; class=&quot;headerlink&quot; title=&quot;编程模型与基本概念&quot;&gt;&lt;/a&gt;编程模型与基本概念&lt;/h2&gt;&lt;p&gt;TensorFlow的计算过程采用一张有向图（DAG）来描述，有向图由许多节点（nodes）构成，图代表了一个数据流（dataflow）计算过程，用户通常用某种前端语言(C++/Python)建立一个计算图，来执行某个过程。&lt;/p&gt;
&lt;p&gt;在TensorFlow图中，每个节点（node）可以有任意个输入，任意个输出，代表了一个操作的实例化，流过图中正常的边（edge）（从输出到输入）的值（Values）称为张量（Tensor），可以理解为任意维的array。有一些特殊的边，称为控制依赖（control dependencies），没有数据流过，表示节点与节点之间一种序关系，也即happens-before关系。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作(Operation)：一个操作代表一次抽象计算，有一个名字，还能有一个属性，所有的属性必须给定或者能够在图建立的时候就推断出来，属性的作用主要就是是操作在不同的张量类型上保持多态(?)&lt;/li&gt;
&lt;li&gt;核(Kernel)：操作的特殊实现，可以运行在一个特定设备上。&lt;/li&gt;
&lt;li&gt;会话(Session)：用户与TensorFlow系统交互的客户端程序，提供许多操作。主要是Run，即获取需要计算的输出，以及fed进来的输入，运行一次整个流图的计算，得到结果填入输出中。一般是对一个图启动一个Session，然后执行多次。&lt;/li&gt;
&lt;li&gt;变量(Variable)：大多数情况下，图是执行多次的，大多数的Tensor在一次执行后不会继续存活，然而变量(Variable)是一种特殊的操作，它返回一个到持久化可变张量(persistent mutable tensor)的句柄，就是说它的生命周期是整个图的计算过程。这样可以保证许多机器学习任务中参数的持续迭代改变。&lt;/li&gt;
&lt;li&gt;设备(device)：设备是TensorFlow的计算核心，每个worker负责一到多个设备，每个设备有一个名字，设备通常指的就是某个CPU或者GPU，它的命名方式有一定讲究，比如&lt;code&gt;/job:localhost/device:cpu:0&lt;/code&gt;等。&lt;/li&gt;
&lt;li&gt;张量(Tensor)：一种有类型的多维数组，元素类型包括大小为从 8 bit 到 64 bit 的带符号和无符号整型，IEEE 浮点数和双精度类型、复数类型和字符串类型（任意长的字节数组）。通过一个分配器来管理其后台存储(backing store)，且维持一个引用计数，在没有引用时释放。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Implementation&quot;&gt;&lt;a href=&quot;#Implementation&quot; class=&quot;headerlink&quot; title=&quot;Implementation&quot;&gt;&lt;/a&gt;Implementation&lt;/h2&gt;&lt;h3 id=&quot;单设备执行&quot;&gt;&lt;a href=&quot;#单设备执行&quot; class=&quot;headerlink&quot; title=&quot;单设备执行&quot;&gt;&lt;/a&gt;单设备执行&lt;/h3&gt;&lt;p&gt;单设备执行不用说了，一切都在本地，每个节点维护一个依赖计数，表示该节点的先序节点还有多少个没有执行，如果该计数为0，则将该节点放入准备队列ReadyQueue等待执行。&lt;/p&gt;
&lt;h3 id=&quot;多设备执行&quot;&gt;&lt;a href=&quot;#多设备执行&quot; class=&quot;headerlink&quot; title=&quot;多设备执行&quot;&gt;&lt;/a&gt;多设备执行&lt;/h3&gt;&lt;p&gt;多设备执行中，主要有两个复杂性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何分配哪个节点在哪台设备上计算？&lt;/li&gt;
&lt;li&gt;管理跨设备的数据通信&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;节点置放&quot;&gt;&lt;a href=&quot;#节点置放&quot; class=&quot;headerlink&quot; title=&quot;节点置放&quot;&gt;&lt;/a&gt;节点置放&lt;/h4&gt;&lt;p&gt;现在有一张计算图，TensorFlow需要将这些节点的计算放置到可用给的设备上，如何分配每个节点到具体的设备是要解决的问题。&lt;/p&gt;
&lt;p&gt;此版本的TensorFlow采用了一种模拟执行过程的启发式的cost model，即先模拟一遍图的执行过程，采用启发式贪心策略来分配。首先设备需要满足能够执行该node所需的操作，然后再谈分配的问题，在备选的设备中选取一个预计执行时间最小的设备，放置，然后进行下面的分配，当然在有控制依赖的时候还需要加以考虑。目前来说，&lt;strong&gt;置放算法还在进一步地研究优化&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&quot;设备间通信&quot;&gt;&lt;a href=&quot;#设备间通信&quot; class=&quot;headerlink&quot; title=&quot;设备间通信&quot;&gt;&lt;/a&gt;设备间通信&lt;/h4&gt;&lt;p&gt;TensorFlow采用Send节点和Receive节点来实现跨设备的数据交换。将设备A中a节点到设备B中b节点之间的边用send和recv的节点隔开，如图所示。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/tensorflow1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;这使得我们将Send和Receive内部的通信机制与节点与节点之间的通信隔离开来。而且这种方式下，master只需要提出“任务”(通过Run)给workers，而无需管理workers之间的通信，这就相当于去中心化(decentralized)了，大大减小了master的负载。&lt;/p&gt;
&lt;p&gt;要注意的是，如果一台设备上的两个或多个tensor都依赖于另一台设备的某一个tensor，TensorFlow只使用一个Recv节点，参看上图右边的b,c。&lt;/p&gt;
&lt;h3 id=&quot;分布式执行&quot;&gt;&lt;a href=&quot;#分布式执行&quot; class=&quot;headerlink&quot; title=&quot;分布式执行&quot;&gt;&lt;/a&gt;分布式执行&lt;/h3&gt;&lt;p&gt;分布式执行非常像多设备执行，之中要解决容错的问题。&lt;/p&gt;
&lt;p&gt;错误主要发生在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Send/Recv的通信错误&lt;/li&gt;
&lt;li&gt;周期性的保活检查(keep-alive)时&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果发生了错误，那么整个图会终止执行，并重启。如果简单地这样处理的话，那些正确计算好的节点就得重新计算，不高效，所以TensorFlow支持在重启过程中一致的检查点和状态恢复。&lt;br&gt;怎么实现的呢？&lt;br&gt;每个节点有一个到Save节点的连接，也被一个Restore节点所连接，周期性地执行Save，持久化变量到比如分布式文件系统等存储上。类似的，Restore节点负责在重启后的第一个迭代中恢复变量的值(或状态?)&lt;/p&gt;
&lt;h2 id=&quot;扩展&quot;&gt;&lt;a href=&quot;#扩展&quot; class=&quot;headerlink&quot; title=&quot;扩展&quot;&gt;&lt;/a&gt;扩展&lt;/h2&gt;&lt;p&gt;TensorFlow内嵌地支持自动梯度计算。&lt;/p&gt;
&lt;p&gt;在存储管理(memory management)，TensorFlow的作者们也在寻求提升的方法。一些可能的选项包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用更加复杂的启发式算法来决定图的执行顺序&lt;/li&gt;
&lt;li&gt;重新计算tensor而不用把他们保持在主存&lt;/li&gt;
&lt;li&gt;将长久存在的tensor从GPU memory中交换到更加丰富的主机CPU&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TensorFlow支持图的部分计算，如图：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/tensorflow2.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;显然，支持条件与循环会导致更加精确和高效地表示机器学习算法，TensorFlow提供了一些控制流操作原语包括Switch，Merge，Enter，Leave，NextIteration等。&lt;br&gt;每轮迭代由一个唯一的tag标识，执行状态由一个frame来表示，一个输入只要可用就可以进入一个迭代过程，因此，多个迭代可以并发地执行。&lt;/p&gt;
&lt;p&gt;尽管输入数据可以通过feed节点提供，另一个典型的训练大规模机器学习模型的机制是在图中采用特殊的输入操作节点(input operation nodes)，节点通过文件名配置，这使得工作节点可以直接从存储系统中将数据拿到内存。&lt;/p&gt;
&lt;p&gt;队列是很有用的一个特性，允许图的不同部分亦不知悉，按照不同的节奏通过Enqueue和Dequeue来处理数据。队列的一个用途是允许输入数据提前从文件中取出，此时并不耽误前一批数据的处理，更有效率。TensorFlow不仅实现了基本的FIFO队列，还实现了一个shuffling队列，可以随机shuffle一个大型内存buffer中的元素。&lt;/p&gt;
&lt;p&gt;容器是用来管理长期存在的可变状态的机制。默认的话，容器一直保持到进程结束。&lt;/p&gt;
&lt;h2 id=&quot;优化&quot;&gt;&lt;a href=&quot;#优化&quot; class=&quot;headerlink&quot; title=&quot;优化&quot;&gt;&lt;/a&gt;优化&lt;/h2&gt;&lt;p&gt;本部分描述了TensorFlow的实现过程中所做的一些优化，提升性能并且提高了资源的重用率。&lt;/p&gt;
&lt;p&gt;这些优化包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消除公共子表达式&lt;/li&gt;
&lt;li&gt;控制数据通信与内存使用，调度优化是必要的且有效的&lt;/li&gt;
&lt;li&gt;异步核(?)&lt;/li&gt;
&lt;li&gt;核实现的优化库，cuDNN,cuda-convnet,cuBLAS等&lt;/li&gt;
&lt;li&gt;有损压缩。为了减少通信量，将一些浮点数的位数压缩，比如32位浮点数压缩到16位，通过损失一定精度换来跨机通信的高效。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;一些经验&quot;&gt;&lt;a href=&quot;#一些经验&quot; class=&quot;headerlink&quot; title=&quot;一些经验&quot;&gt;&lt;/a&gt;一些经验&lt;/h2&gt;&lt;p&gt;本部分介绍了作者们在移植/迁移机器学习模型（从一个系统到另一个系统）中的一些经验教训。&lt;/p&gt;
&lt;p&gt;包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对参数的个数有一个洞察&lt;/li&gt;
&lt;li&gt;从小（模型）开始逐步扩展&lt;/li&gt;
&lt;li&gt;保证目标函数的正确性&lt;/li&gt;
&lt;li&gt;先单机，再分布式&lt;/li&gt;
&lt;li&gt;防备数值错误/误差&lt;/li&gt;
&lt;li&gt;分析网络，理解数值误差的量级和容忍度。可以同时在两个系统中跑，看结果是否一致来判断有无数值误差/错误&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;数据并行，模型并行与并发步&quot;&gt;&lt;a href=&quot;#数据并行，模型并行与并发步&quot; class=&quot;headerlink&quot; title=&quot;数据并行，模型并行与并发步&quot;&gt;&lt;/a&gt;数据并行，模型并行与并发步&lt;/h2&gt;&lt;p&gt;TensorFlow关心的一大领域就是加速计算密集型的大规模神经网络的训练。本部分描述了一些方法。&lt;/p&gt;
&lt;h3 id=&quot;数据并行&quot;&gt;&lt;a href=&quot;#数据并行&quot; class=&quot;headerlink&quot; title=&quot;数据并行&quot;&gt;&lt;/a&gt;数据并行&lt;/h3&gt;&lt;p&gt;数据并行分为同步数据并行和异步数据并行。见图：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/tensorflow3.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;数据并行的意思是，用很多的模型副本，每个副本运行在不同的数据上，然后同时训练，更新模型。通过更新模型的方式不同，可以分为同步和异步，同步的方式是一个用户线程驱动整个大循环，如图上部，等到所有的$\Delta P$都算出来后，将它们相加去更新模型。而异步的方式不同，每个模型副本自己异步地对模型参数进行更新，不用等到所有的梯度算出来再更新，每个模型副本有一个用户线程。见图下部。&lt;/p&gt;
&lt;h3 id=&quot;模型并行和并发步-concurrent-steps&quot;&gt;&lt;a href=&quot;#模型并行和并发步-concurrent-steps&quot; class=&quot;headerlink&quot; title=&quot;模型并行和并发步(concurrent steps)&quot;&gt;&lt;/a&gt;模型并行和并发步(concurrent steps)&lt;/h3&gt;&lt;p&gt;模型并行的意思是，对于同样一批数据，模型计算的不同部分分散在不同的计算设备上同时进行。如图是一个循环深度LSTM用来做序列到序列学习的例子。(?)&lt;/p&gt;
&lt;p&gt;并发步是另一种通常的做法，即通过在同样的设备集合中运行少数的并发步来将同一设备中的模型计算流水线化。(?)&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/tensorflow4.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h2 id=&quot;工具&quot;&gt;&lt;a href=&quot;#工具&quot; class=&quot;headerlink&quot; title=&quot;工具&quot;&gt;&lt;/a&gt;工具&lt;/h2&gt;&lt;p&gt;TensorBoard用来对计算图，总结信息和训练过程等进行可视化，方便观察训练过程。&lt;/p&gt;
&lt;p&gt;性能追踪(performance tracing)，了解哪些地方是瓶颈时间。EEG。&lt;/p&gt;
&lt;h2 id=&quot;未来工作&quot;&gt;&lt;a href=&quot;#未来工作&quot; class=&quot;headerlink&quot; title=&quot;未来工作&quot;&gt;&lt;/a&gt;未来工作&lt;/h2&gt;&lt;p&gt;未来工作包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;子图的重用，像函数一般&lt;/li&gt;
&lt;li&gt;置放算法与节点的调度，可能采用DNN和强化学习相结合来学习置放&lt;/li&gt;
&lt;li&gt;just-in-time compiler&lt;/li&gt;
&lt;li&gt;跨操作动态编译框架(cross-operation dynamic compilation framework)&lt;/li&gt;
&lt;li&gt;等等。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;总的来说，TensorFlow是一个基于数据流的编程模型，它在有足够内存来满足计算工作集时工作良好，但是速度相比于其它框架如MXNet还是显得太慢，以至于被人叫做“TensorSlow”，这些方面还需要加强。它是最火的框架但是并不是目前最优秀的框架，火起来的原因相当一部分是有谷歌这个爹。&lt;/p&gt;
&lt;p&gt;Reference: &lt;a href=&quot;http://www.jianshu.com/p/65dc64e4c81f&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Not_GOD译&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis,Jeffrey Dean, Matthie
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="大数据" scheme="http://whatbeg.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow" scheme="http://whatbeg.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning论文阅读纪要（一）</title>
    <link href="http://whatbeg.com/2017/01/07/paperreading01.html"/>
    <id>http://whatbeg.com/2017/01/07/paperreading01.html</id>
    <published>2017-01-07T14:02:04.000Z</published>
    <updated>2017-01-10T08:18:27.701Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Deep-Learning-Review&quot;&gt;&lt;a href=&quot;#Deep-Learning-Review&quot; class=&quot;headerlink&quot; title=&quot;Deep Learning Review&quot;&gt;&lt;/a&gt;Deep Learning Review&lt;/h2&gt;&lt;p&gt;LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统机器学习方法在处理原始形式的自然数据时受限，需要繁杂的特征工程和大量的领域专家知识&lt;/li&gt;
&lt;li&gt;深度学习的核心在于它们用一个通用目标的学习过程来从数据中学习，无需手工做特征工程&lt;/li&gt;
&lt;li&gt;深度学习在发现高维数据的复杂结构上有一套&lt;/li&gt;
&lt;li&gt;应用方面，深度卷积网络在图像，视频，语音，音频方面，循环网络在序列数据比如文本，语音上取得了巨大突破&lt;/li&gt;
&lt;li&gt;虽然只需少量特征工程，但是需要计算能力和数据&lt;/li&gt;
&lt;li&gt;用小部分样本做SGD，这些小部分样本给出的（平均梯度）是整个样本集的平均梯度的噪声估计(noisy estimate)&lt;/li&gt;
&lt;li&gt;深度的增加使得对大量无关变量（比如图像中的背景，物体的位置等等）逐渐变得不敏感&lt;/li&gt;
&lt;li&gt;在实践中，“差的局部最小”(poor local minima)在大规模网络中一般不是问题。被困在哪个鞍点并不重要，因为他们离目标都很接近&lt;/li&gt;
&lt;li&gt;卷积神经网络的4个核心思想：局部连接，权值共享，池化和多层次&lt;/li&gt;
&lt;li&gt;共享参数是由于，在图像中，物体不论出现在哪个位置，都应该一样的看待，所以一种滤波器（卷积核）使用同样的权值来检测一种模式&lt;/li&gt;
&lt;li&gt;卷积网络(ConvNet)现在是几乎所有识别和检测任务中的最主要方法&lt;/li&gt;
&lt;li&gt;许多公司也在研发ConvNet芯片以实现视觉应用的实时处理，并且嵌入到设备中&lt;/li&gt;
&lt;li&gt;Neutral Turing Machine / Memory Network：用于需要推理和符号操作的任务，核心是推理！&lt;/li&gt;
&lt;li&gt;无监督学习，增强学习等是未来的趋势&lt;/li&gt;
&lt;li&gt;将深度学习与增强学习结合的系统正处于萌芽期，不过他们已经在分类任务中表现出了令人印象深刻的效果&lt;/li&gt;
&lt;li&gt;人工智能的巨大进步考表示学习与复杂推理的结合来推动&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;文章讲述了深度学习中的一些关键性主题，包括监督学习，后向传播，卷积神经网络及其在图像理解上的应用，分布式表示和语言处理，以及循环神经网络，最后对深度学习的未来进行了探讨。&lt;br&gt;文章提交于2015年2月，距今约2年了，深度学习的江湖又发生了巨大的变化，单看这篇综述还不能够了解深度学习的方方面面，还需要更多的资料。&lt;/p&gt;
&lt;h2 id=&quot;Large-Scale-Distributed-Deep-Networks&quot;&gt;&lt;a href=&quot;#Large-Scale-Distributed-Deep-Networks&quot; class=&quot;headerlink&quot; title=&quot;Large Scale Distributed Deep Networks&quot;&gt;&lt;/a&gt;Large Scale Distributed Deep Networks&lt;/h2&gt;&lt;p&gt;Large Scale Distributed Deep Networks. Jeffrey Dean et al. &lt;a href=&quot;http://www.cs.toronto.edu/~ranzato/publications/DistBeliefNIPS2012_withAppendix.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PDF&lt;/a&gt; &lt;a href=&quot;http://wxwidget.github.io/blog/2014/08/17/large-scale-deep-network/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;中文译版&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分布式训练或者优化的一个难点在于各机器处理时间各异，有时候需要等最慢的机器运行完成&lt;/li&gt;
&lt;li&gt;SGD是训练深度神经网络最常用的优化过程了，但是在非凸的情况下就略显颓势了&lt;/li&gt;
&lt;li&gt;一种深度学习规模扩展的方法使，用一些GPU来训练许多小模型，将这些模型应用在数据是，将它们的预测结果平均&lt;br&gt;这篇文章对大规模分布式深度网络的训练框架内，提出了两个算法： Downpour SGD，一个支持大量模型副本的异步随机梯度下降过程，和Sandblaster L-BFGS，一个支持各种分布式批优化过程的框架，但是后者好像没什么大用，后面提到，“Sandblaster L-BFGS或许在30000个处理器的时候能够最后胜出”，暂时都用不到那么多的核，所以后面性能也没有测试结果，所以就不知道了，重点在于前面一个算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Downpour SGD的主要思想是，将训练集划分若干子集，并对每个子集运行一个单独的模型副本。模型副本之间的通信均通过中心参数服务器(parameter server, ps)组，该参数服务器组维护了模型参数的当前状态，并分割到多台机器上（例如，如果我们参数服务器组有10个节点，那么每个节点将负责存储和更新模型参数的1/10，如图1所示）。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/downpoursgd.png&quot; alt=&quot;图1&quot;&gt; &lt;/center&gt;

&lt;p&gt;该方法在两个方面体现异步性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;模型副本之间运行独立，在各自负责的数据集（子集）上独立运行&lt;/li&gt;
&lt;li&gt;参数服务器(parameter server)组各节点之间同样是独立的，PS片独立运行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;考虑Downpour SGD的一个最简单的实现，在处理每个mini-batch（译者注：小型批量）之前，模型副本都会向参数服务器请求最新的模型参数。因为DistBelief框架也是分布在多台机器上，所以其框架的每个节点只需和参数服务器组中包含和该节点有关的模型参数的那部分节点进行通信。在DistBelief副本获得更新后的模型参数后，运行一次mini-batch样本来计算参数的梯度，并推送到参数服务器，以用于更新当前的模型参数值。更新的频度也可以设置，在处理机器失效方面，Downpour SGD比标准（同步）SGD要鲁棒。对于同步SGD来讲，如果一台机器失效，整个训练过程将会延时；但是对于异步SGD来讲，如果某个模型副本的一台机器失效，其他模型副本仍然继续处理样本并更新参数服务器中的模型参数。&lt;br&gt;但是由于每个参数服务器只更新互斥的一部分参数，副本之间不会进行通信，因此可能会导致参数发散而不利于收敛。&lt;br&gt;另外一项能极大提高Downpour SGD鲁棒性的技术是使用Adagrad自适应学习速率方法。&lt;br&gt;通过这种结合，达到了最好的效果（最短的时间内达到了规定的准确率）。&lt;br&gt;Adagrad方法参见:&lt;br&gt;J. C. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121–2159, 2011.&lt;br&gt;中文版的论文翻译中有更详细的内容。&lt;/p&gt;
&lt;h2 id=&quot;A-Brief-Overview-of-Deep-Learning&quot;&gt;&lt;a href=&quot;#A-Brief-Overview-of-Deep-Learning&quot; class=&quot;headerlink&quot; title=&quot;A Brief Overview of Deep Learning&quot;&gt;&lt;/a&gt;A Brief Overview of Deep Learning&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://yyue.blogspot.jp/2015/01/a-brief-overview-of-deep-learning.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;WEB&lt;/a&gt; by Ilya Sutskever. Jan 13, 2015&lt;/p&gt;
&lt;p&gt;文章论述了为什么深度学习是有效的并且强力的，以及深度学习模型的学习和泛化，然后给出了13条实践中训练深度学习模型的建议，摘其要点如下，作者用LDNN这个词来代替Deep Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决复杂问题我们需要强力的，可训练的模型，LDNN(Large Deep Neutral Network)满足这两个条件&lt;/li&gt;
&lt;li&gt;LDNNs learn computation, albeit a massively parallel computation with a modest number of steps&lt;/li&gt;
&lt;li&gt;有了指数级别的数据，任何模型都能够解决问题，但是不现实&lt;/li&gt;
&lt;li&gt;学习（Learning）意味着将有标记数据的信息表现在训练后的参数中&lt;/li&gt;
&lt;li&gt;作者提出了一个假设，neural network start their learning process by noticing the most blatant correlations between the input and the output(神经网络通过注意输入和输出之间最明显的相关性来开始他们的学习过程)&lt;/li&gt;
&lt;li&gt;Tip01: 获取大规模高质量的数据集&lt;/li&gt;
&lt;li&gt;Tip02: 处理成0均值，小方差，效果更佳&lt;/li&gt;
&lt;li&gt;Tip03: 采用minibatchs有效提高性能，降低过拟合，但是batch size不要太大(32,64,128)&lt;/li&gt;
&lt;li&gt;Tip04: gradient的正则化（gradient / batchsize）&lt;/li&gt;
&lt;li&gt;Tip05: 学习率的规划&lt;ul&gt;
&lt;li&gt;0.1是学习率的一个经典值&lt;/li&gt;
&lt;li&gt;用验证集来决定何时降低LR(Learning Rate)和何时早停&lt;/li&gt;
&lt;li&gt;如果验证集error不再降低，减小LR，可以降低过拟合（在这个标准上）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tip06: 监控update norm 和 weight norm之间的比率&lt;/li&gt;
&lt;li&gt;Tip07: 权值初始化&lt;ul&gt;
&lt;li&gt;随机初始化&lt;/li&gt;
&lt;li&gt;随机初始化对深度网络和循环网络非常重要&lt;/li&gt;
&lt;li&gt;浅层网络可以不考虑随机初始化问题，但深度网络需要&lt;/li&gt;
&lt;li&gt;尝试多种初始化方法，这份努力会得到回报&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tip08: 当训练LSTM或者RNN时，对梯度的norm采取硬约束，即对梯度的norm进行修剪&lt;/li&gt;
&lt;li&gt;Tip09: 数值梯度检验(Numerical gradient checking)，主要在Theano,Torch等自定义梯度计算的场景&lt;/li&gt;
&lt;li&gt;Tip10: 使用LSTM处理超长期依赖的时候，应将forget gate的bias设成较大的值&lt;/li&gt;
&lt;li&gt;Tip11: 数据增强，巧妙增加数据集样本，旋转，加噪声等&lt;/li&gt;
&lt;li&gt;Tip12: dropout有效提升性能，且训练越久变得越来越好&lt;/li&gt;
&lt;li&gt;Tip13: 训练多个模型，将它们的预测取平均&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些Tips还期待日后在实践过程中的运用检验，希望能够对深度模型的训练起到一些指导的作用。&lt;br&gt;最后，作者总结，LDNNs是强力的，切实可训练的，如果我们有高质量的大量数据，我们可以找到最好的LDNNs来解决问题。对未来做出预测很难，不过，通常来说，通过大量计算得出的模型更好的可能性更大，神经图灵机是这个方向上的重要进步，无监督学习也是未来的一大方向，期待进一步的突破。&lt;/p&gt;
&lt;h2 id=&quot;小小总结&quot;&gt;&lt;a href=&quot;#小小总结&quot; class=&quot;headerlink&quot; title=&quot;小小总结&quot;&gt;&lt;/a&gt;小小总结&lt;/h2&gt;&lt;p&gt;综合这几篇文章，看到他们都对深度学习的整个脉络，现在的发展和未来的预测进行了梳理。结合自己的看法，我把他们总结成以下几点，&lt;/p&gt;
&lt;p&gt;第一，深度模型在现今许多复杂任务中取得了良好的效果，在图像，视频，音频，语音，自然语言处理方面都取得了start-of-art的效果，这些也是深度学习拿手的几个方向&lt;br&gt;第二，深度学习模型只是一种有别于传统机器学习方法的模型，它大大简化了特征工程的部分，但本质上是神经网络，也即一种机器学习的方法，我们不知道深度学习的未来如何，但是机器学习的未来一定是明朗的&lt;br&gt;第三，未来的大方向在于无监督学习，增强学习，迁移学习等领域，因为无标记的样本比有标记的高质量数据来的多得多，如何有效利用这些无标签样本是需要重点研究的课题&lt;br&gt;第四，在计算能力得到根本性突破之前（比如量子计算机投入使用并且发挥所谓的强大计算能力之前），多机并行以增加计算能力，来训练更加复杂的模型是不可阻挡的趋势，分布式机器学习，分布式深度学习模型训练也是可以做的方向&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Deep-Learning-Review&quot;&gt;&lt;a href=&quot;#Deep-Learning-Review&quot; class=&quot;headerlink&quot; title=&quot;Deep Learning Review&quot;&gt;&lt;/a&gt;Deep Learning Review&lt;/h2&gt;&lt;
    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="深度学习" scheme="http://whatbeg.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://whatbeg.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>2016CCF大数据与计算智能大赛总结</title>
    <link href="http://whatbeg.com/2017/01/01/2016ccfcontest.html"/>
    <id>http://whatbeg.com/2017/01/01/2016ccfcontest.html</id>
    <published>2017-01-01T02:08:42.000Z</published>
    <updated>2017-02-18T13:20:32.499Z</updated>
    
    <content type="html">&lt;h2 id=&quot;赛题简介及任务&quot;&gt;&lt;a href=&quot;#赛题简介及任务&quot; class=&quot;headerlink&quot; title=&quot;赛题简介及任务&quot;&gt;&lt;/a&gt;赛题简介及任务&lt;/h2&gt;&lt;p&gt;情感分析是网络舆情分析中必不可少的技术，基于视角的领域情感分析更是情感分析应用于特定领域的关键技术。在对句子进行情感分析时，站在不同的视角，同一个句子的情感倾向判断结果将有所差别。本赛题意在情感分析任务中，站在数据使用者的角度进行特定的情感分析，使数据分析的结果更具可用性。本赛题可以细分为“视角抽取”与“基于视角的情感分析”两部分。下文首先介绍“视角”的定义，而后对“视角抽取”与“基于视角的情感分析”任务进行详细介绍：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;视角定义&lt;/strong&gt;：在情感分析这一任务中，对于同一个文档或句子，不同的数据使用者去分析，将会有不同的情感倾向。同时，从文中不同内容去分析，也有可能会得到不一样的情感。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;p&gt;在“A车在第三季度一举超过B车成为销量冠军”这样一句话中，如果分析者站在A车的角度去考虑，这句话就是正面的，但是如果分析者在B车的角度，则丢失了销量冠军这样一则消息是负面的。而在本句话中，“A车”和“B车”则是两个不同的情感视角。&lt;/p&gt;
&lt;p&gt;视角泛指某一类的思考角度，可以理解为数据使用者角度，亦可以理解为文本中某些方面，在本赛题中，为了简化《基于视角的领域情感分析》这一任务，我们将视角进行具体化——特指文本中出现的汽车品牌词语（如：“上汽大众”、“美国通用”、“速派”、“POLO”等）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;视角抽取&lt;/strong&gt;：又称为“视角识别”。顾名思义，这一任务意在从文本中抽取（识别）出可以描述视角的词语。由于在本次任务中，视角特指汽车品牌词，故这一步的任务需要参赛队伍抽取（识别）出文本中的汽车品牌词（或别名）。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;“考虑到终端市场的情况，我们本次选取了全新迈腾全系的次顶配车型和帕萨特2.0T排量的顶配车型来进行对比”一句话中，参赛队伍应抽取出“迈腾”和“帕萨特”两个视角。&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;“最终我们放弃了迈腾，把小帕开回了家！”一句中，参赛队伍应抽取出“迈腾”和“小帕”两个视角。在这里“小帕”是“帕萨特”的别名。&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本次评测中，我们将给出一个汽车品牌词语集合来供参赛队伍参考。这个品牌词集合包含了测试语料中出现的大部分汽车品牌词及少部分未出现的汽车品牌词。为了验证参赛队伍“视角抽取”方法的鲁棒性，会有评测语料中的部分汽车品牌词并未出现在这一集合中的现象。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;基于视角的情感分析：给定一个句子，如果该句子中包含“视角”词语，则应针对这一视角进行情感分析；如果句子中包含多个“视角”词语，则应对不同的视角进行单独的情感分析；如果句子中不包含视角，则不做情感判别处理。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;算法模型&quot;&gt;&lt;a href=&quot;#算法模型&quot; class=&quot;headerlink&quot; title=&quot;算法模型&quot;&gt;&lt;/a&gt;算法模型&lt;/h2&gt;&lt;p&gt;本部分介绍一下我们最终模型的演变产生过程，以及我们所做的一些探索及效果。&lt;br&gt;10月10号，我们撸了一个简单的基于规则的情感分析算法，想探一下究竟，视角没有进行细致的抽取，只是利用给的View中的视角，采用简单的字符串匹配来进行简单提取，这一交，在初赛A榜中，只拿到了0.35768的分数，虽然没用，但是我们得到了一个可以用来比较的baseline，接下来就是不断探索，尝试其他的方法了。&lt;br&gt;此后，我们4人通过定期的讨论，每个人都对一部分进行深入研究，然后定期地交流，进行思维的碰撞，以期抛弃一些错误的想法，确定正确的想法，探讨当前阶段的优势与不足，确定下一个着力点等等，ArcherW的主要工作集中在特征工程和传统方法比如逻辑回归，贝叶斯等等，提取了TF，IDF，LDA，POS等等特征，并进行了筛选，组合，后来我们使用基于TF（词频）和POS（词性标注）特征的LR（逻辑回归）算法在11月14号初赛结束前的提交中得到了0.57677的分数。而有趣的是，采用基于TF-IDF和POS的LR仅得到了0.56209的分数，即TF-IDF比纯TF还低一个多百分点，这可能也侧面说明了，在情感分析任务中，代表着词的“重要性”的逆文档频率IDF特征并没有那么重要，因为句子的情感是由整个句子的所有词综合决定，可能一个词并不重要，但是它对决定整个句子的情感却至关重要或者至少有着不可忽视的作用。chenminzoe的工作也集中于特征提取和偏竞赛类的方法比如SVM，XGBoost，GBDT等等上面，她尝试了一些自己探索的创新型的特征，也取得了不错的分数，在复赛中采用SVM模型取得过0.56708的高分，比初赛最好的模型CNN的0.5371高出了3个百分点，但是后来很难取得突破，我们猜想问题，第一个可能出在特征的组合方面，第二个可能出在我们对诸如SVM这些分类器的参数调优缺乏经验，第三个就是我们没有制定与线上一致的有效的线下评测，来对我们的参数进行多次的调优，这个问题同样也出现在传统分类器，以及笔者所做的CNN，RNN等分类器上，这也是我们队值得反思的一点。shizihao123的工作主要集中在视角抽取方面，首先探索的是模式匹配的方法，为了应对官方给的View不太全面和存在噪声的现象，他编写了诸多爬虫爬取各大汽车网站比如汽车之家，车主之家等的汽车品牌词库，以应对这个问题，并对这些词库使用了许多算法进行处理，以得到最大可能的汽车品牌词典，又尽可能少地引入噪声。开始我们就利用给的训练数据和爬取的汽车品牌词典等数据去匹配句子中的视角，速度极慢，整个测试集不到10000条数据，却需要跑一个晚上才能够全部提取出来，在复赛中我们经过商讨，采用了AC自动机来做精确匹配，原来一个晚上的时间缩短到了不到半个小时，同时shizihao123在视角品牌词筛选方面做了大量工作，去除了大量匹配到的却在当前语境中并非汽车品牌的词，这都为后面的情感分类提供了强大的助力。整个过程简图如下，&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ccf3.png-sf7sy&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;可以说，我们的视角工作做得非常丰富，可是不足在于我们的视角提取方法较为单一，对词典依赖比较强，有效性依赖于我们对词典的收集工作，取决于词典是否全面。笔者的主要工作在于CNN，RNN方面，在实现了基于词典和规则的方法后，我们经过调研，发现CNN在处理情感分析问题上面取得了一些成功，然后笔者阅读了大量论文，大致摸清了CNN处理情感分析的方法，然后基于TensorFlow对CNN情感分类算法进行了代码实现，第一次提交取得了0.51543的分数，此后我们进行了诸多优化，包括词向量的优化，参数的优化，数据输入的优化，值得一提的是，我们此时实现了一种相关句划分的数据预处理方式，因为此时的CNN模型是对整句进行一个情感分析，所以需要把句子分给句子所描述的视角，如果把句子分给了并非它所描述的视角，那么我们就会得出错乱的情感，也就降低了正确率。这部分工作由ArcherW来实现，主要是根据几个关键的标点符号来对句子进行划分，如逗号，感叹号等等，如果一个句子部分包含了某个视角，我们认为这部分描述了这个视角，理所当然在判断该视角的情感的时候，我们可以把这部分句子的情感判断一下，如果一个句子部分不包含任何视角，那么根据语言上的惯例，我们将这个句子部分和前一个句子部分归到一起，前一部分是描述哪个视角，这一部分也相应描述哪个视角。这样就得到了每个视角所对应的相关句，我们利用CNN对这些相关句进行情感分类，分类结果就是相关句所对应的视角的情感。在词向量优化方面，我们采用了搜狗实验室的全网新闻语料，还采用了搜狐新闻，网易新闻，以及各处下载的汽车新闻语料40M左右，后来继续增加词向量，从中国汽车新闻网，汽车之家等网站爬取了近300M的汽车语料进行训练，随着汽车语料的增加，词向量训练的越准确，从而每次增加语料后结果都得到一些提升。&lt;br&gt;在不断的优化后，从最初的0.51543的成绩，逐步提升，到0.52，0.58，到最后初赛A榜定榜，我们用CNN做出的成绩是0.5901，排在A榜24名。B榜出来后，我们最高成绩是0.56941，还是排在第24名。然后就进入复赛了。&lt;/p&gt;
&lt;p&gt;复赛阶段，沿用CNN的方法只取得了0.5371的分数，让我们大失所望，传统的LR+TF+POS却在这时取得了0.56834的成绩，SVM方法也取得了0.56708的成绩，这不禁让我们怀疑到底是我们使用CNN的问题，还是CNN本身的局限性，此时我们也对深度学习有了更加深入的了解，我们发现RNN以其独特的对序列建模的能力，在自然语言处理领域发挥了巨大的作用，于是笔者开始钻研采用RNN体系的算法来解决情感分类的问题，这时候，一篇论文给了笔者巨大的启发，这也催生了我队解决情感分类任务的核心算法-BFGRU算法，算法框架如下图，&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ccf4.png-sf7sy&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;算法大致过程为，首先对视角进行提取，找出句子中的所有视角，每个视角会有一个句中的位置，对每个位置进行一次处理，将该位置左边的句子进行序列建模，采用GRU单元来进行状态存储，转换与记忆，最后得到一个输出，我们把它看做该位置的视角左边的语义对该视角的描述，输出为一个实值向量，然后我们再从句子最后跑一遍GRU直到该视角的右边，这又生成了该位置后面句子的语义对它的描述，综合前后的描述，再用softmax进行三分类，如此进行训练，就得到了对句子某个位置的视角进行情感判断的算法，这个算法我们称之为BFGRU(Bidirectional Focus Gated Recurrent Unit)，是从TDLSTM延伸过来的。这个算法初次提交得到0.56813的分数，稍低于LR方法，后来经过各种各样的优化，不断得到提升，从0.59972，到0.63763，再进行视角情感投票法的采用，提升到0.64，再到0.643，最后A榜封榜时我们取得了0.6481的成绩，排在全榜第6！&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ccf5.png-sf7sy&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;最终进入决赛，虽然最后没有取得1,2名的荣誉，但是我们收获了很多，虽然艰辛，我们无悔。真的很谢谢大赛主办方。&lt;br&gt;最后，给出我们整个解决方案的框架图，&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ccf6.png-sf7sy&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;上面就是我们整个比赛的方案提出过程，以及其中的团队合作，成功与失败，点点滴滴，都构成了我们能够站上决赛舞台的基础。&lt;/p&gt;
&lt;h2 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h2&gt;&lt;p&gt;算法解决了汽车领域评论的基于视角的情感分析，提出了一套基于视角的情感分析的解决方案，包括视角提取的方案以及对于评论句进行准确的情感分类的方案。可以应用在汽车领域评论挖掘，情感分析，汽车销售指导，由于视角提取的方案是与情感分类的方案分离的，所以我们可以将视角抽取推广到方面(aspect)抽取，得到对产品某个方面的评价，比如汽车中的油耗，空间等等。进一步的，我们可以推广到各种各样的领域，而不只是局限于汽车领域，在购物网站中完全可以用到我们的这套方案。我们的方案还可以用于舆情分析领域，对社会媒体或者自媒体的评论或者状态或者消息进行情感分析，了解社会中人们对于某个热点事件的看法，这有着巨大的意义。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ccf7.png-sf7sy&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;赛题简介及任务&quot;&gt;&lt;a href=&quot;#赛题简介及任务&quot; class=&quot;headerlink&quot; title=&quot;赛题简介及任务&quot;&gt;&lt;/a&gt;赛题简介及任务&lt;/h2&gt;&lt;p&gt;情感分析是网络舆情分析中必不可少的技术，基于视角的领域情感分析更是情感分析应用于特定领域的关键技术。
    
    </summary>
    
      <category term="深度学习 | Deep Learning" scheme="http://whatbeg.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning/"/>
    
    
      <category term="Summary" scheme="http://whatbeg.com/tags/Summary/"/>
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【数据分析】工作日发文章比周末发文章访问量高？</title>
    <link href="http://whatbeg.com/2016/12/31/zhoumovisit.html"/>
    <id>http://whatbeg.com/2016/12/31/zhoumovisit.html</id>
    <published>2016-12-31T10:02:30.000Z</published>
    <updated>2016-12-31T10:08:32.922Z</updated>
    
    <content type="html">&lt;p&gt;本文是一片老文，用Python做了一个简单的数据分析，2016年1月发表在&lt;a href=&quot;http://www.cnblogs.com/whatbeg/p/5127850.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;老博客&lt;/a&gt;上，在整理旧文的时候翻了出来，觉得有点价值，故移过来与大家分享一下。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看前面有位朋友分析了一下每天某个时间发文章的访问量区别，以讨论非系统性因素对文章访问量的影响。之所以进一步讨论工作日和周末发文对文章访问量的影响，一是觉得很有意思，二是毕业设计与此有很大关系，三是觉得还是有点意义的，于是决定做一下这个工作。那么到底周末发文的访问量是不是总体来说比工作日低呢，请往下看。&lt;/p&gt;
&lt;h2 id=&quot;工具&quot;&gt;&lt;a href=&quot;#工具&quot; class=&quot;headerlink&quot; title=&quot;工具&quot;&gt;&lt;/a&gt;工具&lt;/h2&gt;&lt;p&gt;1.Python 3.5&lt;br&gt;2.BeautifulSoup 4.4.1&lt;br&gt;3.Requests模块&lt;/p&gt;
&lt;h2 id=&quot;分析网页&quot;&gt;&lt;a href=&quot;#分析网页&quot; class=&quot;headerlink&quot; title=&quot;分析网页&quot;&gt;&lt;/a&gt;分析网页&lt;/h2&gt;&lt;p&gt;由于之前的工作已知博客园博客展览页是要通过ajax请求换页，这里我采用了Requests模块，post一个请求即可。&lt;br&gt;&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;payload&lt;/span&gt; = &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;CategoryType&quot;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&quot;SiteHome&quot;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;ParentCategoryId&quot;&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;CategoryId&quot;&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;808&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;PageIndex&quot;&lt;/span&gt;:i,&lt;span class=&quot;string&quot;&gt;&quot;ItemListActionName&quot;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&quot;PostList&quot;&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;r&lt;/span&gt; = requests.post(posturl,data = payload)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样就可以接收到第i页的博文列表的HTML内容了。&lt;br&gt;再来看一下我们要爬取的内容： &lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;我们要爬取两个内容：发布时间 与 阅读量，这次我们爬取40—200页共161页的内容，并分两种情况：剔除3000以上访问量的文章以及考虑全部文章，然后要做的工作有两个：根据打扫过的数据，统计出一周周一到周日每天的文章总数与访问量总数，最后用WPS表格来制作出对比图。一提到解析网页，我毫无疑问地又想到了BeautifulSoup这款工具，简单好用，功能强大，推荐。&lt;/p&gt;
&lt;p&gt;那么我们首先用BeautifulSoup抓出 &lt;code&gt;class = post_item_foot&lt;/code&gt; 的 &lt;code&gt;‘发布于...’&lt;/code&gt; 内容，以及抓出 &lt;code&gt;class = &amp;#39;article_view&amp;#39;&lt;/code&gt; 的 &lt;code&gt;‘阅读(...)’&lt;/code&gt;内容，再去除一些无用的部分，最后提取出日期三个数据y,m,d，以及阅读量，这里我们无需关心文章到底是谁发的或者具体时间。&lt;br&gt;（ps:Python 3.5下装BeautifulSoup老是不成功，后来发现有更高的版本4.4.1，就果断换了，然后一发成功，不知道什么原因）&lt;br&gt;部分代码如下：&lt;br&gt;&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;bs&lt;/span&gt; = BeautifulSoup(r.text,&lt;span class=&quot;string&quot;&gt;&quot;html.parser&quot;&lt;/span&gt;)           #转化成beautifulsoup对象&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;View&lt;/span&gt; = bs.findAll(attrs = &amp;#123;&lt;span class=&quot;string&quot;&gt;&#39;class&#39;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;article_view&#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;class&#39;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;post_item_foot&#39;&lt;/span&gt;&amp;#125;)  #找出两个class内容&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;strallview&lt;/span&gt; = str(View)  #转化为字符串&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;viewcountsmatch&lt;/span&gt; = re.findall(&lt;span class=&quot;string&quot;&gt;&#39;阅读\(\d+\)&#39;&lt;/span&gt;,strallview)   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;viewdaymatch&lt;/span&gt;    = re.findall(&lt;span class=&quot;string&quot;&gt;&#39;发布于 ....-\d+-\d+&#39;&lt;/span&gt;,strallview)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;得出日期三个数据以后，这里我使用蔡勒公式（Zeller Fomula）直接计算出该日是星期几。蔡勒公式函数代码如下：&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ZellerFomula&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(y,m,d)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; m == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; m == &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        y -= &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        m += &lt;span class=&quot;number&quot;&gt;12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    c = y // &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    y = y - c * &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    w = (c // &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;) - &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; * c + (y + y // &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;) + (&lt;span class=&quot;number&quot;&gt;13&lt;/span&gt; * (m + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) // &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;) + d - &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; w &amp;lt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        w += &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    w %= &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; w == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        w += &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; w&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后就是简单的统计了。&lt;br&gt;这里我有一个考虑，由于日子越早的文章显然访问量总是会更高，所以为了在一定程度上抵消这种效应，我为每一页的20篇文章设置了一个权重：&lt;br&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;weight = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; - &lt;span class=&quot;number&quot;&gt;0.0005&lt;/span&gt; * &lt;span class=&quot;comment&quot;&gt;(i - 40)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;即i越大，页数越大，发布越早，访问量相应打一个折扣，这里我设置的最大折扣为92%，即第200页的文章相应的阅读量为其原来阅读量的92%，希望能稍微提升一下结果的公平性。&lt;/p&gt;
&lt;h2 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;&lt;p&gt;这时候写出python代码（剔除3000+文章版本）：&lt;br&gt;&lt;figure class=&quot;highlight gradle&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; requests&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; urllib&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; bs4 &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; BeautifulSoup&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; ZellerFomula(y,m,d):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; m == &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; or m == &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        y -= &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        m += &lt;span class=&quot;number&quot;&gt;12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    c = y &lt;span class=&quot;comment&quot;&gt;// 100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    y = y - c * &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    w = (c &lt;span class=&quot;comment&quot;&gt;// 4) - 2 * c + (y + y // 4) + (13 * (m + 1) // 5) + d - 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; w &amp;lt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        w += &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    w %= &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; w == &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        w += &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; w&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;f = open(&lt;span class=&quot;string&quot;&gt;&#39;keyvalue.txt&#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;w&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;posturl = &lt;span class=&quot;string&quot;&gt;&#39;http://www.cnblogs.com/mvc/AggSite/PostList.aspx&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;daysum = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;count&lt;/span&gt;  = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i in range(&lt;span class=&quot;number&quot;&gt;40&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;201&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    weight = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; - &lt;span class=&quot;number&quot;&gt;0.0005&lt;/span&gt; * (i - &lt;span class=&quot;number&quot;&gt;40&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload = &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;CategoryType&quot;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&quot;SiteHome&quot;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;ParentCategoryId&quot;&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;CategoryId&quot;&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;808&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&quot;PageIndex&quot;&lt;/span&gt;:i,&lt;span class=&quot;string&quot;&gt;&quot;ItemListActionName&quot;&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&quot;PostList&quot;&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    r = requests.post(posturl,data = payload)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    bs = BeautifulSoup(r.text,&lt;span class=&quot;string&quot;&gt;&quot;html.parser&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    View = bs.&lt;span class=&quot;keyword&quot;&gt;findAll&lt;/span&gt;(attrs = &amp;#123;&lt;span class=&quot;string&quot;&gt;&#39;class&#39;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;article_view&#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;class&#39;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;post_item_foot&#39;&lt;/span&gt;&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    strallview = str(View)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    viewcountsmatch = re.&lt;span class=&quot;keyword&quot;&gt;findall&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&#39;阅读\(\d+\)&#39;&lt;/span&gt;,strallview)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    viewdaymatch    = re.&lt;span class=&quot;keyword&quot;&gt;findall&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&#39;发布于 ....-\d+-\d+&#39;&lt;/span&gt;,strallview)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(viewcountsmatch)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(viewdaymatch)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; j in range(len(viewcountsmatch)):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vcm = viewcountsmatch[j]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vcm = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;阅读\(&#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;,vcm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vcm = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;\)&#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;,vcm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(vcm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vc = &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;(vcm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(vc &amp;gt; &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vdm = viewdaymatch[j]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vdm = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;发布于 &#39;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;,vdm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vdm = vdm.split(&lt;span class=&quot;string&quot;&gt;&#39;-&#39;&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(vdm)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ans = ZellerFomula(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;(vdm[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]),&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;(vdm[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]),&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;(vdm[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(ans)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ass = &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;(weight*vc)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt;(str(ass)+ &lt;span class=&quot;string&quot;&gt;&#39; &#39;&lt;/span&gt; +str(vc))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        daysum[ans] += ass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;count&lt;/span&gt;[ans] += &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i in range(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    f.&lt;span class=&quot;keyword&quot;&gt;write&lt;/span&gt;(str(daysum[i])+&lt;span class=&quot;string&quot;&gt;&#39; &#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    f.&lt;span class=&quot;keyword&quot;&gt;write&lt;/span&gt;(str(&lt;span class=&quot;keyword&quot;&gt;count&lt;/span&gt;[i]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    f.&lt;span class=&quot;keyword&quot;&gt;write&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&#39;\n&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;f.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这代码写了很久，主要python很久没碰也不熟悉了。&lt;/p&gt;
&lt;h2 id=&quot;运行结果与分析&quot;&gt;&lt;a href=&quot;#运行结果与分析&quot; class=&quot;headerlink&quot; title=&quot;运行结果与分析&quot;&gt;&lt;/a&gt;运行结果与分析&lt;/h2&gt;&lt;p&gt;然后我们运行就可以爬了，耗时大约40+秒，结果如下：&lt;/p&gt;
&lt;p&gt;1.剔除版本数据&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo2.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;每行前面是161篇文章中星期1~7的文章访问总量，后面是文章数量。不算3000+访问以上的文章总数3104篇，贡献访问量1573399。&lt;/p&gt;
&lt;p&gt;2.未剔除版本&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo3.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;文章总数3220 = 161 x 20篇，贡献访问量2176232.&lt;/p&gt;
&lt;p&gt;由上可以看出，3000+访问以上的较优质文章116篇，占比3.6%，其贡献的访问量为602833，占比27.7%，这也是预料之中的。&lt;/p&gt;
&lt;h2 id=&quot;图表&quot;&gt;&lt;a href=&quot;#图表&quot; class=&quot;headerlink&quot; title=&quot;图表&quot;&gt;&lt;/a&gt;图表&lt;/h2&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo4.png&quot; alt=&quot;&quot;&gt;  &lt;/center&gt;&lt;br&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo5.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;&lt;br&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo6.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;&lt;br&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo7.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;由图可得，两种方式总体上的差距并不大，从发文数量上看，周一发文最多，可能是大家都上班了，开始新一周的工作使然。随后周二到周四发文数量略有波动，但是都差不太多，并且比周一少。到周五由于放假了，文章数量也相应减少。到周末两天发文数量就有了很大下降，这也是预料之中。&lt;/p&gt;
&lt;p&gt;从文章访问量来看，周一达到最大，随后又以较周一低的水平波动，到周末达到低谷，一大原因也是由于文章数量的减少。&lt;/p&gt;
&lt;p&gt;从平均访问情况来看，周一至周五的平均访问量普遍比周末稍高一点，印证了结论“工作日发文要比周末发文平均访问量多”，但是并没有多太多，其中周一达到最高峰，随后有波动，到周日有一个反弹，说明“周一效应”还是有一点的。&lt;/p&gt;
&lt;p&gt;两幅图的有些显著的不同就是访问量来看，剔除3000+文章以后，周二的访问量有10W+的显著下降，这是否说明周二的时候高质量文章的访问在急速增长的原因呢。&lt;/p&gt;
&lt;h2 id=&quot;补充&quot;&gt;&lt;a href=&quot;#补充&quot; class=&quot;headerlink&quot; title=&quot;补充&quot;&gt;&lt;/a&gt;补充&lt;/h2&gt;&lt;p&gt;后来我发现光考虑篇均访问还不全面，因为周一即使篇均访问较高，但是它的文章数也是很大的，所以周一的文章必然会很快被覆盖过去，所以这里有一个性价比的问题，于是我又算了一项指标，即篇均访问与当日文章数量之比，底数越大小即文章数量越小，越晚被覆盖，曝光率越大，篇均访问越大自然带来的效应越大。所以有了下面这张图：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/zhoumo8.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;事实证明，性价比最高的发文日期居然是发的很少，访问很少的周末！&lt;/p&gt;
&lt;h2 id=&quot;后续工作&quot;&gt;&lt;a href=&quot;#后续工作&quot; class=&quot;headerlink&quot; title=&quot;后续工作&quot;&gt;&lt;/a&gt;后续工作&lt;/h2&gt;&lt;p&gt;虽然本次挖掘3220篇文章数据较小，感觉还是可以从速度方面进行优化的。&lt;br&gt;权重也是我自己简单设计的，这方面也可以进一步优化。&lt;br&gt;欢迎大家提出意见与建议。&lt;/p&gt;
&lt;h2 id=&quot;结论与启示&quot;&gt;&lt;a href=&quot;#结论与启示&quot; class=&quot;headerlink&quot; title=&quot;结论与启示&quot;&gt;&lt;/a&gt;结论与启示&lt;/h2&gt;&lt;p&gt;所以说，如果你想要让你的文章获得更多的访问量，获得更大的影响力，尽量在工作日发文吧。当然，我前面说过，这些都只是非系统性因素，俗话说，打铁还需自身硬，提高自己文章的质量和水平才是获得更大文章影响力的决定性因素。希望广大园友能够致力于发布质量更高的文章，共同构建一个属于我们的优质的博客园。&lt;br&gt;本文就是上星期四晚上写就的，一直到现在才发，试下效果。事实是写完文章很难忍住不发，哈哈。&lt;/p&gt;
&lt;p&gt;同样，爬取博客园只是为了学习之用，无其他目的，望理解。感谢韩子迟的工作。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文是一片老文，用Python做了一个简单的数据分析，2016年1月发表在&lt;a href=&quot;http://www.cnblogs.com/whatbeg/p/5127850.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;老博客&lt;/a&gt;上，在整理旧
    
    </summary>
    
      <category term="数据科学 | Data Science" scheme="http://whatbeg.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-Data-Science/"/>
    
    
      <category term="Python" scheme="http://whatbeg.com/tags/Python/"/>
    
      <category term="数据分析" scheme="http://whatbeg.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>那不平凡的2016</title>
    <link href="http://whatbeg.com/2016/12/31/annualsummary2016.html"/>
    <id>http://whatbeg.com/2016/12/31/annualsummary2016.html</id>
    <published>2016-12-31T02:09:52.000Z</published>
    <updated>2017-01-02T06:22:49.828Z</updated>
    
    <content type="html">&lt;h2 id=&quot;引子&quot;&gt;&lt;a href=&quot;#引子&quot; class=&quot;headerlink&quot; title=&quot;引子&quot;&gt;&lt;/a&gt;引子&lt;/h2&gt;&lt;p&gt;光阴荏苒，似白驹过隙，又到了新的一年即将到来的时候，事务稍缓，得闲坐下来好好撸一下这篇年终总结，回顾一下今年这有生以来算是最不平凡的一年。说她不平凡自有不平凡的理由，今年算是人生中的一个关键转折点，从一个状态，经过中间状态，到达新的状态，收获很多，也失去了不少，有欢乐，有悲伤，有痛苦，有涅槃重生，有胜利的喜悦，有失败的自责，发生了许许多多的事情，明白了许许多多的道理，自己评价起来，今年才是自己真正成为一个“成年人”的一年。所以说，鉴于今年真的发生了很多事，所以可能篇幅会比较长，闲言少叙，进入常规的流水账时间。&lt;/p&gt;
&lt;h2 id=&quot;关于2016&quot;&gt;&lt;a href=&quot;#关于2016&quot; class=&quot;headerlink&quot; title=&quot;关于2016&quot;&gt;&lt;/a&gt;关于2016&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1月&lt;/strong&gt;： 1月份属于刚刚考完研，全面闲下来的时候，这个月也到了学期末，基本就是准备毕业设计开题，然后闲着，闲的没事，只能继续回到图书馆，看看闲书，记得那段时间去图书馆五楼，简直是空空荡荡，跟考研前的人满为患对比起来，会产生一种人走茶凉的感觉。即便如此，也只能忍着继续看，这段时间看了两本以前早就想看的书，一本是卢梭的《忏悔录》，另一本是梭罗的《瓦尔登湖》，在&lt;a href=&quot;http://www.cnblogs.com/whatbeg/p/5189146.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;【2016读书】1月读书笔记&lt;/a&gt;中写了一点札记。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2月&lt;/strong&gt;： 2月份就是寒假期间了，寒假期间也一直在看《瓦尔登湖》，然后就在家里跟朋友们聚聚，等待考研结果，最后在正月初九这一天成绩公布，373，还挺高的，大大出乎自己的意料，同时也感到很欣慰，也知道自己真的很可能要走上研究生的道路了，那时候就跟家里说，再等我三年，家里也都很支持我，关于读书的事情我从来遇不到阻力，我真的很幸运。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3月&lt;/strong&gt;： 3月回到学校，准备复试，要看两科很久没碰的学科，有点捉襟见肘，最后3月14号去复试，机试只做出一题，面试感觉也答得不是很理想，结果20多号出成绩，复试成绩竟然还逆袭到第一，有点不可思议，感觉可能是哪里搞错了，也就没管了。3月份为了毕设，开始接触机器学习，数据挖掘方面的东西，看的是周sir的《机器学习》，当时也没有全部看懂，略看了一些，没想到上研究生后还一直在用这方面的知识，感谢自己当初选了一个机器学习方面的毕设题目，虽然，现在看来，当时的毕设做得真的是水！两个字，太水。现在看来，那时做的毕设简直是连机器学习的思想都没有摸到，就在那里瞎做，当然这也是自学的弊端，周围完全没有氛围，自己自学能力也有限，所以就糊弄一般地在做。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4月&lt;/strong&gt;： 4月份就看看剧，然后做做毕设，看看书，4月初开始用hexo搭了自己的独立博客，&lt;a href=&quot;http://whatbeg.com&quot;&gt;whatbeg.com&lt;/a&gt;，新博客的诞生标识着自己的有了一块独立自主的表达自己思想，分享一些技术，心得等等的领地了，还是很开心的。然后一直在摸索这个东西，现在已经比较熟练的摆弄自己的博客了。然后就没什么印象了，过得比较庸庸碌碌。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5月&lt;/strong&gt;： 5月的最大的事情就是面试实习了，先是面试了一家当地的小公司的java，被拒了，然后在学校论坛上看到了北京一家上市公司的python数据分析师招聘贴，就给HR发了一封邮件，结果还被通知面试了，就只需要视频面试，然后面试的时候题目还比较简单，最后不久就收到了录取通知，给的还不能算少，说起来也是缘分，有时候幸福来得就是这么突然，找工作除了实力以外，真的还看一点运气，又一次觉得自己很幸运。5月份开始在做一份兼职，赚点小外快，反正也是闲的，然而6月的毕业旅行把所有外块钱花的一干二净还倒贴了不少。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6月&lt;/strong&gt;： 6月开始考虑毕业的事情了，这期间完成了毕设的答辩，毕业旅行，以及各种毕业的后期工作。毕业旅行从6月14号起，到6月19号结束，期间去了西安，后来转重庆，简要说一下对这两个地方的印象就是，西安biangbiang面很好吃，可能是多朝古都的原因，感觉文化底蕴比较浓厚，西安人有着独特的阳刚之气和自信。重庆的话，玩的地方不多，没地方去了我们居然去了科技馆玩，，也是醉了，但是真的，火锅店超多！吃了好几顿火锅，虽然感觉都是那个味道，但是现在想想火锅还是很馋，不说了，饿了。。^~^ 6月底跟同学们聚一聚，就散了，有的留下，有的离开，相处了四年的同学，真到离别时总是有点不舍，但是也没办法，希望早日再聚吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7月&lt;/strong&gt;： 7月初正式落地北京，开始实习生涯，开始找房子真的很难找的，当然，贵的还是容易找的，但是不想在住上面花费太多钱，最终在论坛上找到了一个还比较靠谱的住的地方，具体就不细说了，也结实了几个同在北京工作或者考研的朋友，晚上回去就聊聊，也是挺惬意，这就是北京，你总能找到许多跟你一起奋斗的年轻人。住在人大里面，相当于在人大读了两个月书一般，感觉每个大学都差不多，设施差不多，人也差不多，由于是放假期间，也看不到多少学习氛围，有的只是一些考研人或者参观者的身影。7月份的工作比较简单，基本就是想解决方案，给你一个问题，让你把它解决，当然不需要做成实际的东西，所以很轻松，很多时间花在了看书学习上，因为发现自己在数据分析的解决方案这上面懂得太少，数学上也是一个短板，最后在与几位老师的交流中，顺利地做完了两个任务，自我感觉做得一般。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8月&lt;/strong&gt;： 8月份就开始有具体的活了，基本就是重构一个数据展示平台，我负责底层数据的提取整理，将多个业务线的数据整合到一起，这期间有什么不懂的就问老大，老大也是很耐心，常常在下班后跟我们聊一聊，跟他学到了不少技术上的东西以及职业规划上面的东西，而且老大不仅很厉害，而且很努力，基本每天第一个到，然后很晚也不带走的，总而言之，老大是一个我很敬佩的人。实习时候的几个一起进来的小伙伴们也都非常好，大家建立了非常深厚的友谊，真的感觉在这个团体很开心，公司的待遇，福利，比如无限的零食，各种吃大餐，还有团建免费旅游等等，真是没的说，所以整个7,8月份实习阶段的感觉就是一个字：爽~。这期间，每逢周末就没闲着，到处去玩，整个两个月下来，基本玩遍了大半个北京，综合感觉，北京能玩的地方还是很多的，而且每个地方都有很多人，从来不缺人。。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9月&lt;/strong&gt;： 9月份就入学啦，又进入了一个新的阶段—研究僧阶段，可以说又走上了学校的培养模式道路，也即上课，作业，考试这么一条路子，最大的区别就是研究生的作业会更加偏重实践，偏重编程，难度会更大，但是真正做下来都不会没有收获。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10月&lt;/strong&gt;： 继续学习，10月份爷爷大病了一场，10月底回家一趟，给奶奶祝寿。怎么也没有想到这次回家就是最后一次见到爷爷了。我们的成长，伴随着的是家人的老去，对“子欲养而亲不待”有了一种深切的体会，另一个体会就是真的要关注自己的身体健康，身体是革命的本钱，没有一个好的身体，什么都是空的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11月&lt;/strong&gt;： 10月份开始做了一个竞赛， 11月份也主要在做这个竞赛，以及一些作业啥的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12月&lt;/strong&gt;： 12月13号，回家送走了爷爷，真的就再也见不到了，有生以来第一次经历亲人的离世，心情百般复杂，却又说不出来。略去。&lt;br&gt;19号回学校，说竞赛进决赛了，于是24,25号去青岛参加了一个决赛，成绩不怎么样，只能说自己还太弱了，在机器学习，数据分析类的这种竞赛中，我们讨不到便宜，自己这方面的知识技能也有限，总之，能进决赛就不错了，玩的开心就好。&lt;/p&gt;
&lt;p&gt;流水账【完】&lt;/p&gt;
&lt;p&gt;总的来说，今年的大致经历就是这样子，发生了很多事，不自禁地想把他们理一下，觉得自己今年最大的成长就是自信心的增长，关键在于自我在逐渐建立，自我的认同在逐渐建立，不再那么强烈地收到别人眼光的控制，逐渐有了一套自己坚信的信念，自己的一套价值观，人生观，世界观，当然，有时候，“我”的执念还是会卷土重来，但是我一定会尽可能把它扼杀在襁褓中。所以，2017年要做的还是继续进行自我的建立，完善自身，不管是信念，做人和做事等方面。&lt;/p&gt;
&lt;h2 id=&quot;关于计划的完成情况&quot;&gt;&lt;a href=&quot;#关于计划的完成情况&quot; class=&quot;headerlink&quot; title=&quot;关于计划的完成情况&quot;&gt;&lt;/a&gt;关于计划的完成情况&lt;/h2&gt;&lt;p&gt;去年的总结&lt;a href=&quot;http://whatbeg.com/2016/04/05/annualsummary2015.html&quot;&gt;《象牙塔里的2015》&lt;/a&gt;提出了以下的计划：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.加大自己专业能力的提升力度，适当减少专业无关书籍的阅读，选择高质量的作品阅读。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第一条算是做了，花了很多时间在专业上，但是从另一个角度说，也是不得不如此，任务使然，当然也有自己的探索，总体感觉深度还不够，都没有一个深入的理解和领会，还浮于表面，看见师兄们对一些系统方面举一反三，深入剖析的时候，就感觉这才是expert的正确打开方式。&lt;br&gt;在做第一条的时候，第二条也没有减少，无关书籍还是读了很多，但是要说无关也有关，在精神层面上得到了一些滋养，这也是必要的。在选择高质量作品方面，今年有了一些经验了，稍稍懂了一点判断，比如某本书是不是好书，是不是感兴趣的书，是不是浪费精力得不到收获的书，是消遣的书还是干货书，等等等等，如何如何。&lt;br&gt;希望来年继续努力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.知行合一。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;总的来说，这一点比较宽泛，不去了解下王阳明的学说，我不好意思说我懂“知行合一”，也就不好判断自己是否就“知行合一”了，于是只能判断其另一个版本，“理论与实践相结合”，这样说来感觉谁都在做，一直在做。所以，继续践行“知行合一”吧，其实就是不断强化理论，然后与实践相结合，又不断强化了实践，实践反过来又可以推动理论的深刻掌握或者创造，太绕了，不说了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3.简化生活。 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以说，“简约生活”是我今年一直奉行的一条原则，也努力在简化生活，还是引用那句话：&lt;br&gt;&lt;strong&gt;&lt;code&gt;真正自由的人总能给人以苗条潇洒的印象，那正是因为他们的精神与内心抛弃了多余的东西。&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;我认为，主要从两个方面践行这条原则，一是减少自己的物质需求，克制自己的物质需求，买东西时，先想一下，这件东西，是不是真的有用？是不是长久有用？在购物车里待几天是不是就不会想买了？等等等等，二是内心不断抛弃多余的东西，首要抛弃的就是一个“我”，心如止水，乱则不明，执念于“我”，则心乱而不明。&lt;br&gt;希望来年继续践行~&lt;/p&gt;
&lt;h2 id=&quot;关于读书&quot;&gt;&lt;a href=&quot;#关于读书&quot; class=&quot;headerlink&quot; title=&quot;关于读书&quot;&gt;&lt;/a&gt;关于读书&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/whatbeg/ReadList/blob/master/ReadList.md&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;2016 Read List&lt;/a&gt;&lt;br&gt;今年大抵的书单如上，可以看到，今年读文学作品和技术类的书籍比较多，历史，艺术等类则稍有涉猎。明年也看情况了，想读什么就读什么，但是有本书明年打算读一下，《禅与摩托车维修技术》，阮大神推荐，有机会还是想把《红楼梦》看完，红楼梦里面的语言着实细腻有味，读来如品甘浆，好像甄嬛传里面的对话语句好多是与红楼梦里面的相似的，莫不是模仿过去的？&lt;/p&gt;
&lt;p&gt;有几本印象很深的书，以及年中写过的一篇文章： &lt;a href=&quot;http://whatbeg.com/2016/05/02/talkread.html&quot;&gt;《当我谈阅读时我谈些什么》&lt;/a&gt;，稍稍推荐一下。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;梭罗《瓦尔登湖》&lt;/strong&gt;&lt;br&gt;简约生活指导手册一般的书，《瓦尔登湖》对简约生活的倡导我现在都时时铭记于心，可以说对我人生观的形成有着巨大的帮助。这是今年第一本要推荐的书。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;欧文·斯通《梵高传》&lt;/strong&gt;&lt;br&gt;感觉非常震撼，很少认认真真地把一本厚厚的传记小说读完了，这本真是有着独特的吸引力让人爱不释手。这是今年第二本要推荐的书。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;罗素《幸福之路》&lt;/strong&gt;&lt;br&gt;然后就是罗素先生的幸福之路，第一次读罗素先生的著作，就被这本书给吸引到了，书中主要关于“怎样获得幸福”进行了探讨，提出了很多有意思的观点。值得一看。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;吴军《数学之美》&lt;/strong&gt;&lt;br&gt;这本书是一本非常好的科普书，将计算机行业里面一些涉及到的数学领域的知识用通俗的语言讲述出来，易懂却又不失启发，IT人推荐读一读。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;叔本华《叔本华美学随笔》&lt;/strong&gt;&lt;br&gt;还没全看完，但是看了其中几篇我就毫不犹豫的买了一本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;王小波《王小波文集》&lt;/strong&gt;&lt;br&gt;这本书有趣有料，充满着王小波式的黑色幽默，有直言不讳，又有拐着弯骂人骂事，爱不释手的一本书。但是不是所有人都喜欢这种风格，所以自我量度吧。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;一些思考&quot;&gt;&lt;a href=&quot;#一些思考&quot; class=&quot;headerlink&quot; title=&quot;一些思考&quot;&gt;&lt;/a&gt;一些思考&lt;/h2&gt;&lt;p&gt;不知不觉就到年底，许许多多的事恍如发生在昨日。&lt;br&gt;这一年，整个世界发生了巨大的变化，互联网与IT行业也风云迭起。&lt;br&gt;这一年，AlphaGo在堪称人脑游戏巅峰的围棋领域屡战告捷。&lt;br&gt;这一年，Pokémon Go称霸大洋彼岸，虚拟游戏与现实场景没有了界限。&lt;br&gt;这一年，双十一的天猫，用20秒的时间，实现了“挣它一个亿”的小目标。&lt;br&gt;这一年，美帝的黑客，用网络技术，把即将坐上总统交椅的希拉里掀翻在地。&lt;br&gt;这一年，深度学习，人工智能，区块链，小程序占据了各大IT网站的主要版面。&lt;br&gt;我们的行业正在以惊人的速度发展，几乎每周都有新技术出现，新知识以幂指数增加，几乎每三年就要翻上一番。需要学习的东西多到令人发指。我们的同路人越来越多，有经验的领路人却越来越少：世界上程序员的数量每五年会增加一倍，但太多人都无暇思考与沉淀，在一项技术过时之前，又开始忙着使用另一项新技术……&lt;br&gt;在风云变幻的年代，我们应该如何自处？如何把握时代的脉搏？我们是不可能掌握每一项新技术的，只能够保证在关键的地方不落后，然后找到自己的不可代替点。&lt;br&gt;这一年，收获了许多成长，不再苛求他人的目光，认真做事，踏实做人。&lt;br&gt;这一年，看了许多风景，走过了许多&lt;a href=&quot;http://7xsl28.com1.z0.glb.clouddn.com/footprint170102.png&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;远方&lt;/a&gt;，方知最美的地方是故乡，最美的人是自己的亲人，身边人。&lt;br&gt;这一年，也犯过不少错误，方知需思而后行，思而后言，思不足则少言，甚至不言，凡事应从容不迫，急躁则滋生鲁莽。&lt;br&gt;这一年，也曾被一些小毛病困扰，这肯定是身体的反抗，提醒我自己的身体要常挂在心上，不能过劳，不要给自己太大压力，也不能过分纵容自己的一些欲望和习惯。&lt;/p&gt;
&lt;h2 id=&quot;关于计划&quot;&gt;&lt;a href=&quot;#关于计划&quot; class=&quot;headerlink&quot; title=&quot;关于计划&quot;&gt;&lt;/a&gt;关于计划&lt;/h2&gt;&lt;p&gt;又到了计划时间，在这个关头，总得立一立小目标，想一想自己以后的路大致该怎么走。&lt;br&gt;大致计划如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;对自己的课题进行深入研究，把论文发掉&lt;br&gt;定期运动，注意健康饮食&lt;br&gt;简约生活&lt;br&gt;Continue Feeling, Thinking, Reading and Writing&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;计划先列这几个，其他的就是增强型的，反正都是要做的，就不作为计划了。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;时光飞逝，现在的我，坐在实验室，等待着本学期最后一门考试，未来的研究方向还没有确定，师兄们有早早把论文发掉的，也有研三了还没发掉的，不知道自己会不会成为那个幸运的人呢？不管怎么样，还是保持一个良好的心态吧，毕竟，持续地焦虑根本不能解决问题，踏踏实实把事做了才是正道。就这样吧，2017，开始新的篇章！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;引子&quot;&gt;&lt;a href=&quot;#引子&quot; class=&quot;headerlink&quot; title=&quot;引子&quot;&gt;&lt;/a&gt;引子&lt;/h2&gt;&lt;p&gt;光阴荏苒，似白驹过隙，又到了新的一年即将到来的时候，事务稍缓，得闲坐下来好好撸一下这篇年终总结，回顾一下今年这有生以来算是最不平凡的一年。说
    
    </summary>
    
      <category term="成长之路 | Biography" scheme="http://whatbeg.com/categories/%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF-Biography/"/>
    
    
      <category term="Summary" scheme="http://whatbeg.com/tags/Summary/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘综合实践</title>
    <link href="http://whatbeg.com/2016/12/29/dataminingsynthesize.html"/>
    <id>http://whatbeg.com/2016/12/29/dataminingsynthesize.html</id>
    <published>2016-12-29T06:08:18.000Z</published>
    <updated>2016-12-29T06:17:49.637Z</updated>
    
    <content type="html">&lt;p&gt;本文描述了几个月以来所做的一些数据挖掘实践，综合总结一下，形成此文，也对本学期数据挖掘课程做一个总结。&lt;br&gt;代码Github地址： &lt;a href=&quot;https://github.com/whatbeg/DataMiningTasks&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/whatbeg/DataMiningTasks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;TF-IDF-Feature-Extraction-TF-IDF特征提取）&quot;&gt;&lt;a href=&quot;#TF-IDF-Feature-Extraction-TF-IDF特征提取）&quot; class=&quot;headerlink&quot; title=&quot;TF-IDF Feature Extraction (TF-IDF特征提取）&quot;&gt;&lt;/a&gt;TF-IDF Feature Extraction (TF-IDF特征提取）&lt;/h2&gt;&lt;h3 id=&quot;数据&quot;&gt;&lt;a href=&quot;#数据&quot; class=&quot;headerlink&quot; title=&quot;数据&quot;&gt;&lt;/a&gt;数据&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;数据为数据集 ICML&lt;/li&gt;
&lt;li&gt;采用 Python 2.7.10 和 Windows10 系统 作为编程环境&lt;/li&gt;
&lt;li&gt;输出的结果名为 “类名_RESULT.txt”，位于与类目录同级的目录下。&lt;/li&gt;
&lt;li&gt;结果数据包含 N 条， N 为此类中文章数目，在每条输出结果中，第一行为文章名字，然后紧跟着的是词的 TF-IDF 值向量，由于值向量稀疏，所以做了压缩，即以“序号： TF-IDF 值”的表示方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;步骤&quot;&gt;&lt;a href=&quot;#步骤&quot; class=&quot;headerlink&quot; title=&quot;步骤&quot;&gt;&lt;/a&gt;步骤&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;首先集合所有文章，得到他们的路径&lt;/li&gt;
&lt;li&gt;然后将所有文章分词，将无关或者非法字符用空格替换，然后采用 NLTK 的 word_tokenize 方法进行&lt;br&gt;分词， 然后用 NLTK 的 SnowballStemmer 进行词干提取，然后将单词进行小写化， 通过字典去重（存&lt;br&gt;成字典 key），然后去除一些无关词，数字以及停用词，停用词选用了网上一个版本的停用词，约 900&lt;br&gt;个停用词。&lt;/li&gt;
&lt;li&gt;然后将所有词排序，编号，后续输出时以编号代替词，而不需写出词。&lt;/li&gt;
&lt;li&gt;然后循环处理每个类（每种论文的目录），对这个目录下的所有文章，对每篇文章的词算出他们的TF 和 IDF 值，得到 TF-IDF 值，存储到这个类这篇文章的结果数据中。&lt;/li&gt;
&lt;li&gt;TF 词频采用的计算方法为： TF = 词在文章中出现次数 / 文章总词数&lt;/li&gt;
&lt;li&gt;IDF 计算方法为： IDF = log(总文章数 / 此词出现的文章数目)&lt;/li&gt;
&lt;li&gt;处理完每个类，结束。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;结果&quot;&gt;&lt;a href=&quot;#结果&quot; class=&quot;headerlink&quot; title=&quot;结果&quot;&gt;&lt;/a&gt;结果&lt;/h3&gt;&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask1-1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;


&lt;h3 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;p&gt;TF，IDF 的计算方法多种多样，本文采用的方法中，最终结果的TF-IDF数值上偏小，在保证含义的情况下可以采用其他方法，使 TF-IDF大致为一个正常值，以便更好地比较。用NLTK包的stemmer提取词干的时候难免会有一些提取的错误，这是由于词干提取并非完美的缘故，由于这个缘故，可以不进行词干提取，这样可以保持所有的信息，但是缺点就是会有多种变形词，单词数会增加 1/4到1/3，导致矩阵增大。&lt;/p&gt;
&lt;h2 id=&quot;Dimensionality-Reduction-（降维方法）&quot;&gt;&lt;a href=&quot;#Dimensionality-Reduction-（降维方法）&quot; class=&quot;headerlink&quot; title=&quot;Dimensionality Reduction （降维方法）&quot;&gt;&lt;/a&gt;Dimensionality Reduction （降维方法）&lt;/h2&gt;&lt;h3 id=&quot;任务&quot;&gt;&lt;a href=&quot;#任务&quot; class=&quot;headerlink&quot; title=&quot;任务&quot;&gt;&lt;/a&gt;任务&lt;/h3&gt;&lt;p&gt;本部分描述实现降维的三种方法，分别是 PCA， SVD 以及流形学习中的 ISOMAP 算法，其中 ISOMAP 算法还需调用 MDS（ Multiple Dimensional Scaling 多维缩放），并且对这三种算法在两个不同规模的数据集上进行了测试。&lt;/p&gt;
&lt;h3 id=&quot;PCA&quot;&gt;&lt;a href=&quot;#PCA&quot; class=&quot;headerlink&quot; title=&quot;PCA&quot;&gt;&lt;/a&gt;PCA&lt;/h3&gt;&lt;p&gt;PCA 算法的原理这里不做详细描述，只写明实现过程，首先将训练数据集中心化，然后计算训练数据集的协方差矩阵，对此协方差矩阵 C 做特征值分解，可以得出 C 的所有特征值和对应的特征向量，选取最大的k（降维后的维度数）个特征值和其对应的特征向量，即可得到高维到低维的映射矩阵 W。&lt;br&gt;PCA 算法伪代码如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/PCA1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h3 id=&quot;SVD&quot;&gt;&lt;a href=&quot;#SVD&quot; class=&quot;headerlink&quot; title=&quot;SVD&quot;&gt;&lt;/a&gt;SVD&lt;/h3&gt;&lt;p&gt;SVD 算法与 PCA 算法很相似，并且可以使用SVD来计算PCA，它们的唯一区别就是SVD并不对训练样本集进行中心化，使各个维度的均值为 0，而是直接对训练集样本矩阵做 SVD分解，得出排序后的特征值和特征向量矩阵，取前k个特征值对应的特征向量即可组成高维到低维的映射矩阵。&lt;br&gt;SVD 算法伪代码如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/SVD1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;


&lt;h3 id=&quot;ISOMAP&quot;&gt;&lt;a href=&quot;#ISOMAP&quot; class=&quot;headerlink&quot; title=&quot;ISOMAP&quot;&gt;&lt;/a&gt;ISOMAP&lt;/h3&gt;&lt;p&gt;ISOMAP 是一个非线性降维算法，全称 Isometric Mapping，等度量映射，重点在于高维空间的测地线距离在低维空间的保持。算法流程如下：&lt;br&gt;（a） 计算样本集（测试集和训练集）的欧式距离&lt;br&gt;（b） 对于每个样本，取 4 个最近的样本，建立连边&lt;br&gt;（c） 用最短路算法算出两两点间的最短距离，这里会出现一个整个图可能形成多个&lt;br&gt;连通分量而导致不连通的问题，这样的话令不连通点间的距离为 0。&lt;br&gt;（d） 将整个图的距离矩阵作为 MDS 的输入，直接得出低维空间的样本表示，包括&lt;br&gt;测试集和训练集。&lt;br&gt;ISOMAP 算法伪代码如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/ISOMAP1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;最后的测试是讲高维样本映射到低维空间，然后运行 1-NN 算法对测试数据进行分类。&lt;/p&gt;
&lt;h3 id=&quot;数据-1&quot;&gt;&lt;a href=&quot;#数据-1&quot; class=&quot;headerlink&quot; title=&quot;数据&quot;&gt;&lt;/a&gt;数据&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;数据 sonar 和 splice 数据集， sonar 是小数据集， splice 是较大的数据集。&lt;/li&gt;
&lt;li&gt;采用 Python 2.7.10 和 Windows10 系统 作为编程环境&lt;/li&gt;
&lt;li&gt;输出的结果将会被组成一个表格在下文给出。&lt;/li&gt;
&lt;li&gt;结果数据包括在不同数据集下和不同的降维后维度数 k 的条件下，得到的最后 1NN 分类结果的准确率。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;几点细节&quot;&gt;&lt;a href=&quot;#几点细节&quot; class=&quot;headerlink&quot; title=&quot;几点细节&quot;&gt;&lt;/a&gt;几点细节&lt;/h3&gt;&lt;p&gt;（a） 在实现 ISOMAP 的时候， 4NN 地建立邻接图很有可能会形成多个联通分量，这时候有两种解决方法，一种是增大 Nearest Neighbor 的数量，直到联通，但是这种方法有所不妥， NN 越大，越有可能形成“短路”的现象，即明明两个点距离很远（他们的连边跨越了不可达区域），还是会将它们连起来，距离为其欧氏距离，这样破坏了流形的性质，可能造成结果的偏差；另一种方法使不连通的两两联通分量，各自取一个点使这两点距离最近，将这两点连边，这样就可以使这两个连通分量联通，这种方式大大降低了“短路”的概率，小小的不足就是会有一笔计算开销，不过经过测试，这种开销的增加可以近乎忽略。&lt;/p&gt;
&lt;p&gt;详细过程如下：&lt;/p&gt;
&lt;figure class=&quot;highlight markdown&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;1. &lt;/span&gt;得到 4NN 图，通过 dfs 对图中点进行着色，两点之间如果可以连通则着同一色，最后得到的颜色数就是联通分量数。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;2. &lt;/span&gt;找两个距离最近的联通分量合并，将颜色赋为相同颜色&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;3. &lt;/span&gt;重复 2 直到全部为一个联通分量&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用了贪心的思想，在算法的正确性上，可以在保证“短路”概率最小的前提下将非连通图变成连通图。&lt;/p&gt;
&lt;p&gt;（b） ISOMAP 计算任意两点之间的最短距离时，在大数据集 splice（ 3000+条）下，python计算效率明显低下， 测试下发现需要 8 个小时左右！ 于是在代码中嵌入了 C 程序的执行，将时间缩短到百秒级别，传参采用文件形式。&lt;/p&gt;
&lt;h3 id=&quot;结果-1&quot;&gt;&lt;a href=&quot;#结果-1&quot; class=&quot;headerlink&quot; title=&quot;结果&quot;&gt;&lt;/a&gt;结果&lt;/h3&gt;&lt;p&gt;测试结果如下，不同数据集，不同维度 k 下不同算法进行 1NN 分类的准确率见下图。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask2-1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h3 id=&quot;代码解释&quot;&gt;&lt;a href=&quot;#代码解释&quot; class=&quot;headerlink&quot; title=&quot;代码解释&quot;&gt;&lt;/a&gt;代码解释&lt;/h3&gt;&lt;p&gt;其中 DimensionalityReduction.py 实现三种降维算法，floyd.c, floyd.exe, floyd.o 为 C 语言实现的 Floyd 算法，供 python 调用，graph.txt 为 python 往 C 传的参数。graph_floyded.txt 为 C 对图运行完 floyd 算法后传回的图参数。然后接下来是 4 个数据集和测试集。最后是 Test.py 测试程序。&lt;/p&gt;
&lt;h3 id=&quot;思考-1&quot;&gt;&lt;a href=&quot;#思考-1&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;python 调用 C 有一套接口，如 ctypes, cython 等，可以将 floyd 算法或者 dijkstra 算法直接嵌入到 python 程序中，可以免去文件传参的开销，加快运行速度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MDS 中，对内积矩阵 B 进行特征分解的时候，明明 B 是实对称矩阵， 采用numpy.linalg.eig()函数计算还是会出现复数特征值的情况，尽管他们的虚部或正或负都很小，即使 B = 0.5(B+B’)这样的处理之后还是会出现，后来采用了eigh()函数，即计算埃尔米特矩阵或者对称矩阵特征值和特征向量的专用函数，则分解出来的都是实数。所以可能是函数的问题，因为我们已经知道B是实对称的，所以直接可以用 eigh 函数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在处理 ISOMAP 邻接图不连通的情况时，不知道有没有更好的方法，在网上基本鲜有这方面的资料，不知道看到这里的读者有没有建议呢？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;最后由于能够保证联通，所以测试了建立近邻连接图的邻接个数（这里是 4）对测试结果的影响， 选了 3NN， 4NN， 5NN， 6NN 四种， 最后在发现 3NN 最差，在大数据集 splice 上， 5NN 取得了很好的效果， 6NN 次之， 4NN 再次之，但是在小数据集上，4NN 是最好的， 5NN 和 6NN 的表现就大大的变差了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以来说，最后选择了用 4NN（近邻连接图）来测试小数据集， 5NN 来测试大数据集。&lt;/p&gt;
&lt;p&gt;取得效果如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask2-2.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;p&gt;总的来说， NN 太小容易使本来很近的点却要在图中绕很远才能到，给距离带来了误&lt;br&gt;差， NN 越大则“短路”可能性又提高。&lt;/p&gt;
&lt;h2 id=&quot;Clustering-（聚类）&quot;&gt;&lt;a href=&quot;#Clustering-（聚类）&quot; class=&quot;headerlink&quot; title=&quot;Clustering （聚类）&quot;&gt;&lt;/a&gt;Clustering （聚类）&lt;/h2&gt;&lt;h3 id=&quot;任务-1&quot;&gt;&lt;a href=&quot;#任务-1&quot; class=&quot;headerlink&quot; title=&quot;任务&quot;&gt;&lt;/a&gt;任务&lt;/h3&gt;&lt;p&gt;本部分描述实现两种聚类算法，其一为K-medoids（K-中心点）算法，其二为基于谱图理论的谱聚类算法。数据集有两个，一个是小数据集 german.txt，其中有1000个样本，每个样本有24个特征，每个样本占一行，最后为该样本的标签，标签分两类，1和-1，标签用作Gini系数和Purity的计算。另一个是大数据集mnist.txt，其中包括10000个样本，每个样本有784个特征，每个样本占一行，最后为该样本的标签，标签分 10&lt;br&gt;类， 0-9。&lt;br&gt;下面简要说明两种聚类算法的流程。&lt;/p&gt;
&lt;h3 id=&quot;K-medoids-算法&quot;&gt;&lt;a href=&quot;#K-medoids-算法&quot; class=&quot;headerlink&quot; title=&quot;K-medoids 算法&quot;&gt;&lt;/a&gt;K-medoids 算法&lt;/h3&gt;&lt;p&gt;类似 K-means 算法的原理，只是聚类的中心不是所有该类所有样本的特征平均值，而是限制聚类的中心必须是该类的某一个样本，这样做的好处是可以有效避免离群点的影响，适用于异构数据等。初始找 k 个中心点，然后将每个点分到离它最近的中心点代表的类中，然后对每一类更新中心点，这样循环往复直到中心点不再变化。&lt;/p&gt;
&lt;p&gt;算法伪代码如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/KMEDOIDS1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;


&lt;h3 id=&quot;谱聚类算法&quot;&gt;&lt;a href=&quot;#谱聚类算法&quot; class=&quot;headerlink&quot; title=&quot;谱聚类算法&quot;&gt;&lt;/a&gt;谱聚类算法&lt;/h3&gt;&lt;p&gt;基于谱图理论，适用于数据是非凸的或者类似于嵌入高维空间的低维流形时。基本思路是对每个样本点，与跟它最相似的多个样本点之间连边，边的权值可以赋为相似度或者 1（两种方式），然后计算拉普拉斯矩阵 L=D-W，其中 D 为每个样本点的度2作为对角元素组成的对角矩阵，W就是刚才的距离矩阵。然后对拉普拉斯矩阵 L 进行特征分解，取最小的 k 个特征值对应的特征向量作为新的样本表示，然后对这个样本表示进行K-medoids 聚类或者 K-means 聚类等即可得到聚类结果。&lt;/p&gt;
&lt;p&gt;算法伪代码如下：&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/SPECTUALCLUSTRING.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h3 id=&quot;数据与环境&quot;&gt;&lt;a href=&quot;#数据与环境&quot; class=&quot;headerlink&quot; title=&quot;数据与环境&quot;&gt;&lt;/a&gt;数据与环境&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;数据为 german 和 mnist 数据集， german 是小数据集， mnist 是较大的数据集，数据说明见上一节。&lt;/li&gt;
&lt;li&gt;采用 Python 2.7.12 和 Ubuntu16.04 系统 作为编程环境&lt;/li&gt;
&lt;li&gt;输出的结果将会被组成一个表格在下文给出。&lt;/li&gt;
&lt;li&gt;结果数据包括在不同数据集下k-medoids算法聚类的效果，以Gini系数和Purity作为衡量依据，以及在不同数据集下和不同近邻数下 Spectral Clustering 聚类的效果，结果也以 Gini系数和 Purity 作为依据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;结果-2&quot;&gt;&lt;a href=&quot;#结果-2&quot; class=&quot;headerlink&quot; title=&quot;结果&quot;&gt;&lt;/a&gt;结果&lt;/h3&gt;&lt;p&gt;测试结果如下，不同数据集下，不同算法下进行聚类的 Purity 见图 1。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask3-1.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;


&lt;p&gt;不同数据集下，不同算法下进行聚类的 Gini 系数见图 2。&lt;/p&gt;
&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask3-2.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;


&lt;center&gt; &lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/dataminingtask3-3.png&quot; alt=&quot;&quot;&gt; &lt;/center&gt;

&lt;h3 id=&quot;思考-2&quot;&gt;&lt;a href=&quot;#思考-2&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;p&gt;纯枚举中心点替换的方法虽然说准确度高，但是速度太慢，在更大的数据集下必然很低效，可以考虑采用随机选取 r 个点对进行替换的方式，损失一点准确度，来对算法进行加速。或者也可以采用其他优化算法优化效率&lt;/p&gt;
&lt;h2 id=&quot;Training-Classifers-via-Stochastic-Gradient-Descent-（随机梯度下降）&quot;&gt;&lt;a href=&quot;#Training-Classifers-via-Stochastic-Gradient-Descent-（随机梯度下降）&quot; class=&quot;headerlink&quot; title=&quot;Training Classifers via Stochastic Gradient Descent （随机梯度下降）&quot;&gt;&lt;/a&gt;Training Classifers via Stochastic Gradient Descent （随机梯度下降）&lt;/h2&gt;&lt;p&gt;这部分详见文章： &lt;a href=&quot;http://whatbeg.com/2016/11/18/trainclassifiersviaSGD.html&quot;&gt;Training Classifers via Stochastic Gradient Descent&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Ensemble-Learning-（集成学习）&quot;&gt;&lt;a href=&quot;#Ensemble-Learning-（集成学习）&quot; class=&quot;headerlink&quot; title=&quot;Ensemble Learning （集成学习）&quot;&gt;&lt;/a&gt;Ensemble Learning （集成学习）&lt;/h2&gt;&lt;p&gt;这部分详见文章： &lt;a href=&quot;http://whatbeg.com/2016/12/01/naivebayesboosting.html&quot;&gt;谈一谈朴素贝叶斯作为基分类器的Adaboost算法 （Naive Bayes Based Adaboost）&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Association-rule-mining-（关联规则挖掘）&quot;&gt;&lt;a href=&quot;#Association-rule-mining-（关联规则挖掘）&quot; class=&quot;headerlink&quot; title=&quot;Association rule mining （关联规则挖掘）&quot;&gt;&lt;/a&gt;Association rule mining （关联规则挖掘）&lt;/h2&gt;&lt;p&gt;这部分源码见AprioriTest，实现了一下Apriori算法，具体流程不细述。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;p&gt;本文简要总结了一下数据挖掘的几个实践project，其中包括最基本的TF-IDF统计，以及降维，聚类，分类，集成学习，随机梯度下降等等，简要实现了几个数据挖掘上的基本算法，实现的比较简单，当做进一步理解算法之用，机器学习的方面远远不止这些，比如降维方法除了上述三种之外还有LLE，LE，LTSA，KPCA等等，聚类还包括层次聚类，AGNES等，以及kmeans，CLARANS等基于代表的算法，还有基于密度的方法，包括DENCLUE,DBSCAN等等，以及基于网格的方法(grid-based)包括CLIQUE等。分类方法那就更多了，SVM，LR，DT，，，一些数据挖掘比赛中用的比较多的是XGBoost，GBDT等，有时间要好好了解一下，最后集成学习中主要包括两大类算法，一种叫Bagging（Bootstrapped Aggregating）,主要通过多次采样平均，来降低variance，另一种Boosting，通过多个分类器的集成，降低bias。总之，数据挖掘课程的学习到这里就告一段落了，接下来的学习就要靠自己了，慢慢的运用，慢慢的学习吧，数据挖掘这条路，还是有很远要走的。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文描述了几个月以来所做的一些数据挖掘实践，综合总结一下，形成此文，也对本学期数据挖掘课程做一个总结。&lt;br&gt;代码Github地址： &lt;a href=&quot;https://github.com/whatbeg/DataMiningTasks&quot; target=&quot;_blank&quot; r
    
    </summary>
    
      <category term="数据科学 | Data Science" scheme="http://whatbeg.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-Data-Science/"/>
    
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop MapReduce 社交网络三角形统计</title>
    <link href="http://whatbeg.com/2016/12/02/trianglecount.html"/>
    <id>http://whatbeg.com/2016/12/02/trianglecount.html</id>
    <published>2016-12-02T03:50:09.000Z</published>
    <updated>2017-01-11T06:52:13.501Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;图的三角形计数问题是一个基本的图计算问题，是很多复杂网络分析（比如社交网络分析）的基础。&lt;br&gt;在一个随机图中三角形的期望数目大约是$\frac {4} {3} (m/n)^3$, 其中m是边数，n是点数。而在一张社会网络关系图中，我们预期其中的三角形数会远远高于随机图中的三角形数目，原因在于A,B是朋友，B,C是朋友时，A,C也是朋友/可能成为朋友的概率大于随机值。所以三角形技术能够帮助我们度量一张图看上去像社会网络的程度，也可以帮我们判断社会网络的成熟度或者社区的年龄。&lt;br&gt;目前图的三角形计数问题已经成为了Spark系统中GraphX图计算库所提供的一个算法级API。本次实验任务就是要在Hadoop系统上实现 Twitter 社交网络图的三角形计数任务。&lt;/p&gt;
&lt;h2 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述&quot;&gt;&lt;/a&gt;任务描述&lt;/h2&gt;&lt;p&gt;一个社交网络可以看做是一张图（离散数学中的图）。社交网络中的人对应于图的顶点；社交网络中的人际关系对应于图中的边。在本次实验任务中，我们只考虑一种关系——用户之间的关注关系。假设“王五”在 Twitter/微博中关注了“李四”，则在社交网络图中，有一条对应的从“王五”指向“李四”的有向边。图 1 中展示了一个简单的社交网络图，人之间的关注关系通过图中的有向边标识了出来。本次的实验任务就是在给定的社交网络图中，统计图中所有三角形的数量。&lt;br&gt;在统计前，需要先进行有向边到无向边的转换，依据如下逻辑转换：&lt;br&gt;$$IF~(A→B)~OR~(B→A)~ THEN~A→B$$&lt;/p&gt;
&lt;p&gt;“A→B”表示从顶点 A 到顶点 B 有一条有向边。A-B 表示顶点 A 和顶点 B 之间有一条无向边。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/trianglecount2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;一个示例见图 1，图 1 右侧的图就是左侧的图去除边方向后对应的无向图。&lt;/p&gt;
&lt;p&gt;请在无向图上统计三角形的个数。在图 1 的例子中，一共有 3 个三角形。&lt;br&gt;本次实验将提供一个 Twitter 局部关系图[1]作为输入数据（给出的图是有向图），请统计该图对应的无向图中的三角形个数。&lt;/p&gt;
&lt;h3 id=&quot;输入格式&quot;&gt;&lt;a href=&quot;#输入格式&quot; class=&quot;headerlink&quot; title=&quot;输入格式&quot;&gt;&lt;/a&gt;输入格式&lt;/h3&gt;&lt;p&gt;输入数据仅一个文件。该文件由若干行组成，每一行由两个以空格分隔的整数组成：&lt;br&gt;A B&lt;br&gt;A，B 分别是两个顶点的 ID。这一行记录表示图中具有一条由 A 到 B 的有向边。整个图的&lt;br&gt;结构由该文件唯一确定。&lt;/p&gt;
&lt;p&gt;下面的框中是文件部分内容的示例：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/trianglecount1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;方法思路&quot;&gt;&lt;a href=&quot;#方法思路&quot; class=&quot;headerlink&quot; title=&quot;方法思路&quot;&gt;&lt;/a&gt;方法思路&lt;/h2&gt;&lt;p&gt;找三角形在离散数学中有数学上的方法，即矩阵自乘两次，矩阵自乘一次后的结果矩阵的对角线上的元素$A_{ii}$代表的是$i$节点经过两条边再回到该点的路径数目，再乘一次后的结果对角线上的元素表示经过三条边回到该点的路径数目，这时候就有了一个三角形，由于每个在三角形中的点都会从两个方向出发走三条边回到自己，所以，每个三角形都做了点数(3)乘以方向数(2)次计算，所以应该将最后的结果除以6得到最终结果。&lt;/p&gt;
&lt;p&gt;另一种想法是，直观的去找，要找三角形，先找到两条边，比如要找$\nabla ABC$，可以先找到A-&amp;gt;B, A-&amp;gt;C，那么下一步就是找B-&amp;gt;C或者C-&amp;gt;B了，由于我们先对边做了无向处理，将所有的无向边的端点按字典序排序好了，所以相当于找B-&amp;gt;C就可以了。所以考虑有A-&amp;gt;B和A-&amp;gt;C时发射一个B-&amp;gt;C的需求，再发射自己A-&amp;gt;B,A-&amp;gt;C的供给，如果别的地方需要A-&amp;gt;B或者A-&amp;gt;C的边，那么可以直接供给，一旦有边，就可以供给给任意多的需要，这时候看最终某条边到底有多少需求，然后有没有供给，如果有供给，则三角形数目更新为加上这条边需求的数目。同样的，如果别的地方有B-&amp;gt;C这条边的供给，那么此时的B-&amp;gt;C需求就得到了满足，相当于新发现了一个三角形。按照这种Feed&amp;amp;Eat的方式，就可以使用MapReduce来处理社交网络三角形统计了。&lt;/p&gt;
&lt;h2 id=&quot;初步探索&quot;&gt;&lt;a href=&quot;#初步探索&quot; class=&quot;headerlink&quot; title=&quot;初步探索&quot;&gt;&lt;/a&gt;初步探索&lt;/h2&gt;&lt;p&gt;初步探索的算法分以下四个模块，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GraphUndirecter.java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;图的无向化，按照OR逻辑，$IF~(A→B)~OR~(B→A)~ THEN~A-B$，如果存在某一个方向的边，则按字典序对两个端点从小到大排序，发射一条从小指到大的边，为了防止发射重复边，全局采用一个HashSet&lt;string&gt;来判重。并且需要判断自环。这个类只需要读取文件发射边即可，无需Reduce步骤。&lt;/string&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Value: &lt;span class=&quot;string&quot;&gt;&quot;A B&quot;&lt;/span&gt;    （A,B为点的ID）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A#B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; Value: &lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;伪代码如下：&lt;br&gt;&lt;figure class=&quot;highlight cs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;Object key, Text &lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;, Context context&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    st &lt;/span&gt;= Tokenizer(&lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    A = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    B = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; A != B:   &lt;span class=&quot;comment&quot;&gt;//判自环&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; A &amp;lt; B:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            emit(&lt;span class=&quot;string&quot;&gt;&quot;A#B   #&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            emit(&lt;span class=&quot;string&quot;&gt;&quot;B#A   #&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TilingGraph.java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将上一步得到的边展开成邻接表一样的形式，方便发射需求边和供给边。如： A-&amp;gt;[B, C, D]，此时我们会发射需求边： B-&amp;gt;C, B-&amp;gt;D, C-&amp;gt;D，和供给边A-&amp;gt;B, A-&amp;gt;C, A-&amp;gt;D。由于前面已经将&lt;/p&gt;
&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Value: &lt;span class=&quot;string&quot;&gt;&quot;A#B #&quot;&lt;/span&gt;    （A,B为点的ID）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A#B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; Value: &lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt; 或者 &lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;    (&lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;供给，&lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;需求）&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;伪代码如下：&lt;br&gt;&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void &lt;span class=&quot;built_in&quot;&gt;map&lt;/span&gt;(Object &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, Text value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    st = Tokenizer(value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    A = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    B = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    emit(A,B)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void reduce(Text &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, Iterable&amp;lt;Text&amp;gt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; v &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        emit(&lt;span class=&quot;string&quot;&gt;&quot;key#v&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; -&amp;gt; len(&lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; j = i+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; -&amp;gt; len(&lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[i] &amp;lt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[j]:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                emit(&lt;span class=&quot;string&quot;&gt;&quot;values[i]#values[j]&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                emit(&lt;span class=&quot;string&quot;&gt;&quot;values[j]#values[i]&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FeedAndCount.java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;得到了所有边是否有需求有供给的情况我们只需要统计每条边是否有供给，如果有，那么它有多少需求，将这些需求满足形成若干个三角形，以此累加三角形数。&lt;/p&gt;
&lt;figure class=&quot;highlight qml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;Value&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A#B #&quot;&lt;/span&gt; 或者 &lt;span class=&quot;string&quot;&gt;&quot;A#B @&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Output &lt;span class=&quot;attribute&quot;&gt;Key&lt;/span&gt;: &amp;lt;Result &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; Triangle &lt;span class=&quot;built_in&quot;&gt;Number&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;伪代码如下：&lt;br&gt;&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;RESULT = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void &lt;span class=&quot;built_in&quot;&gt;map&lt;/span&gt;(Object &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, Text value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    st = Tokenizer(value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    A = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    B = st.nextToken()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    emit(A, B)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void reduce(Text &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, Iterable&amp;lt;Text&amp;gt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int jin = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;at&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (Text val : &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (val.toString().equals(&lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;)) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            jin++;   // &lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;有&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (val.toString().equals(&lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;)) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;built_in&quot;&gt;at&lt;/span&gt;++;   // &lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;数目加&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (jin &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) RESULT += &lt;span class=&quot;built_in&quot;&gt;at&lt;/span&gt;;  // 如果有（&lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;），则统计&lt;span class=&quot;built_in&quot;&gt;at&lt;/span&gt;个三角形&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TriangleCountDriver.java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;驱动三个Job的执行，读取用户命令行参数，然后调用以上三个类，统筹整个程序的执行。&lt;/p&gt;
&lt;figure class=&quot;highlight scss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;GraphUndirecter&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[0]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[1]&lt;/span&gt;&amp;#125;);  &lt;span class=&quot;comment&quot;&gt;// input -&amp;gt; middle1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;TilingGraph&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[1]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[2]&lt;/span&gt;&amp;#125;);      &lt;span class=&quot;comment&quot;&gt;// middle1 -&amp;gt; middle2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FeedAndCount&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[2]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[3]&lt;/span&gt;&amp;#125;);     &lt;span class=&quot;comment&quot;&gt;// middle2 -&amp;gt; output&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;调优后最好的成绩跑twitter数据集用了6分多钟，跑google数据集只跑了一次，跑了20+小时，所以效率并不是最优的。&lt;/p&gt;
&lt;h2 id=&quot;进一步的尝试&quot;&gt;&lt;a href=&quot;#进一步的尝试&quot; class=&quot;headerlink&quot; title=&quot;进一步的尝试&quot;&gt;&lt;/a&gt;进一步的尝试&lt;/h2&gt;&lt;p&gt;由于以上三个job的方式仍需要6分钟，感觉还是太慢，想了想能否优化一下呢，因为这里会读三次磁盘（数据，中间结果1，中间结果2），这样磁盘读写的消耗是很大的。仔细分析一下是可以缩减磁盘读写次数的。&lt;/p&gt;
&lt;h3 id=&quot;尝试一&quot;&gt;&lt;a href=&quot;#尝试一&quot; class=&quot;headerlink&quot; title=&quot;尝试一&quot;&gt;&lt;/a&gt;尝试一&lt;/h3&gt;&lt;p&gt;看到第一个类其实就是map一下，去一下重，把无向图做出来，没有reduce，所以想直接一步做图的无向化和图展开，发射需求和供给边，即&lt;br&gt;&lt;figure class=&quot;highlight livescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;第一步： &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;map:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;A B&quot;&lt;/span&gt;&lt;span class=&quot;function&quot;&gt; -&amp;gt;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;key:A, value:B&quot;&lt;/span&gt;  （为了不发射重边，做了一个HashSet判重）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;reduce:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     A, [B, C, D...,S]&lt;span class=&quot;function&quot;&gt; -&amp;gt;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;A&lt;span class=&quot;subst&quot;&gt;#B&lt;/span&gt;   #&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;A&lt;span class=&quot;subst&quot;&gt;#C&lt;/span&gt;    #&quot;&lt;/span&gt;, ... , &lt;span class=&quot;string&quot;&gt;&quot;B&lt;span class=&quot;subst&quot;&gt;#C&lt;/span&gt;  @&quot;&lt;/span&gt;, ...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;第二步：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    统计&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样直接两步做完，第一步工作量会大一点。可是很遗憾，在本地跑是完全可以的，可是放到集群上运行，map到21%就map不动了，可能是HashSet同步问题的原因？或者是shuffle量太大的原因？不得而知，没有报错也看不到日志，怀疑是后者，量太大导致内存不够，一直在GC，导致卡死。因为缩减数据规模还是勉强能跑的，不过才30M（twitter）就这样了，肯定不可取。&lt;/p&gt;
&lt;h3 id=&quot;尝试二&quot;&gt;&lt;a href=&quot;#尝试二&quot; class=&quot;headerlink&quot; title=&quot;尝试二&quot;&gt;&lt;/a&gt;尝试二&lt;/h3&gt;&lt;p&gt;上一步的失败可能是因为第一个job工作量太大了，既要判重发射所有无向边，又要发射存在的边和枚举近邻之间发射需求边，这对它不公平，所以考虑将工作分配均匀一下，这样就得到了下面一种方法：&lt;br&gt;(注：这里的A,B,C,D…都代表某一个点)&lt;/p&gt;
&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;JOB1：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Value: &lt;span class=&quot;string&quot;&gt;&quot;A B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; value: &lt;span class=&quot;string&quot;&gt;&quot;B,C,E,D,...,S&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JOB2：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Value: &lt;span class=&quot;string&quot;&gt;&quot;A   B,C,E,D,...,S&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A#B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;Output&lt;/span&gt; value: &lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt; 或者 &lt;span class=&quot;string&quot;&gt;&quot;@&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;好吧，这样终于可行了，结果也是对的，但是结果却并让人高兴不起来，因为效率上并没有提升，反而比读三次磁盘的方法慢得多，跑了将近11分钟！这也太诡异了。绝对还有什么地方不对，再想想。其实我们没有注意到到底是不是并行在做？查找资料得知，hadoop mapreduce每个作业如果没有配置map,reduce数的话，默认map任务数是2，而默认reduce数为1！这能行？这还叫并行？全挤到一两个reduce task去做，能不慢么？&lt;br&gt;于是看看哪些地方可以增加reduce数。可以看到，第一种方法的GraphUndirecter虽然reduce数为0，但是TilingGraph的reduce是可以许多节点来做的，我们把numReduceTasks设为4，或者6，然后这个reduce数一般就是下一步的map数，然后最后FeedAndCount由于需要计算总数，所以必须一个reduce节点来做。所以总的来说，我们可以把中间步用多个reduce task来做。&lt;br&gt;同样的，尝试二的方法也可以在GraphUndirecterAndTiling步多设几个reduce来做。&lt;/p&gt;
&lt;h3 id=&quot;此时的程序性能&quot;&gt;&lt;a href=&quot;#此时的程序性能&quot; class=&quot;headerlink&quot; title=&quot;此时的程序性能&quot;&gt;&lt;/a&gt;此时的程序性能&lt;/h3&gt;&lt;p&gt;最终采用了尝试二中的方法，两个job完成这个工作，跑了以下2个数据集，效果勉强还可以。大概是4分钟跑完twitter数据集，比原来缩短一倍，跑Google+数据集也比一开始跑的20+个小时缩短到了13个小时。但是显然，这还不够快！天下武功，唯快不破。继续优化吧。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;数据集&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;三角形个数&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Driver程序在集群上的运行时间（s）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Twitter&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;13082506&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;247&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Google+&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1073677742&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;47760&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;继续优化&quot;&gt;&lt;a href=&quot;#继续优化&quot; class=&quot;headerlink&quot; title=&quot;继续优化&quot;&gt;&lt;/a&gt;继续优化&lt;/h2&gt;&lt;p&gt;由上面的尝试二，这里又有了启发，我们可以看到，最后一步由1个reduce去统计和求和，这里要求总数的话又必须只让一个reduce来做，鸭梨不要太大，可以看到他做的两个工作实际上差异很大，一个是要扫描统计多少需要，另一个只要简单加和一下就行了，为了减轻该同志的鸭梨，那么我们再造一个job，把这两个工作分开是不是会快一点呢。猜测得到了证实，确实是可以的！意思就是，前面第三个job只统计求局部和（有一个扫描过程），这样的话我们可以搞很多reduce来做局部统计求和，然后把它们存到中间文件，最后由job4来对所有这些数求和，因为最后一步就是发射求和，所以时间远比统计来得快。&lt;br&gt;所以最终的JOB工作分配如下：&lt;/p&gt;
&lt;figure class=&quot;highlight qml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;JOB1：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;Value&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Output &lt;span class=&quot;attribute&quot;&gt;key&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Output &lt;span class=&quot;attribute&quot;&gt;value&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;B,C,E,D,...,S&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JOB2：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;Key&lt;/span&gt;: 输入文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;Value&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A   B,C,E,D,...,S&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;MapOutputKey&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;A#B&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;MapOutputValue&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;(have) 或者 &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;(need)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Output &lt;span class=&quot;attribute&quot;&gt;key&lt;/span&gt;: NULL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Output &lt;span class=&quot;attribute&quot;&gt;value&lt;/span&gt;: 三角形个数(局部)    &lt;span class=&quot;comment&quot;&gt;//这里做成VIntWritable类型，把单个字符的2个字节空间做成1个字节的VIntWritable&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;JOB3&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;key&lt;/span&gt;: 中间文件的行偏移&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;Value&lt;/span&gt;: 三角形个数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;OutputKey&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Total Triangles: &quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attribute&quot;&gt;OutputValue&lt;/span&gt;: 三角形总数&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最终算法如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GraphUndirecterAndTiling&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight cs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;key, &lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    A &lt;/span&gt;= &lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    B = &lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; A != B:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        emit(As, Bs)  &lt;span class=&quot;comment&quot;&gt;// As = min(A, B), Bs = max(A,B)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;reduce&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;key, values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;title&quot;&gt;emit&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;key, &lt;span class=&quot;string&quot;&gt;&quot;,&quot;&lt;/span&gt;.&lt;span class=&quot;keyword&quot;&gt;join&lt;/span&gt;(values&lt;/span&gt;))   &lt;span class=&quot;comment&quot;&gt;// A    B,C,D...,S&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;JustCount&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void &lt;span class=&quot;built_in&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, value):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; val &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; value.&lt;span class=&quot;built_in&quot;&gt;split&lt;/span&gt;(&#39;,&#39;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        emit(&lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;#val, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)    // 供给&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i, j &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; value.&lt;span class=&quot;built_in&quot;&gt;split&lt;/span&gt;(&#39;,&#39;) &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; i &amp;lt; j:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        emit(Vs1#Vs2, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)    // 需求 Vs1 = &lt;span class=&quot;built_in&quot;&gt;min&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[i], &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[j]), Vs2 = &lt;span class=&quot;built_in&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[i], &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;[j])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void reduce(&lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int have = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, need = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, res = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (val : &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (val.equals(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            have++;   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (val.equals(&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            need++;   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (jin &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) res += need;  // 如果有（have），则统计need个三角形&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; res &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        write(res)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;CollectSum&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void &lt;span class=&quot;built_in&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, value):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    emit(&lt;span class=&quot;string&quot;&gt;&quot;#&quot;&lt;/span&gt;, value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void reduce(&lt;span class=&quot;built_in&quot;&gt;key&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; val &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;values&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt; += val&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    write(&lt;span class=&quot;string&quot;&gt;&quot;Total Triangles: &quot;&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;TCDriver&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight scss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;GraphUndirecterAndTiling&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[0]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[1]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[4]&lt;/span&gt;&amp;#125;);  &lt;span class=&quot;comment&quot;&gt;// input -&amp;gt; middle1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// myArgs[4] is numReduceTasks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JustCount&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[1]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[2]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[4]&lt;/span&gt;&amp;#125;);     &lt;span class=&quot;comment&quot;&gt;// middle1 -&amp;gt; middle2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CollectSum&lt;span class=&quot;selector-class&quot;&gt;.main&lt;/span&gt;(new String&lt;span class=&quot;selector-attr&quot;&gt;[]&lt;/span&gt;&amp;#123;myArgs&lt;span class=&quot;selector-attr&quot;&gt;[2]&lt;/span&gt;, myArgs&lt;span class=&quot;selector-attr&quot;&gt;[3]&lt;/span&gt;&amp;#125;);    &lt;span class=&quot;comment&quot;&gt;// middle2 -&amp;gt; output&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;程序性能分析&quot;&gt;&lt;a href=&quot;#程序性能分析&quot; class=&quot;headerlink&quot; title=&quot;程序性能分析&quot;&gt;&lt;/a&gt;程序性能分析&lt;/h2&gt;&lt;p&gt;最终程序性能得到了很大的提高，耗时如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;数据集&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;三角形个数&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Driver程序在集群上的运行时间（s）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Twitter&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;13082506&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;108&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Google+&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1073677742&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;01:54:28 (6868s)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;效果还是挺不错的，不到两分钟完成了31M twitter数据集的统计，不到两个小时完成了Google+ 570多M的数据统计，可能也跟集群当前的负载有关系，集群负载轻的时候应该会快一些，较前面的方法提升了两倍和6倍多，并且结果也是对的，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/twitterandgplus.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里的算法和reduce数还是可以调整的，并且在某些条件下，应该还是能够进一步优化下去的。没有最快，只有更快，但是由于时间关系，就不继续探索下去了，读者自探，欢迎留言评论。&lt;/p&gt;
&lt;h2 id=&quot;后话&quot;&gt;&lt;a href=&quot;#后话&quot; class=&quot;headerlink&quot; title=&quot;后话&quot;&gt;&lt;/a&gt;后话&lt;/h2&gt;&lt;p&gt;这里由于想进行大量的优化，所以用到了一些技巧，也是从别人那里学来的，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在在乎网络传输的时候，可适当使用压缩（我没用）&lt;/li&gt;
&lt;li&gt;重用Writable类型。 各类Writable占用空间如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/writable.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Text类采用的UTF-8编码，使用变长的1～4个字节对字符进行编码。对于ASCII字符只使用1个字节，而对于High ASCII和多字节字符使用2～4个字节表示，而不像Java基本Character类的UTF-16编码，每个字符用两个字节表示。所以注意，IntWritable是固定4个字节存储的，比一个字符存储量大，所以如果一个字符能表示，那么就用一个字符，如果不能用一个字符，那么可以考虑VIntWritable类型，VIntWritable类型则根据数值的大小使用相应的字节长度表示，当数值在-112～127之间时使用1个字节表示，在-112～127范围之外的数值使用头一个字节表示该数值的正负符号以及字节长度（zero-compressed encoded integer）。&lt;br&gt;IntWritable适合数值均匀分布的情形，而变长的Writable类型适合数值分布不均匀的情形，一般情况下变长的Writable类型更节省空间，因为大多数情况下数值是不均匀的，对于整数类型的Writable选择，Zhou’s Blog建议：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;除非对数据的均匀分布很有把握，否则使用变长Writable类型&lt;/li&gt;
&lt;li&gt;除非数据的取值区间确定在int范围之内，否则为了程序的可扩展性，请选择VLongWritable类型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以多使用VIntWritable, VLongWritable类型也不失一种好的选择。当然，能用一个ASCII字符表示那就用Text也就行了。&lt;/p&gt;
&lt;p&gt;所以这里面还是有很多学问的。&lt;/p&gt;
&lt;h2 id=&quot;References-amp-Links&quot;&gt;&lt;a href=&quot;#References-amp-Links&quot; class=&quot;headerlink&quot; title=&quot;References &amp;amp; Links&quot;&gt;&lt;/a&gt;References &amp;amp; Links&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;《Mining of Massive Datasets》 2.Ed&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/whatbeg/TriangleCounting&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Code on my Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cs.utah.edu/~jeffp/teaching/MCMD/S16-MR-triangles.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;L16: Counting Triangles in MapReduce&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vertica/Graph-Analytics----Triangle-Counting&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Graph-Analytics—-Triangle-Counting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://i11www.iti.uni-karlsruhe.de/extra/publications/sw-fclt-05_wea.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Finding, Counting and Listing all Triangles inLarge Graphs, An Experimental Study?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dl2.iteye.com/upload/attachment/0061/9798/27cf0ab8-4e6d-3fff-bfc8-05cc51f985f4.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MapReduce Performance Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.sandia.gov/~tgkolda/pubs/pubfiles/KoPiPlSeTa14.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;COUNTING TRIANGLES IN MASSIVE GRAPHS WITH MAPREDUCE∗&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://yoyzhou.github.io/blog/2013/05/10/hadoop-serialization-and-writable-object-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hadoop序列化与Writable接口(二)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://chato.cl/papers/becchetti_2007_approximate_count_triangles.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Efficient Semi-streaming Algorithms for Local Triangle Counting in Massive Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/yangjl38/article/details/7583374&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hadoop 三个文件默认配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://monkey-h.github.io/blog/hadoop-4/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;图的三角形计数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://islab.kaist.ac.kr/chungcw/InterConfPapers/km0805-ha-myung.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;An Efficient MapReduce Algorithm for Counting Triangles in a Very Large Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/graphx/src/main/scala/org/apache/spark/graphx/lib/TriangleCount.scala&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Spark Triangle Count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/BladeMasterCoder/TriangleCount&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Triangle Count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/jianjian1992/article/details/45625339&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;hadoop编程—-寻找社交网络图中的三角关系&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://repository.cmu.edu/cgi/viewcontent.cgi?article=2120&amp;amp;context=compsci&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Approximate Triangle Counting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://people.seas.harvard.edu/~babis/int-math-triangles.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Efficient Triangle Counting in Large Graphs via Degree-based Vertex Partitioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;图的三角形计数问题是一个基本的图计算问题，是很多复杂网络分析（比如社交网络分析）的基础。&lt;b
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="Hadoop" scheme="http://whatbeg.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>谈一谈朴素贝叶斯作为基分类器的Adaboost算法 （Naive Bayes Based Adaboost）</title>
    <link href="http://whatbeg.com/2016/12/01/naivebayesboosting.html"/>
    <id>http://whatbeg.com/2016/12/01/naivebayesboosting.html</id>
    <published>2016-12-01T08:58:03.000Z</published>
    <updated>2016-12-01T09:12:42.173Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;Adaboost大家很熟了，是比较经典的一个提升方法，这次实现一下以朴素贝叶斯为基分类器的Adaboost，首先实现一个朴素贝叶斯分类器，然后以朴素贝叶斯作为基分类器，实现Adaboost算法，并在两个数据集上进行测试。在实现朴素贝叶斯分类器时，同时处理了离散值属性和连续值属性，在结果表中给出了Adaboost算法应用在两个数据集上分别的准确率均值和方差。很少看到网上有NB作为基分类器的boosting，自己实现了一下，如果有什么错漏或者不对的地方欢迎指出。&lt;/p&gt;
&lt;p&gt;关键词:    朴素贝叶斯; 集成学习; Adaboost; 提升方法; 交叉验证&lt;/p&gt;
&lt;h2 id=&quot;朴素贝叶斯算法简介&quot;&gt;&lt;a href=&quot;#朴素贝叶斯算法简介&quot; class=&quot;headerlink&quot; title=&quot;朴素贝叶斯算法简介&quot;&gt;&lt;/a&gt;朴素贝叶斯算法简介&lt;/h2&gt;&lt;p&gt;朴素贝叶斯算法(Naïve Bayes)算法是基于贝叶斯定理和特征条件独立的假设的一种分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布，然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y. 朴素贝叶斯法实现简单，并且也有不俗的学习与预测的效率，是一种常用的方法，也被列入“机器学习十大算法”之一。&lt;/p&gt;
&lt;h2 id=&quot;离散特征和连续特征&quot;&gt;&lt;a href=&quot;#离散特征和连续特征&quot; class=&quot;headerlink&quot; title=&quot;离散特征和连续特征&quot;&gt;&lt;/a&gt;离散特征和连续特征&lt;/h2&gt;&lt;p&gt;利用朴素贝叶斯法进行分类我们采用极大似然法对条件概率和先验概率进行估计，然后利用此条件概率和先验概率对测试集样本进行预测，所以我们需要得到$P(Y=ck)$和$P(Xj=a_{jl} | Y=ck)$，然而，对于离散值和连续值而言两个条件概率的处理方法是不同的。&lt;/p&gt;
&lt;h3 id=&quot;离散值特征的处理&quot;&gt;&lt;a href=&quot;#离散值特征的处理&quot; class=&quot;headerlink&quot; title=&quot;离散值特征的处理&quot;&gt;&lt;/a&gt;离散值特征的处理&lt;/h3&gt;&lt;p&gt;在离散特征中，由于属性的取值情况总数固定，我们可以采用频数进行估计，并做一定的拉普拉斯平滑，即有&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;进行拉普拉斯平滑后，先验概率的贝叶斯估计为&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;连续值特征的处理&quot;&gt;&lt;a href=&quot;#连续值特征的处理&quot; class=&quot;headerlink&quot; title=&quot;连续值特征的处理&quot;&gt;&lt;/a&gt;连续值特征的处理&lt;/h3&gt;&lt;p&gt;在处理连续值特征时，假定连续值属性服从均值为μ，标准差为σ的高斯分布，由下式定义&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;则$P(x_k | C_i) = g(x_k, {\mu}_C, {\sigma}_C)$&lt;br&gt;只要计算出训练样本中连续值属性属于各个类别的数据样本的均值和标准差，我们就可以利用上述公式算得一个相对的概率，虽然上式的P可能不在0到1之间，但是并不影响最后后验概率的比较结果。&lt;/p&gt;
&lt;h2 id=&quot;朴素贝叶斯以及提升方法的实现&quot;&gt;&lt;a href=&quot;#朴素贝叶斯以及提升方法的实现&quot; class=&quot;headerlink&quot; title=&quot;朴素贝叶斯以及提升方法的实现&quot;&gt;&lt;/a&gt;朴素贝叶斯以及提升方法的实现&lt;/h2&gt;&lt;h3 id=&quot;提升方法&quot;&gt;&lt;a href=&quot;#提升方法&quot; class=&quot;headerlink&quot; title=&quot;提升方法&quot;&gt;&lt;/a&gt;提升方法&lt;/h3&gt;&lt;p&gt;提升方法的基本思想是提高前一个弱分类器分错的样本的权重，使接下来的弱分类器能够学习到这个“残差”，相当于把分类问题交给多个弱分类器分而治之，每个分类器把前面分类器不擅长的数据学好，最后大家一起表决，表决时错误率低的分类器的分类结果应该占以更大的比重，通过这种方式，得到“三个臭皮匠赛过诸葛亮”的效果。Adaboost也是一直以来被使用最广泛的提升算法。其他的boosting方法还有gradient boost，boosting tree等。&lt;br&gt;Adaboost算法的伪代码如下&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;提升方法权重调整&quot;&gt;&lt;a href=&quot;#提升方法权重调整&quot; class=&quot;headerlink&quot; title=&quot;提升方法权重调整&quot;&gt;&lt;/a&gt;提升方法权重调整&lt;/h3&gt;&lt;p&gt;由于提升方法有一个数据样本的权重调整过程，我们需要探索如何将权重对模型的训练的作用体现出来，有如下两种方法可以达到效果。&lt;br&gt;一是重采样法，对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。&lt;br&gt;二是重赋权法，对每个样本附加一个权重，对离散值来说，在计算条件概率的贝叶斯估计时，不再是简单将其出现次数相加，而是带有各个样本权重的相加；对于连续值来说，样本权重的增大表现为均值向该样本做更多的偏移，实际上可以直接提高该样本该属性该连续值的数值大小来实现。&lt;br&gt;笔者开始采用的是重采样法实现Adaboost训练，因为这种方式简单，不需要改变数据的值，但是后来发现，这种方式做出来效果并不好，甚至随着基分类器的增多，Adaboost的效果呈下降趋势！仔细检查过代码，应该没有问题，翻阅资料得知，两种方法除了有固定的可使用的场景外，还有各自的适用场景，样本集重采样法(resampling)对于不稳定的算法能够取得很好的效果，不稳定算法指的是样本集的微小变动就能够对结果有很大的影响的算法，很遗憾，朴素贝叶斯是稳定的算法，并且其估计的参数少，对缺失数据都不是很敏感。还有一些算法如Linear Model, SVM, kNN等都是稳定的算法，而不稳定算法的代表是决策树和神经网络两位。&lt;br&gt;最后，迫于效果太差，于是又转用了重新赋权的方式，将权重嵌入到数据中，最终结果显示还好，Adaboost较单个朴素贝叶斯基分类器有提升，虽然提升并不是很大。&lt;br&gt;代码中两种实现方式都有，最终测试使用的adaboost_weight(), get_model_weight(),get_err_rate_weight()等方法，即重赋权的方法。&lt;/p&gt;
&lt;h2 id=&quot;结果&quot;&gt;&lt;a href=&quot;#结果&quot; class=&quot;headerlink&quot; title=&quot;结果&quot;&gt;&lt;/a&gt;结果&lt;/h2&gt;&lt;p&gt;最终在两个数据集上都做了10折交叉验证实验，实施交叉验证前程序都将整个数据集顺序打乱，所以每次运行程序的结果都会有变化，但是总体上还是能够体现结果，选取某次实验结果如下表&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;为了更加直观地观察Adaboost的提升效果，将准确率随Adaboost基分类器数的增加呈现的趋势通过图像展示出来，方便观察，下面图1，图2分别给出在两个数据集上的提升情况&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/adanb7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;后记&quot;&gt;&lt;a href=&quot;#后记&quot; class=&quot;headerlink&quot; title=&quot;后记&quot;&gt;&lt;/a&gt;后记&lt;/h2&gt;&lt;p&gt;交叉验证实验结果证明Adaboost能够以朴素贝叶斯分类器进行集成学习，并提升单个朴素贝叶斯分类器的效果，但是由于朴素贝叶斯已经是一个不错的分类器，单个朴素贝叶斯分类器的交叉验证平均准确率已经能够达到0.74-0.75，尤其是第二个数据集，由于数据集较大，所以概率估计和分类效率都较为稳定，使得单个NB Classifier准确率能够达到很高，所以提升效果显得不那么明显，Adaboost可能更适合于提升较弱的分类器的效果。&lt;br&gt;另外，虽然朴素贝叶斯的准确率很高，但是他是有瓶颈的，它的模型完全是根据数据集而得来，所以感觉没有什么需要学习的，完全是统计的方法，并且它有一个固有的弱点就是做了属性独立性假设，而现实条件往往不能满足属性独立性，尤其是数据属性冗余性大的时候，朴素贝叶斯的效果不会太好。&lt;/p&gt;
&lt;h2 id=&quot;Reference-and-Links&quot;&gt;&lt;a href=&quot;#Reference-and-Links&quot; class=&quot;headerlink&quot; title=&quot;Reference and Links&quot;&gt;&lt;/a&gt;Reference and Links&lt;/h2&gt;&lt;p&gt;[1] &lt;a href=&quot;http://cmp.felk.cvut.cz/~sochmj1/adaboost_talk.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Adaboost Introduction Slides&lt;/a&gt;&lt;br&gt;[2]  李航.统计学习方法.&lt;br&gt;[3]     Jiawei Han et. al.数据挖掘：概念与技术.&lt;br&gt;[4]  周志华.机器学习.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;Adaboost大家很熟了，是比较经典的一个提升方法，这次实现一下以朴素贝叶斯为基分类器的A
    
    </summary>
    
      <category term="机器学习 | Mac.Learning" scheme="http://whatbeg.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Mac-Learning/"/>
    
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>近几个月读书总结</title>
    <link href="http://whatbeg.com/2016/11/26/2016read6month.html"/>
    <id>http://whatbeg.com/2016/11/26/2016read6month.html</id>
    <published>2016-11-26T14:32:23.000Z</published>
    <updated>2017-01-14T13:45:35.292Z</updated>
    
    <content type="html">&lt;p&gt;有几个月没有写读书笔记了，一是没抽出时间，二是读的书基本都没有读完，都不是短时间能够读完的书，但是要是必得等到读完才写，那今年都别写了，但是这样不好，虽然没有读完，但多少算读了一点，有些心得就得记下来，不然后面就忘了，所以才有此文。&lt;/p&gt;
&lt;p&gt;这几个月读的书很杂，一路读过来书一直在换，从6月份到快要过去的11月份，总共6个月，跨度也不小，也难怪，中间的环境一直在变动，在不同的环境下要学习不同的东西，面对不同的任务也需要读不同的书。&lt;/p&gt;
&lt;p&gt;下面就这几个月度过的一些书和读的感受做一下梳理，大致分为三个阶段，分别是还未毕业阶段，暑期实习阶段，研一入学之后。&lt;/p&gt;
&lt;h2 id=&quot;还未毕业阶段&quot;&gt;&lt;a href=&quot;#还未毕业阶段&quot; class=&quot;headerlink&quot; title=&quot;还未毕业阶段&quot;&gt;&lt;/a&gt;还未毕业阶段&lt;/h2&gt;&lt;h3 id=&quot;《鸟哥的Linux私房菜：基础学习篇》&quot;&gt;&lt;a href=&quot;#《鸟哥的Linux私房菜：基础学习篇》&quot; class=&quot;headerlink&quot; title=&quot;《鸟哥的Linux私房菜：基础学习篇》&quot;&gt;&lt;/a&gt;《鸟哥的Linux私房菜：基础学习篇》&lt;/h3&gt;&lt;p&gt;还没毕业的时候末期那段时间很闲，除了玩和浪之外，就是闲来看看这些技能类的书，实话说，这段时间看这本书学了一些linux的知识带我入linux的门，里面的一些基本技能现在也一直在使用，很遗憾，自打毕业以后真的就没翻过这本书，一直在吃老本，或者平时上网查命令。当然说这些的意思是这本书真的很有用…，尤其是入门！&lt;/p&gt;
&lt;h3 id=&quot;《机器学习》&quot;&gt;&lt;a href=&quot;#《机器学习》&quot; class=&quot;headerlink&quot; title=&quot;《机器学习》&quot;&gt;&lt;/a&gt;《机器学习》&lt;/h3&gt;&lt;p&gt;这本书一直在看啦，现在回过头来发现，很多机器学习方面的基础都是从这本书打起来的，现在还是经常会用到这本书，发现里面真的是有取之不尽用之不竭的资源一样，反正现在还没挖完这片金矿。这本书周sir经典之作，内容讲的很通俗易懂，但是也是由易到难，覆盖了绝大多数的传统机器学习算法，大抵因为如此，所以才会挖不完吧。严重推荐啦。&lt;/p&gt;
&lt;h3 id=&quot;《统计学习方法》&quot;&gt;&lt;a href=&quot;#《统计学习方法》&quot; class=&quot;headerlink&quot; title=&quot;《统计学习方法》&quot;&gt;&lt;/a&gt;《统计学习方法》&lt;/h3&gt;&lt;p&gt;这本书给我的感觉就是，都是干货~，不扯多的，上来就讲算法原理，感觉当算法手册真是好极了，但是用这本书入门和学习基础的机器学习算法，感觉有点太直白了，初学者一般都希望通俗易懂一点的。这本书还有一个特点是基本没有涉及无监督算法，所以并不是很全面，但是该讲到的讲的绝不含糊。推荐！&lt;/p&gt;
&lt;h2 id=&quot;暑期实习阶段&quot;&gt;&lt;a href=&quot;#暑期实习阶段&quot; class=&quot;headerlink&quot; title=&quot;暑期实习阶段&quot;&gt;&lt;/a&gt;暑期实习阶段&lt;/h2&gt;&lt;h3 id=&quot;《数学分析新讲》-张筑生&quot;&gt;&lt;a href=&quot;#《数学分析新讲》-张筑生&quot; class=&quot;headerlink&quot; title=&quot;《数学分析新讲》 张筑生&quot;&gt;&lt;/a&gt;《数学分析新讲》 张筑生&lt;/h3&gt;&lt;p&gt;暑假做了一个月策略设计方面的事，简单来说就是自主设计方案解决一个问题，是蛮有意思的，整个上班时间就是看书学习然后实验，所以那段时间感觉都有点太闲了（指对于公司）。由于都是面向的实际问题，这其中其实会用到很多数学方法去解决，所以那段时间就一直觉得自己数学太菜，于是去清华的书店硬生生淘了很多本数学书，这一套《数学分析》是三本，是张筑生先生的大作，可惜的是，没看多少。。&lt;/p&gt;
&lt;h3 id=&quot;《随机过程》-林元烈&quot;&gt;&lt;a href=&quot;#《随机过程》-林元烈&quot; class=&quot;headerlink&quot; title=&quot;《随机过程》 林元烈&quot;&gt;&lt;/a&gt;《随机过程》 林元烈&lt;/h3&gt;&lt;p&gt;那段时间有一个问题涉及到概率图模型的一些东西，其中的根本数学概念又在随机过程里面，所以搞了一本随机过程，遗憾的是这本书没选好，清华的这版太老了，而且写的太难，很难看懂，豆瓣的评价也很低。整体来讲，作为非数学系科班的我来说，读起来有点难度。&lt;/p&gt;
&lt;h3 id=&quot;《概率论与数理统计》-陈希孺&quot;&gt;&lt;a href=&quot;#《概率论与数理统计》-陈希孺&quot; class=&quot;headerlink&quot; title=&quot;《概率论与数理统计》 陈希孺&quot;&gt;&lt;/a&gt;《概率论与数理统计》 陈希孺&lt;/h3&gt;&lt;p&gt;陈希孺老先生的著作之一，看了以后不得不感慨，中科大的数学是厉害，，包括整个合肥的学校好像都是这样。这本书最大的优点是并不是作为一本教科书那样严格的一个定理到另一个定理然后给点例题，它对很多概率论上的基本原理以一种通俗易懂的方式揭开来，让读者能够体会到一些概率论上的基本思想方法上的东西，要读完收获不会小，可惜也没有读完，但是这本书现在就离我一米之内（桌上）。。&lt;/p&gt;
&lt;p&gt;注： 除了上面的，还有机器学习和统计学习方法那段时间也一直在读。&lt;/p&gt;
&lt;h3 id=&quot;《叔本华美学随笔》&quot;&gt;&lt;a href=&quot;#《叔本华美学随笔》&quot; class=&quot;headerlink&quot; title=&quot;《叔本华美学随笔》&quot;&gt;&lt;/a&gt;《叔本华美学随笔》&lt;/h3&gt;&lt;p&gt;叔本华是我非常喜欢的一个哲学家，他的文字思想很对我的胃口。这本书名为美学随笔，但是我不知道为什么叫美学随笔，书中阐述了叔本华自己对很多问题的看法，直指人心，读来怡人心脾。喜欢叔本华的话推荐，不过如果是这样的话很可能你已经看过了。。&lt;/p&gt;
&lt;h2 id=&quot;研一入学之后&quot;&gt;&lt;a href=&quot;#研一入学之后&quot; class=&quot;headerlink&quot; title=&quot;研一入学之后&quot;&gt;&lt;/a&gt;研一入学之后&lt;/h2&gt;&lt;h3 id=&quot;《深入理解大数据》&quot;&gt;&lt;a href=&quot;#《深入理解大数据》&quot; class=&quot;headerlink&quot; title=&quot;《深入理解大数据》&quot;&gt;&lt;/a&gt;《深入理解大数据》&lt;/h3&gt;&lt;p&gt;本门派的武功秘籍。。讲了Mapreduce编程框架，HBase，Hive，基础分布式算法设计，机器学习并行化算法设计，整体来讲内容是不错的，可是大数据的东西变化太快了，现在Hadoop已经2.7.x了，书的速度难免不能精准地跟上，不过绝大多数内容是很有意义的，学习Mapreduce推荐！&lt;/p&gt;
&lt;h3 id=&quot;《The-Elements-of-Statistic-Learning》&quot;&gt;&lt;a href=&quot;#《The-Elements-of-Statistic-Learning》&quot; class=&quot;headerlink&quot; title=&quot;《The Elements of Statistic Learning》&quot;&gt;&lt;/a&gt;《The Elements of Statistic Learning》&lt;/h3&gt;&lt;p&gt;中文名叫《统计学习基础》，看这本书是因为看见《统计学习方法》中老是引用这本书的内容，所以找到了这本书的中文版，然后看中文版，翻译惨不忍睹，，就搞了一个英文版来看。写的还是不错的，做数据挖掘，机器学习方面工作的时候需要哪部分知识就去翻阅一下，收获是有的，但是不能说非常大，整体来说，从统计学的角度讲了统计学习的很多方法，挺全面的。现在担心不做数据挖掘这方面的事情的时候，是不是又会荒废这本书。。&lt;/p&gt;
&lt;h3 id=&quot;《王小波文集》&quot;&gt;&lt;a href=&quot;#《王小波文集》&quot; class=&quot;headerlink&quot; title=&quot;《王小波文集》&quot;&gt;&lt;/a&gt;《王小波文集》&lt;/h3&gt;&lt;p&gt;这本就是课外书了，之前在UESTC图书馆没有找到王小波《思维的乐趣》，这次来南大马上去搜刮了一下，也没找到，不过找到了这本《王小波文集》，里面就包括了《思维的乐趣》。恩，没事就翻翻，看的很爽，小波哥的文字总是经常逗我发笑，又经常说一些那个年代的各种各样的事情，透出一个知识分子的严肃思考，很喜欢。&lt;/p&gt;
&lt;h3 id=&quot;《红楼梦》&quot;&gt;&lt;a href=&quot;#《红楼梦》&quot; class=&quot;headerlink&quot; title=&quot;《红楼梦》&quot;&gt;&lt;/a&gt;《红楼梦》&lt;/h3&gt;&lt;p&gt;这学期上了一个讲红楼梦的课，教课的是苗怀明老师，苗老师讲课风趣幽默，每次上完他的课都意犹未尽，所以也一直坚持在上，既然上红楼梦的课，就难免要去读一读《红楼梦》，最终选中了人民文学出版社的庚辰本红楼梦来读，也是前一段时间比较闲的时候读了一些，读了不到二十来回，后来就没空看了，想想也真难，从高中开始，先后读了3回红楼梦，回回都是读个一二十回就因为各种原因放到了一边，什么时候能够痛痛快快读完一次呢？&lt;/p&gt;
&lt;h3 id=&quot;《小站》-海子&quot;&gt;&lt;a href=&quot;#《小站》-海子&quot; class=&quot;headerlink&quot; title=&quot;《小站》 海子&quot;&gt;&lt;/a&gt;《小站》 海子&lt;/h3&gt;&lt;p&gt;最近看的，海子的第一部诗集，海子的诗读起来就是一种美妙而不可言的享受，即使是他早年的诗，那就摘录一首《小站》（《黑夜的献诗（献给黑夜的女儿）》 1983）吧，这是这本诗集中我最喜欢的一首诗。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我年纪很轻&lt;br&gt;不用向谁告别&lt;br&gt;有点感伤&lt;br&gt;我让自己静静地坐了一会儿&lt;br&gt;然后我出发&lt;br&gt;背上黄挎包&lt;br&gt;装有一本本薄薄的诗集&lt;br&gt;书名是一个僻静的小站名&lt;br&gt;小站到了&lt;br&gt;一盏灯淡得亲切&lt;br&gt;大家在熟睡&lt;br&gt;这样&lt;br&gt;我是唯一的人&lt;br&gt;拥有这声车鸣&lt;br&gt;它在深山散开&lt;br&gt;唤醒一两位敏感的山民&lt;br&gt;并得到隐约的回声&lt;br&gt;不用问&lt;br&gt;我们已相识&lt;br&gt;对话中成为真挚的朋友&lt;br&gt;向你们诉愿&lt;br&gt;是自自然然的事&lt;br&gt;我要到草原去&lt;br&gt;去晒黑自己&lt;br&gt;晒黑日记蓝色的封皮&lt;br&gt;去吧，朋友&lt;br&gt;那片美丽的牧场属于你&lt;br&gt;朋友，去吧&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;最后&quot;&gt;&lt;a href=&quot;#最后&quot; class=&quot;headerlink&quot; title=&quot;最后&quot;&gt;&lt;/a&gt;最后&lt;/h2&gt;&lt;p&gt;先总结这些，虽然可能漏掉了一些没写，但是这些是主要的，简要的谈了一些对这些书的看法，虽然都没读完，不过，继续吧，有收获就好啦，没有收获开心就好啦^_^。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;有几个月没有写读书笔记了，一是没抽出时间，二是读的书基本都没有读完，都不是短时间能够读完的书，但是要是必得等到读完才写，那今年都别写了，但是这样不好，虽然没有读完，但多少算读了一点，有些心得就得记下来，不然后面就忘了，所以才有此文。&lt;/p&gt;
&lt;p&gt;这几个月读的书很杂，一路读
    
    </summary>
    
      <category term="读书 | Reading" scheme="http://whatbeg.com/categories/%E8%AF%BB%E4%B9%A6-Reading/"/>
    
    
      <category term="读书" scheme="http://whatbeg.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>Training Classifiers via Stochastic Gradient Descent</title>
    <link href="http://whatbeg.com/2016/11/18/trainclassifiersviaSGD.html"/>
    <id>http://whatbeg.com/2016/11/18/trainclassifiersviaSGD.html</id>
    <published>2016-11-18T07:33:51.000Z</published>
    <updated>2016-11-19T02:53:16.033Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;This report states how I implements two algorithm: Logistic Regression and Ridge Regression(Classifier) which are tailored to large-scale classification. Given the datasets with a large number of examples, we will train classifiers via stochastic gradient descent(SGD) in order to make training phase more efficient. &lt;/p&gt;
&lt;h2 id=&quot;Introduction-to-Datasets&quot;&gt;&lt;a href=&quot;#Introduction-to-Datasets&quot; class=&quot;headerlink&quot; title=&quot;Introduction to Datasets&quot;&gt;&lt;/a&gt;Introduction to Datasets&lt;/h2&gt;&lt;p&gt;There are two datasets which come from LIBSVM, Dataset 1(Training) contains 32561 rows and 124 columns, and dataset 1(Testing) contains 16281 rows and 124 columns; Dataset 2 (Training) contains 290507 rows and 54 columns, and dataset 2 (Testing) contains 290505 rows and 54 columns. Each row represents an example. The last column represents the label of the corresponding example, and the remaining columns represent the features of the corresponding example. For each dataset, label $\mathcal{Y} = {-1, +1}$. After carefully observing the datasets, I find Dataset 1 contains only 0 or 1, but Dataset 2 contains both float numbers between 0 and 1 and integer 0 or 1, indicating that Dataset 2 may not be scaled, so I scaled then to [0, 1], using Min-Max scaling, fortunately Dataset 1 was immune to the scaling because of above description.&lt;/p&gt;
&lt;h2 id=&quot;Logistic-Regression-via-SGD-with-L1-Regularization&quot;&gt;&lt;a href=&quot;#Logistic-Regression-via-SGD-with-L1-Regularization&quot; class=&quot;headerlink&quot; title=&quot;Logistic Regression via SGD with L1-Regularization&quot;&gt;&lt;/a&gt;Logistic Regression via SGD with L1-Regularization&lt;/h2&gt;&lt;p&gt;Logistic Regression is one of most popular classification algorithm in our daily life and industrial application. In this section, I will show you a profile of Logistic Regression at first, and then give the pseudo code of my implementation, then I will show results in two datasets after run my code, and compare it to a python machine learning library Scikit-Learn’s results, and at last show some figures of results for you understanding the whole process.&lt;/p&gt;
&lt;h3 id=&quot;What-is-Logistic-Regression&quot;&gt;&lt;a href=&quot;#What-is-Logistic-Regression&quot; class=&quot;headerlink&quot; title=&quot;What is Logistic Regression?&quot;&gt;&lt;/a&gt;What is Logistic Regression?&lt;/h3&gt;&lt;p&gt;In linear regression, we note the model as $$y = w^Tx + b$$ but can we let predictions approach some thing derive from y ? Answer is absolutely yes, for example we can use log of y as objective that linear models should approach to, which is called log-linear regression.&lt;br&gt;$$\log{y} = w^Tx + b$$ Generally, consider a differentiable monotone function $ g(\cdot) $, let $$y = g^{-1}(w^Tx+b)$$ models like above form is called generalized linear model. Logistic regression can be seen as a special case of the generalized linear model and thus analogous to&lt;br&gt;linear regression. The binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features),[@wiki] it’s $ g^{-1}(\cdot) $ is $$y = \frac {1} {1 + e^{-w^Tx+b} }$$ above equation is actually using prediction results of linear regression model to approach logit probability of true label, thus, the corresponding model is called “Logistic Regression”, although it’s name contains “Regression”, it is truly a classifier. Logistic regression have many advantages in classification task, including that it directly modeling on the real data, unnecessary to make hypothesis of data distribution, which avoided problems with inaccurate hypothesis of data distribution, moreover, it not only predict “categories”, but approximation of categories’ probability, last but not least, logistic function is a convex function which have many merits.&lt;br&gt;We can do some conversion Eq.4 that: $$\ln{\frac {y} {1-y} } = w^Tx+b$$ and we can see y as posterior probability estimates $ p(y=1|x) $, so Eq.5 can be rewrite as $$\ln{\frac {p(y=1|x)} {p(y=-1|x)} } = w^Tx+b$$ absolutely we can infer following two equation:&lt;br&gt;$$p(y=1|x) = \frac{e^{w^Tx+b} } {1+e^{w^Tx+b} } = \frac{1}{1+e^{-(w^Tx+b)} }$$&lt;br&gt;$$p(y=1|x) = \frac{1}{1+e^{w^Tx+b} }$$ thus we can use maximum likelihood&lt;br&gt;method to estimate $w$ and $b$, and for convenience, we note $ \beta = (b;w) $ and $ x = (1;x) $, and we add L1-regularization to our loss function, so our loss function can be written as&lt;/p&gt;
&lt;p&gt;$$ {Loss = \frac{1}{N} \sum_{i=1}^N {\log(1+e^{-y_i\beta^Tx_i}) }  + \lambda||\beta||_1} $$&lt;/p&gt;
&lt;p&gt;after add L1-regularization, we note the final goal is to&lt;/p&gt;
&lt;p&gt;$$ min {\frac{1}{N} \sum_{i=1}^N {\log(1+e^{-y_i\beta^Tx_i}) }  + \lambda||\beta||_1} $$&lt;/p&gt;
&lt;p&gt;Stochastic Gradient Descent method usually used to solve the above optimization problem, which from Gradient Descent, because of GD’s low efficiency in large scale dataset, people want to speed up the rate of&lt;br&gt;convergence, at the same time without losing accuracy, so, they use a randomly selected every time to update parameters, that is to say, the batch size(the number of training examples) used for approximation of Eq.10 is 1. Using SGD to solve Eq.10, we first calculate the gradient of Eq.10 for a&lt;br&gt;sample $x_i$:&lt;br&gt;$$\frac {\partial{loss(\beta, x_i)} }{ {\partial\beta} } = \frac{-y_ix_i} {1+e^{y_i\beta^Tx_i} } + \lambda sign(\beta) $$&lt;/p&gt;
&lt;p&gt;so we can update weights $\beta$ with every iteration and every data&lt;/p&gt;
&lt;p&gt;sample using following equation:&lt;/p&gt;
&lt;p&gt;$$\beta_{k+1} = \beta_k - \gamma \frac {\partial{loss(\beta, x_i)} } {\partial\beta}&lt;br&gt;                = \beta_k + \gamma\frac{y_ix_i} {1+e^{y_i\beta^Tx_i} } - \gamma\lambda sign(\beta) $$&lt;/p&gt;
&lt;p&gt;where $sign(x) = 1$ if x &amp;gt; 0, $sign(x) = -1$, and $sign(x) = 0$ if x = 0. This update equation was called “SGD-L1(Naive)”[@cumulative], and this naive method will cause two problems, one is that at each update, we need to perform the application of L1 penalty to all features, including the features that are not used in current training sample, and it does not produce a compact model, that is, when a dimension of $\beta$ is very small and we can neglect it’s impact, but we will update that dimension as 1 or -1 times regularization lambda and learning rate, regardless of it’s size, at next update, this will cause appearance of many non-zero value in $\beta$, but we want that with the same effect, the less features the better.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Occam’s Razor: Entities should not be multiplied unnecessarily.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For this reason, I tried some methods in Yoshimasa’s paper, including Clipping, which clip the weight that crosses zero, and the update function can refer his paper, and finally I used L1 regularization with cumulative penalty to apply L1 penalty to object function, any details can be find in his paper.[@cumulative]&lt;/p&gt;
&lt;h3 id=&quot;Implementation&quot;&gt;&lt;a href=&quot;#Implementation&quot; class=&quot;headerlink&quot; title=&quot;Implementation&quot;&gt;&lt;/a&gt;Implementation&lt;/h3&gt;&lt;p&gt;After above analysis and derivation, we can easily write the algorithm using SGD to solve logistic regression with L1 regularization,($wh$ is a temporary variable). &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/SGDalgorithm1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;In order to evaluate effectiveness of my algorithm implementation, I written a implementation using&lt;br&gt;Scikit-Learn, a python machine learning library, and you can see the comparison in Table.2. After conduct a simple Cross Validation and adopted some tricks[@leonbottou] on dataset, I set hyperparameters as following values:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Hypermeters&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Learning Rate $\gamma$&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Regularization Lambda $\lambda$&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.0001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Max Iteration Times on Dataset&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;200(Dataset1), 30(Dataset2)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;Results-of-Experiment&quot;&gt;&lt;a href=&quot;#Results-of-Experiment&quot; class=&quot;headerlink&quot; title=&quot;Results of Experiment&quot;&gt;&lt;/a&gt;Results of Experiment&lt;/h3&gt;&lt;p&gt;After the programming, I evaluated the effectiveness and accuracy of my training algorithm on all 2 datasets, Figure.1 and Figure.2 show the change of key dependent variable including Train set error rate, Test error rate, Objective function and Sparsity in training process.&lt;br&gt;Figure.1 shows results of logistic regression with L1-regularization on dataset 1 that with increasing value of iteration times of training, the training error rate and test set error rate decrease, like one line, after nearly 500000 times of iteration, the training error and test set&lt;br&gt;error keep stable and smooth, only have some small fluctuations, indicating the loss function converged. Objective function has the same trend. See the red line indicating that with the increasing of training iteration, sparsity of weights vector increasing continually, final results after more than 6000000+ iterations, weights vector have sparsity of 31 dimension of 124 dimension, holding a quarter, that is to say, we just need use 3/4 of origin features to predict class labels of data sample, without loss of accuracy of prediction, see, we did a feature selection unconsciously.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/LRfig1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Figure.2 shows results of conducting algorithm on dataset 2, and we can see almost the same trend on Figure.1, training error rate, test set error rate and objective function decrease with increasing of iteration times, and sparsity increase. What different is that test set error rate on data set 2 is about 0.45, more than stable training error rate, 0.1879, and following form is the final results of logistic regression with L1 regularization on two Dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/LRfig2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Dataset&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Training error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Test error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Sparsity&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Scikit-Learn Test error rate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Dataset 1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1504&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1501&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;31/124&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Dataset 2&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1879&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4475&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;9/55&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;Comparison-of-Naive-and-Cumulative-Penalty-L1-regularization-in-LR&quot;&gt;&lt;a href=&quot;#Comparison-of-Naive-and-Cumulative-Penalty-L1-regularization-in-LR&quot; class=&quot;headerlink&quot; title=&quot;Comparison of Naive and Cumulative Penalty L1 regularization in LR&quot;&gt;&lt;/a&gt;Comparison of Naive and Cumulative Penalty L1 regularization in LR&lt;/h3&gt;&lt;p&gt;As I stated, there are many approach to apply L1 penalty to our logistic regression’s loss function, one of that is so-called “Naive” method[@cumulative], which directly use absolute value of $sign(\beta)$ as it’s sub-gradient for weight update, but I used the cumulative penalty method, and following is the comparison of this two method. From Table.3 and Table.4, we can see that two methods have nearly the same performance, but cumulative penalty method has large sparsity and Naive method has 0 sparsity. See figures of the performance of Naive method in&lt;br&gt;Appendix.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Methods&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Training error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Test error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Sparsity&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Scikit-Learn Test error rate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Naive&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1507&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1493&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0/124&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Cumulative&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1504&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1501&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;31/124&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table. Comparison of Naive and Cumulative method in Dataset 1&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Methods&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Training error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Test error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Sparsity&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Scikit-Learn Test error rate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Naive&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1878&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4467&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0/55&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Cumulative&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1879&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4475&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;9/55&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table. Comparison of Naive and Cumulative method in Dataset2&lt;/p&gt;
&lt;h2 id=&quot;Ridge-Regression-via-SGD-with-L2-regularization&quot;&gt;&lt;a href=&quot;#Ridge-Regression-via-SGD-with-L2-regularization&quot; class=&quot;headerlink&quot; title=&quot;Ridge Regression via SGD with L2-regularization&quot;&gt;&lt;/a&gt;Ridge Regression via SGD with L2-regularization&lt;/h2&gt;&lt;p&gt;Ridge Regression is a variant of Linear Regression, as we all know, there are many different methods to fit the linear model to a set of training data, but by far the most popular is the method of $least~squares$, in this approach, we pick the coefficients $w$ to minimize the residual sum of squares[@elmml] &lt;/p&gt;
&lt;p&gt;$$RSS(w) = \sum_{i=1}^N {(y_i - w^Tx_i)^2}$$ &lt;/p&gt;
&lt;p&gt;because $RSS(w)$ is a quadratic function of the parameters, its’ minimum always exists, we can use many numerical optimization algorithm to optimize the function, like SGD. But what’s ridge regression, actually it’s very simple, ridge regression shrinks the regression coefficients by imposing a penalty on their size, the ridge coefficients minimize a penalized residual sum of squares &lt;/p&gt;
&lt;p&gt;$$min {\frac{1}{N} \sum_{i=1}^N{ (y_i-w^Tx_i)^2 } + \lambda|w|_2^2} $$ &lt;/p&gt;
&lt;p&gt;and that, is our objective. Using SGD to solve this optimization problem, we just need to get the gradient of objective in one training sample, which is&lt;/p&gt;
&lt;p&gt;$$\nabla loss(w, x_i) = -2x_i(y_i-w^Tx_i) + 2\lambda w$$ So, according Eq.15, we can easily write update function of weights by one iteration and one training example as:&lt;/p&gt;
&lt;p&gt;$$w_{k+1} = w_k - \gamma \frac {\partial{loss(w, x_i)} }{ {\partial w} }&lt;br&gt;                = w_k + 2\gamma {x_i(y_i-w^Tx_i)} - 2 \gamma\lambda w$$&lt;/p&gt;
&lt;h3 id=&quot;Implementation-1&quot;&gt;&lt;a href=&quot;#Implementation-1&quot; class=&quot;headerlink&quot; title=&quot;Implementation&quot;&gt;&lt;/a&gt;Implementation&lt;/h3&gt;&lt;p&gt;As we have the update function of ridge coefficient, we write it’s pseudo-code easily in Algorithm 2. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/SGDalgorithm2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;In order to evaluate effectiveness of my algorithm implementation, I also written a implementation using Scikit-Learn, a python machine learning library, and you can see the comparison in Table.6. And after conduct a simple Cross Validation and use some tricks[@leonbottou]on dataset, I set hyperparameters as following values: ($t$ is iteration times)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Hyperparameters&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Learning Rate $\gamma$&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.001 / (1.0 + 0.001&lt;em&gt;t&lt;/em&gt;0.003)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Regularization Lambda $\lambda$&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.0001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Max Iteration Times on Dataset&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;200(Dataset1), 30(Dataset2)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;Results-of-Experiment-1&quot;&gt;&lt;a href=&quot;#Results-of-Experiment-1&quot; class=&quot;headerlink&quot; title=&quot;Results of Experiment&quot;&gt;&lt;/a&gt;Results of Experiment&lt;/h3&gt;&lt;p&gt;After the programming, I evaluated the effectiveness and accuracy of my training algorithm on all 2 datasets, Figure.3 and Figure.4 show the change of key dependent variable including Train set error rate, Test error rate, Objective function and Sparsity in training process. Figure.3 shows results of ridge regression with L2-regularization on dataset 1 that with increasing value of iteration times of training, the training error rate and test set error rate decrease, like one line, after nearly 350000 times of iteration, the training error and test set error keep stable and smooth, only have some small fluctuations, indicating the loss function converged. Objective function has the same trend. Because of algorithm applying L2 regularization on loss function,&lt;br&gt;so there will be no sparsity, because of the property of L2 regularization. From here we can know that, L1 regularization will cause more sparsity of weights vector than L2 regularization, which is the main reason of L1 regularization has been adopted/used in many scenarios, no matter in industry or academia. Figure.4 shows results of conducting algorithm on dataset 2, and we can see almost the same trend on Figure.1, training error rate, test set error rate and objective function decrease with increasing of iteration times, and sparsity increase. What different is that test set error rate on data set 2 is about 0.45, more than stable training error rate, 0.1921, and following form is the final results of ridge regression with L2 regularization on two Dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/RRfig3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/RRfig4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Results-Appendix&quot;&gt;&lt;a href=&quot;#Results-Appendix&quot; class=&quot;headerlink&quot; title=&quot;Results Appendix&quot;&gt;&lt;/a&gt;Results Appendix&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Dataset&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Training error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Test error rate&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Scikit-Learn Test error rate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Dataset 1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1547&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1548&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Dataset 2&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1921&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4449&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.4100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/LRfig5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/LRfig6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Reference&quot;&gt;&lt;a href=&quot;#Reference&quot; class=&quot;headerlink&quot; title=&quot;Reference&quot;&gt;&lt;/a&gt;Reference&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/refernce1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;This report states how I implements two algori
    
    </summary>
    
      <category term="机器学习 | Mac.Learning" scheme="http://whatbeg.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Mac-Learning/"/>
    
    
      <category term="机器学习" scheme="http://whatbeg.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>如何从头开始实现一个中文拼音输入法？</title>
    <link href="http://whatbeg.com/2016/11/16/godtianpinyin.html"/>
    <id>http://whatbeg.com/2016/11/16/godtianpinyin.html</id>
    <published>2016-11-16T08:26:26.000Z</published>
    <updated>2016-11-24T14:37:58.105Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;众所周知，中文输入法是一个历史悠久的问题，但也实在是个繁琐的活，不知道这是不是网上很少有人分享中文拼音输入法的原因，接着这次NLP Project的机会，我觉得实现一发中文拼音输入法，看看水有多深，结果发现还挺深的，但是基本效果还是能出来的，而且看别的组都做得挺好的，这次就分享一下我们做的结果吧。 （注：此文假设读者已经具备一些隐马尔可夫模型的知识）&lt;/p&gt;
&lt;h2 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述&quot;&gt;&lt;/a&gt;任务描述&lt;/h2&gt;&lt;p&gt;实现一个中文拼音输入法。&lt;/p&gt;
&lt;p&gt;经过分析，分为以下几个模块来对中文拼音输入法进行实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心功能包括拼音切分(SplitPinyin.py)&lt;/li&gt;
&lt;li&gt;HMM模型训练(TrainMatrix.py)&lt;/li&gt;
&lt;li&gt;Trie树构建与搜索接口实现(PinyinTrie.py)&lt;/li&gt;
&lt;li&gt;维特比算法实现以及提供给UI的服务接口(GodTian_Pinyin.py)&lt;/li&gt;
&lt;li&gt;最后的UI实现(gui.py)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;技术路线&quot;&gt;&lt;a href=&quot;#技术路线&quot; class=&quot;headerlink&quot; title=&quot;技术路线&quot;&gt;&lt;/a&gt;技术路线&lt;/h2&gt;&lt;p&gt;在中文拼音输入法中，我们需要完成拼音序列到汉字序列的转换，比如输入“nihao”，输入法会给出我们想输入的字“你好”，到这里我们就可以问出几个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;如何切分拼音？ &lt;/strong&gt;&lt;br&gt;如： 用户输入”xiana”， 输入法应该判断用户想输入”xian a”（闲啊） 还是”xia na”（夏娜） 还是”xi an a”（西安啊）？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如何实时给用户以反馈？&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对于切分好的拼音，怎样找出用户最想输入的一串中文显示给用户？&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户输入的拼音是错的的情况下，如何容忍这种错误？该如何显示？&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也许我们还能问出更多的问题，中文拼音输入法就是这样，总有可以继续抠下去的细节。&lt;br&gt;那么我们如何解决上面的问题？我们的方案如下：&lt;/p&gt;
&lt;h3 id=&quot;如何切分拼音？&quot;&gt;&lt;a href=&quot;#如何切分拼音？&quot; class=&quot;headerlink&quot; title=&quot;如何切分拼音？&quot;&gt;&lt;/a&gt;如何切分拼音？&lt;/h3&gt;&lt;p&gt;这里我们暂时采用最长匹配的方式，也就是说，如果用户输入的首个串是拼音或者是某个合法拼音的前缀，那么我们会继续向后发现，等待用户输入，直到用户输完后发现这个字符（假设是第n个）与原来n-1个不是合法的拼音也不是合法的拼音的前缀，那么此时将前面n-1串切分成拼音，这就完成了一个拼音的发现，比如说输入”xiant”（想输xiantian），则我们会扫描这个串，一直到”xian”，到”xiant”的时候发现既不是合法拼音的前缀也不是合法拼音，那么从t前面划分开，得到”xian’t”，同样的道理发现后续的拼音。&lt;br&gt;在实时任务中，用户即使没有输完我们仍应该显示东西，那么我们先切分拼音，最多只会有最后一个是不完整的拼音前缀，那么我们将完整的和不完整的分开处理。假设是”xian’t”的情况，我们将”xian”放入viterbi算法中，通过HMM得出概率最大的一个输出串，然后将最后的”t”在训练过的Trie树中搜索出所有以”t”为前缀的字，以及他们出现的频率，取频率最高的若干个，作为viterbi算法的下一个状态的可能集合，然后得到他们的拼音，与前面n-1个拼音组合起来跑Viterbi算法，得到最可能的一个中文串，由于这些频率最高的字的拼音（即我们可能的观测值）可能不相同，我们只能将相同音的字作为一次viterbi算法运行的下一状态，这样viterbi跑的次数就是这些字里面不同音的个数，但是由于总数固定，异音越多，每个音对应的越少，所以总时间是没有差别的。&lt;br&gt;具体Trie树会在后面讲解。&lt;/p&gt;
&lt;h3 id=&quot;如何实时给用户以反馈？&quot;&gt;&lt;a href=&quot;#如何实时给用户以反馈？&quot; class=&quot;headerlink&quot; title=&quot;如何实时给用户以反馈？&quot;&gt;&lt;/a&gt;如何实时给用户以反馈？&lt;/h3&gt;&lt;p&gt;上面其实已经初步解释了如何实时反馈，实时反馈我们要做的就是用户每输一个字母，我们就能够显示出用户可能想要打的字，那么，以一个字母开头的拼音有很多，每个拼音对应的字也可能有很多，也即结果有很多，但是我们又不能漏掉，所以只能考虑所有的字，比较选出概率最大的若干个字，这时候我们可以采用Trie树来解决。Trie树就是前缀树，说白了就是将拼音的字母按顺序顺着根插入到树中，每个叶子节点就是一个拼音，这个拼音就是顺着根一路走下来取的字母的顺序组合，这样我们就可以找出以任意字符串为前缀的所有拼音，方法就是dfs遍历每一个以其为前缀的子树的叶子节点，这时候我们叶子节点存的其实是一个字典，key为这个拼音对应的可能的字，value为这个字出现的频率，以作为比较。&lt;/p&gt;
&lt;h3 id=&quot;对于切分好的拼音，怎样找出用户最想输入的一串中文显示给用户？&quot;&gt;&lt;a href=&quot;#对于切分好的拼音，怎样找出用户最想输入的一串中文显示给用户？&quot; class=&quot;headerlink&quot; title=&quot;对于切分好的拼音，怎样找出用户最想输入的一串中文显示给用户？&quot;&gt;&lt;/a&gt;对于切分好的拼音，怎样找出用户最想输入的一串中文显示给用户？&lt;/h3&gt;&lt;p&gt;这里我们使用隐马尔可夫模型，将用户想输入的中文字作为隐状态，用户输入的拼音为显状态，通过最大似然估计即频率估计出HMM的三个矩阵的值，最后通过viterbi算法找出概率最大的若干个中文字串显示出来。&lt;/p&gt;
&lt;h3 id=&quot;用户输入的拼音是错的的情况下，如何容忍这种错误？该如何显示？&quot;&gt;&lt;a href=&quot;#用户输入的拼音是错的的情况下，如何容忍这种错误？该如何显示？&quot; class=&quot;headerlink&quot; title=&quot;用户输入的拼音是错的的情况下，如何容忍这种错误？该如何显示？&quot;&gt;&lt;/a&gt;用户输入的拼音是错的的情况下，如何容忍这种错误？该如何显示？&lt;/h3&gt;&lt;p&gt;由于考虑到实现高度容错的复杂性，我们假设用户会输入正确的拼音，在想分割的时候会自行添加分隔符”‘“，由于大部分输入法用户绝大部分时间都会输入正确的拼音，所以，这样一个假设既简化了实现的过程，又没有损失太大的用户体验。&lt;/p&gt;
&lt;h2 id=&quot;用到的数据&quot;&gt;&lt;a href=&quot;#用到的数据&quot; class=&quot;headerlink&quot; title=&quot;用到的数据&quot;&gt;&lt;/a&gt;用到的数据&lt;/h2&gt;&lt;p&gt;由于训练HMM模型的需要，我们从搜狗实验室找到了SogouQ用户查询数据集，预处理成合法的句子之后大约有360M，且为了避免查询句太短，我们也增加了将近30M的搜狐新闻数据作为训练语料，这里面包含了很多的长句子。&lt;br&gt;通过这两个语料的训练，我们得到了长句和短句皆可表现较好效果的HMM模型。并且我们还可以继续拓展语料，以增加我们HMM模型的准确性，这是后话，不提。&lt;/p&gt;
&lt;h2 id=&quot;遇到的问题及解决方案，&quot;&gt;&lt;a href=&quot;#遇到的问题及解决方案，&quot; class=&quot;headerlink&quot; title=&quot;遇到的问题及解决方案，&quot;&gt;&lt;/a&gt;遇到的问题及解决方案，&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;UI界面的问题，由于UI设计的复杂性与不同系统的考虑，出现了许多莫名其妙的BUG，这使得我们花了许多时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;viterbi算法的效率问题，由于以某个字母开头的拼音对应的字有很多个，假设我们取最优的K个，我们需要将这K个与前面已有的拼音组合，然后跑一遍Viterbi算法，由于Viterbi算法从一个状态转移到另一个状态的计算量很大，我们使用了记忆（cache）的方法来加速，具体方法就是记录下某一个完整拼音串所对应的viterbi算法的最后一个状态的相关情况，这样如果我们再次遇到这个拼音串（A） 加上另一个拼音（B）跑viterbi的情况，我们就不需要从这个组合串的开头开始跑viterbi算法了，而是直接从A 串跑完viterbi的最后一个状态（从记忆单元读取）开始，向B进行转移。&lt;br&gt;这个记忆单元会随着程序而一直存在，并且我们对这个对象做了持久化，在输入法启动时我们会读取这个文件（记忆单元），这也就意味着，如果我们曾经输入过某个拼音串，那么我们以后再输入同样的拼音串的时候，不再需要跑核心算法，而是直接显示结果，这样在速度上就取得了显著的提高，就会出现，输入法越用越好用，越用越快的好处，当然这牺牲了一些存储空间，但是如今我们都不缺存储空间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;重复计算的问题，比如在用户觉得打错了的时候，往后退格，这时就会退到某一个前缀，但是其实这个前缀我们是算过了的，也显示过了的，就是说我们退回到我们以前显示过的内容的时候，如果不加优化，那么又会重新跑一遍核心的viterbi算法，这样就会很慢，那么我们还是利用cache思想，将输入的拼音串以及对应的显示结果相对应并且存起来，这样我们就做到了飞速的退格操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Python语言固有的性能问题，解决这个问题只有更换语言，事实上用C++语言实现的话我相信会快很多，这在后面可以考虑用C++实现，这也是完全可行的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;性能评价&quot;&gt;&lt;a href=&quot;#性能评价&quot; class=&quot;headerlink&quot; title=&quot;性能评价&quot;&gt;&lt;/a&gt;性能评价&lt;/h2&gt;&lt;p&gt;输入比较迅速，绝大多数输入能在1秒以内显示。输入过的句子再输入和退格操作都是毫秒级别的。&lt;/p&gt;
&lt;h2 id=&quot;给出程序的运行环境&quot;&gt;&lt;a href=&quot;#给出程序的运行环境&quot; class=&quot;headerlink&quot; title=&quot;给出程序的运行环境&quot;&gt;&lt;/a&gt;给出程序的运行环境&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Python 2.7&lt;/li&gt;
&lt;li&gt;需要安装的Python包： Tkinter, cPickle, pypinyin等模块&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;执行方法及参数&quot;&gt;&lt;a href=&quot;#执行方法及参数&quot; class=&quot;headerlink&quot; title=&quot;执行方法及参数&quot;&gt;&lt;/a&gt;执行方法及参数&lt;/h2&gt;&lt;p&gt;在项目Project目录下，运行&lt;br&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ &lt;span class=&quot;keyword&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;gui&lt;/span&gt;.&lt;span class=&quot;keyword&quot;&gt;py&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;即可。&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/GodTian_Pinyin.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Future-Works&quot;&gt;&lt;a href=&quot;#Future-Works&quot; class=&quot;headerlink&quot; title=&quot;Future Works&quot;&gt;&lt;/a&gt;Future Works&lt;/h2&gt;&lt;p&gt;由上面我们可以看到其实可以做的工作还很多，比如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;改换编译型语言，如C++，大幅减小计算开销&lt;/li&gt;
&lt;li&gt;不断随着用户的输入更新HMM模型&lt;/li&gt;
&lt;li&gt;将软件嵌入系统中&lt;/li&gt;
&lt;li&gt;我们观察到，长句输入很少有多个是想打的，不想短句可能想打的情况很多，所以很多与输入拼音串长度相同的句子我们可以换成短句。&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Reference-and-Links&quot;&gt;&lt;a href=&quot;#Reference-and-Links&quot; class=&quot;headerlink&quot; title=&quot;Reference and Links&quot;&gt;&lt;/a&gt;Reference and Links&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;A Revealing Introduction to Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://my.oschina.net/u/158589/blog/61037&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Trie 的原理和实现 (python 实现)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/LiuRoy/Pinyin_Demo&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Pinyin_Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/letiantian/Pinyin2Hanzi&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Pinyin2Hanzi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S1571066115000638&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Adapting Hidden Markov Models for Online Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://core.ac.uk/download/pdf/4881023.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Smooth On-Line Learning Algorithm for Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.7176&amp;amp;rep=rep1&amp;amp;type=pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;A survey of techniques for incremental learning of HMM parameters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/whatbeg/GodTian_Pinyin&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GodTian_Pinyin Code on my Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.sogou.com/labs/resource/list_pingce.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;搜狗实验室&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SogouQ 和 SohuNews 整理好的数据有兴趣可以发邮件问我要&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;众所周知，中文输入法是一个历史悠久的问题，但也实在是个繁琐的活，不知道这是不是网上很少有人分
    
    </summary>
    
      <category term="算法 | Algorithm" scheme="http://whatbeg.com/categories/%E7%AE%97%E6%B3%95-Algorithm/"/>
    
    
      <category term="算法" scheme="http://whatbeg.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>大数据系统方面的经典论文</title>
    <link href="http://whatbeg.com/2016/10/06/bigdatapapers.html"/>
    <id>http://whatbeg.com/2016/10/06/bigdatapapers.html</id>
    <published>2016-10-06T12:57:12.000Z</published>
    <updated>2017-01-11T06:52:15.457Z</updated>
    
    <content type="html">&lt;p&gt;本文转自&lt;a href=&quot;www.52cs.org/?p=1203&quot;&gt;《大数据系统方面的经典论文》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;说明：下面倾向选取已经在工业界广泛使用的系统论文，还有很多优秀论文没有在列表中，可以查阅近年来SOSP/OSDI/EuroSys/USENIX ATC/SIGMOD/VLDB/NIPS/ICML/KDD等相关会议获取。&lt;/p&gt;
&lt;h2 id=&quot;分布式数据并行处理框架与编程模型&quot;&gt;&lt;a href=&quot;#分布式数据并行处理框架与编程模型&quot; class=&quot;headerlink&quot; title=&quot;分布式数据并行处理框架与编程模型&quot;&gt;&lt;/a&gt;分布式数据并行处理框架与编程模型&lt;/h2&gt;&lt;p&gt;[Google MapReduce] Jeffrey Dean, Sanjay Ghemawat:&lt;br&gt;MapReduce: Simplified Data Processing on Large Clusters. OSDI 2004: 137-150&lt;/p&gt;
&lt;p&gt;[Microsoft Dryad] Michael Isard, Mihai Budiu, Yuan Yu, Andrew Birrell, Dennis Fetterly:&lt;br&gt;Dryad: distributed data-parallel programs from sequential building blocks. EuroSys 2007: 59-72&lt;/p&gt;
&lt;p&gt;[Microsoft DryadLINQ] Yuan Yu, Michael Isard, Dennis Fetterly, Mihai Budiu, Úlfar Erlingsson, Pradeep Kumar Gunda, Jon Currey:&lt;br&gt;DryadLINQ: A System for General-Purpose Distributed Data-Parallel Computing Using a High-Level Language. OSDI 2008: 1-14&lt;/p&gt;
&lt;p&gt;[Google FlumeJava] Craig Chambers, Ashish Raniwala, Frances Perry, Stephen Adams, Robert R. Henry, Robert Bradshaw, Nathan Weizenbaum:&lt;br&gt;FlumeJava: easy, efficient data-parallel pipelines. PLDI 2010: 363-375&lt;/p&gt;
&lt;p&gt;[Apache Spark Core] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauly, Michael J. Franklin, Scott Shenker, Ion Stoica:&lt;br&gt;Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing. NSDI2012: 15-28&lt;/p&gt;
&lt;p&gt;[Google Cloud Dataflow] Tyler Akidau, Robert Bradshaw, Craig Chambers, Slava Chernyak, Rafael Fernández-Moctezuma, Reuven Lax, Sam McVeety, Daniel Mills, Frances Perry, Eric Schmidt, Sam Whittle:&lt;br&gt;The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing. PVLDB 8(12): 1792-1803 (2015)&lt;/p&gt;
&lt;p&gt;[Apache Tez] Bikas Saha, Hitesh Shah, Siddharth Seth, Gopal Vijayaraghavan, Arun C. Murthy, Carlo Curino:&lt;br&gt;Apache Tez: A Unifying Framework for Modeling and Building Data Processing Applications. SIGMOD Conference 2015: 1357-1369&lt;/p&gt;
&lt;p&gt;[Apache Flink] Paris Carbone, Asterios Katsifodimos, Stephan Ewen, Volker Markl, Seif Haridi, Kostas Tzoumas:&lt;br&gt;Apache Flink™: Stream and Batch Processing in a Single Engine. IEEE Data Eng. Bull. 38(4): 28-38 (2015)&lt;/p&gt;
&lt;h2 id=&quot;大数据SQL&quot;&gt;&lt;a href=&quot;#大数据SQL&quot; class=&quot;headerlink&quot; title=&quot;大数据SQL&quot;&gt;&lt;/a&gt;大数据SQL&lt;/h2&gt;&lt;p&gt;[Google Sawzall] Rob Pike, Sean Dorward, Robert Griesemer, Sean Quinlan:&lt;br&gt;Interpreting the data: Parallel analysis with Sawzall. Scientific Programming 13(4): 277-298 (2005)&lt;/p&gt;
&lt;p&gt;[Apache Pig] Christopher Olston, Benjamin Reed, Utkarsh Srivastava, Ravi Kumar, Andrew Tomkins:&lt;br&gt;Pig latin: a not-so-foreign language for data processing. SIGMOD Conference 2008: 1099-1110&lt;/p&gt;
&lt;p&gt;[Apache Hive] Ashish Thusoo, Joydeep Sen Sarma, Namit Jain, Zheng Shao, Prasad Chakka, Suresh Anthony, Hao Liu, Pete Wyckoff,Raghotham Murthy:&lt;br&gt;Hive - A Warehousing Solution Over a Map-Reduce Framework. PVLDB 2(2): 1626-1629 (2009)&lt;/p&gt;
&lt;p&gt;[Berkeley Spark Shark] Reynold S. Xin, Josh Rosen, Matei Zaharia, Michael J. Franklin, Scott Shenker, Ion Stoica:&lt;br&gt;Shark: SQL and rich analytics at scale. SIGMOD Conference 2013: 13-24&lt;/p&gt;
&lt;p&gt;[Apache Spark SQL] Michael Armbrust, Reynold S. Xin, Cheng Lian, Yin Huai, Davies Liu, Joseph K. Bradley, Xiangrui Meng, Tomer Kaftan, Michael J. Franklin, Ali Ghodsi, Matei Zaharia:&lt;br&gt;Spark SQL: Relational Data Processing in Spark. SIGMOD Conference 2015: 1383-1394&lt;/p&gt;
&lt;p&gt;[Google Tenzing] Biswapesh Chattopadhyay, Liang Lin, Weiran Liu, Sagar Mittal, Prathyusha Aragonda, Vera Lychagina, Younghee Kwon, Michael Wong:&lt;br&gt;Tenzing A SQL Implementation On The MapReduce Framework. PVLDB 4(12): 1318-1327 (2011)&lt;/p&gt;
&lt;h2 id=&quot;大规模图计算&quot;&gt;&lt;a href=&quot;#大规模图计算&quot; class=&quot;headerlink&quot; title=&quot;大规模图计算&quot;&gt;&lt;/a&gt;大规模图计算&lt;/h2&gt;&lt;p&gt;[Google Pregel] Grzegorz Malewicz, Matthew H. Austern, Aart J. C. Bik, James C. Dehnert, Ilan Horn, Naty Leiser, Grzegorz Czajkowski:&lt;br&gt;Pregel: a system for large-scale graph processing. SIGMOD Conference 2010: 135-146&lt;/p&gt;
&lt;p&gt;[CMU GraphLab] Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin, Joseph M. Hellerstein:&lt;br&gt;Distributed GraphLab: A Framework for Machine Learning in the Cloud. PVLDB 5(8): 716-727 (2012)&lt;/p&gt;
&lt;p&gt;[CMU PowerGraph] Joseph E. Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson, Carlos Guestrin:&lt;br&gt;PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs. OSDI 2012: 17-30&lt;/p&gt;
&lt;p&gt;[CMU GraphChi] Aapo Kyrola, Guy E. Blelloch, Carlos Guestrin:&lt;br&gt;GraphChi: Large-Scale Graph Computation on Just a PC. OSDI 2012: 31-46&lt;/p&gt;
&lt;p&gt;[Apache Spark GraphX] Joseph E. Gonzalez, Reynold S. Xin, Ankur Dave, Daniel Crankshaw, Michael J. Franklin, Ion Stoica:&lt;br&gt;GraphX: Graph Processing in a Distributed Dataflow Framework. OSDI 2014: 599-613&lt;/p&gt;
&lt;h2 id=&quot;分布式机器学习&quot;&gt;&lt;a href=&quot;#分布式机器学习&quot; class=&quot;headerlink&quot; title=&quot;分布式机器学习&quot;&gt;&lt;/a&gt;分布式机器学习&lt;/h2&gt;&lt;p&gt;[Google Distbelief] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V. Le, Mark Z. Mao, Marc’Aurelio Ranzato, Andrew W. Senior, Paul A. Tucker, Ke Yang, Andrew Y. Ng:&lt;br&gt;Large Scale Distributed Deep Networks. NIPS 2012: 1232-1240&lt;/p&gt;
&lt;p&gt;[CMU Parameter Server] Mu Li, David G. Andersen, Jun Woo Park, Alexander J. Smola, Amr Ahmed, Vanja Josifovski, James Long,Eugene J. Shekita, Bor-Yiing Su:&lt;br&gt;&lt;a href=&quot;https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Scaling Distributed Machine Learning with the Parameter Server&lt;/a&gt;. OSDI 2014: 583-598&lt;/p&gt;
&lt;p&gt;[CMU Petuum] Eric P. Xing, Qirong Ho, Wei Dai, Jin Kyu Kim, Jinliang Wei, Seunghak Lee, Xun Zheng, Pengtao Xie, Abhimanu Kumar, Yaoliang Yu:&lt;br&gt;Petuum: A New Platform for Distributed Machine Learning on Big Data. KDD 2015: 1335-1344&lt;/p&gt;
&lt;p&gt;[Google TensorFlow] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis,Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,Yangqing Jia, Rafal Józefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore,Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, Xiaoqiang Zheng:&lt;br&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.04467&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems&lt;/a&gt;. CoRR abs/1603.04467 (2016)&lt;/p&gt;
&lt;p&gt;[Open-source MXNet] Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, Zheng Zhang:&lt;br&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.01274&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems&lt;/a&gt;. CoRRabs/1512.01274 (2015)&lt;/p&gt;
&lt;p&gt;[Apache Spark MLlib] Xiangrui Meng, Joseph K. Bradley, Burak Yavuz, Evan R. Sparks, Shivaram Venkataraman, Davies Liu, Jeremy Freeman, D. B. Tsai, Manish Amde, Sean Owen, Doris Xin, Reynold Xin, Michael J. Franklin, Reza Zadeh, Matei Zaharia, Ameet Talwalkar:&lt;br&gt;MLlib: Machine Learning in Apache Spark. CoRR abs/1505.06807 (2015)&lt;/p&gt;
&lt;p&gt;[CMU SSP Protocol] Henggang Cui, James Cipar, Qirong Ho, Jin Kyu Kim, Seunghak Lee, Abhimanu Kumar, Jinliang Wei, Wei Dai,Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, Eric P. Xing:&lt;br&gt;Exploiting Bounded Staleness to Speed Up Big Data Analytics. USENIX Annual Technical Conference2014: 37-48&lt;/p&gt;
&lt;h2 id=&quot;流式数据处理&quot;&gt;&lt;a href=&quot;#流式数据处理&quot; class=&quot;headerlink&quot; title=&quot;流式数据处理&quot;&gt;&lt;/a&gt;流式数据处理&lt;/h2&gt;&lt;p&gt;[Apache Spark Streaming] Matei Zaharia, Tathagata Das, Haoyuan Li, Timothy Hunter, Scott Shenker, Ion Stoica:&lt;br&gt;Discretized streams: fault-tolerant streaming computation at scale. SOSP 2013: 423-438&lt;/p&gt;
&lt;p&gt;[Google MillWheel] Tyler Akidau, Alex Balikov, Kaya Bekiroglu, Slava Chernyak, Josh Haberman, Reuven Lax, Sam McVeety, Daniel Mills, Paul Nordstrom, Sam Whittle:&lt;br&gt;MillWheel: Fault-Tolerant Stream Processing at Internet Scale. PVLDB 6(11): 1033-1044 (2013)&lt;/p&gt;
&lt;p&gt;[Microsoft TimeStream] Zhengping Qian, Yong He, Chunzhi Su, Zhuojie Wu, Hongyu Zhu, Taizhi Zhang, Lidong Zhou, Yuan Yu, Zheng Zhang:&lt;br&gt;TimeStream: reliable stream computation in the cloud. EuroSys 2013: 1-14&lt;/p&gt;
&lt;h2 id=&quot;资源管理与任务调度&quot;&gt;&lt;a href=&quot;#资源管理与任务调度&quot; class=&quot;headerlink&quot; title=&quot;资源管理与任务调度&quot;&gt;&lt;/a&gt;资源管理与任务调度&lt;/h2&gt;&lt;p&gt;[Apache Hadoop YARN] Vinod Kumar Vavilapalli, Arun C. Murthy, Chris Douglas, Sharad Agarwal, Mahadev Konar, Robert Evans,Thomas Graves, Jason Lowe, Hitesh Shah, Siddharth Seth, Bikas Saha, Carlo Curino, Owen O’Malley, Sanjay Radia, Benjamin Reed, Eric Baldeschwieler:&lt;br&gt;Apache Hadoop YARN: yet another resource negotiator. SoCC 2013: 5:1-5:16&lt;/p&gt;
&lt;p&gt;[Apache Mesos] Benjamin Hindman, Andy Konwinski, Matei Zaharia, Ali Ghodsi, Anthony D. Joseph, Randy H. Katz, Scott Shenker, Ion Stoica:&lt;br&gt;Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center. NSDI 2011&lt;/p&gt;
&lt;p&gt;[Google Borg] Abhishek Verma, Luis Pedrosa, Madhukar Korupolu, David Oppenheimer, Eric Tune, John Wilkes:&lt;br&gt;Large-scale cluster management at Google with Borg. EuroSys 2015: 18:1-18:17&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文转自&lt;a href=&quot;www.52cs.org/?p=1203&quot;&gt;《大数据系统方面的经典论文》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;说明：下面倾向选取已经在工业界广泛使用的系统论文，还有很多优秀论文没有在列表中，可以查阅近年来SOSP/OSDI/EuroSys/USENIX ATC/
    
    </summary>
    
      <category term="大数据系统与技术 | Big Data" scheme="http://whatbeg.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%8A%80%E6%9C%AF-Big-Data/"/>
    
    
      <category term="大数据" scheme="http://whatbeg.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>多台虚拟机搭建模拟网络环境</title>
    <link href="http://whatbeg.com/2016/09/24/vmnetconstruction.html"/>
    <id>http://whatbeg.com/2016/09/24/vmnetconstruction.html</id>
    <published>2016-09-24T07:19:51.000Z</published>
    <updated>2016-09-24T07:39:41.339Z</updated>
    
    <content type="html">&lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;采用多台虚拟机在一台计算机实体上模拟一个小型的网络环境。&lt;br&gt;我们采用虚拟机（ Virtual Machine）软件来模拟一个网络环境进行实验，这类软件的主&lt;br&gt;要功能是利用软件来模拟出具有完整硬件系统功能的且运行在隔离环境中的完整计算机系统。这样我们可以在一台物理计算机即宿主机器（Host Machine）上模拟出一台或多台虚拟的计算机。这些虚拟机能够像真正的计算机那样进行工作，我们可以在其上安装全新的操作系统和应用软件。通过虚拟机软件中的虚连接设备将各个虚拟机连接起来，我们就可以搭建出实验所需的网络环境。&lt;/p&gt;
&lt;h2 id=&quot;网络拓扑&quot;&gt;&lt;a href=&quot;#网络拓扑&quot; class=&quot;headerlink&quot; title=&quot;网络拓扑&quot;&gt;&lt;/a&gt;网络拓扑&lt;/h2&gt;&lt;p&gt;接下来给出要构建的网络拓扑结构和拓扑结构配置信息表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-01.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-02.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;此次实验我们采用5台虚拟机，分别为UT-571~UT-575，网络拓扑中有两台路由器，分别用UT-571和UT-574来模拟，两个路由器通过网络相连，这里用虚拟网络VMnet4来模拟，两个路由器分别下辖PC0，PC1和PC2三台主机，三台主机分别用UT-572,UT-573和UT-575来模拟。&lt;/p&gt;
&lt;p&gt;由网络拓扑结构图可以看出，PC0，PC1和Route0处于同一个网段，网段为192.168.2.0/24，而PC2和Route1处于同一个网段，为192.168.3.0/24，然后为了实现两个网段的联通，我们将两个路由器设置在同一个网段192.168.4.0/24中，即需要三个虚拟网络，来实现5台机器相互的联通。&lt;br&gt;我们的目标是配置每台机器的网卡，IP，网关和路由器的转发表，使得此虚拟网络上的每台机器之间都可以实现通信。&lt;br&gt;图中正方体的图形表示局域网的交换机。&lt;br&gt;最后我们通过机器之间相互Ping操作来测试是否联通。&lt;/p&gt;
&lt;h2 id=&quot;步骤&quot;&gt;&lt;a href=&quot;#步骤&quot; class=&quot;headerlink&quot; title=&quot;步骤&quot;&gt;&lt;/a&gt;步骤&lt;/h2&gt;&lt;h3 id=&quot;配置虚拟机&quot;&gt;&lt;a href=&quot;#配置虚拟机&quot; class=&quot;headerlink&quot; title=&quot;配置虚拟机&quot;&gt;&lt;/a&gt;配置虚拟机&lt;/h3&gt;&lt;p&gt;我们至少需要给每台虚拟机配置一个网卡以实现网络互连，并且需要给虚拟机UT-571和UT-574配置两块网卡，因为它们是路由器，分属于两个网段，配置虚拟机的过程如下所示：&lt;br&gt;在虚拟机开机之前选择编辑选项&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-0301.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果之前没有网卡，那么点Add添加网卡，然后next：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-03.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-04.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;添加网卡的配置，选择Custom: Specific virtual network，将机器配置到对应的虚拟网络，如PC0和PC1配置到VMnet2，PC2配置到VMnet3，两个路由器虚拟机配置添加两块网卡分别设为两个网段。&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-05.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-06.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置每个终端PC&quot;&gt;&lt;a href=&quot;#设置每个终端PC&quot; class=&quot;headerlink&quot; title=&quot;设置每个终端PC&quot;&gt;&lt;/a&gt;设置每个终端PC&lt;/h3&gt;&lt;p&gt;ip 地址是计算机进行网络通讯的基础，每一台联网计算机都至少具有一个 ip 地址。在日常使用中，我们通常能自动获取 ip，这是由于 DHCP 协议的作用。这次我们需要手动为配置好的虚拟网络分配 ip 地址。&lt;/p&gt;
&lt;p&gt;打开每台机器（PC0，PC1，PC2）的终端Terminal，输入&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ifconfig &lt;span class=&quot;_&quot;&gt;-a&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;将会看到如下的输出：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输出显示机器网卡还没有配置IPV4地址，我们将手动配置固定的IP地址。&lt;/p&gt;
&lt;p&gt;为了防止DHCP协议和Network Manager的干扰，改变我们设置的IP地址，我们输入&lt;br&gt;&lt;figure class=&quot;highlight arduino&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo service network-manager &lt;span class=&quot;built_in&quot;&gt;stop&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;停用network-manager服务，这样我们设置的IP就不会被系统改变了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Network Manager是Linux系统进行网络管理的一项服务。&lt;br&gt;Network Manager由一个管理系统网络连接、并且将其状态通过D-BUS（是一个提供简单的应用程序互相通讯的途径的自由软件项目，它是做为freedesktoporg项目的一部分来开发的。）进行报告的后台服务，以及一个允许用户管理网络连接的客户端程序。&lt;br&gt;Network Manager的优点：简化网络连接的工作，让桌面本身和其他应用程序能感知网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想了解network manager请自行查阅资料。&lt;/p&gt;
&lt;p&gt;然后设置各个PC的IP，PC0和PC1由于同处192.168.2.0/24网段，所以我们将它们的IP分别设置为192.168.2.2（UT-572）和192.168.2.3（UT-573），将192.168.2.1留给路由器Route0（UT-571）使用。&lt;br&gt;设置IP地址有如下命令：（以192.168.2.2为例）&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ifconfig&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;eth0&lt;/span&gt; 192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;netmask&lt;/span&gt; 255&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后可使用&lt;code&gt;ifconfig -a&lt;/code&gt;命令查看IP情况如图。&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-09.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后设置默认网关为该网段的路由器Route0的eth0的IP地址（192.168.2.1）：&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;gw&lt;/span&gt; 192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样一个终端PC就已经配置好了，它有了自己的IP地址和默认网关。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;大家都知道，从一个房间走到另一个房间，必然要经过一扇门。同样，从一个网络向另一个网络发送信息，也必须经过一道“关口”，这道关口就是网关。顾名思义，网关（Gateway）就是一个网络连接到另一个网络的“关口”，也就是网络关卡（–百度百科），此时PC0的网络关口就是它的路由器Route0的eth0。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其它终端PC配置相似。&lt;/p&gt;
&lt;h3 id=&quot;设置路由器&quot;&gt;&lt;a href=&quot;#设置路由器&quot; class=&quot;headerlink&quot; title=&quot;设置路由器&quot;&gt;&lt;/a&gt;设置路由器&lt;/h3&gt;&lt;p&gt;IP地址设置同上，&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;ifconfig&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;-a&lt;/span&gt;  # 查看&lt;span class=&quot;selector-tag&quot;&gt;IP&lt;/span&gt;地址情况&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ifconfig&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;eth0&lt;/span&gt; 192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;netmask&lt;/span&gt; 255&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;  # 设置&lt;span class=&quot;selector-tag&quot;&gt;eth0&lt;/span&gt;端&lt;span class=&quot;selector-tag&quot;&gt;IP&lt;/span&gt;地址&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;selector-tag&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;ifconfig&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;eth1&lt;/span&gt; 192&lt;span class=&quot;selector-class&quot;&gt;.168&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.4&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.1&lt;/span&gt; &lt;span class=&quot;selector-tag&quot;&gt;netmask&lt;/span&gt; 255&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.255&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.0&lt;/span&gt;  # &lt;span class=&quot;selector-tag&quot;&gt;eth1&lt;/span&gt;端&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;eth0是面向PC0和PC1的网卡，而eth1是面向另一个网段(192.168.4.0/24)的的网卡&lt;br&gt;但路由器毕竟是路由器，它还需要有一套路由转发表，以便起到路由的作用。&lt;br&gt;所以接下来设置Route0（UT-571）的路由表：&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;sudo&lt;/span&gt; ip route add &lt;span class=&quot;number&quot;&gt;192.168.2.0&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt; via &lt;span class=&quot;number&quot;&gt;192.168.2.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ip route add &lt;span class=&quot;number&quot;&gt;192.168.3.0&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt; via &lt;span class=&quot;number&quot;&gt;192.168.4.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ip route add &lt;span class=&quot;number&quot;&gt;192.168.4.0&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt; via &lt;span class=&quot;number&quot;&gt;192.168.4.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其中 ip route add 192.168.2.0/24 via 192.168.2.1 命令添加的规则，告诉路由目的 ip 在&lt;br&gt;192.168.2.0/24(192.168.2.1~192.168.2.255)网段内的封包经由 ip 地址为 192.168.2.1 的设备(Route0)转发出去，即下一跳的 ip 为 192.168.2.1。而 192.168.2.0/24 是 Linux 中常用的掩码表示方式。&lt;br&gt;24 表示掩码字长为 24 即掩码为 255.255.255.0， 192.168.2 为网络号， 1 ~ 254 为网络中的主机号。此外还有其他形式用于添加路由规则的命令。&lt;br&gt;而第二条规则表示告诉路由目的IP在192.168.3.0/24网段的封包要经过的下一跳IP为192.168.4.2（即VMnet4的另一端，也即Route1的eth1，因为Route1是网段192.168.3.0/24的路由器）&lt;br&gt;最后一条规则表示，告诉路由目的IP在192.168.4.0/24网段的封包将被转发的下一跳IP为192.168.4.1即Route0的eth1.&lt;/p&gt;
&lt;p&gt;最后我们要让虚拟路由允许转发，置虚拟机 U-571 的 &lt;code&gt;ip_forward&lt;/code&gt; 标志为 1。 这里我们需要把&lt;code&gt;/proc/sys/net/ipv4/&lt;/code&gt;目录下的文件&lt;code&gt;ip_forward&lt;/code&gt;值置为 1。使用命令 echo，形如：&lt;br&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &amp;gt; /&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;proc&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;sys&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;net&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;ipv4&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;ip_forward&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样我们的路由器Route0也就设置好了，以相同的步骤我们很快可以设置好Route1。&lt;br&gt;一些步骤图如下：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-07.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-08.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h3&gt;&lt;p&gt;最后我们可以在不同的虚拟机上ping别的虚拟机的IP，已测试是否实现互联互通。&lt;/p&gt;
&lt;p&gt;PC0 ping PC1:&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;PC0 ping Route1 eth1 和 PC2:&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;PC2 ping PC0, PC1:&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-22.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;等等等等，容易看到，正确设置的情况下，都可以ping通，实现了两个局域网的互联互通。&lt;/p&gt;
&lt;h3 id=&quot;wireshark抓包&quot;&gt;&lt;a href=&quot;#wireshark抓包&quot; class=&quot;headerlink&quot; title=&quot;wireshark抓包&quot;&gt;&lt;/a&gt;wireshark抓包&lt;/h3&gt;&lt;p&gt;在Terminal中输入&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;sudo&lt;/span&gt; wireshark&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;启动wireshark，通过下图蓝框选择要监听的设备，如eth0，然后在终端中启动ping，观测数据包的来往：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;结果如下，PC0 ping PC1的包流动情况：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-24.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;PC0 ping PC2的包流动情况：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-25.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;点开某个包，可以看到：&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/network-27.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;协议框中显示所选分组的各层协议：物理层帧、以太网帧及其首部、 IP 协议数据报及其首部， Internet控制报文协议。原始框中则显示分组中包含的数据的每个字节。从中可以观察到原始数据，其中左边显示的是十六进制的数据，右边则是 ASCII 码。在协议框中选中一个条目，在原始框中会标记出对应的原始数据，反之在原始框中选中也一样。&lt;/p&gt;
&lt;h2 id=&quot;完结&quot;&gt;&lt;a href=&quot;#完结&quot; class=&quot;headerlink&quot; title=&quot;完结&quot;&gt;&lt;/a&gt;完结&lt;/h2&gt;&lt;p&gt;这样，此次虚拟网络构建就成功了。&lt;br&gt;总的来说，计算机网络这个东西，知道 和 会做 之间有着很大的距离，一些基础的网络理论知识，真正用起来却显得无比的生疏，终究还是太菜了罢~&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;采用多台虚拟机在一台计算机实体上模拟一个小型的网络环境。&lt;br&gt;我们采用虚拟机（ Virtual Machine）软件来模拟一个网络环境进行
    
    </summary>
    
      <category term="计算机相关 | CS.Related" scheme="http://whatbeg.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9B%B8%E5%85%B3-CS-Related/"/>
    
    
      <category term="CS" scheme="http://whatbeg.com/tags/CS/"/>
    
  </entry>
  
  <entry>
    <title>珍藏多年的计算几何模板</title>
    <link href="http://whatbeg.com/2016/09/20/computationgeometrycomplate.html"/>
    <id>http://whatbeg.com/2016/09/20/computationgeometrycomplate.html</id>
    <published>2016-09-20T07:46:49.000Z</published>
    <updated>2016-09-20T08:04:17.120Z</updated>
    
    <content type="html">&lt;h2 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h2&gt;&lt;p&gt;珍藏多年的从前自己收集整理的一套计算几何的模板，如今也很少会用到了，不如公布出来供给广大ACMer学习参考之用，也算是没白费这一番功夫了。&lt;/p&gt;
&lt;p&gt;模板包括二维计算几何的绝大多数封装，包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;点，线，圆的基础定义&lt;/li&gt;
&lt;li&gt;向量操作&lt;/li&gt;
&lt;li&gt;点到线段的距离&lt;/li&gt;
&lt;li&gt;点到直线的距离&lt;/li&gt;
&lt;li&gt;判断直线相交并求交点&lt;/li&gt;
&lt;li&gt;判断线段相交并求交点&lt;/li&gt;
&lt;li&gt;向量旋转&lt;/li&gt;
&lt;li&gt;环顾法、射线法判断点是否在多边形内部&lt;/li&gt;
&lt;li&gt;判断未知时针方向的多边形是否是凸包&lt;/li&gt;
&lt;li&gt;求二维凸包&lt;/li&gt;
&lt;li&gt;求凸包面积&lt;/li&gt;
&lt;li&gt;求凸包周长&lt;/li&gt;
&lt;li&gt;旋转卡壳求凸包最远两点&lt;/li&gt;
&lt;li&gt;求两个凸包的最短距离&lt;/li&gt;
&lt;li&gt;多边形的边转为直线&lt;/li&gt;
&lt;li&gt;求半平面交&lt;/li&gt;
&lt;li&gt;直线切割多边形形成新的多边形&lt;/li&gt;
&lt;li&gt;判断点是否在圆内&lt;/li&gt;
&lt;li&gt;求两个圆的交点&lt;/li&gt;
&lt;li&gt;求线段与圆的交点&lt;/li&gt;
&lt;li&gt;求三角形与圆的交点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等，并且都通过了基础题的测试，形成一套可用的模板体系。&lt;/p&gt;
&lt;p&gt;大家有需要即取，不过模板虽好，必也得自己对算法有一番深入的学习理解才好，才有见效。&lt;/p&gt;
&lt;h2 id=&quot;模板&quot;&gt;&lt;a href=&quot;#模板&quot; class=&quot;headerlink&quot; title=&quot;模板&quot;&gt;&lt;/a&gt;模板&lt;/h2&gt;&lt;p&gt;C++语言&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;171&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;173&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;174&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;175&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;176&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;177&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;178&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;179&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;180&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;181&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;182&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;183&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;184&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;185&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;186&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;187&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;188&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;189&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;190&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;191&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;192&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;193&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;194&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;196&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;197&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;198&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;199&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;200&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;201&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;202&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;203&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;204&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;205&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;206&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;207&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;208&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;209&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;210&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;211&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;212&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;213&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;214&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;215&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;216&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;217&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;218&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;219&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;220&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;221&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;222&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;223&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;224&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;225&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;226&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;227&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;228&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;229&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;230&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;231&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;232&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;233&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;234&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;235&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;236&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;237&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;238&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;239&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;240&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;241&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;242&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;243&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;244&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;245&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;246&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;247&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;248&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;249&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;250&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;251&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;252&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;253&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;254&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;255&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;256&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;257&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;258&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;259&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;260&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;261&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;262&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;263&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;264&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;265&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;266&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;267&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;268&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;269&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;270&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;271&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;272&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;273&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;274&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;275&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;276&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;277&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;278&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;279&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;280&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;281&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;282&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;283&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;284&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;285&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;286&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;287&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;288&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;289&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;290&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;291&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;292&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;293&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;294&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;struct Point&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double x,y;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point(double x=0, double y=0):x(x),y(y) &amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    void input() &amp;#123; scanf(&quot;%lf%lf&quot;,&amp;amp;x,&amp;amp;y); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;typedef Point Vector;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;struct Circle&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point c;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double r;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Circle()&amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Circle(Point c,double r):c(c),r(r) &amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point point(double a) &amp;#123; return Point(c.x + cos(a)*r, c.y + sin(a)*r); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    void input() &amp;#123; scanf(&quot;%lf%lf%lf&quot;,&amp;amp;c.x,&amp;amp;c.y,&amp;amp;r); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;struct Line&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector v;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double ang;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Line()&amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Line(Point p, Vector v):p(p),v(v) &amp;#123; ang = atan2(v.y,v.x); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point point(double t) &amp;#123; return Point(p.x + t*v.x, p.y + t*v.y); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    bool operator &amp;lt; (const Line &amp;amp;L)const &amp;#123; return ang &amp;lt; L.ang; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int dcmp(double x) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(x &amp;lt; -eps) return -1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(x &amp;gt; eps) return 1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;template &amp;lt;class T&amp;gt; T sqr(T x) &amp;#123; return x * x;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector operator + (Vector A, Vector B) &amp;#123; return Vector(A.x + B.x, A.y + B.y); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector operator - (Vector A, Vector B) &amp;#123; return Vector(A.x - B.x, A.y - B.y); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector operator * (Vector A, double p) &amp;#123; return Vector(A.x*p, A.y*p); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector operator / (Vector A, double p) &amp;#123; return Vector(A.x/p, A.y/p); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool operator &amp;lt; (const Point&amp;amp; a, const Point&amp;amp; b) &amp;#123; return a.x &amp;lt; b.x || (a.x == b.x &amp;amp;&amp;amp; a.y &amp;lt; b.y); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool operator &amp;gt;= (const Point&amp;amp; a, const Point&amp;amp; b) &amp;#123; return a.x &amp;gt;= b.x &amp;amp;&amp;amp; a.y &amp;gt;= b.y; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool operator &amp;lt;= (const Point&amp;amp; a, const Point&amp;amp; b) &amp;#123; return a.x &amp;lt;= b.x &amp;amp;&amp;amp; a.y &amp;lt;= b.y; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool operator == (const Point&amp;amp; a, const Point&amp;amp; b) &amp;#123; return dcmp(a.x-b.x) == 0 &amp;amp;&amp;amp; dcmp(a.y-b.y) == 0; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double Dot(Vector A, Vector B) &amp;#123; return A.x*B.x + A.y*B.y; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double Length(Vector A) &amp;#123; return sqrt(Dot(A, A)); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double Angle(Vector A, Vector B) &amp;#123; return acos(Dot(A, B) / Length(A) / Length(B)); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double Cross(Vector A, Vector B) &amp;#123; return A.x*B.y - A.y*B.x; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector VectorUnit(Vector x)&amp;#123; return x / Length(x);&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector Normal(Vector x) &amp;#123; return Point(-x.y, x.x) / Length(x);&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double angle(Vector v) &amp;#123; return atan2(v.y, v.x); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool OnSegment(Point P, Point A, Point B) &amp;#123;         //端点也算&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return dcmp(Cross(A-P,B-P)) == 0 &amp;amp;&amp;amp; dcmp(Dot(A-P,B-P)) &amp;lt;= 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double DistanceToSeg(Point P, Point A, Point B) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(A == B) return Length(P-A);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector v1 = B-A, v2 = P-A, v3 = P-B;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(Dot(v1, v2)) &amp;lt; 0) return Length(v2);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(Dot(v1, v3)) &amp;gt; 0) return Length(v3);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return fabs(Cross(v1, v2)) / Length(v1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double DistanceToLine(Point P, Point A, Point B) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector v1 = B-A, v2 = P-A;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return fabs(Cross(v1,v2)) / Length(v1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Point GetLineIntersection(Line A, Line B) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector u = A.p - B.p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double t = Cross(B.v, u) / Cross(A.v, B.v);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return A.p + A.v*t;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double DisP(Point A,Point B) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return Length(B-A);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool SegmentIntersection(Point A,Point B,Point C,Point D) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return max(A.x,B.x) &amp;gt;= min(C.x,D.x) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           max(C.x,D.x) &amp;gt;= min(A.x,B.x) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           max(A.y,B.y) &amp;gt;= min(C.y,D.y) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           max(C.y,D.y) &amp;gt;= min(A.y,B.y) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           dcmp(Cross(C-A,B-A)*Cross(D-A,B-A)) &amp;lt;= 0 &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           dcmp(Cross(A-C,D-C)*Cross(B-C,D-C)) &amp;lt;= 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool LineSegmentIntersection(Point A,Point B,Point C,Point D) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return dcmp(Cross(C-A,B-A)*Cross(D-A,B-A)) &amp;lt;= 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void SegIntersectionPoint(Point&amp;amp; P,Point a,Point b,Point c,Point d) &amp;#123;  //需保证ab,cd相交&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P.x = (Cross(d-a,b-a)*c.x - Cross(c-a,b-a)*d.x)/(Cross(d-a,b-a)-Cross(c-a,b-a));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P.y = (Cross(d-a,b-a)*c.y - Cross(c-a,b-a)*d.y)/(Cross(d-a,b-a)-Cross(c-a,b-a));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Vector Rotate(Point P,Vector A,double rad)&amp;#123;     //以P为基准点把向量A旋转rad&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return Vector(P.x+A.x*cos(rad)-A.y*sin(rad),P.y+A.x*sin(rad)+A.y*cos(rad));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//点是否在多边形内部（环顾法）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int CheckPointInPolygon(Point A,Point* p,int n)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double TotalAngle = 0.0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Cross(p[i]-A,p[(i+1)%n]-A)) &amp;gt;= 0) TotalAngle += Angle(p[i]-A,p[(i+1)%n]-A);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        else TotalAngle -= Angle(p[i]-A,p[(i+1)%n]-A);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(TotalAngle) == 0)                 return 0;   //外部&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else if(dcmp(fabs(TotalAngle)-2*pi) == 0) return 1;   //完全内部&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else if(dcmp(fabs(TotalAngle)-pi) == 0)   return 2;   //边界上&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else                                      return 3;   //多边形顶点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//射线法&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int Ray_PointInPolygon(Point A,Point* p,int n) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int wn = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        //if(OnSegment(A,p[i],p[(i+1)%n])) return -1;    //边界&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int k = dcmp(Cross(p[(i+1)%n]-p[i], A-p[i]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int d1 = dcmp(p[i].y-A.y);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int d2 = dcmp(p[(i+1)%n].y-A.y);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(k &amp;gt; 0 &amp;amp;&amp;amp; d1 &amp;lt;= 0 &amp;amp;&amp;amp; d2 &amp;gt; 0) wn++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(k &amp;lt; 0 &amp;amp;&amp;amp; d2 &amp;lt;= 0 &amp;amp;&amp;amp; d1 &amp;gt; 0) wn--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(wn) return 1;     //内部&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return 0;            //外部&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//判断未知时针方向的多边形是否是凸包&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool CheckConvexHull(Point* p,int n)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int dir = 0;   //旋转方向&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int nowdir = dcmp(Cross(p[(i+1)%n]-p[i],p[(i+2)%n]-p[i]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(!dir) dir = nowdir;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dir*nowdir &amp;lt; 0) return false;     //非凸包&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return true;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//////凸包&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int ConvexHull(Point* p, int n, Point* ch) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sort(p,p+n);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int m = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(m &amp;gt; 1 &amp;amp;&amp;amp; Cross(ch[m-1]-ch[m-2], p[i]-ch[m-2]) &amp;lt;= 0) m--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ch[m++] = p[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int k = m;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=n-2;i&amp;gt;=0;i--) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(m &amp;gt; k &amp;amp;&amp;amp; Cross(ch[m-1]-ch[m-2], p[i]-ch[m-2]) &amp;lt;= 0) m--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ch[m++] = p[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(n &amp;gt; 1) m--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return m;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double CalcConvexArea(Point* p,int n) &amp;#123;        //凸包面积&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double area = 0.0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=1;i&amp;lt;n-1;i++)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        area += Cross(p[i]-p[0],p[i+1]-p[0]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return fabs(area*0.5);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double CalcConvexLength(Point* p,int n) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double Len = 0.0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0;i&amp;lt;n;i++) Len += Length(p[(i+1)%n]-p[i]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return Len;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//////////旋转卡壳求凸包最远两点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double RotatingCalipers(Point* ch,int n) &amp;#123;  //旋转卡壳&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int p,q = 1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double ans = 0.0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ch[n] = ch[0];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(p=0;p&amp;lt;n;p++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(dcmp(Cross(ch[p+1]-ch[p],ch[q+1]-ch[p])-Cross(ch[p+1]-ch[p],ch[q]-ch[p])) &amp;gt; 0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            q = (q+1)%n;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ans = max(ans,max(DisP(ch[p],ch[q]),DisP(ch[p+1],ch[q+1])));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return ans*ans;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double MinDisOfTwoConvexHull(Point P[],int n,Point Q[],int m) &amp;#123;   //旋转卡壳求两个顺时针凸包的最近距离&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int Pymin = 0, Qymax = 0, i,j;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(i=0;i&amp;lt;n;i++) if(dcmp(P[i].y-P[Pymin].y) &amp;lt; 0) Pymin = i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(i=0;i&amp;lt;m;i++) if(dcmp(Q[i].y-Q[Qymax].y) &amp;gt; 0) Qymax = i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    P[n] = P[0], Q[m] = Q[0];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double Mindis = Mod, Tmp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(i=0;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(dcmp(Tmp = Cross(P[Pymin+1]-P[Pymin],Q[Qymax+1]-P[Pymin])-Cross(P[Pymin+1]-P[Pymin],Q[Qymax]-P[Pymin])) &amp;gt; 0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            Qymax = (Qymax+1)%m;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Tmp) &amp;lt; 0) Mindis = min(Mindis,DistanceToSeg(Q[Qymax],P[Pymin],P[Pymin+1]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        else              Mindis = min(Mindis,SegDistancetoSeg(P[Pymin],P[Pymin+1],Q[Qymax],Q[Qymax+1]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Pymin = (Pymin+1)%n;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return Mindis;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool OnLeft(Line L, Point p) &amp;#123; return dcmp(Cross(L.v,p-L.p)) &amp;gt; 0; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Point* p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool CmpPolarPoint(Point a,Point b) &amp;#123;     //点极角排序&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int d = dcmp(Cross(a-p[0],b-p[0]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(!d) return DisP(p[0],a) &amp;lt; DisP(p[0],b);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return d &amp;gt; 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool CmpPolarLine(Line a,Line b) &amp;#123;        //直线极角排序&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return angle(a.v) &amp;lt; angle(b.v);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void GetL(bool counter,Point* p,int n,Line* L) &amp;#123;  //多边形的边转为直线&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(counter) &amp;#123; for(int i=n-1;i&amp;gt;=0;i--) L[n-i-1] = Line(p[(i+1)%n],p[i]-p[(i+1)%n]); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else &amp;#123; for(int i=0;i&amp;lt;n;i++) L[i] = Line(p[i],p[(i+1)%n]-p[i]); &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int HalfPlaneIntersection(Line* L, int n, Point* poly) &amp;#123;    //半平面交点存入poly&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sort(L,L+n,CmpPolarLine);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int first,last;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point *p = new Point[n];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Line  *q = new Line[n];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    q[first=last=0] = L[0];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=1;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(first &amp;lt; last &amp;amp;&amp;amp; !OnLeft(L[i],p[last-1])) last--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(first &amp;lt; last &amp;amp;&amp;amp; !OnLeft(L[i],p[first]))  first++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        q[++last] = L[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Cross(q[last].v, q[last-1].v)) == 0) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            last--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if(OnLeft(q[last], L[i].p)) q[last] = L[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(first &amp;lt; last) p[last-1] = GetLineIntersection(q[last-1],q[last]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(first &amp;lt; last &amp;amp;&amp;amp; !OnLeft(q[first],p[last-1])) last--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(last-first &amp;lt;= 1) return 0;       //点或线或无界平面，返回0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    p[last] = GetLineIntersection(q[last],q[first]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int m = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=first;i&amp;lt;=last;i++) poly[m++] = p[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    delete p; delete q;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return m;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int LineCrossPolygon(Point&amp;amp; L1,Point&amp;amp; L2,Point* p,int n,Point* poly) &amp;#123;  //直线(L1,L2)切割多边形p，形成新的多边形poly&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int m = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(int i=0,j;i&amp;lt;n;i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Cross(L1-p[i],L2-p[i])) &amp;gt;= 0) &amp;#123; poly[m++] = p[i]; continue; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        j = (i-1+n)%n;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Cross(L1-p[j],L2-p[j])) &amp;gt; 0) poly[m++] = GetLineIntersection(Line(L1,L2-L1),Line(p[j],p[i]-p[j]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        j = (i+1+n)%n;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(Cross(L1-p[j],L2-p[j])) &amp;gt; 0) poly[m++] = GetLineIntersection(Line(L1,L2-L1),Line(p[j],p[i]-p[j]));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return m;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//////圆&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool InCircle(Point x, Circle c) &amp;#123; return dcmp(c.r - Length(c.c-x)) &amp;gt; 0; &amp;#125; //not in border&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int GetCircleCircleIntersection(Circle C1, Circle C2, vector&amp;lt;Point&amp;gt;&amp;amp; sol) //return 交点个数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double d = Length(C1.c - C2.c);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(d) == 0)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(dcmp(C1.r - C2.r) == 0) return -1;  //两圆重合&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(C1.r + C2.r - d) &amp;lt; 0) return 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(fabs(C1.r - C2.r) - d) &amp;gt; 0) return 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double a = angle(C2.c - C1.c);             //向量C1C2的极角&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double da = acos((sqr(C1.r) + sqr(d) - sqr(C2.r)) / (2*C1.r*d)); //C1C2到C1P1的极角&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point p1 = C1.point(a-da), p2 = C1.point(a+da);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sol.push_back(p1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(p1 == p2) return 1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sol.push_back(p2);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return 2;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;int GetSegCircleIntersection(Line L, Circle C, Point* sol)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector Noml = Normal(L.v);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Line PL = Line(C.c, Noml);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Point IP = GetLineIntersection(PL, L); //弦的中点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double Dis = Length(IP - C.c);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(Dis-C.r) &amp;gt; 0) return 0;        //在圆外&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector HalfChord = VectorUnit(L.v)*sqrt(sqr(C.r)-sqr(Dis));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int ind = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sol[ind] = IP + HalfChord;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(OnSegment(sol[ind],L.p,L.point(1))) ind++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sol[ind] = IP - HalfChord;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(OnSegment(sol[ind],L.p,L.point(1))) ind++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return ind;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Point Zero = Point(0,0);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;double TriAngleCircleInsection(Circle C, Point A, Point B)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector OA = A-C.c, OB = B-C.c;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector BA = A-B, BC = C.c-B;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Vector AB = B-A, AC = C.c-A;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    double DOA = Length(OA), DOB = Length(OB),DAB = Length(AB), r = C.r;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(Cross(OA,OB)) == 0) return 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(dcmp(DOA-C.r) &amp;lt; 0 &amp;amp;&amp;amp; dcmp(DOB-C.r) &amp;lt; 0) return Cross(OA,OB)*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else if(DOB &amp;lt; r &amp;amp;&amp;amp; DOA &amp;gt;= r) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double x = (Dot(BA,BC) + sqrt(r*r*DAB*DAB-Cross(BA,BC)*Cross(BA,BC)))/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double TS = Cross(OA,OB)*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return asin(TS*(1-x/DAB)*2/r/DOA)*r*r*0.5+TS*x/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else if(DOB &amp;gt;= r &amp;amp;&amp;amp; DOA &amp;lt; r) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double y = (Dot(AB,AC)+sqrt(r*r*DAB*DAB-Cross(AB,AC)*Cross(AB,AC)))/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double TS = Cross(OA,OB)*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return asin(TS*(1-y/DAB)*2/r/DOB)*r*r*0.5+TS*y/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else if(fabs(Cross(OA,OB)) &amp;gt;= r*DAB || Dot(AB,AC) &amp;lt;= 0 || Dot(BA,BC) &amp;lt;= 0) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(Dot(OA,OB) &amp;lt; 0) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if(Cross(OA,OB) &amp;lt; 0) return (-acos(-1.0)-asin(Cross(OA,OB)/DOA/DOB))*r*r*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            else                 return ( acos(-1.0)-asin(Cross(OA,OB)/DOA/DOB))*r*r*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        else                     return asin(Cross(OA,OB)/DOA/DOB)*r*r*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    else &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double x = (Dot(BA,BC)+sqrt(r*r*DAB*DAB-Cross(BA,BC)*Cross(BA,BC)))/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double y = (Dot(AB,AC)+sqrt(r*r*DAB*DAB-Cross(AB,AC)*Cross(AB,AC)))/DAB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double TS = Cross(OA,OB)*0.5;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return (asin(TS*(1-x/DAB)*2/r/DOA)+asin(TS*(1-y/DAB)*2/r/DOB))*r*r*0.5 + TS*((x+y)/DAB-1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h2&gt;&lt;p&gt;珍藏多年的从前自己收集整理的一套计算几何的模板，如今也很少会用到了，不如公布出来供给广大ACMer学习参考之用，也算是没白费这一番功夫了。&lt;
    
    </summary>
    
      <category term="算法 | Algorithm" scheme="http://whatbeg.com/categories/%E7%AE%97%E6%B3%95-Algorithm/"/>
    
    
      <category term="算法" scheme="http://whatbeg.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Hexo部署环境迁移--多台电脑搭建Hexo环境</title>
    <link href="http://whatbeg.com/2016/09/17/hexo-migrate.html"/>
    <id>http://whatbeg.com/2016/09/17/hexo-migrate.html</id>
    <published>2016-09-17T11:34:50.000Z</published>
    <updated>2016-09-17T11:41:14.803Z</updated>
    
    <content type="html">&lt;p&gt;最近在实验室配上了电脑，原来有Hexo的环境的笔记本放在了宿舍作为娱乐机，以后主要就是使用实验室的台式机了，但是没有Hexo环境，有时候想发个文章也挺麻烦的，故想在台式机上配一个Hexo环境，以便在两端都可以发文章，并且主要在台式机上发布文章。&lt;/p&gt;
&lt;h2 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理&quot;&gt;&lt;/a&gt;原理&lt;/h2&gt;&lt;p&gt;由以前我们对Hexo的认识，其实hexo就是一个静态的博客，他的所有结构和内容都存储在Github（或者其他代码托管平台）上，因此，我们只需要一个能push新的结构和内容的环境即可，类似于重新搭建一个Hexo环境。&lt;/p&gt;
&lt;p&gt;只是两台电脑对同一个库操作有一个问题，由于push上去的结构和内容是由本地的代码和post文件决定的，当电脑A本地新建一篇文章发布的时候，电脑A本地多了一篇文章，但是电脑B并不知道这次新增，虽然此时github上有新的文章，但是使用电脑B重新部署的话，这篇文章就会在github上消失，因为B没有该篇文章的本地文件，所以这里涉及一个两台电脑的本地文件同步问题。&lt;/p&gt;
&lt;p&gt;解决有很多方法，其实无非是文件的同步。&lt;/p&gt;
&lt;p&gt;简单点可以直接用U盘拷贝，但是稍有不便，每次还得拷贝本地文件，如果是经常切换电脑发布文章的话，这就很麻烦。&lt;/p&gt;
&lt;p&gt;复杂点可以用Git来同步，新建一个Github repository来存储本地文件，每次要发文章前都先从github上拉取最新的本地文件，这样的好处就是随时用哪台电脑都可以发，缺点是稍微有点麻烦，每次还得推来拉去。&lt;/p&gt;
&lt;p&gt;综合考虑，由于以后主要在一台电脑上发（台式机），所以相当于迁移过来，用U盘拷一次为宜。&lt;/p&gt;
&lt;p&gt;最好是hexo d部署的机制中加一个新增部署方式，不改动原来结构，只新增内容上去，不过这个功能现在还没有，所以，只能麻烦的用上述的方法了。&lt;/p&gt;
&lt;p&gt;或者，读者发现有什么更好的方法也可以评论或者邮件告诉我哦。&lt;/p&gt;
&lt;h2 id=&quot;步骤&quot;&gt;&lt;a href=&quot;#步骤&quot; class=&quot;headerlink&quot; title=&quot;步骤&quot;&gt;&lt;/a&gt;步骤&lt;/h2&gt;&lt;p&gt;1.安装 &lt;a href=&quot;http://nodejs.cn/download/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;node.js&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2.安装 &lt;a href=&quot;https://git-scm.com/downloads/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Git&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3.在Git bash中输入&lt;/p&gt;
&lt;figure class=&quot;highlight applescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;npm install -g hexo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo -&lt;span class=&quot;built_in&quot;&gt;version&lt;/span&gt;   &lt;span class=&quot;comment&quot;&gt;# 测试hexo是否安装成功&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/hexo-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.选一个hexo主目录（如D:\hexo），在该目录输入&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;hexo&lt;/span&gt; init&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;5.配置ssh key，首先&lt;br&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ls&lt;/span&gt; -&lt;span class=&quot;keyword&quot;&gt;al&lt;/span&gt; ~/.ssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;6.如果啥都没有，那么可以新建，有了也可以新生成ssh key&lt;br&gt;&lt;figure class=&quot;highlight perl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ssh-keygen -t rsa -C &lt;span class=&quot;string&quot;&gt;&quot;youremail@example.com&quot;&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;# 输入邮箱&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/hexo-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;7.登入自己的github，在settings下新建SSH KEY，将用户目录下的&lt;code&gt;id_rsa.pub&lt;/code&gt;（公钥）的内容复制填入新建的SSH KEY，保存。&lt;/p&gt;
&lt;p&gt;8.在Git bash中输入&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;ssh&lt;/span&gt; -T git&lt;span class=&quot;variable&quot;&gt;@github&lt;/span&gt;.com&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/hexo-3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;9.用U盘拷贝原来电脑的hexo文件夹，除了&lt;code&gt;.deploygit&lt;/code&gt;和&lt;code&gt;node_modules&lt;/code&gt;不用拷以外，其他都拷过来，替换现在的hexo除上两个文件夹的内容。&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/hexo-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;10.生成，部署&lt;br&gt;&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo &lt;span class=&quot;keyword&quot;&gt;g&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo &lt;span class=&quot;built_in&quot;&gt;d&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;11.如果&lt;code&gt;hexo d&lt;/code&gt;失败，并提示deployer未安装，那么安装：&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;npm &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; hexo-deployer-git &lt;span class=&quot;comment&quot;&gt;--save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;12.再生成，部署即可。如果遇到&lt;br&gt;&lt;figure class=&quot;highlight groovy&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;bash:&lt;/span&gt; &lt;span class=&quot;regexp&quot;&gt;/dev/&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;tty:&lt;/span&gt; No such device or address&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;错误，那么重新生成，部署一下应可解决问题。&lt;br&gt;&lt;img src=&quot;http://7xsl28.com1.z0.glb.clouddn.com/hexo-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;13.当然如果原来有wordcount模块，这会遇到一个wordcount不存在的问题，原因是新机没有安装wordcount字符计数模块，用下面的命令安装：&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;npm &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; hexo-wordcount &lt;span class=&quot;comment&quot;&gt;--save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;14.如果你是同时部署到github和coding.net的话，还要记得在coding.net中新建一个SSH KEY并将id_rsa.pub内容复制进去，并运行：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ssh -T git@git&lt;span class=&quot;selector-class&quot;&gt;.coding&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.net&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;成功的话会显示：&lt;br&gt;&lt;figure class=&quot;highlight erlang-repl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Hello xxx! You&#39;ve connected to Coding.net via SSH successfully!&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这样的话，基本就迁移成功了，以后直接在这台机器上生成，部署即可。&lt;/p&gt;
&lt;p&gt;15.如果是采用Git来同步的话，Git上传项目的基本流程如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1、在github上创建项目（尽量为空，即不要有README.txt, LISENCE等）&lt;br&gt;2、使用&lt;code&gt;git clone https://github.com/xxxxxxx/xxxxx.git&lt;/code&gt;克隆到本地&lt;br&gt;3、编辑项目&lt;br&gt;4、&lt;code&gt;git add .&lt;/code&gt; （将改动添加到暂存区）&lt;br&gt;5、&lt;code&gt;git commit -m &amp;quot;提交说明&amp;quot;&lt;/code&gt;&lt;br&gt;6、&lt;code&gt;git push origin master&lt;/code&gt; 将本地更改推送到远程master分支。&lt;br&gt;这样你就完成了向远程仓库的推送。&lt;br&gt;如果在github的remote上已经有了文件，会出现错误。此时应当先pull一下，即：&lt;br&gt;&lt;code&gt;git pull origin master&lt;/code&gt;&lt;br&gt;然后再进行：&lt;br&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;16.如果在&lt;code&gt;hexo d&lt;/code&gt;时出现很多&lt;code&gt;warning: LF will be replaced by CRLF&lt;/code&gt;的警告的话，那是由于windows中的换行符为CRLF，而linux中换行符为LF导致的，运行下面语句：&lt;br&gt;&lt;figure class=&quot;highlight fsharp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git config --&lt;span class=&quot;keyword&quot;&gt;global&lt;/span&gt; core.autocrlf &lt;span class=&quot;keyword&quot;&gt;false&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;//禁用自动转换&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在实验室配上了电脑，原来有Hexo的环境的笔记本放在了宿舍作为娱乐机，以后主要就是使用实验室的台式机了，但是没有Hexo环境，有时候想发个文章也挺麻烦的，故想在台式机上配一个Hexo环境，以便在两端都可以发文章，并且主要在台式机上发布文章。&lt;/p&gt;
&lt;h2 id=&quot;原理
    
    </summary>
    
      <category term="错误解决与优化 | Err&Opt" scheme="http://whatbeg.com/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E4%B8%8E%E4%BC%98%E5%8C%96-Err-Opt/"/>
    
    
      <category term="hexo" scheme="http://whatbeg.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>（转）长沙美食地图</title>
    <link href="http://whatbeg.com/2016/09/17/eatinchangsha.html"/>
    <id>http://whatbeg.com/2016/09/17/eatinchangsha.html</id>
    <published>2016-09-17T10:41:11.000Z</published>
    <updated>2016-09-17T11:14:33.646Z</updated>
    
    <content type="html">&lt;p&gt;转自: &lt;a href=&quot;http://cs.voc.com.cn/thread-102396-1-3.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;长沙美食地图&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;转者说&quot;&gt;&lt;a href=&quot;#转者说&quot; class=&quot;headerlink&quot; title=&quot;转者说&quot;&gt;&lt;/a&gt;转者说&lt;/h2&gt;&lt;p&gt;近来逛论坛看到一张讲述长沙美食的帖子，写的比较长比较全，觉得还可以，就转过来了，并做了一定的整理，排版，原贴发布于&lt;a href=&quot;http://bbs.0731go.cn/thread-102396-1-3.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;，发布于2008年4月，距今也八九年了，有些内容可能已经过时了，各位看官自辨真伪，转者也没有试过，概不负责鉴别，只想留作一份指引，以作参考，可能对于吃长沙，逛长沙有多帮助。各位如果有最新的信息不妨留言或者邮件告诉转者（我），咱们可以一起维护这样一份美食地图，也为他人做了个便，算是一件好事。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;中国千年的古文化里，就包括了美食，在现代文明发展迅速的今天，美食已经成为一&lt;br&gt;个地区或者城市的风景线，缺少便乏味很多，八大菜系已经是昨天的传说，在今天，个性&lt;br&gt;和风格已经成为一个主题，一个超越昨天的标志。&lt;/p&gt;
&lt;p&gt;湖南是自古便以湘楚文化闻名的地方，有文化渊源的地方，自然便多些有特色的东西&lt;br&gt;，比如菜式与特别的味道，如此，作为一个喜好美食的传统中国人，莫不慕名而来，以慰&lt;br&gt;口福。&lt;/p&gt;
&lt;p&gt;而风味小吃更是湖南地方特色的一个最为诱人的闪亮点，不说外地来的食客，就说本&lt;br&gt;土人，也是沉迷在美食特色里不可自拨。油炸臭豆腐,闻着臭吃着奇香，是中国小吃一绝。&lt;br&gt;“臭豆腐”各地皆有，而湖南长沙“火宫殿”的油炸“臭豆腐”却更有名气。它是用黄豆&lt;br&gt;为原料的水豆腐，经过专用卤水浸泡半月，再以茶油经文火炸焦，佐以麻油，辣酱。它具&lt;br&gt;有“黑如墨，香如醇，嫩如酥，软如绒”的特点，奇在以臭命名，不同于其它食卤以香自&lt;br&gt;翊。闻起来臭，吃起来香，外焦微脆，内软味鲜。这是因为卤水中放有鲜冬笋、浏阳豆豉&lt;br&gt;、香菇、上等白酒等多种上乘原料，故味道特别鲜香。&lt;/p&gt;
&lt;p&gt;湘菜，到土菜，到蒸菜以及面食小吃，有名气的各处食店均是高朋满座，几乎座无虚&lt;br&gt;席，有时去得晚了，还得排位置，脾气好不好都得等待，只因为湖南本土人太好吃，如果&lt;br&gt;换家其他有名气的餐馆，也一样需要等候。&lt;/p&gt;
&lt;h2 id=&quot;小吃篇&quot;&gt;&lt;a href=&quot;#小吃篇&quot; class=&quot;headerlink&quot; title=&quot;小吃篇&quot;&gt;&lt;/a&gt;小吃篇&lt;/h2&gt;&lt;p&gt;1.火宫殿&lt;/p&gt;
&lt;p&gt;最早的风味小吃店就要从“火宫殿”说起了，火宫殿已经有250多年历史，也是目前长&lt;br&gt;沙市最兴旺的老字号。清乾隆十二年（1747）在这里建殿祀火神，火宫殿庙宇、神像、戏&lt;br&gt;台，火博馆，形成了“一宫二庙二阁三通四景”的独特人文景观。&lt;br&gt;这里原是敬火神的地方，又叫火神庙，每年火神生日，这里赶庙会，唱大戏，游客云&lt;br&gt;集，他们在观剧游览之余，都喜就地用餐，有顺口溜：“火官殿样样有，饭菜小吃热甜酒&lt;br&gt;。油炸豆腐喷喷香，姊妹团子数二姜；撒子麻花嘣嘣脆，猪血蹄花味道美；各式小吃尝不&lt;br&gt;完，乐得食客笑呵呵”。&lt;/p&gt;
&lt;p&gt;据说1942年时，坡子街边上的空坪盖起了48间木架棚屋，其中的42间棚屋全部为小吃&lt;br&gt;店，热闹非凡，兼杂各类杂耍，节日期间更为热闹，人山人海，江湖各类人物均可在这里&lt;br&gt;见识到，那时主要经营的品种有：色青、肉嫩、松脆、鲜香可口的臭豆腐干；形如荸荠、&lt;br&gt;质如白玉、外表柔嫩、内吐芳香的姊妹团子和东坡馓子，龙脂猪血，神仙糯米饭；四季香&lt;br&gt;甜酒，麻辣狗肉，煨牛蹄筋，红烩乌龟等。&lt;/p&gt;
&lt;p&gt;目前来说，各类的娱乐场所代替了街头文化，小吃店的也发展到了集团规模，长沙火&lt;br&gt;宫殿也飞速发展，它的总店在黄兴路上的坡子街78号，总店电话：5813161可定座，分店遍&lt;br&gt;布长沙。臭豆腐、姊妹团子、银丝卷都是这里的招牌小食，还有排骨藕汤、肉排骨、珍珠&lt;br&gt;丸子。长沙火宫殿是湖南民俗特色小吃的发源地，与北京天桥、上海城隍庙、天津三不管&lt;br&gt;、南京夫子庙齐名。其风味小吃“臭豆腐”更是远近闻名。&lt;/p&gt;
&lt;p&gt;2.口味虾. 鸭架子&lt;/p&gt;
&lt;p&gt;但是要说风味，要数前几年的南门口的四埃骥（婆婆）的口味虾了，记得最初去这一&lt;br&gt;条她老人家带动的风味小吃一条街的时候，是浓冬的时候，湖南日报一个朋友相约另外一&lt;br&gt;个平时极为腐败的朋友，晚上吃消夜，半夜11点，打上的士直奔这家乱喳喳的街边小摊，&lt;br&gt;一见环境真是恐怖，满地的小龙虾壳简直要把街道铺满，红通通的，把冬季的夜晚差不多&lt;br&gt;都照亮的感觉，人人吃得大汗淋漓，鼻涕直冒，纸巾这里是大量供应的，也是知道这样的&lt;br&gt;辣是人人都顶不住的。&lt;/p&gt;
&lt;p&gt;环境虽然不好，那时候吃的时候却觉得味道真是一流，口味极重，虾也是非常新鲜的&lt;br&gt;，四五人来这里，一般都是要上一个大份的口味虾68元，一些凉菜就足够了。一会工夫，&lt;br&gt;大盆的口味虾便上了上来，用白铝盆装上，红油汤冒着刺激鼻孔的热气，虾拱着身体，表&lt;br&gt;示是新鲜的，上面点缀着几棵香菜，色调鲜艳，整棵的干辣椒在盆里随处可见，一看之下&lt;br&gt;胃口自然就大开了。于是喝就猜拳，感觉非常的畅快。主要的是吃虾，虾壳虽然厚了些，&lt;br&gt;不过总敌不牙齿的坚硬，于是手抓起来便咬，辣虽然辣，辣的不怕啊，大家都很勇敢，吃&lt;br&gt;得眼泪都快流出来，还继续革命，末了还不满足，要么还要一小份的上，或者就叫老板，&lt;br&gt;下光头面，把口味虾的汤料混进面里，淅沥哗啦的就进了肚子。&lt;/p&gt;
&lt;p&gt;说起这口味虾也的确是首创于湖南的，以前着小龙虾因为生长极快，又没找到合适的&lt;br&gt;炮制方法，本土人还很是烦恼，这四埃骥家的生活也比较贫苦，买不起好菜，某一天因为&lt;br&gt;图便宜便买了这龙虾回家做菜，一时新鲜就放了辣椒，麻油，酱油，香料，紫苏等大量的&lt;br&gt;调味品进去，一锅做出来，香味扑鼻，拿出来给家人隔壁邻居一试味道，简直不得了，这&lt;br&gt;好吃的连汤都要下面条来喝掉，于是便一家人齐心的开起了这家口味虾的摊位，把整个长&lt;br&gt;沙的南门口都带动了起来。把原来在中山路一带的鸭脖子唆螺的生意，全部都抢到了南门&lt;br&gt;口，一时间沿街的店铺全都改行做口味虾了。不过除非是这家没座位了，客人是断不会跑&lt;br&gt;去其他摊位的，要吃也得吃个正宗，长沙人就是这样的耿直。听说是一天要卖掉好几百斤&lt;br&gt;的虾，这一做就是四五年，直到城市整顿，还有就是长沙人的口味变化得也快了，于是，&lt;br&gt;这南门口的小吃一条街道又向前移动了少少，去了书院路口了，与南门口只相差一百米左&lt;br&gt;右的距离，这里除了老风格的口味虾，又多了卤鸭脖子、鸭翅膀、鸭架子、鸭掌等，卤鸭&lt;br&gt;脖子、还有凉菜小吃、汤类小吃（如烫猪血、荷兰粉、白粒丸）等，鸭翅膀只要2元一个，&lt;br&gt;鸭架子、鸭掌只要1元一个，卤制得黄黄的，见了口水便要流下来，也是以手拿起便啃，左&lt;br&gt;右开弓，大有英雄气概，不过消灭的不是敌人，是这骨架子罢了。就一瓶啤酒，仰头便喝&lt;br&gt;，与朋友高谈阔论，真是有几分绿林英雄的气魄。&lt;/p&gt;
&lt;h2 id=&quot;蒸菜土菜&quot;&gt;&lt;a href=&quot;#蒸菜土菜&quot; class=&quot;headerlink&quot; title=&quot;蒸菜土菜&quot;&gt;&lt;/a&gt;蒸菜土菜&lt;/h2&gt;&lt;p&gt;1.五里牌建军蒸菜馆&lt;/p&gt;
&lt;p&gt;要说蒸菜必定想起地处于火车站边上五里牌的两室一厅，十年前这地方全是家属楼，&lt;br&gt;某个脑壳精明的人做起了家常生意，在自家两室一厅的居家的地方做起了以腊味为主的蒸&lt;br&gt;菜，一般是以小钵装上腊肉腊鱼等合蒸，后来又改革，连青菜也可以蒸了出来吃，其实做&lt;br&gt;工很简单，只是不知道为什么味道极好，生意逐渐红火兴旺起来，带动了方圆几栋的两室&lt;br&gt;一厅做起这样的蒸菜生意，无论政府官员还是贫民百姓，无不经常来光顾，苦于没有餐馆&lt;br&gt;的名字，大家便不约而同的叫这里两室一厅了。&lt;br&gt;事过境迁，城市规划不再容许无证经营，于是建军蒸菜馆便脱颖而出，从一层楼发展&lt;br&gt;至现在上下三层楼，门前还留有一片很宽的停车场方便来往的客人停车，仍然是家常菜式&lt;br&gt;，蒸菜为主，炒菜为辅。&lt;br&gt;从蒸芋头到剁辣椒鱼头，都是一只没有样式的大碗装着，看相不是很精致，却有种吸&lt;br&gt;引人马上动筷子的欲望，消灭掉大碗里的东西。&lt;/p&gt;
&lt;p&gt;槟榔芋蒸排骨适合男士们吃排骨，女士吃把鲜味都吸收进去了的槟榔芋头，糯糯粉粉&lt;br&gt;的口感，咸淡正好，又蒸入了油味，带些微甜，然后再吃口剁辣椒炒大白菜，真是爽口。&lt;/p&gt;
&lt;p&gt;石灰蒸蛋是湖南人喜欢吃的家产菜，这里也是主要的招牌菜式之一，&lt;br&gt;如果客人要求炒菜，店家服务员必定第一个介绍的是炒青蛙，虽然现在讲究环保，可&lt;br&gt;这种可以大量繁殖的野味实在是让人不忍舍弃的想吃，并且口味极重的客人必定是爱吃的&lt;br&gt;，一碗青蛙，（也叫田鸡）摆了上台，用中型海碗装着，新鲜的青红辣椒做主要配料，加&lt;br&gt;上大蒜子，少少的酸萝卜，一把紫苏叶，麻油，少量的白糖，干辣椒起锅，几滴酱油，浓&lt;br&gt;香扑鼻，叫上几碗钵子饭，大口的吃完，真是舒服。&lt;br&gt;如果口味比较淡的客人，可以点这里的蒸南瓜，黄色的南瓜不加任何的色素的，本身&lt;br&gt;的颜色都是极为诱人了，好象还有美容效果，女士们可以尝试。&lt;br&gt;在这里不能太要求服务员有求必应，因为实在客人太多，服务员都忙碌得不得了，所&lt;br&gt;以，只要好吃，上菜是很快的，其他的能免就免了，一般三四个人吃上一大桌，也不过百&lt;br&gt;来十元的，价格是绝对便宜。&lt;/p&gt;
&lt;p&gt;2.紫东阁美食街&lt;/p&gt;
&lt;p&gt;位于五里牌的紫东阁是间四星级的宾馆，不过在副楼开设了这间紫东阁美食街倒是体&lt;br&gt;现出了四星的水准，平民的消费，这里的装修古香古色，全是四方的紫红色的木头桌椅，&lt;br&gt;嵌进了些贝壳，显得高雅不凡，四周的墙壁上挂满黑白的照片，长沙的某些方面的历史在&lt;br&gt;这里可以从照片上揣摩一二，穿着土布旗袍和土布对开衫的服务员都是经过正规酒店式培&lt;br&gt;训出来的，故此在可以享受家常小炒的好菜同时，还可以享受星级的服务。&lt;br&gt;长颈的铜茶壶由青年的男子用手肘挂着，随时给客人加水，很是好玩，如果没有特别&lt;br&gt;要求，一般泡的茶就是八宝茶了，用菊花，红枣，桂圆，甘草，加香片茶泡制，可解湘菜&lt;br&gt;的火气，这里也可看出一般大众饭馆跟这里的不同，一般小资点的人士到是很喜欢光顾这&lt;br&gt;里，虽然相对而言，菜的价格比同类家常菜馆要稍微贵一点点，不过也是值得的。&lt;/p&gt;
&lt;p&gt;这里菜式扮相很漂亮，用来盛菜的碗碟也很有特色，都是蓝花白底，雅静而大方，看&lt;br&gt;着就有些想马上动筷去吃，最喜欢吃的是鸡汁蒸白萝卜，用鸡汤做底料，把萝卜切成很薄&lt;br&gt;的片，放在蒸气里蒸上几分钟，加点绿色的葱花，鲜得一人可以吃一碗。&lt;/p&gt;
&lt;p&gt;玉米也是必点的小点，一人一根黄黄的玉米，啃着，谁也不会笑话谁好吃，已经没时&lt;br&gt;候看别人怎么的吃相了。&lt;br&gt;凉粉也是地道的，里面放上辣椒油，麻油，花生米，黄豆，醋，糖等十几种调料，很&lt;br&gt;是有地方特色。&lt;br&gt;萝卜皮炒土腊肉也是经典菜，酸辣鸡杂更是入味三分，鲜而不腥，还有里面的佐菜也&lt;br&gt;入了调料的味道，加上用泰国米做的钵子饭，一口气，女士也能吃上两钵，不用想减肥了&lt;br&gt;，吃了再说吧。&lt;/p&gt;
&lt;p&gt;3.四方坪土鸡&lt;/p&gt;
&lt;p&gt;位于长沙城北开福区郊区的四方坪以做土鸡出名的地方，在去往飞机场的大马路边上&lt;br&gt;，98年起，林立起了众多的大型餐馆，与五里牌的风格不同的是，这里的装修要干净整洁&lt;br&gt;些，楼面也大气些，有些好似广东郊区的平价海鲜酒楼，这里的土鸡引来了很多的食客，&lt;br&gt;因为交通不如市里方便，一般都是打的士或者客人自己开车来吃，尽管交通要不方便，但&lt;br&gt;也阻止不了好吃的人们不断的往这里赶，一般中午12点后，就要等座位了，湖南人好吃在&lt;br&gt;这里就可以得到很突出的演绎，热闹的个性也充分发挥。&lt;br&gt;这里开始最正宗的做爆炒土鸡的店子就叫四方坪土鸡，后来一时间大家都往这个招牌&lt;br&gt;上去取自家餐馆的名字，诸如正宗四方坪土鸡等等，后来弄不清楚到底那家是正宗了的，&lt;br&gt;其实味道做出来都不错，于是去的时候到不必居于一定要找到这家了，俗话说人多的地方&lt;br&gt;，自然怠慢客人，反正都是柴火做的菜式，都是好味道的，人多了，东西自然会假一些，&lt;br&gt;于是每次去，都选人正好不多也不少的地方去吃，一般都能满意而归的。&lt;br&gt;    这里的爆炒的土鸡都是新鲜炮制的，客人点了后，可以一鸡几吃，鸡血内脏用萝卜丁&lt;br&gt;料炒，加干辣椒和葱点缀，色彩很漂亮，鸡肉用新鲜的青红辣椒，是尖椒极辣的那种土辣&lt;br&gt;椒加上大片的姜片蒜子一起爆炒，没有其他的调料，不过味道绝对的霸道，并且，价格也&lt;br&gt;不贵，一份土鸡也就是38元而已。&lt;br&gt;此时和着湖南的甜米酒一起小酌，用湖南话来说，就是：好韵味的呢。&lt;/p&gt;
&lt;p&gt;4.潭州瓦缸&lt;/p&gt;
&lt;p&gt;说起土菜又必须说起在长沙市雨花区芙蓉南路110号的潭州瓦缸饭庄，定坐电话是：0&lt;br&gt;731-5221300。这“潭州”就是古长沙的旧称，这家餐馆的老板原来是做酒楼生意的，开了&lt;br&gt;几家，有了些经验，于是在当时长沙的餐饮业主还没想到在偏僻的今天方便的临市区的地&lt;br&gt;方开餐馆的时候，抢先走了一步，开起了这间占地一千多个平方的食堂似的饭店，那时大&lt;br&gt;家还思维还停留在雅致豪华的酒家似的饭店，出现了这样怀旧式的食堂，便大肆的宣传，&lt;br&gt;亲友互相带动相约在这里来吃饭，这里的装饰的确就跟大练钢铁时的食堂相似，一个棚子&lt;br&gt;，木头的柱子，瓦片的屋顶，大圆桌可坐十几个人，进去好似七八十年代农村办酒席的盛&lt;br&gt;会，也不会管你身份如何，有什么区别，大家在这里来了，就是一个口号：海吃。&lt;br&gt;最初这里是以瓦罐汤为招牌菜，如黄豆墩猪脚，野山菇墩排骨，水鸭黄豆等煲得很浓&lt;br&gt;的罐子汤，在大门口一排水缸式的罐子就是保温的炊具，很有特色。&lt;br&gt;其他的菜也是大份大份的，竹香鱼是每次必叫的菜，把约八两重的鲫鱼破开两边贴在&lt;br&gt;竹蔑上油炸后烤制，加了梓然，香味很重，吃起来外焦内嫩，鱼肉的鲜甜味仍然保持得很&lt;br&gt;好，是首选的下酒菜，大份的田螺口味很好，肉也干净，用了酱香的调料，和卤水，田螺&lt;br&gt;有鸡蛋大小，吃起来很轻松，懒人应该是喜欢吃的。&lt;br&gt;有一次吃这里的口味鸭，感觉上比北京烤鸭更多鲜味，并且入味到肉内，又嫩又香，&lt;br&gt;饭都不用吃了，虽然这里有好吃的柴火做的芋头饭，可肚子实在是太饱了，只得放弃，记&lt;br&gt;得第一次去吃，简直可以说是狼吞虎咽的顷刻间把一桌子的菜全吃了个精光，然后大家打&lt;br&gt;着饱嗝说还要来吃。&lt;br&gt;现在潭州瓦缸连续的开了好几家分店，不过，再去吃的时候，总觉得没有前几次去吃&lt;br&gt;的好吃了，也许是厨师换了好轮了吧。不过朋友聚会或者外地朋友来长沙，这里应该还是&lt;br&gt;一道城市的风景的。&lt;/p&gt;
&lt;h2 id=&quot;湘菜，外地菜系&quot;&gt;&lt;a href=&quot;#湘菜，外地菜系&quot; class=&quot;headerlink&quot; title=&quot;湘菜，外地菜系&quot;&gt;&lt;/a&gt;湘菜，外地菜系&lt;/h2&gt;&lt;p&gt;1.玉楼东&lt;/p&gt;
&lt;p&gt;玉楼东酒家始建于清光绪三十年（公元1904年），老店以前是解放西路一部分，目前&lt;br&gt;解放西路已经成了酒吧一条街，玉楼东也就撤离了老地方，在长沙的各处繁华地带以新的&lt;br&gt;面貌出现，红色的仿古式建筑到是显露出新的气象，风格和味道倒是比老的玉楼东更有特&lt;br&gt;色。&lt;br&gt;当年号称“湖南第一厨“的谭奚庭掌勺主理，清末湘乡翰林曾广钧（曾国藩之孙）登&lt;br&gt;楼用膳后，留下的“麻辣仔鸡汤泡肚，令人常忆玉楼东“的佳句，时致今日仍被人传诵。&lt;br&gt;五一路上的玉楼东店堂，人流如鲫，南来北往客在这里饱尝湘菜以及风味小吃，做工精制&lt;br&gt;，不过好象有些向广东菜系风格接近的倾向，味道虽然改良了，花色也漂亮，却已经不是&lt;br&gt;正宗以辣得怕出味的原调了。&lt;br&gt;在玉楼东总部（五里牌店），值得推荐的有干锅系列，如“干锅莴笋排骨”、“干锅&lt;br&gt;飘香鸡”等酱香味浓，汤紧菜香，还有药膳系列，让人真正“食补胜药补”；在玉楼东五&lt;br&gt;一分店，可以吃到正宗的“卤水鹅掌（翅）”，以及沙煲、白灼系列，还有各式精致包点&lt;br&gt;，如“水晶包”、“紫菜卷”等，在玉楼东东塘分店，麻辣烫系列比较诱惑人， “泡凤爪&lt;br&gt;”、“皮蛋卷”、“烧辣椒”、“吊烧乳鸽”、“蜜汁猪手”也可以尝到 “活鱼新吃”、&lt;br&gt;“猪手王”、“香辣田螺”等口味菜&lt;br&gt;东塘玉楼东分店处于长沙市雨花区韶山路96号，而处于马王堆的玉楼东则是以湘菜为&lt;br&gt;主，却更倾向于土菜为主，本土人更喜欢在这里一饱口福，蒸南瓜清香四溢，原色原味。&lt;br&gt;手撕鱼的味道也不错，听说是从浏阳来的火焙鱼，没有经过污染的河水里的小鱼崽焙干而&lt;br&gt;成的，加上干辣椒，火辣辣的，却辣得舒服。还有干锅仔，煮起来热气腾腾，干锅辣子鸡&lt;br&gt;，辣子兔等，都是不错的下饭菜。&lt;/p&gt;
&lt;p&gt;2.大丰和&lt;/p&gt;
&lt;p&gt;在长沙的曙光中路３３３号大丰和酒家是曙光路美食街的发祥地，曾经带动了一条美&lt;br&gt;食街的兴起，曾经令多少长沙食客称颂和向往。虽然现在林林总总的各家有特色的食店在&lt;br&gt;这里聚集，但大丰和依然还是朋友相约聚会的地方。现在大丰和以常德菜为主，粤菜为辅&lt;br&gt;，湘、粤佳肴荟萃，令越来越多的顾客饱享口福。大丰和乌龟炖黄豆，采用正宗的常德野&lt;br&gt;生龟，加以数十种佐料，经文火慢慢精心煨制而成，此菜口感微辣，辣而不腻，是大丰和&lt;br&gt;出品的招牌菜。这里的腊肉炖腊干子，精选正宗的常德土家腊肉，加以号称“常德一绝”&lt;br&gt;的特制腊干子烹制而成，此菜味浓喷香，是理想的下饭钵子。这里的手撕腊狗肉，选用上&lt;br&gt;等的精致狗肉，配以数种香料经柴烟熏制而成，再加上手工撕制，选料之精，上菜时香气&lt;br&gt;扑鼻，菜色红亮，慢嚼细咽，回味无穷。这里的一品鸡，采用正宗的常德乡里土鸡，口感&lt;br&gt;鲜美，深受顾客喜爱。&lt;/p&gt;
&lt;p&gt;3.大福口的龟肉&lt;/p&gt;
&lt;p&gt;大福口是2002年新异军突起的一家湘菜馆，这家远离城市中心的饭馆位于长沙的二环&lt;br&gt;线上，只好坐的士过去，不过一走进饭馆，400平方的大厅，别具慧心的装修让我眼前为之&lt;br&gt;一亮，木头结构的大堂，高雅而不流于俗套，大红的中国同心结现得极有情调，很难想象&lt;br&gt;这是吃湘菜的地方，经过了解，这家餐馆的老板是做广告出身的，自然在布局上有些别出&lt;br&gt;心裁的风格，把文化的气氛带入了饮食的文化中去。&lt;br&gt;去的时候客源不断，我们等候了一阵才有了座位，我们马上占领了靠墙壁边上的位置&lt;br&gt;，点了这里拿手的菜式，菜单很漂亮，每个菜式都有彩色的图片，方便客人点菜的时候选&lt;br&gt;择，我们很快的就点了菜，当然，龟肉是不可缺少的重头戏。询问了经理，知道了做龟肉&lt;br&gt;的秘方，&lt;br&gt;    菜名： 红烧龟肉 198/份&lt;br&gt;    【所属菜系】 湘菜&lt;br&gt;    【特点】 滋阴补血。适用于阴虚或血虚患者所出现的低热、咯血、 便血等症。&lt;br&gt;    【原料】 龟1只(250～500克) 菜油60克 黄酒20克 生姜 葱 花椒 冰糖 酱油各适量&lt;br&gt;    【制作过程】 1. 将龟放入盆中，加热水(约40℃)，使其排尽尿，然后剁去其头、足&lt;br&gt;，剖开，去龟壳、内脏，洗净，将龟肉切块。 2. 锅中加菜油，烧热后，放入龟肉块，反&lt;br&gt;复翻炒，再加生姜、葱、花椒、冰糖等调料，烹以酱油、黄酒、加适量清水，用文火煨炖&lt;br&gt;， 至龟肉烂为止。&lt;/p&gt;
&lt;p&gt;4.金味酒楼&lt;/p&gt;
&lt;p&gt;沿着长沙市工商局旁的一条小巷前行进入三湘大市场，再右拐前进50米左右就见到金&lt;br&gt;味酒楼。 4729436订好了座位。很快的，所点的五道菜先后闪亮登场：青辣椒炒盐蛋，鲜&lt;br&gt;蘑菇炒肉泥，香嫩爽滑的肉丁，配上小红椒，再撒上些葱花，颜色搭配恰到好处，举筷一&lt;br&gt;尝，就更一发不可收拾；酸菜豆腐汤和萝卜菜，地地道道的家常菜，但加几粒豆鼓进去，&lt;br&gt;又别有一番风味；滴，食之又原汁原味，肉质鲜嫩。口味蛇一斤，原料是：活蛇、多种香&lt;br&gt;料、麻油、蚝油等，切段，加多种香料爆香，小火慢煨40－50分钟，用麻油、蚝油等调味&lt;br&gt;，加蒜末装盘上桌。特点：香辣、鲜美、爽口； 参考价：68元／斤 ，朋友边吃边聊，从&lt;br&gt;中得知：本酒店的菜是以湘菜重油、色浓的特点为主，结合八大菜系的优点，经主厨反复&lt;br&gt;烹制而成，口味都侧重于家常口味。所以说，这里的每一道菜均是该店的特色菜。再者，&lt;br&gt;来这里就餐能吃到放心菜，蔬菜都是附近的菜农定点直供，基本杜绝了污染蔬菜入店，很&lt;br&gt;大程度上提高了酒店的可信度。&lt;/p&gt;
&lt;p&gt;5.潭鱼头&lt;/p&gt;
&lt;p&gt;长沙黄土岭有四川人跑到湖南长沙开设了这家连锁店，没想到湖南人是如此好美食，&lt;br&gt;不加一点拒绝的就完全接受了外地的口味风格，这家与其他店貌装修一样风格的四川菜馆&lt;br&gt;就这样顺利的打进了长沙市场，占据了一席之位，这样来说，肯定味道自然有其独到的一&lt;br&gt;面。&lt;br&gt;去潭鱼头的时候是下午6点来钟，正是晚餐时间，打105路汽车在黄土岭桥下下车，走&lt;br&gt;进去一看，又是爆满，火锅的蒸汽正冒得起劲，服务员态度很好，请我们稍微等了会就安&lt;br&gt;排的座位，于是坐下就点了鱼头火锅，在这里不吃火锅吃其他的就没意思了。&lt;br&gt;火锅上来了，颜色真是极妙，尝了一口，鲜甜可口，不是很辣，极鲜到是，估计是放&lt;br&gt;了些白糖以吊味，放白糖吊味是四川菜式的常用作料。鱼头选取精加工的成年草鱼，采用&lt;br&gt;谭鱼头密制大料，单锅炒制，再配合四川特产泡菜系列精心烹制成火锅。香辣鱼有着红汤&lt;br&gt;鱼头的特点，色泽红艳，辣而不燥，鲜而不腥，吃后不上火；它的特别之处更在于草鱼肉&lt;br&gt;厚刺少，又加上了酸脆可口的四川泡菜，所以吃起来麻辣鲜香，细嫩爽口。泡菜有开胃消&lt;br&gt;暑的功能，更令人觉得鲜酸爽脆，胃口大开。香辣鱼的汤料与红汤鱼头有明显不同，初时&lt;br&gt;不点火，待鱼肉食尽再点燃火锅，下入配菜，让人感觉鲜美不可方物，暑气一扫而光，且&lt;br&gt;回味无穷，再不觉盛夏难以进食了。&lt;/p&gt;
&lt;p&gt;6.巴西卡特兰餐厅&lt;/p&gt;
&lt;p&gt;在五一广场的平和堂商厦的六楼，定坐电话2244888，有一家巴西烧烤餐厅，自助餐形&lt;br&gt;式的，58元一位的消费水准，包括了饮料啤酒和水果，凉菜热菜几十种可供选择，不过，&lt;br&gt;最主要这里吸引客人去的，还是正宗的巴西烧烤，来自巴西的大厨，33岁的简琦罗经常会&lt;br&gt;出现在客人面前，用生硬而好玩的中国话问客人喜不喜欢吃自己主理的各种烤肉。&lt;/p&gt;
&lt;p&gt;简琦罗眼睛很大，身材不太高，约1.70的个头，很结实，也很憨厚，与他对话时用着&lt;br&gt;半生不熟的英文单词与他沟通，很是好玩，他的国语说的不好，英文也不是他的母语，他&lt;br&gt;16岁就随父亲学习烧烤了，原来巴西风俗也跟中国一般，打仗不离父子兵的，半猜半明白&lt;br&gt;中知道了他曾经在日本也呆过八年，然后被长沙的这家老板挖到了湖南，一做就是两年，&lt;br&gt;并且还交了一位漂亮的长沙美女做女朋友，他所起女朋友的时候眼神有些害羞，问他准备&lt;br&gt;回家吗，他说当然要回 巴西，于是便问怎么不结婚，他说希望结婚啊，并且还特别希望有&lt;br&gt;小孩子，说的时候他笑得很可爱，很单纯的样子，我们于是便笑，日本有没有也找了日本&lt;br&gt;的女朋友，他做了个很苦恼的样子，摇了摇头，说日本人太厉害，一天忙到晚，根本就累&lt;br&gt;死了，那有机会找女朋友，然后就说中国好。&lt;br&gt;我们觉得真是很好玩，原来中国真的是很好的地方啊，连国外过来的外籍人，也喜欢&lt;br&gt;这地方。&lt;br&gt;吃的时候，询问了下巴西烧烤的情况，巴西烧烤发展如此迅猛，可能它不光只是一道&lt;br&gt;美食，还因为它蕴含了丰富的巴西亚马逊文化和南美风情的真谛。烧烤配自助餐一并享用&lt;br&gt;是其区别于其它流行烧烤菜食品最大的特征，巴西烤肉注重外焦内嫩，且肉是用红酒、番&lt;br&gt;西腌制一天而成的。巴西烧烤在烤制的时候很有讲究，该酒店除了请到专门的巴西人员进&lt;br&gt;行烤制之外，选料、用料也相当讲究。主料牛肉是选用烤牛的三角肉，配料除了必备的辣&lt;br&gt;椒、香料、油等等之外，还配有葡萄汁、柠檬和巴西香叶。开始烤制了，主理人将牛肉切&lt;br&gt;成两厘米长的薄片，抹上敲碎的大颗粒粗海盐、大蒜、香色拉油、红酒、香叶等进行调料&lt;br&gt;，用铁烧串制起来，放至微火中进行烧烤约30分钟，烤时不停地翻动，只感觉丝丝肉香扑&lt;br&gt;鼻而来，令人垂涎欲滴。&lt;/p&gt;
&lt;h2 id=&quot;另小吃篇&quot;&gt;&lt;a href=&quot;#另小吃篇&quot; class=&quot;headerlink&quot; title=&quot;另小吃篇&quot;&gt;&lt;/a&gt;另小吃篇&lt;/h2&gt;&lt;p&gt;都说食在广州，其实要论嘴刁，还得属湖南。&lt;br&gt;湖南人嗜辣，无辣不欢，离乡背井几十年还是改不了这口味，而外地人到湖南则个个&lt;br&gt;意志不坚，被湖南人同化，成为辣味的拥护者，甚至比正宗的湖南人有过之而无不及。&lt;br&gt;湖南好吃的菜很多，这么说吧，就是一个青椒炒肉，也比大多数地方的做得地道，青&lt;br&gt;椒是深碧的绿，肉成了一种酱色的红，一粒粒的青椒籽是鲜明的黄，油而不腻，辣而不火&lt;br&gt;，闻着有炝人的香，吃起来连汤都不剩。别的菜就不介绍了，就介绍一些湖南的小吃。因&lt;br&gt;敝人是长沙人，就先介绍长沙的街头吧，不尽之处，请大家补正。特别是湖南的老乡啊，&lt;br&gt;不得藏私，好味共享。&lt;/p&gt;
&lt;p&gt;1.口味虾&lt;/p&gt;
&lt;p&gt;长沙人喜欢吃口味虾，其实这话还不太准确，长沙是好吃的都爱，而且爱吃流行，这&lt;br&gt;口味虾流行的时间不过数年，已象龙卷风一样卷遍了长沙的大小食肆（长沙的大小食肆都&lt;br&gt;被各种各样的食品卷过了很多次，已到泰山崩于前而色不变的地步）。&lt;br&gt;比较出名的有教育街花鸟市场那一块（佼佼者为顺丰楼）、南门口（佼佼者为四唉揭&lt;br&gt;——唉揭这个词在长沙大约是奶奶或是大妈的意思，找不到那字就音同字不同吧）[应该是&lt;br&gt;“娭毑”－－哈蜊油注。]，湖大的堕落街也比较有名，但本人最喜欢还是袁家岭的球宝大&lt;br&gt;排档（因为店主做得好，现在已升级为三层楼的球宝酒楼了）。那的虾个大，而且特新鲜&lt;br&gt;，从虾的本身来说比长沙市的任何一家质量都好，甚至好过你自己从菜市场买的。汤做得&lt;br&gt;好，顺丰楼号称鸡汁熬汤，但油腻有余，鲜香不够，四娭毑的味道猛，但辣得太尖锐，不&lt;br&gt;及球宝淳厚。&lt;br&gt;在球宝吃虾吃了两个夏天。总结出来的结论：&lt;br&gt;1、实惠，五个人吃不了一百元。&lt;br&gt;2、轻松，虽然已经是酒楼了，感觉还是大排档，老板也没架子。&lt;br&gt;3、味道，这是最重要的，而且除了口味虾，这里的烟笋、凉拌粉皮（比松花江饺子馆&lt;br&gt;的好）也很不错。&lt;br&gt;4、有成就感，吃完后人人面前都有一大堆虾壳，感觉自己有进一石米的豪气。&lt;br&gt;5、安静，大伙都埋头吃，叽叽歪歪的话比较少，呵呵。&lt;/p&gt;
&lt;p&gt;2.巴蜀布衣&lt;/p&gt;
&lt;p&gt;板儿砖喜欢大排档，随意，热闹，不拘吃相，不过也喜欢一些有特色的店，比如巴蜀&lt;br&gt;布衣。&lt;br&gt;初听这个名字以为是个服装店，直到有天从长岭路过才知是食肆。既然是巴蜀，自然&lt;br&gt;是川味，的确不错，就算没学到十成，起码也有九成象，这么正宗的川味在长沙只有原来&lt;br&gt;的重庆大酒楼才有（可惜一个好好的店，愣没做起来，从解放路溜达到河西，最后的结果&lt;br&gt;还是灰飞烟灭）。巴蜀的结局大约会比重庆强，布置就独具匠心，咋一看挺朴实，乌木运&lt;br&gt;用得比较多，其实小地方很精巧，包括水龙头，一些小装饰，和它的桌子。它的桌子是长&lt;br&gt;沙市唯一的一种，类似于台球桌，其实更象麻将桌，不过铺的不是毡子，而是洁净的石子&lt;br&gt;，台上有块玻璃，让你看得见石头又不至于硌手。&lt;br&gt;总之属于有个性的装璜，味道还不赖，喜欢川味和情调的朋友可以一试。&lt;br&gt;加一句，价格中等。&lt;/p&gt;
&lt;p&gt;3.湘都酱板鸭&lt;/p&gt;
&lt;p&gt;酱板鸭不知是哪里的特产，总觉得不象是地道的湖南菜，不过长沙哪地都有它，也算&lt;br&gt;成长沙的风味小吃之一吧。&lt;br&gt;酱板鸭一定要吃湘都的，要不就吃迷你，别随便逮个菜场就进去买，买回来的价格可&lt;br&gt;能便宜而味道难以下咽。&lt;br&gt;湘都的酱鸭做出了规模，长沙任意一条街上都有，而且大多是集中制作，再分送到各&lt;br&gt;个零售点去，这样有助于保持本身的品质。看到湘都出了名还是如此一丝不苟感到十分欣&lt;br&gt;慰，想当年就是从它还只有一家店面时就开始吃它，颇有草莽识英雄的味道，眼见它一步&lt;br&gt;步地成长，当然希望它威名常在，盛名不衰。&lt;br&gt;湘都的酱板鸭的特点在香，干瘦瘦的一只小鸭子，放秤上称顶多一斤，但肉干而不韧&lt;br&gt;，用白话说就是有嚼劲而不费牙。味道咸鲜，有一点点辣（如果是不吃辣的人那就是相当&lt;br&gt;的辣了），刚吃也只觉得一点点好吃，一路吃下去，就恨不能连皮带骨一起吞下去。经板&lt;br&gt;儿砖及其同事共同推荐，最好吃的是鸭脖子，其他部位有人说是鸭皮，有人说是鸭胁，也&lt;br&gt;有人强力推荐鸭翅，呵呵，各有千秋，不一而论。&lt;br&gt;中午不回家吃饭，买酱鸭一只，玉米棒数个，啤酒酌量，以手撕之，以齿嚼之，不亦&lt;br&gt;说乎。&lt;/p&gt;
&lt;p&gt;4.麻辣烫&lt;/p&gt;
&lt;p&gt;据说麻辣烫是川味，但在湖南也着实火了一阵，湖南人最大的特点是哪的菜都吃，但&lt;br&gt;吃着吃着，哪的菜都成了湘味。&lt;br&gt;麻辣烫说白了是煮红薯粉，也有用圆形米粉或粉丝来代替的，但怎么着也没有红薯粉&lt;br&gt;够劲。做麻辣烫的店很多，但得好的要属省政府后门的那家（店名总记不住，每次都是冲&lt;br&gt;进去吃，没想到抬头看一眼，而大家好象也都心照不宣，只要说省政府后门全都心领神会&lt;br&gt;）。那的麻辣烫不知加了什么，味厚、辣、香，一碗热腾腾的红薯粉端上来，撒着葱花，&lt;br&gt;干椒，浮着一层金红色的油。你还可以加料，一串串洗得干干净净，清清爽爽的菜，象豆&lt;br&gt;皮裹芫荽，黄螺，土豆片，海带片，蘑菇（有两三种），金针茹，藕片，二三十种，当然&lt;br&gt;也少不了鸡肉牛肉猪肉等荤菜，以解肉虫子们吃肉之需要。这些菜你想要哪些就拿哪些，&lt;br&gt;店主帮你煮好，放在辣辣香香的汤里给你一块端上来。闻着那味，吃着那菜，出一身汗，&lt;br&gt;那叫痛快。&lt;br&gt;特佩服的不是店主，是老板娘，店里人头涌动，每人最少都吃四五样东东，自己在架&lt;br&gt;上取了就往店主那一扔，自己找位子坐，过不多会就给端过来，吃完后才付钱，有时连自&lt;br&gt;己也记不大全自己拿了什么吃的。也不知那老板娘怎么记住的，反正也没出过什么错，起&lt;br&gt;码我没遇到过[呵呵，老板娘是按红签和白签收费的，简单易记。&lt;/p&gt;
&lt;p&gt;5.煲仔饭&lt;/p&gt;
&lt;p&gt;严格地说煲仔饭不属于湖南小吃，但湖南人吃的一大特点就是博取众家之长，取其精&lt;br&gt;华去其糟粕，将天下美食融进湘菜之洪炉。&lt;br&gt;长沙卖煲仔饭的地方挺多，属中式快餐的一种，店面大多也类同西式快餐，走简单大&lt;br&gt;方的路子，但我想说的只是一家小店。&lt;br&gt;店很小，只是十几平米，装修也极简单，浅栗色的杂木桌椅，墙上贴了几张用儿童水&lt;br&gt;彩笔写的煲仔饭的名目。据我观察，好象真的只卖煲仔饭，其他一概没有，连水都是靠门&lt;br&gt;一自动饮水机，想喝自己倒。&lt;br&gt;进门自己找位子坐下，一般的来说人还挺多，有位子就坐吧，没有挑三拣四的余地。&lt;br&gt;小姐一手拿笔一手拿个小本溜达过来，极象拦了违章车准备开罚单的警察。点了菜，水就&lt;br&gt;不喝了，到店门口的摊上端碗排骨炖湖藕或者牛肉炖芋头（真正的老火例汤，汤清而入味&lt;br&gt;，不知是不是这店做的，反正煲仔饭与汤算是相得益彰）。&lt;br&gt;板儿砖喜欢吃这的鳝鱼黄瓜煲仔，后来听说长沙的鳝鱼都放激素，就没敢再吃，改吃&lt;br&gt;红烧牛肉，焦焦的饭，浓浓的汤，打开盖子，混和着浓冽香味的蒸气扑面而来。味好，量&lt;br&gt;又足，十来块钱可以吃得撑住。&lt;br&gt;备注：号称长沙第一煲仔，位于先锋厅的一条小巷内。&lt;/p&gt;
&lt;p&gt;6.牛肉面&lt;/p&gt;
&lt;p&gt;李合盛是一家清真馆，里面别的东东很少光顾，极有印象的是麻辣牛肉面。&lt;br&gt;看样子是很简单的食品，青椒牛肉加面条，但火候好，牛肉熟而嫩，青椒炒得颜色深&lt;br&gt;碧，但又没起壳起泡，还保留着一点生生的冲辣。既然是麻辣牛肉，自然有一点点麻，开&lt;br&gt;始总疑心放了花椒或麻辣油，很仔细地找过，并未找到证据。后来经不懈追求与努力探索&lt;br&gt;才知道，这面的主要原因是咸淡的调和与火候的掌握，用料方面倒是极简单。&lt;br&gt;可能是经营无方，店堂感觉越来越脏，服务生的态度越来越差。这些板儿砖都忍了，&lt;br&gt;直到面的味道也越来越不行了，真是是可忍孰不可忍，拍案而起，拂袖而去。&lt;br&gt;怀念是什么味道？有人说是清晨的薄雾，有人说是雨后的山林，我说，怀念，就是李&lt;br&gt;合盛麻辣牛肉面的味道。&lt;br&gt;备注：本人因为天性疏懒，没人做饭的日子一般是吃面，手艺N流，号称面大师（自己&lt;br&gt;封的），吃面的境界相当高。所以，我推荐，没错的，可惜你已吃不着……。&lt;/p&gt;
&lt;p&gt;7.唆螺&lt;/p&gt;
&lt;p&gt;长沙很有名的唆螺一条街在黄兴中路，现因城市规划，黄兴中路正在修，不知唆螺街&lt;br&gt;是否无恙。&lt;br&gt;唆螺，是一种螺（好象是废话），一直怀疑是田螺，吃了很多次，总不记得向店主们&lt;br&gt;求证（店主们的意思是那里有很多家店）。个不大，和食指的指头差不多，还有一种大个&lt;br&gt;的，状如法国蜗牛，但味道并不算好，也不叫唆螺，买的时候为了区别，将它叫成是田螺&lt;br&gt;，到底是还不是无法考证，毕竟从没去过它的生存环境。&lt;br&gt;白天吃的人好象不多，到了晚上就热闹起来，应该是属于夜市的一种吧，三五好友，&lt;br&gt;找一家店坐了，唆螺都煮在直径过七十公分的大锅里，一人叫上一份，再点些卤的鸡翅鸭&lt;br&gt;翅鸡腿鸭腿，喜欢素食的点些蒜苗、海带、豆笋之类，带上几瓶啤酒——吃夜市不喝啤酒&lt;br&gt;总是不够尽兴的，而除了啤酒，在夜市摊上喝红酒或白酒总觉得有些奇怪——那里的小孩&lt;br&gt;开啤酒的样子倒是可以大书特书一番，一瓶啤酒拿过来，左手抓住一晃，右手在瓶底一拍&lt;br&gt;，轻微地一“砰”，酒瓶就开了，姿势潇洒飘逸，极有大家风范，板儿砖不能形容之万一&lt;br&gt;，完全没有某些同志用牙用筷子，一头汗还打不开的尴尬劲。&lt;br&gt;吃唆螺是要有点技术的，看小姑娘吃最赏心悦目，三个指头掇起一个，放在小嘴里一&lt;br&gt;吮，螺肉就进去了，而肠子什么的都弃之于外，干净利落，见之忘俗。要搁在一不会吃的&lt;br&gt;男同志嘴里就比较难看了，两指头拎一螺（手太大，就只能两指头了），放嘴里，螺与嘴&lt;br&gt;不成正比，用力一吸，螺肉没进去，再吸，还是没进去，一脸通红，螺里的汁水洒到了腮&lt;br&gt;帮子上。这个就得向板儿砖学习了，不收你们学费，一个个听好了：板儿砖吃那玩意儿的&lt;br&gt;简单方法就是——用牙签。呵呵，随你多狡猾的螺都得乖乖地……。&lt;/p&gt;
&lt;p&gt;8.永州血鸭&lt;/p&gt;
&lt;p&gt;永州就是永州之野产异蛇的永州，也就是柳子庙的永州。板儿砖并不知道它的特色小&lt;br&gt;吃是什么，只是在长沙长岭看见了这么一个叫永州血鸭的小店。&lt;br&gt;经过板儿砖的实地考查，这个血鸭其实就是干锅鸭。火锅是大家所熟悉的，干锅又是&lt;br&gt;个什么东东呢？其实干锅类似于火锅，下面是个酒精炉，上面放一小号炒菜铁锅，菜至其&lt;br&gt;内。菜一般是荤菜，大多成块类（个别也有成丝状的，比如干锅手撕鸡，干锅手撕腊兔肉&lt;br&gt;，干锅酱板鸭等等），锅内无水，故称干锅，有别于放汤的火锅。&lt;br&gt;血鸭先姜蒜孜然干红椒等暴炒，再煨熟，放至干锅开上火，鸭油烧得之之地响，这是&lt;br&gt;一般的做法，而永州血鸭与众不同高人一筹的地方（现在也算不上与从不同，几乎所有长&lt;br&gt;沙的店都学了这么一手）就是在做好的干锅上撒上一大把生的大片青椒（其数量之多以至&lt;br&gt;于看上去象风吹草低见牛羊的草原，给人的感觉就是长沙的青椒不要钱）。鸭子本来是有&lt;br&gt;一种膻味的，被暴炒后，已几乎闻不到了，放上青椒，再被下面的热油一暴，只闻到一股&lt;br&gt;青椒的清炝和鸭肉的浓香。&lt;br&gt;虽然味道这么好，还价格不贵，一份三十几元的血鸭两个人基本吃不完。&lt;/p&gt;
&lt;p&gt;9.罐子一条街&lt;/p&gt;
&lt;p&gt;长沙人喜欢热闹，随便什么一出来就是一大片，聚在一块就成了一条街。什么嗦螺一&lt;br&gt;条街，蒸菜一条街，甚至烂布一条街，其中就有罐子一条街。&lt;br&gt;罐子一条街不是卖罐子的，罐子倒是很多，它那卖的是罐子里盛的菜。对不吃辣的朋&lt;br&gt;友来说，罐子一条街是避风港，对喜欢吃辣的来说，罐子一条街也是别有风味。&lt;br&gt;看名字就可以知道，这菜与罐子有关，一条窄窄小小的巷，两边都是店铺，每家店门&lt;br&gt;口都有一二十多头的灶，灶上煨的自然都是罐子了。进巷的第一感觉是晕：巷窄而昏，光&lt;br&gt;线暗淡，眼前蒙蔽着罐中冒出的白汽，鼻中闻的是数十种菜炖出的异香，耳中听到是热情&lt;br&gt;的招呼“您请进您几位”，喉中也不由自主地冒出口水，真是无处不忙，无处不晕。&lt;br&gt;板儿砖私下最喜欢的是笋，不管是洋鸭炖笋还是土鸡炖笋，上来趁别人还在傻乎乎地&lt;br&gt;吃肉，板砖就瞄准笋子猛挟，吃完后再告诉别人：“这个菜嘛，滋味都在笋子里，其次是&lt;br&gt;汤，最后是肉。”让其他人深恶痛绝，徒呼荷荷。当然，此计只可一不可再，等第二次和&lt;br&gt;同一帮人去的时候，笋落谁家就各凭本事了。&lt;br&gt;说实话，要不是老板告诉我那是笋我还真不敢确定，白白的，象过于疏松的海绵，看&lt;br&gt;它的样就让人遐想：“这汤得炖多久啊。”笋本来是无味的，可它的特点是易于吸收其他&lt;br&gt;的味道（这特性类似于茶叶，有人就用茶叶的这特性放冰箱里吸收异味），当它炖在汤里&lt;br&gt;时，不但吸收了肉的鲜味，还有姜的辛味，葱的香味，当然还有些我不大知道的调料，如&lt;br&gt;果全知道了，罐子也就不再有什么出奇之处。&lt;br&gt;前年号称正宗老字号的第一家罐子搬出了那条街，转移到了街旁边的马路上，虽然宽&lt;br&gt;敞了，舒服了，吃着喝着的时候，偶尔也会怀念原来晕乎的感觉。&lt;/p&gt;
&lt;p&gt;10.蒸菜&lt;/p&gt;
&lt;p&gt;长沙的街很多，除了上面说的外，还有蒸菜一条街。&lt;br&gt;蒸菜一条街所在的地理位置人人都知道——火车站，但去过的人并不一定多。玉楼东&lt;br&gt;的对面，极不显眼的一条小巷子。同样的有很多门面，有很热情的老板。第一次进去时是&lt;br&gt;一个朋友带去的，被拖向一不怎么显眼的小门面时，我的眼睛还颇留恋地盯在显得最气派&lt;br&gt;的“建军蒸菜馆”（名字不保证正确）的招牌上。&lt;br&gt;进去后果不其然，极狭小昏暗，朋友一付老马识途的模样向蒸菜馆的小妹要座位。那&lt;br&gt;么个小地方偏偏人还极多，想要的雅座没有了。所谓雅座也就是一间极小的房，里面只能&lt;br&gt;放一桌子，我瞄了一眼，大约是老板家的阳台改造的。&lt;br&gt;去蒸菜馆倒没怎么吃蒸菜，因朋友一力主荐那里的老干妈炒腰花，我又主吃牛肉，蒸&lt;br&gt;菜只上了个南瓜应景。但从客观上说，那里菜的味道还是不错的，而且相当便宜。&lt;br&gt;正宗的蒸菜应该是浏阳的比较多吧，食肆中经常可以看到小钵的蒸茄子、蒸青椒、蒸&lt;br&gt;排骨，而腊味合蒸是传统湘菜，就不用说了吧。&lt;/p&gt;
&lt;h2 id=&quot;长沙小吃地图&quot;&gt;&lt;a href=&quot;#长沙小吃地图&quot; class=&quot;headerlink&quot; title=&quot;长沙小吃地图&quot;&gt;&lt;/a&gt;长沙小吃地图&lt;/h2&gt;&lt;p&gt;1.南门口：烧烤小贩聚集地&lt;/p&gt;
&lt;p&gt;旧劳动剧院旁的小雨厂坪附近，过去是烧烤及各类制作小吃的小贩驱之不去的地方。&lt;br&gt;除四娭毑后来赫然在黄兴南路立起门面，现在刘记烧烤租了个小地方容身外，其他长沙市&lt;br&gt;井中人传说的王婆婆水饺、糊涂婆婆经营的凉面、炖菜、小炒、五圆肚条似乎已寻不着踪&lt;br&gt;影。南门口尚有杨眼镜夜宵排档具有一定名气。劳动剧院下去的南门口菜场的哑巴糖油粑&lt;br&gt;粑，已有五六年左右的历史，据说过去摆在金沙超市前时，人们爱其味美，就已开始排队&lt;br&gt;。&lt;/p&gt;
&lt;p&gt;2.学院街：刘记夜宵老店的糖醋排骨&lt;/p&gt;
&lt;p&gt;学院街曾有文化电影院，颇能聚集人气，夜宵街市存在已有十多年，以凉菜冷碟而出&lt;br&gt;名。当年长沙饮食业的一哥玉楼东尚在五一广场红火经营的时候，凉菜冷碟一度占到其经&lt;br&gt;营收入的七成以上。现在凉菜冷碟在各店几乎无处不有，而学院街在十几年的发展中已成&lt;br&gt;为凉菜冷碟最有特色者，如刘记夜宵老店中的糖醋排骨在长沙就有相当名气。此外，该街&lt;br&gt;经营的干面干粉亦有名。这里还有一家小店专营刀削面，虽然经营未免单调，但打出请来&lt;br&gt;新华楼退休师傅的牌号还是能吸引一些顾客的。学院街对面的小古道巷与晏家塘横街街口&lt;br&gt;有一叫娜姨麻辣烫者颇能吸引一些年轻女士品尝。她们自称吃着这里的麻辣烫从初中生长&lt;br&gt;到结婚生子。&lt;/p&gt;
&lt;p&gt;3.坡子街：火宫殿的臭豆腐&lt;/p&gt;
&lt;p&gt;坡子街有被誉为湘风小吃的源头、湘菜的主要代表的火宫殿。始建于清朝乾隆年间的&lt;br&gt;火宫殿以“火庙文化”为底蕴，辅以名品素食，以其独特的风格使历代名人纷纷慕名而来&lt;br&gt;。&lt;br&gt;火宫殿有“八小吃十二名肴”之称。其八小吃为臭豆腐、龙脂猪血、煮馓子、八宝果&lt;br&gt;饭、姊妹团子、荷兰粉、红烧蹄花、三角豆腐。1958年毛泽东视察火宫殿亲尝臭豆腐使火&lt;br&gt;宫殿更加名扬寰宇。2003年3月，全国“两会”期间，朱镕基总理在参加湖南代表团审议时&lt;br&gt;说：“我曾经想起火宫殿的小吃就垂涎不已，饮食文化对长沙很重要，一定要保持长沙的&lt;br&gt;风味……”&lt;/p&gt;
&lt;p&gt;4.游击坪：李娭毑的葱油粑粑&lt;/p&gt;
&lt;p&gt;解放西路游击坪电线杆子旁李娭毑所炸、添加了胡椒的葱油粑粑，被一些长沙年轻网&lt;br&gt;友评为“长沙第一好呷葱油粑粑”，李娭毑师从北正街头卡子一街办厂的老同事，1982年&lt;br&gt;左右自立门户，李娭毑称要炸好葱油粑粑有一定的诀窍，比如磨制米浆中加入的现饭子必&lt;br&gt;须是半生不熟的撩饭等，她的磨浆工作都是当天早上4点完成，每天炸完200个左右的葱油&lt;br&gt;粑粑即收摊。而她的技艺，因为儿子、儿媳的不愿接手，可能失传。毕竟这是个辛苦活。&lt;br&gt;真正的滋味在民间，而美食的悄然消亡有时就真像是一曲广陵散绝。&lt;/p&gt;
&lt;p&gt;5.黄兴北路：李公庙的糖油粑粑&lt;/p&gt;
&lt;p&gt;位于黄兴北路新大新斜对面的李公庙，有长沙目前人气最旺的一家糖油粑粑小店。上&lt;br&gt;个周末的黄昏，记者留心数了一下，排队的人竟然达到41人之多，队伍从李公庙排到了黄&lt;br&gt;兴北路上。人们一般用盒饭盒子将其带回家中品尝。炸制糖油粑粑的金炳炎师傅13岁就在&lt;br&gt;饮食公司学徒，后转往建筑公司，再到工厂中。下岗后重操入行时的旧业，用料注重真材&lt;br&gt;实料，经营则薄利多销。名声之大，竟吸引一些在五一广场商圈活动的台湾和香港客商前&lt;br&gt;来品尝，他们称，像这样的传统产品，经营得好，在香港是要受到政府保护的，并拨给免&lt;br&gt;费和低廉的门面以扶植和经营。问金师傅的经营诀窍，答，用心来做，舍得投本。自然就&lt;br&gt;做得好。&lt;/p&gt;
&lt;p&gt;6.蔡锷北路：长青汤圆店&lt;/p&gt;
&lt;p&gt;长青汤圆店是一家有百年历史的私营小店。小店主营小磨汤圆。祖传手艺，粉质细嫩&lt;br&gt;。如今已传至第四代。其店内所经营的肉馅汤圆目前在长沙可能是独一无二的。其店不远&lt;br&gt;另有一家开办于1985年的晶莹汤圆店。两家店面几乎比邻而居，颇有竞争之势。在竞争中&lt;br&gt;两店互相促进提高，皆成为长沙最有生机的小吃店之一。两店均经营有荷兰粉、烫粉、白&lt;br&gt;粒丸、麻油猪血等十数甚至是数十个品种。萝卜白菜各有所爱。两家店面共存反而可能吸&lt;br&gt;引更多的顾客前往自主选择。只可惜，两家门面上均已写了一个大红的拆字，晶莹汤圆店&lt;br&gt;暂移至中医附二医院那一头的粉店旁。两家小店的南面有华南小吃店，开了数家连锁。绿&lt;br&gt;豆沙和凉面最有名。&lt;/p&gt;
&lt;p&gt;7.荷花池：翁不倒蚕豆&lt;/p&gt;
&lt;p&gt;翁不倒蚕豆以炒奶油蚕豆而闻名。其创始人翁国良先生，经研制于1997年将色香独具&lt;br&gt;的翁家蚕豆投入市场，面市不久一度出现排队、凭票、限购的抢购狂潮。成为长沙市井的&lt;br&gt;一个传奇。附近马路对面学宫街有一家叫马复胜的老字号，以卖结麻花、米花等出名。&lt;br&gt;在蔡锷北路粮店内还有卖糖油粑粑摊点，黄昏时一般都有20人以上在此排队等候，为&lt;br&gt;长沙又一最有人气的糖油粑粑摊点。附近另有二马路天恩啤酒店的糖油粑粑也是人头攒动&lt;br&gt;。这个冬天，长沙人确实掀起了一股吃糖油粑粑之风。&lt;/p&gt;
&lt;h2 id=&quot;温故篇&quot;&gt;&lt;a href=&quot;#温故篇&quot; class=&quot;headerlink&quot; title=&quot;温故篇&quot;&gt;&lt;/a&gt;温故篇&lt;/h2&gt;&lt;p&gt;这个冬天风行吃糖油粑粑&lt;/p&gt;
&lt;p&gt;这个乍暖还寒的时节，春节气氛一天浓过一天，在酒楼美宴觥筹交错的时候，蓦然发&lt;br&gt;觉，长沙人依然离不开小吃，市井传统和现代的小吃依然让长沙人沉醉，为了让小吃安慰&lt;br&gt;唇齿口腹，人们竟然不惜在周末，排起耐心等候的长队。&lt;br&gt;    在星城的街头巷尾，有多少传统小吃让人在等待；又有多少新潮小吃让人企望。吃在&lt;br&gt;长沙，口舌生津，“食”尚之趣，如“吃”如醉。&lt;br&gt;    在长沙寻找传统小吃，有一条最便捷的道路，那就是沿着黄兴北路转蔡锷路，基本沿&lt;br&gt;着2路公共汽车的线路穿行于长沙老城区，星城的著名传统小吃基本由这条线可以一网打尽&lt;br&gt;。毕竟传统小吃皆有源自，老城区文化积淀深厚，而南门口的“娭毑现象”更是为人们津&lt;br&gt;津乐道。我们的传统小吃之旅就从南往北开始：&lt;br&gt;    快要下午3点了，请将要出摊的王五娭毑和他的小儿子留张影。看看王五娭毑粗大的手&lt;br&gt;，你会有种莫名的感动。每一种出色的民间小吃背后都有一个故事。&lt;/p&gt;
&lt;p&gt;劳动广场：王五娭毑的臭干子&lt;/p&gt;
&lt;p&gt;劳动广场是黄兴南路的起点。附近有新小吃鸭锁骨店“易家姜记”。这家小店本来是&lt;br&gt;个路边摊，现在已在附近开了四家门面，由易家的大姐和两个弟弟经营。之所以叫易家姜&lt;br&gt;记是因为发明卤汁的为易家兄弟的姐夫姜某，而把生意真正做大则是易家兄弟姐妹团结一&lt;br&gt;心的结果。&lt;br&gt;在这里，我要说的是王五娭毑的臭干子。五娭毑一度在长沙被误传为古娭毑，五娭毑&lt;br&gt;笑笑，从不解释，一错就是好多年。经本地媒体报道，以及中央电视四台的播出，五娭毑&lt;br&gt;的臭干子摊前排起长龙。现在五娭毑回家照顾二度中风的爱人黄爹爹，已不再亲自到摊前&lt;br&gt;炸臭干子了，一些排队的年轻人怅然若失，臭干子还是那个臭干子，但总觉得少了五娭毑&lt;br&gt;就少了一个味儿。&lt;br&gt;五娭毑的臭干子绝对在长沙是寥若晨星的珍稀。五娭毑的臭干子设有两个点：一、早&lt;br&gt;先由其亲自或与大儿子一起在黄兴南路旁一个近马路的地方摆设的摊点，另一个摊则由其&lt;br&gt;小儿子设在沙河街下坡处。王五娭毑的臭干子每天据说只卖1000片，从下午3点开摊起，早&lt;br&gt;卖完早散摊，绝不多卖一片。她的这两处臭干子注定会要在长沙兴盛下去。因为长沙很多&lt;br&gt;小摊贩的臭干子因为不知制作素卤水，即采用短视恶劣的做法，将螺坨肉或蚌壳肉等浸泡&lt;br&gt;发臭加色素等做成荤卤水，而荤卤水在口感上有股令人腻烦的腥臭，并且因其含有肉毒素&lt;br&gt;，对人体危害极大，使人对这些臭干子大倒胃口。而长沙过去的素卤水，据已故美食家俞&lt;br&gt;润泉的记载，在“文革”前期之“破四旧”中就已多被倒掉，知道发卤或保存有素卤水的&lt;br&gt;人家在长沙现在是寥寥无几。&lt;/p&gt;
&lt;h3 id=&quot;口味菜-（共同特点：口味重，辣，环境简陋，食客盈门）&quot;&gt;&lt;a href=&quot;#口味菜-（共同特点：口味重，辣，环境简陋，食客盈门）&quot; class=&quot;headerlink&quot; title=&quot;口味菜 （共同特点：口味重，辣，环境简陋，食客盈门）&quot;&gt;&lt;/a&gt;口味菜 （共同特点：口味重，辣，环境简陋，食客盈门）&lt;/h3&gt;&lt;p&gt;1、无名家菜馆 好象用不着我说了，生意好得吓人。往巷子里进去第三家也还不错&lt;/p&gt;
&lt;p&gt;蔡锷南路香格里拉酒吧旁&lt;/p&gt;
&lt;p&gt;2、辣椒炒肉 因为实在没有一个招牌，以辣椒炒肉闻名，鸡汤也很好喝&lt;/p&gt;
&lt;p&gt;芙蓉北路银苑海鲜右侧&lt;/p&gt;
&lt;p&gt;3、老天富 财政厅附近广济桥南侧&lt;/p&gt;
&lt;p&gt;3、赵记 其实应该叫“钱四口味鸡”？特色菜：口味鸡、口味田鸡&lt;/p&gt;
&lt;p&gt;长沙电脑城旁&lt;/p&gt;
&lt;p&gt;4、星沙 一个小店，在省移动指挥中心旁的鸿翔大厦后面的小巷子里&lt;/p&gt;
&lt;p&gt;特色菜：鳝鱼炒豆子&lt;/p&gt;
&lt;p&gt;5、一家罐子老店 先锋厅 才鱼抱蛋&lt;/p&gt;
&lt;p&gt;6、三味食府 这里是个祸的好地方，老板亲自坐台，陪吃陪喝陪祸，你想干嘛就干嘛&lt;br&gt;，果真宾至如归。 湘春路陋园宾馆对面 竹香黄鸭叫、香菜凉拌腰花&lt;/p&gt;
&lt;h3 id=&quot;地方特色&quot;&gt;&lt;a href=&quot;#地方特色&quot; class=&quot;headerlink&quot; title=&quot;地方特色&quot;&gt;&lt;/a&gt;地方特色&lt;/h3&gt;&lt;p&gt;1、浏阳蒸菜&lt;/p&gt;
&lt;p&gt;（1）首推“北美”，左家塘阿弥岭，大部分都为蒸菜&lt;/p&gt;
&lt;p&gt;推荐：各色汤味道不错。一定要尝店里木桶装的山葡萄酒，每次我都能喝一斤：）&lt;/p&gt;
&lt;p&gt;（2）喜玛拉雅店附近有一家蒸菜馆也不错，具体地址谁知道请补充&lt;/p&gt;
&lt;p&gt;2、宁乡口味蛇&lt;/p&gt;
&lt;p&gt;九龙鱼头城 名为鱼头城，实际好吃的是蛇，尤其用剩下的汁拌面条，极鲜美&lt;/p&gt;
&lt;p&gt;地址：天心宾馆旁&lt;/p&gt;
&lt;p&gt;3、永州血鸭&lt;/p&gt;
&lt;p&gt;广济桥底往长岭方向，有两家吃永州血鸭的小店，不记得名字，都很好吃&lt;/p&gt;
&lt;p&gt;4、常德钵子菜&lt;/p&gt;
&lt;p&gt;（1）大丰和&lt;/p&gt;
&lt;p&gt;（2）芙蓉国 有两年没吃了，不知现在如何&lt;/p&gt;
&lt;p&gt;5、长沙的黄鸭叫&lt;/p&gt;
&lt;p&gt;（1）橘子洲头 几次都在“老江岸”吃的。味道一般，但夏天的晚上，江风渔火加啤&lt;br&gt;酒，有一帮朋友对酒当歌，感觉很好。据说有另一家味道要好，请记得名字的补充。&lt;/p&gt;
&lt;p&gt;（2）南大桥 河西桥底，有几条船。以前是在叫“石砣”的船上吃，后来旁边另开了&lt;br&gt;一家叫“张立斯”，也不错。不冷的白天或晚上，在江中四面临风，不意快哉。特色：鱼&lt;br&gt;、河虾、河蚌&lt;/p&gt;
&lt;h3 id=&quot;小吃&quot;&gt;&lt;a href=&quot;#小吃&quot; class=&quot;headerlink&quot; title=&quot;小吃&quot;&gt;&lt;/a&gt;小吃&lt;/h3&gt;&lt;p&gt;1、米粉&lt;/p&gt;
&lt;p&gt;（1）无名 省人民医院对面的小巷子里&lt;/p&gt;
&lt;p&gt;（2）烈士公园北大门旁边的玉林米粉也很有名，搞得这里几乎每天都要堵车！&lt;/p&gt;
&lt;p&gt;（3）一家粉店 的米粉不错，口感好，分量多，码子齐，地方也还大，推荐椒脆粉，&lt;br&gt;就是辣椒，榨菜，肉丝，香菇一起炒的码子，也还辣，要是放多点醋，更加开胃~可以恰2&lt;br&gt;碗&lt;/p&gt;
&lt;p&gt;在春天百货旁的药王巷内200米&lt;/p&gt;
&lt;p&gt;2、臭干子&lt;/p&gt;
&lt;p&gt;沙河街口，往北50米巷子口，五埃皆的摊子。只有下午和晚上供应&lt;/p&gt;
&lt;p&gt;3、牛肉串&lt;/p&gt;
&lt;p&gt;解放西路畅行天下隔壁巷内20米处一个小摊，生意极好，总要排队。且只在下午4：0&lt;br&gt;0 – 6：00供应&lt;/p&gt;
&lt;p&gt;4、牛杂汤&lt;/p&gt;
&lt;p&gt;朝阳电器城旁的小店，那里的牛肉串也久负盛名&lt;/p&gt;
&lt;p&gt;5、兰花豆&lt;/p&gt;
&lt;p&gt;“翁不倒”的兰花豆 荷花池 长沙市第13中学门口&lt;/p&gt;
&lt;p&gt;6、包子，馒头等&lt;/p&gt;
&lt;p&gt;天津小吃店（就是酒吧一条街的杨欲兴旁边）的包子里面不止有肉，还有姜葱香姑末&lt;br&gt;。小汤包的汤汁好鲜，又不油，余香留齿~~那里的其他面点也很好~&lt;/p&gt;
&lt;p&gt;特别推荐 天津小吃店的馒头~都是老面发的~自然的发酵糖味~不是别的地方的糖精味&lt;br&gt;~ ～本人最喜欢在那里觅～每个5角，一次买一堆，便宜又开胃，那里馒头极度畅销，一天&lt;br&gt;几十笼搞手脚不赢&lt;/p&gt;
&lt;p&gt;7、玉米棒&lt;/p&gt;
&lt;p&gt;九所宾馆7号楼餐厅（不是外面那家大餐厅），炸的“臭豆腐”和蒸的“玉米棒”都非&lt;br&gt;常好吃，虽然臭豆腐炸得地道的地方很多，但在九所就不必担心吃进潲水油。&lt;/p&gt;
&lt;p&gt;8、煲仔饭&lt;/p&gt;
&lt;p&gt;在长沙，有空调的地方中，好象就属华南小吃的煲仔饭最便宜，就是难得等，吃的人&lt;br&gt;太多了&lt;/p&gt;
&lt;p&gt;9、糖油粑粑&lt;/p&gt;
&lt;p&gt;（1）、蔡锷北路粮店的糖油粑粑：黄昏时一般有20余人左右排队等候。为长沙又一有&lt;br&gt;人气的糖油粑粑摊点。这个冬天长沙人掀起了一股吃糖油粑粑之风。附近另有二马路的糖&lt;br&gt;油粑粑较有名。&lt;/p&gt;
&lt;p&gt;（2）、黄兴北路新大新斜对面李公庙：这里有长沙目前人气最旺的一家糖油粑粑小店&lt;br&gt;。人们一般用盒饭盒子将其带回家中品尝。炸制糖油粑粑的金炳炎师傅13岁就在饮食公司&lt;br&gt;学徒，后转往建筑公司，再到工厂中。下岗后重操入行时的旧业，用料注重真材实料，经&lt;br&gt;营则薄利多销。&lt;/p&gt;
&lt;p&gt;10、葱油粑粑&lt;/p&gt;
&lt;p&gt;游击坪：解放西路游击坪电线杆子旁炸葱油粑粑的李娭毑所炸的加过胡椒味的葱油粑&lt;br&gt;粑，被一些长沙年轻的网友评为“长沙第一好呷葱油粑粑”，李娭毑师从头卡子一街办厂&lt;br&gt;的老同事，1982年左右自立门户，李娭毑称要炸葱油粑粑有一定的诀窍，比如磨制米浆中&lt;br&gt;加入的现饭子必须是半生不熟的撩饭等，她的磨浆工作都是当天完成，每天炸完200个葱油&lt;br&gt;粑粑，即告收摊。而她的技艺，因为儿子、儿媳的不愿接手，可能失传。毕竟这是个辛苦&lt;br&gt;活。真正的滋味在民间，而美食从来都是源自民间的。&lt;/p&gt;
&lt;p&gt;11、蚕豆&lt;/p&gt;
&lt;p&gt;荷花池翁不倒蚕豆：翁不倒蚕豆以炒奶油蚕豆而闻名。其创始人翁国良先生，经研制&lt;br&gt;，于1997年将色香独具的翁家蚕豆投入市场，面市不久一度出现排队、凭票、限购的抢购&lt;br&gt;狂潮。成为长沙市井的一个传奇。附近马路对面学宫街有一家叫马复胜的老字号，以卖结&lt;br&gt;麻花、米花等出名。&lt;/p&gt;
&lt;p&gt;12、汤圆&lt;/p&gt;
&lt;p&gt;蔡锷北路长青汤圆店与晶莹汤圆店：长青汤圆店是一家有百年历史的私营小店。小店&lt;br&gt;主营小磨汤圆。祖传手艺，粉质细嫩。如今已传至第四代。其店内所经营的肉馅汤圆目前&lt;br&gt;在长沙可能是独一无二的。其店不远另有一家开办于1985年的晶莹汤圆店。两家店面几乎&lt;br&gt;比邻而居，颇有竞争之势。在竞争中两店互相促进提高。两店均经营有荷兰粉、烫粉、葱&lt;br&gt;油粑粑、白粒丸、麻油猪血等十数甚至是数十个品种。萝卜白菜各有所爱。两家店面共存&lt;br&gt;反而可能吸引更多的顾客前往自主选择。只可惜，两家门面上均已写了一个大红的拆字，&lt;br&gt;晶莹汤圆店暂移至中医附二医院那一头的粉店旁。这两家店在拆迁重建后多半仍将选择在&lt;br&gt;原址上营业。&lt;/p&gt;
&lt;p&gt;13、猪脚&lt;/p&gt;
&lt;p&gt;河西银鸿小区内“猪脚王”，很辣，要小心&lt;/p&gt;
&lt;p&gt;14、烧烤&lt;/p&gt;
&lt;p&gt;奥莎体育馆对面“两重天”&lt;/p&gt;
&lt;p&gt;15、香干&lt;/p&gt;
&lt;p&gt;梓园路“世平餐馆”，在附二对面沿梓园路右侧走不远&lt;/p&gt;
&lt;p&gt;16、粥&lt;/p&gt;
&lt;p&gt;南门口“一品粥”&lt;/p&gt;
&lt;p&gt;17、小炒腊鸟&lt;/p&gt;
&lt;p&gt;西湖楼，招牌菜：千丝万缕，刀功了得。&lt;/p&gt;
&lt;p&gt;18、锁骨和猪脚&lt;/p&gt;
&lt;p&gt;沙河街”姜记”的锁骨和猪脚的确是不错!!!最近又有鹌鹑吃……呵呵！4元一个。味&lt;br&gt;道都进去了！&lt;/p&gt;
&lt;p&gt;19、羹&lt;/p&gt;
&lt;p&gt;五一路上的银华大酒店有道“太极蔬菜羹”，一白一青，调成了太极图案，清淡鲜美&lt;br&gt;，值得品味。&lt;/p&gt;
&lt;p&gt;补充&lt;/p&gt;
&lt;p&gt;（1）、炒饭当然是金牛角芙蓉北路店&lt;/p&gt;
&lt;p&gt;（2）、粉则是书院路的牛肉粉（公安寻呼的对面）一个小门面，两个妇女开的&lt;/p&gt;
&lt;p&gt;（3）、粥则一定是南门口的正粤，现在解放西路也开了分店&lt;/p&gt;
&lt;p&gt;（4）、口味虾么，梅园的也很不错哦，单记的就名气大口味差了些&lt;/p&gt;
&lt;h3 id=&quot;其它&quot;&gt;&lt;a href=&quot;#其它&quot; class=&quot;headerlink&quot; title=&quot;其它&quot;&gt;&lt;/a&gt;其它&lt;/h3&gt;&lt;p&gt;1、鱼&lt;/p&gt;
&lt;p&gt;赤岗冲再往前一直走有一条街，全是吃鱼的。我去的那一家叫：诗韵。分量比伍家岭&lt;br&gt;活鱼村的还足，好大一盆哦! 味道也不错，很辣，很过瘾。如果要去吃的话，一定要记得&lt;br&gt;让老板多加点摩芋豆腐!&lt;/p&gt;
&lt;p&gt;谭州瓦罐店的“竹香鱼”，第一次吃觉得很不错，没吃过的可去尝尝。&lt;/p&gt;
&lt;p&gt;香辣鱼火锅：在湖南日报大门对面，就是体育馆路那个巷子里进去不到30米，有一家&lt;br&gt;“老四川鱼馆”&lt;/p&gt;
&lt;p&gt;鱼头：二环线“菩提树”&lt;/p&gt;
&lt;p&gt;2、鸡汤&lt;/p&gt;
&lt;p&gt;五一路粮贸大厦下面的湘楚人家，有道“十里飘香”的鸡汤，像极小时候外婆家熬的&lt;br&gt;土鸡汤，黄澄澄的鸡油漂在上面，喷香的。&lt;/p&gt;
&lt;p&gt;3、佛跳墙&lt;/p&gt;
&lt;p&gt;广济桥下有家做“佛跳墙”的，很专业很好吃也很贵。&lt;/p&gt;
&lt;p&gt;4、酸菜煮肉&lt;/p&gt;
&lt;p&gt;岳麓山顶有家路边餐馆，做的“酸菜煮肉”，实在太下饭了，就着那点汤汁都能吃下&lt;br&gt;两大碗饭。&lt;/p&gt;
&lt;p&gt;5、西餐炒饭&lt;/p&gt;
&lt;p&gt;绿茵阁的西餐炒饭都一般，但配的辣椒酱不错，好象是李锦记的海鲜辣椒酱，现在去&lt;br&gt;超市却买不到李锦记的那种辣椒酱了，不知道他们在哪买的。&lt;/p&gt;
&lt;p&gt;6、烤牛肉&lt;/p&gt;
&lt;p&gt;金源大酒店的巴西烧烤自助餐，有种烤的“三角牛肉”，那个外国人说是“牛排”的&lt;br&gt;，割起来油汁和血水一块往下带，趁个五六分熟去吃，外面那点儿肥肉焦脆香嫩，里面的&lt;br&gt;精肉鲜美耐嚼，无敌了。我到那儿其它的都不想吃，专等这玩艺&lt;/p&gt;
&lt;p&gt;7、平常菜&lt;/p&gt;
&lt;p&gt;省政府大门对面迎宾路上有个雅亨酒家，有很多不错的菜，比如“鸡汁罗卜”、“干&lt;br&gt;锅麻花带皮蛇”、“铁板紫苏黄瓜”、“猪脚”，都很不错，菜的样子漂亮，吃起来也比&lt;br&gt;别家味道正。正式一点的请客去那儿比较体面。&lt;/p&gt;
&lt;p&gt;8、肥肠火锅&lt;/p&gt;
&lt;p&gt;财经学院外面有家肠子火锅店，肥肠实在是太诱人了，吃起来就顾不得什么环境呀卫&lt;br&gt;生呀，有时候我一个人就要吃掉一个中份。不过那儿离市区实在是太远了，去起来很不方&lt;br&gt;便，而且环境卫生条件不是太好，带朋友去吃不太好意思。&lt;/p&gt;
&lt;p&gt;9、熊记面馆&lt;/p&gt;
&lt;p&gt;窑岭由西往东方向右手第一个路口，上面横幅挂着“湘水足浴”那个巷子，笔直往里&lt;br&gt;走，当头有一家“熊记面馆”。别误会，这里早上也不卖面，只中午晚上经营家常菜肴。&lt;br&gt;自家的三间房子，桌面特别紧张，通常去这里吃饭需要早退来占位子，否则算好时间来吃&lt;br&gt;第二轮。老板娘瘦精精的，眼睛头发特别黑。招牌菜：鸭子、红烧桂鱼、香干回锅肉、红&lt;br&gt;烧猪脚……可以直接去厨房看着菜再点，切洗得清清澈澈。鸭子每天只做有限的几只，可&lt;br&gt;以打电话预定好了打包回家去吃，切得小小鸭子放姜片用沙锅慢火煨出来，恨不得每块骨&lt;br&gt;头都吞下去。电话：4129645&lt;/p&gt;
&lt;p&gt;10、猪脚王&lt;/p&gt;
&lt;p&gt;河西由南往北方向，过了那个著名的红房子饭馆（不好吃）右边第一个路口进去（叫&lt;br&gt;什么创远花园），左拐约N米，有家“猪脚王”。招牌菜是猪脚，香辣入味，绝不油腻，我&lt;br&gt;曾带过多人次前去品尝，全部留下深刻印象。其它家常菜也口味不错，腊鸡都是自家熏制&lt;br&gt;的，干干净净，很香。&lt;/p&gt;
&lt;p&gt;11、新沙饭店&lt;/p&gt;
&lt;p&gt;芙蓉路由北往南，过了湘鄂情第一个路口下一个大下坡左拐，“新沙饭店”，里面的&lt;br&gt;蒜苗炒肉好吃得不得了，肉怎么可以炒得那么嫩呢……招牌菜还有红烧狗肉，一片一片的&lt;br&gt;，喷香。还有红烧桂鱼……个人认为没有熊记的好吃，但也不错了，外地好吃鬼曾连点两&lt;br&gt;份。&lt;/p&gt;
&lt;p&gt;12、铁胖子餐馆&lt;/p&gt;
&lt;p&gt;在“水库（上的士说“水库”，司机一般都晓得）桂花公园附近，有家“铁胖子餐馆&lt;br&gt;”…….土菜火爆得很&lt;/p&gt;
&lt;p&gt;13、红烧肉&lt;/p&gt;
&lt;p&gt;侯家塘的“帝豪”，红烧肉肥而不腻，肉质松软。&lt;/p&gt;
&lt;p&gt;14、羊肉&lt;/p&gt;
&lt;p&gt;人人家：韶山南路往长潭高速的路口，涮羊肉很棒，比“小肥羊”的好吃。更绝的是&lt;br&gt;吃到一半，会有人举着一个黄澄澄的巨大的锅——是一个大锅底的锅巴出来，所有的人就&lt;br&gt;冲上去每人掰一块。&lt;/p&gt;
&lt;h3 id=&quot;民间小规模粉店面摊不完全记录&quot;&gt;&lt;a href=&quot;#民间小规模粉店面摊不完全记录&quot; class=&quot;headerlink&quot; title=&quot;民间小规模粉店面摊不完全记录&quot;&gt;&lt;/a&gt;民间小规模粉店面摊不完全记录&lt;/h3&gt;&lt;p&gt;1、曙光北路的粉摊&lt;/p&gt;
&lt;p&gt;这个粉摊摆在从五一路往曙光路上去的路口附近，营业时间每天早上6点多开到上午1&lt;br&gt;0点左右，摊主是一对夫妻，粉摊外还摆了个烟摊。此处以排骨粉最吸引人气。其实每份粉&lt;br&gt;上所盖排骨有限，只是几小块，可是就这几小块，每天都要让粉摊卖掉很大一盆排骨，蛮&lt;br&gt;多人为此而捧这家粉摊的场。此处粉汤亦炖得特别香，比一般小店里粗糙的汤好多了，那&lt;br&gt;味一喝就很明显能感觉到自然的清鲜，却又不腻。唯一的缺点就是粉皮很一般。&lt;/p&gt;
&lt;p&gt;2、浏正街口、东庆街里的“无名粉店”&lt;/p&gt;
&lt;p&gt;这家粉店，需要自己买筹，自家端粉，生意好得下不得地，经常有人为吃这碗粉从很&lt;br&gt;远的地方开车搭的来吃，甚至晚上生意可以好到男士们只得蹲在地上解决这碗粉，因为实&lt;br&gt;在是等不到位子。在这家粉店里，竟然可以碰到湖南一些最著名的电视主持人的脸。&lt;/p&gt;
&lt;p&gt;3、仰天湖无名小粉店&lt;/p&gt;
&lt;p&gt;这家小粉店在贺龙体育场对面仰天湖三岔路口往扫把塘方向几百米处。只买上午，到&lt;br&gt;10点多钟，粉就没有了。该店汤做得特别鲜，肉饼蒸蛋很有特色。&lt;/p&gt;
&lt;p&gt;4、通泰街中的工农粉店&lt;/p&gt;
&lt;p&gt;肉丝粉非常好吃，油水很足，而且看起来也很新鲜。粉店外观看去似停留在十多年前&lt;br&gt;，有点破败陈旧的感觉，桌椅也还是那些刷了一层红漆的，陈旧的店堂，黯淡的横梁，对&lt;br&gt;比着每碗新鲜的米粉，每碟鲜红的剁辣椒，每份碧绿清香的刀豆，唉，好吃的东西往往就&lt;br&gt;埋藏在不起眼的地方啊！肉丝粉好像是2元。&lt;/p&gt;
&lt;p&gt;5、白沙路的“粉身是劲”&lt;/p&gt;
&lt;p&gt;这家小店刷在右边墙上的“粉身是劲”的宣传口号要比他的店名更吸引人，所以人们&lt;br&gt;不记得它的店名。小店位于劳动路和白沙路交界的十字路口的东南侧，就在街口，仅此一&lt;br&gt;家，门脸很小，只有七八上十个卡座的位子，干净整洁，此店米粉的味道很浓郁，份量也&lt;br&gt;足，好吃！我对这里的三鲜粉情有独钟。&lt;/p&gt;
&lt;p&gt;6、刘聋子津市牛肉粉店&lt;/p&gt;
&lt;p&gt;津市牛肉粉在长沙的风光已不再，但该店味道的确不同。吃法也不同：一个牛肉钵子&lt;br&gt;，下面一个炉子，把汤烧得滚滚的，然后把一碗光头无汤的米粉倒下去，自己捞上来吃。&lt;br&gt;有点像吃火锅的味道。这是最豪华的吃法，当地叫吃炖粉。一般情况下，津市牛肉粉是先&lt;br&gt;把粉下好放碗里，盖上葱。然后盖上炖牛肉的原汁和牛肉码子。所以它的牛肉味道很浓，&lt;br&gt;而且很辣很麻。味道很劲，这与长沙街上那种先浇骨头汤，再盖码子的做法有本质区别，&lt;br&gt;味道也截然不同。&lt;/p&gt;
&lt;p&gt;7、南门口的金玲粉店&lt;/p&gt;
&lt;p&gt;这家粉店炒码甚佳，尤其腰片在食客中较有名。附近天心阁后蔡锷南路小巷人家的周&lt;br&gt;记粉店亦有名。红旗区广济桥下的胖子粉铺亦以炒码获得邻近居民的支持。&lt;/p&gt;
&lt;p&gt;8、德雅路动物园附近的玉林粉店&lt;/p&gt;
&lt;p&gt;味道不错，自产的辣椒酱很出味。的哥廖先生称，早上该地段堵车，就因这家粉店人&lt;br&gt;气太旺。&lt;/p&gt;
&lt;p&gt;9、浏城桥一粉店&lt;/p&gt;
&lt;p&gt;地处浏城桥小李口味鸡的斜对面。每天早上吃粉的人多得不得了，份量扎实，一碗就&lt;br&gt;是一大碗，而且配料都很地道，什么“乱七八糟”的都有：排骨粉，煎蛋粉，肉丝粉啦…&lt;br&gt;…估计东成、华联、银港上班的人没少在这里吃。&lt;/p&gt;
&lt;p&gt;10、藩城堤的“一家粉店”&lt;/p&gt;
&lt;p&gt;推荐那里的手工粉，煮得软但有韧性，汤熬得也地道，特别是酸辣码子很够味，我觉&lt;br&gt;得真正的好的粉店就是把最普通的粉变成最不得了的，就像这个“一家”的酸辣粉一样。&lt;/p&gt;
&lt;p&gt;11、湘春路“矮子粉铺”&lt;/p&gt;
&lt;p&gt;无名粉店，矮子粉铺的“名头”为顾客俗称。该店在明德中学附近，人气极旺，更反&lt;br&gt;衬出某老字号的冷清。&lt;/p&gt;
&lt;p&gt;12、梓园路“友谊饮食店”&lt;/p&gt;
&lt;p&gt;地处省政府宿舍对面的友谊饮食店专卖粉面，腰肝、肉肝、牛肉、鳝鱼炒码都好吃，&lt;br&gt;人很多。&lt;/p&gt;
&lt;p&gt;13、杨妹子面粉铺&lt;/p&gt;
&lt;p&gt;地处松桂园衡清里省参事室门口宿舍。红烧肉码子和肉汁盖在面粉上，味重，适合长&lt;br&gt;沙人口味；拿个小碟子任意选取刀豆、酸菜的做法也很吸引人。&lt;/p&gt;
&lt;p&gt;14、香辣粉&lt;/p&gt;
&lt;p&gt;就是平时我们说的烫粉。但我最近在金苹果大市场对面发现一家“重庆香辣粉”的小&lt;br&gt;店，味道特别，且看起来还干净。他们用的不是我们平常所吃的扁扁的红薯粉，而是圆的&lt;br&gt;，特别细滑。加上高汤、辣油、花椒、芝麻、豆子、香菜等等十几样配料，吃起来又辣又&lt;br&gt;麻又香，如果是冬天吃一碗一定爽到极点。&lt;/p&gt;
&lt;p&gt;15、来个便宜点的：&lt;/p&gt;
&lt;p&gt;劳动路与白沙路十字路口东南角上，白沙路路边，有个小饭铺，10平米左右。没注意&lt;br&gt;过名字。只做粉，面，煲仔饭。注意无夜宵。早点的粉，面都还不错，只要3块5。特色煲&lt;br&gt;仔为辣椒炒肉和茄子炒肉，5块。鳝鱼，鸡杂也不错，8块。一般价位为5-10块。价格便宜&lt;br&gt;量又足。只有一个菜，加送辣萝卜丁一份，汤一碗。可随意加饭，萝卜，汤。正吃饭的点&lt;br&gt;也要排队挤位置。&lt;/p&gt;
&lt;p&gt;16、老长沙面粉馆面牌粉牌术语&lt;/p&gt;
&lt;p&gt;² 落锅起：见水跑，面条浮起来就挑起&lt;/p&gt;
&lt;p&gt;² 带迅：熟而不烂&lt;/p&gt;
&lt;p&gt;² 带迅干：带迅，油稍多，不要汤&lt;/p&gt;
&lt;p&gt;² 二排：熟而不溶&lt;/p&gt;
&lt;p&gt;² 溶排：溶而不碎&lt;/p&gt;
&lt;p&gt;² 轻挑：份量少一点&lt;/p&gt;
&lt;p&gt;² 重挑：份量多一点&lt;/p&gt;
&lt;p&gt;² 轻油：油少一点&lt;/p&gt;
&lt;p&gt;² 重油：油多一点&lt;/p&gt;
&lt;p&gt;² 宽汤：汤稍多&lt;/p&gt;
&lt;p&gt;² 扣汤：汤稍少&lt;/p&gt;
&lt;p&gt;² 免青：不放葱蒜&lt;/p&gt;
&lt;p&gt;² 免色：不放酱油&lt;/p&gt;
&lt;p&gt;² 过桥：面和码子分开&lt;/p&gt;
&lt;p&gt;² 过桥加码：双份码子过桥&lt;/p&gt;
&lt;p&gt;² 二排干：熟而不烂，不要汤&lt;/p&gt;
&lt;p&gt;² 二排宽汤；熟而不烂，汤稍多&lt;/p&gt;
&lt;p&gt;² 来原：不要码子，多放原汤&lt;/p&gt;
&lt;h3 id=&quot;学校附近&quot;&gt;&lt;a href=&quot;#学校附近&quot; class=&quot;headerlink&quot; title=&quot;学校附近&quot;&gt;&lt;/a&gt;学校附近&lt;/h3&gt;&lt;p&gt;1、铁道学院&lt;/p&gt;
&lt;p&gt;铁道学院往南过禁毒支队再往乡里去，有一个修记狗肉馆。就象豹子岭土菜馆那样的&lt;br&gt;场合，  狗肉火锅，爆炒狗肠，自家熏的腊牛肉，味道真的好，和党校那边的狗肉不是一&lt;br&gt;种风格，也不是贵州花江狗肉的搞法，就是交通不便，冒得车就去不了，的士可能都不得&lt;br&gt;去。&lt;/p&gt;
&lt;p&gt;2、师大南院：&lt;/p&gt;
&lt;p&gt;（1）、地下餐厅&lt;/p&gt;
&lt;p&gt;这家已经有8年历史的餐馆无疑是学生聚餐的首选。地位好，价格实惠，味道确实不错&lt;br&gt;。招牌菜首推香辣鱼片。在南院这道菜人气不可谓不旺，名气不可谓不大。在每年全省的&lt;br&gt;艺术类考生联考的时期是地下餐厅生意最火暴的时刻。其络绎不绝的客流量令其他餐厅黯&lt;br&gt;然失色，每天在店外摆放恰完的饭钵子的壮观场景可谓南院一绝。&lt;/p&gt;
&lt;p&gt;（2）佐粮餐厅&lt;/p&gt;
&lt;p&gt;餐厅消费群以老师为主，招牌菜为老师们津津乐道的牛排火锅。但最近的人气明显下&lt;br&gt;降，主要原因是菜的味道大不如前，食客骤减。佐粮大势已去。&lt;/p&gt;
&lt;p&gt;（3）香满楼&lt;/p&gt;
&lt;p&gt;论资历，远不如先前两位。但香满楼的生意蒸蒸日上是不争的事实。其主打菜为雨花&lt;br&gt;石油爆里脊肉。味道鲜美，又给人无尽的新鲜感！但香满楼的上菜速度雀湿影响食客的心&lt;br&gt;情与食欲。&lt;/p&gt;
&lt;p&gt;3、计专&lt;/p&gt;
&lt;p&gt;花江狗肉店不错，但是环境急需改善&lt;/p&gt;
&lt;p&gt;口味虾、不怕辣口味虾、怕不辣口味虾子相隔不远，都是恰口味虾不错的选择。味道&lt;br&gt;难分上下。&lt;/p&gt;
&lt;p&gt;4、补充&lt;/p&gt;
&lt;p&gt;还要补充一个地方，在河西银洲附近，好像附近还有一个公园，有一家饭店，很有特&lt;br&gt;色，叫“问客杀鸡”，价钱不贵，是主要是有自己的特色。清一色的竹凳，竹桌，墙上贴&lt;br&gt;满大字报样的海报，标语很有创意。&lt;/p&gt;
&lt;h3 id=&quot;补充几点&quot;&gt;&lt;a href=&quot;#补充几点&quot; class=&quot;headerlink&quot; title=&quot;补充几点&quot;&gt;&lt;/a&gt;补充几点&lt;/h3&gt;&lt;p&gt;1、无名巷子进去第三家叫做东南阁，味道比无名要好，而且也比无名便宜，强力推荐&lt;br&gt;！名菜是：蒸蛋，手撕包菜，老干妈炒肚丝。。。。&lt;/p&gt;
&lt;p&gt;2、三角花园巷子里有一家粉店，叫做强哥粉店，比一家粉店的米粉好呷得多，肉丝粉&lt;br&gt;还只要两块，我以前晚上常常去呷，只是环境冒得一家的好。&lt;/p&gt;
&lt;p&gt;人民路与曙光路交叉的口子上有一家叫做味思令的粉店味道也不错。&lt;/p&gt;
&lt;p&gt;无名巷子进去十米有家叫做周记粉店的，每天只早上开门，味道比无名的还好，好多&lt;br&gt;人走好远去呷！&lt;/p&gt;
&lt;p&gt;3、烧烤做得不错的还有朝阳路里面有好多家，劳动广场的岳阳三毛烧烤，还有二马路&lt;br&gt;。&lt;/p&gt;
&lt;p&gt;4、广济桥下面呷佛跳墙的叫做三鸣，价钱是不便宜，但是要呷高档的也只有咯扎价，&lt;br&gt;冒得办法。如果想呷便宜的，可以去试试万代后面的福满楼的狮子头，味道不错也便宜，&lt;br&gt;绝对划算。&lt;/p&gt;
&lt;p&gt;5、华南有名的是凉面，要呷煲仔饭的话，切记要去解放东路中国城对面的煲仔堡，味&lt;br&gt;道绝对一流，只是价钱比其他地方稍高，不过还是值得！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的臭干子： 沙子塘一带游走的三轮（起码有10几年的历史！几乎东塘这&lt;br&gt;边的所有小孩子都是吃他的臭干子长大的！对了，146公共汽车的终点站有个炸臭干子的，&lt;br&gt;味道也不错。）劳动广场一站也有个，每天晚上限量销售的，我一直都没有去试过。不知&lt;br&gt;道为什么，对那里印象不好。关于14中巷子里面的下岗牌臭干子越来越有名了，而且他们&lt;br&gt;范围也还大，不单单是14中大概一直到23中，13中之间的大范围都有耳闻了~呵不用排队哦&lt;br&gt;，只是看碰~~卖臭干子的嗓子好有力度~：）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的糖油油粑粑：李公庙（另外还有好多家都不错：万代后面的一家，南&lt;br&gt;阳街里面的。。。。。。。）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的红薯粑粑：水絮塘（是一个老公公炸的，这个还分季节，只有深冬季&lt;br&gt;节的时候才有恰！而且只有10点以后到2点左右！这个老公公一到这个时候就把摊子摆在自&lt;br&gt;己的水果店的前面，身穿很厚的大棉袄，经常炸着炸着睡着了！但是买他的粑粑几乎每天&lt;br&gt;排队！炸出来一个卖掉一个！呵呵）我突然想起可能很多人不知道这个水絮塘在什么地方&lt;br&gt;OK ：在定王台的东成大酒店 正大门的马路对面！&lt;br&gt;对了 长沙市最好恰的炸红薯粑粑 我今天已经看见那个老头已经摆摊出来答 ~ 哈哈&lt;br&gt;他果然还是一身棉袄 睡着在那里了~ 但是今天没有红薯粑粑 我今天仔细看了门牌是：白&lt;br&gt;沙路，35号&lt;/p&gt;
&lt;p&gt;长沙市最好恰的葱油粑粑：沙子塘的一个菜市场里面当街是韶山路，每天早上生意都&lt;br&gt;很不错！（但是老板有个毛病，你不申请的时候，炸得味道都很淡，喜欢吃味道重点的朋&lt;br&gt;友一定要申请老板加一点盐！）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的粉：浏正街的无名（当然我还是很支持旁边的四盛园也是很不错的，&lt;br&gt;但是现在越来越不行了。至于其他的杨欲兴，黄春和什么的就不用我去多费口舌了）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的脚饼：146终点站那边蒋家垄的菜场有个脚饼不错！（ 其实现在很多&lt;br&gt;地方都做得可以，但是都不如从前了~ 呵呵）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炸香蕉：文庙坪 这个地方在里面里面的巷子 很难找~ 呵呵 耐心一点&lt;br&gt;一定可以找到！！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的堡仔饭：地质学校正对面的百姓 我主推 然后旁边大概50米内也有一&lt;br&gt;家，虽然环境没有百姓好，但是听说味道超过百姓 HOHO 以后一定要去试试。 然后赤岗冲&lt;br&gt;稻田中学那边有一家堡仔饭也是非常不错的，老板也特别客气~ 呵呵~ 今天听说一中对面&lt;br&gt;也有一家好吃的，有空一定要去尝尝到底味道怎么样！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的噶吗（青蛙）：也是在水絮塘那边，叫“四满” 里面还有别人送的打&lt;br&gt;油诗，好长，压韵有味 一定要认准四满~&lt;/p&gt;
&lt;p&gt;长沙市最好恰的口味虾：河西渔湾市 什么胖子 名字我忘记了，因为这个地方也是需&lt;br&gt;要碰运气的，第一次去吃的时候狂好吃，虾子里面的油水都不能说是油水了，完全是酱的&lt;br&gt;样子了！！狂好吃~哇哈哈～～～～～～～但是后来去吃虽然也好吃，但是始终都没有那种&lt;br&gt;“酱”的感觉了！  至于南门口的东西，本人特别反感！ “最近虾子好多小的，吃起来不&lt;br&gt;新鲜又没有味道，大家为了口服和环境，应该都反对吃小虾子！”&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炒货瓜子：劳动广场的  傻子瓜子！    哈哈  好久没有去光顾了～&lt;br&gt;我是那里的忠实顾客！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炒板栗：天星的板栗～  街上很多分店    但是经常有假的！唉，本&lt;br&gt;人遗憾的就是一直都没有找到比较正宗的卖得很火的板栗店！要是说上海，我到是知道在&lt;br&gt;什么地方有  ～～&lt;/p&gt;
&lt;p&gt;长沙市最好恰的烧烤：不用说，肯定是沙子塘的烧烤，干锅一条街～～  又便宜，又&lt;br&gt;够味ＨＯＨＯ不要跟我抢位置！！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炒蚕豆：荷花池（１３中门口）  虽然曾经出过不好的负面新闻，但&lt;br&gt;是确实是最好恰的～～&lt;/p&gt;
&lt;p&gt;长沙市最好恰的鱼火锅：长沙锅炉厂那边的一个什么什么什么店子  呵呵  现在想不&lt;br&gt;起来了  我没去吃过  别人说的    知道后马上更改上来！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的麻拉烫：燕山街里面的ＧＯＯＤ  ！  还有就是窑岭的一个益阳麻拉&lt;br&gt;烫  ～虽然没有真－正益阳市步行街里面的那家好吃，但是也是很不错的 哈哈。。。&lt;/p&gt;
&lt;p&gt;长沙最好恰的麻花：浏正街16中附近的一家，也是N多年历史答！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的馄饨：其实曾经长沙最好恰的馄饨是沙子塘老菜场的一个每天从梨子&lt;br&gt;山那里挑着担子的人弄的好吃，现在都不曾找到过那样好吃的了，只有沙子塘口子往烧烤&lt;br&gt;街走进去有一家馄饨店味道还不错~ 现在又发现下河街口子上的一个天津馄饨狂好恰，肉&lt;br&gt;好新鲜，而且口干跟长沙本地的完全不同！ 一定要去TRY TRY！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的二号烧烤店：在省体委那边！ 很多人印象说那里已经拆了，其实野火&lt;br&gt;烧不尽，春风吹又生。 还是有很多，甚至又有新开的店子，味道也是不错的。然后本人推&lt;br&gt;荐烤鸡肉几好恰的~~但是本人还是主推沙子塘的，呵呵&lt;/p&gt;
&lt;p&gt;长沙市最好恰的清凉脯：金满地。&lt;/p&gt;
&lt;p&gt;长沙市最好恰的汤圆，步行街靠近司门口这边的一家，只有元宵节才有吃！ 15块钱一&lt;br&gt;脸盆！ 哈哈&lt;/p&gt;
&lt;p&gt;长沙市最好恰的酸辣粉：步行街司门口那里往里面数第二家！（是曾经在外面的那家&lt;br&gt;，后来搬到里面去了，环境不错，还有位置坐，而且还有热的巧克力汁饮料！）&lt;/p&gt;
&lt;p&gt;长沙市最好恰又实惠的大排挡：桂林米粉~ ：） 这个不用我多介绍把？ 而且里面的&lt;br&gt;服务峦的服务态度非常好！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的小笼：还没找到。 上海的我就知道！ 这边的普遍都是很假的！ 真-&lt;br&gt;正的小笼包子，皮是非常非常薄的，象饺子一样，而且吃的时候，口感很耐嚼，一口下去&lt;br&gt;，一定会流出油水出来。。。。。哇 好吃！！！ 长沙的还没找到正宗的！ 555555 如果&lt;br&gt;有谁知道正宗的 请一定发帖子好吗？？&lt;/p&gt;
&lt;p&gt;长沙市最好恰的卤味：中山路上有个叔叔年纪的人整天提着个小木箱子，走遍所有的&lt;br&gt;服装门面，问别个要卤味拨，他只有4样：鸭脖子，鸭肚片，鸡腿和和鸡翅。。 另外曾经&lt;br&gt;的老照壁也有个老爷爷的卤味好吃！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的冰正绿豆沙，冰正酸梅汤，鸡汁香干：华南小吃！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的花生）：无名附近 往省人民医院那进来的口子第一家炒货&lt;/p&gt;
&lt;p&gt;长沙市最好恰的海鲜：建湘路上面的好世界（太贵了） 如果要便宜的去遥岭的盛记海&lt;br&gt;鲜&lt;/p&gt;
&lt;p&gt;长沙最好恰的炒粉：得知在长沙理工大学后街里面~ 大家一起去找出来啊~ 哈哈~3块&lt;br&gt;钱一份，好多把多 哇哈哈~~~虽然别个不喜欢，但是我还是一直喜欢中山亭网吧里面的炒&lt;br&gt;粉，好恰~嘿嘿&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炸土豆：司门口的天津小吃店下面有个小门面，炸土豆的生意很火，&lt;br&gt;哈哈~~&lt;/p&gt;
&lt;p&gt;长沙最好恰的熟食：玫瑰肉干！！！！！！！！！！！！！步步为赢的素牛肉~~好恰&lt;br&gt;，N久以前吃的，后来就找不到了，现在又出现了哈哈！口服口服&lt;/p&gt;
&lt;p&gt;长沙最好恰的方便面：1块8一盒的康师傅红烧牛肉面！（是最小盒子的那种 卖得非常&lt;br&gt;好！！超市经常脱销~ 哈哈~ 就是这个味道的脱销！！！）&lt;/p&gt;
&lt;p&gt;长沙市最好恰的火锅：财经学院一条线火锅！ 再就是四方平的火锅OK。哇哈哈&lt;/p&gt;
&lt;p&gt;长沙市最好恰的蒸菜：南阳街一条&lt;/p&gt;
&lt;p&gt;长沙市最好恰的炒意大利粉 ：黑椒牛肉炒意大利粉 蒙娜丽莎和新怡园KTV&lt;/p&gt;
&lt;p&gt;长沙市最好恰的奶昔：麦当劳还有马里奥&lt;/p&gt;
&lt;p&gt;长沙最好恰的热巧克力：KFC和麦当劳 冰巧克力是桂林米粉的不错！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的鸡翅：必胜客，KFC的烤翅本人最喜欢~~&lt;/p&gt;
&lt;p&gt;长沙最好恰的卡布奇诺咖啡冰沙：名典&lt;/p&gt;
&lt;p&gt;长沙最好恰的爱尔兰咖啡：花时间&lt;/p&gt;
&lt;p&gt;长沙最好恰的水饺：省体委&lt;/p&gt;
&lt;p&gt;长沙最好恰的咖啡：通城商业广场下面很著名的连锁—-真锅 但是很贵！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的凉面：华南小吃！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的辣椒炒肉，手撕包菜：明盛 在南阳街里面进去的一个饭店！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的卤肉饭：曾经的塔客堡，和现在还有的台北豆浆&lt;/p&gt;
&lt;p&gt;长沙市最好恰的豆浆：台北豆浆拉~~哈哈 加蛋 我喜欢！&lt;/p&gt;
&lt;p&gt;长沙最好恰的刨冰：米雪儿，罗莎&lt;/p&gt;
&lt;p&gt;长沙市最好恰的鸭架子和便宜的粉：沙子塘烧烤街那里！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的鸭舌子：金色年华，中山亭附近~&lt;/p&gt;
&lt;p&gt;长沙市同样好恰的饭店：昱龙，金色年华的隔壁巷子进去！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的刀削面：新华楼 不用说拉~ 哈哈~老店！&lt;/p&gt;
&lt;p&gt;长沙市最好恰的蛋桶冰淇淋：小神童 哇哈哈~ 我喜欢~~很少有店子有买！如果有长期&lt;br&gt;供应的点 一定要告诉我们！ 我记得沙子塘那里有个专卖店 哈哈 好幸福~&lt;/p&gt;
&lt;p&gt;长沙市最好恰的牛排：绿茵阁，金牛角&lt;/p&gt;
&lt;p&gt;长沙比较实惠的牛排：现在的城市英雄隔壁的：皇室牛排 价格便宜，而且还可以免费&lt;br&gt;吃一些自助，是吃牛排很实惠的选择，味道还可以~&lt;/p&gt;
&lt;p&gt;长沙市最好恰的贡丸：自从塔客堡西园店的改版后，我们就不再有这样的口福吃了！&lt;/p&gt;
&lt;p&gt;在省移动指挥中心旁的鸿翔大厦后面的小巷子里&lt;br&gt;罐子老店 先锋厅 才鱼抱蛋&lt;/p&gt;
&lt;p&gt;粉：织机街夏记的粉&lt;br&gt;牛肉串—-下河街 ~~ 这个到是知道 就是辣得够味咯~~ HOHO&lt;br&gt;药王街西安凉皮&lt;br&gt;八一路百胜旁的塔客堡里卤肉饭和贡丸（虽然没有很久，由于本人在那里工作过，作&lt;br&gt;为经典怀念版同样也记录上来了~）&lt;br&gt;步行街小雅咖啡里的肉酱意粉&lt;br&gt;南门口正粤粥铺的口味泥蛙堡&lt;br&gt;长沙电脑城旁 鳝鱼炒豆子&lt;br&gt;农 大 滴 食 堂 好 恰 （用钱还是用菜票咯？ 进大门要证件不？？晕）&lt;br&gt;最好的鱼 在往肿瘤医院（银洲）去的路上有一家叫“问客杀鸡”的店的九龙全鱼&lt;br&gt;民主西街靠营盘街附近有个做包子的 （不知道跟北方小笼包有没有一比~不过老德元&lt;br&gt;的包子倒是油和肉是绝味，现在完全不同了~人非物也非哟~~）&lt;br&gt;农大的草莓~（等到成熟的时候 农大的兄弟姐妹们多多留点给我们也去踩摘啊~）&lt;br&gt;最好恰滴奶茶是六中门口那里滴极品茉艿 小杯3块 大杯5块 好恰又实惠 好卫生 白色&lt;br&gt;透明滴椰果 荧光PINK滴珍珠&lt;/p&gt;
&lt;p&gt;有不对之处，敬请指正！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;转自: &lt;a href=&quot;http://cs.voc.com.cn/thread-102396-1-3.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;长沙美食地图&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;转者说&quot;&gt;&lt;a href=&quot;#转者说&quot; class
    
    </summary>
    
      <category term="成长之路 | Biography" scheme="http://whatbeg.com/categories/%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF-Biography/"/>
    
    
      <category term="吃喝玩乐" scheme="http://whatbeg.com/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
  </entry>
  
</feed>
